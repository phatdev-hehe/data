TITLE: Extending AutoGPT Agent with Custom Component in Python
DESCRIPTION: This snippet demonstrates how to create a custom agent class by extending the main AutoGPT `Agent` class. It shows how to call the parent constructor (`super().__init__`) to inherit default components and logic, and then add a new custom component (`MyComponent`) to the agent instance. The custom agent requires initialization parameters like settings, LLM provider, file storage, and app configuration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/agents.md#_snippet_0

LANGUAGE: python
CODE:
```
class MyComponent(AgentComponent):
    pass

class MyAgent(Agent):
    def __init__(
        self,
        settings: AgentSettings,
        llm_provider: MultiProvider
        file_storage: FileStorage,
        app_config: AppConfig,
    ):
        # Call the parent constructor to bring in the default components
        super().__init__(settings, llm_provider, file_storage, app_config)
        # Add your custom component
        self.my_component = MyComponent()
```

----------------------------------------

TITLE: Defining Custom Webpage Fetching Ability - Python
DESCRIPTION: Defines a custom ability `fetch_webpage` using the `@action` decorator, requiring the `requests` library. It fetches content from a URL parameter and returns it as a string, demonstrating how to create custom agent actions.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_11

LANGUAGE: Python
CODE:
```
import requests

@action(
  name="fetch_webpage",
  description="Retrieve the content of a webpage",
  parameters=[
      {
          "name": "url",
          "description": "Webpage URL",
          "type": "string",
          "required": True,
      }
  ],
  output_type="string",
)
async def fetch_webpage(agent, task_id: str, url: str) -> str:
  response = requests.get(url)
  return response.text
```

----------------------------------------

TITLE: Full GitHub Webhooks Manager Example - Python
DESCRIPTION: This snippet shows a full implementation of a `BaseWebhooksManager` for GitHub. It includes the concrete logic for subscribing to and unsubscribing from GitHub webhooks via their API, processing incoming GitHub payloads (including signature validation), listing supported events, and providing the credentials schema.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_21

LANGUAGE: python
CODE:
```
# Example taken from autogpt_platform/backend/backend/integrations/webhooks/github.py
# This snippet represents the full GitHub Webhooks Manager implementation

import hmac
import hashlib
import json
from typing import Any, Dict, List, Tuple

# Assuming imports for BaseWebhooksManager and requests utility
from autogpt_platform.backend.backend.integrations.webhooks._base import BaseWebhooksManager
from autogpt_platform.backend.backend.util.request import requests # Secure requests wrapper

class GitHubWebhooksManager(BaseWebhooksManager):
    provider = "github"
    BASE_URL = "https://api.github.com"

    # Credentials schema definition using Pydantic model schema()
    # Assuming Pydantic model defined elsewhere, e.g., GitHubCredentials(BaseModel): token: str
    def get_credentials_schema(self) -> Dict[str, Any]:
        # Placeholder: In reality, this would return the schema dict
        return {
            "type": "object",
            "properties": {
                "token": {"type": "string", "title": "GitHub Token"}
            },
            "required": ["token"]
        }

    async def subscribe(
        self,
        webhook_id: str,
        callback_url: str,
        events: List[str],
        credentials: Dict[str, Any] | None,
    ) -> None:
        # Implementation to create a webhook via GitHub API
        # Requires 'token' from credentials
        token = credentials.get("token") if credentials else None
        if not token:
             raise ValueError("GitHub token is required for subscribing.")

        headers = {"Authorization": f"token {token}", "Accept": "application/vnd.github.v3+json"}
        payload = {
            "name": "web",
            "active": True,
            "events": events,
            "config": {
                "url": callback_url,
                "content_type": "json"
                # Optionally add 'secret' here for security
            }
        }
        # Example API call (needs organization/repo context, simplified here)
        # response = await requests.post(f"{self.BASE_URL}/repos/YOUR_ORG/YOUR_REPO/hooks", headers=headers, json=payload)
        # response.raise_for_status()
        print(f"[Simulated] Subscribed GitHub webhook {webhook_id} to {callback_url} for events: {events}")

    async def unsubscribe(
        self,
        webhook_id: str,
        credentials: Dict[str, Any] | None,
    ) -> None:
        # Implementation to delete a webhook via GitHub API
        # Requires 'token' from credentials and the webhook ID from GitHub
        print(f"[Simulated] Unsubscribed GitHub webhook {webhook_id}")
        # Real implementation would make an API call like:
        # token = credentials.get("token") if credentials else None
        # headers = {"Authorization": f"token {token}"}
        # response = await requests.delete(f"{self.BASE_URL}/repos/YOUR_ORG/YOUR_REPO/hooks/GITHUB_HOOK_ID", headers=headers)
        # response.raise_for_status()

    async def process_webhook(
        self,
        webhook_id: str,
        headers: Dict[str, str],
        payload: Dict[str, Any] | bytes,
        credentials: Dict[str, Any] | None,
    ) -> Tuple[str, Dict[str, Any]]:
        # Implementation to validate signature and return event name and parsed payload
        # Assumes a 'secret' was set during subscription and is available via credentials/config
        # secret = credentials.get("webhook_secret") if credentials else None # Example: Retrieve secret

        # Basic validation (more rigorous signature validation required for real use)
        github_event = headers.get("X-GitHub-Event")
        if not github_event:
             raise ValueError("Missing X-GitHub-Event header")

        # If a secret is used, validate signature:
        # signature = headers.get("X-Hub-Signature-256")
        # if signature and secret:
        #     expected_signature = "sha256=" + hmac.new(secret.encode('utf-8'), payload, hashlib.sha256).hexdigest()
        #     if not hmac.compare_digest(expected_signature, signature):
        #         raise ValueError("Webhook signature validation failed")

        if isinstance(payload, bytes):
            payload = json.loads(payload.decode('utf-8'))

        # Return the event type and the parsed payload
        return github_event, payload

    async def list_supported_events(self, credentials: Dict[str, Any] | None) -> List[str]:
        # Placeholder: In reality, this would list supported events dynamically or from a static list
        return ["pull_request", "push", "issues", "star"] # Example supported events

```

----------------------------------------

TITLE: Defining and Registering Basic Agent Components in Python
DESCRIPTION: This Python snippet demonstrates how to define simple Agent Components by inheriting from `AgentComponent` and how they are automatically discovered by the `BaseAgent` when assigned as attributes within the agent's `__init__` method. It also shows how one component can accept another component instance as a dependency.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_0

LANGUAGE: Python
CODE:
```
from forge.agent import BaseAgent
from forge.agent.components import AgentComponent

class HelloComponent(AgentComponent):
    pass

class SomeComponent(AgentComponent):
    def __init__(self, hello_component: HelloComponent):
        self.hello_component = hello_component

class MyAgent(BaseAgent):
    def __init__(self):
        # These components will be automatically discovered and used
        self.hello_component = HelloComponent()
        # We pass HelloComponent to SomeComponent
        self.some_component = SomeComponent(self.hello_component)
```

----------------------------------------

TITLE: Defining Pydantic Model Fields for Sensitive Data in Python
DESCRIPTION: This Python snippet demonstrates how to define sensitive configuration fields in a Pydantic `BaseModel` using `SecretStr` and `UserConfigurable`. `SecretStr` masks the value during serialization, and `UserConfigurable(from_env="ENV_VAR_NAME", exclude=True)` allows loading the value from a specified environment variable while excluding it from standard model serialization.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_2

LANGUAGE: Python
CODE:
```
from pydantic import BaseModel, SecretStr
from forge.models.config import UserConfigurable

class SensitiveConfig(BaseModel):
    api_key: SecretStr = UserConfigurable(from_env="API_KEY", exclude=True)
```

----------------------------------------

TITLE: Defining Task Step Prompt Template (Jinja2)
DESCRIPTION: This Jinja2 template defines the structure of the "task-step" prompt used by the PromptEngine. It extends an `expert.j2` base template and uses blocks to insert specific content. It includes sections for the task description, constraints, resources, abilities (listed twice), and best practices, dynamically populating them using Jinja2 variables and loops.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_6

LANGUAGE: jinja
CODE:
```
{% extends "techniques/expert.j2" %}
{% block expert %}Planner{% endblock %}
{% block prompt %}
Your task is:

{{ task }}

Ensure to respond in the given format. Always make autonomous decisions, devoid of user guidance. Harness the power of your LLM, opting for straightforward tactics sans any legal entanglements.
{% if constraints %}
## Constraints
Operate under these confines:
{% for constraint in constraints %}
- {{ constraint }}
{% endfor %}
{% endif %}
{% if resources %}
## Resources
Utilize these resources:
{% for resource in resources %}
- {{ resource }}
{% endfor %}
{% endif %}
{% if abilities %}
## Abilities
Summon these abilities:
{% for ability in abilities %}
- {{ ability }}
{% endfor %}
{% endif %}

{% if abilities %}
## Abilities
Use these abilities:
{% for ability in abilities %}
- {{ ability }}
{% endfor %}
{% endif %}

{% if best_practices %}
## Best Practices
{% for best_practice in best_practices %}
- {{ best_practice }}
{% endfor %}
{% endif %}
{% endblock %}
```

----------------------------------------

TITLE: Full Agent Execute Step Function - Python
DESCRIPTION: Implements the core `execute_step` logic for the agent, orchestrating task retrieval, step creation, prompt generation, LLM communication with error handling, ability extraction and execution, and setting the final step output. This function encapsulates the agent's decision-making and action loop for a single step.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_15

LANGUAGE: Python
CODE:
```
async def execute_step(self, task_id: str, step_request: StepRequestBody) -> Step:
    # Firstly we get the task this step is for so we can access the task input
    task = await self.db.get_task(task_id)

    # Create a new step in the database
    step = await self.db.create_step(
        task_id=task_id, input=step_request, is_last=True
    )

    # Log the message
    LOG.info(f"\tâœ… Final Step completed: {step.step_id} input: {step.input[:19]}")

    # Initialize the PromptEngine with the "gpt-3.5-turbo" model
    prompt_engine = PromptEngine("gpt-3.5-turbo")

    # Load the system and task prompts
    system_prompt = prompt_engine.load_prompt("system-format")

    # Initialize the messages list with the system prompt
    messages = [
        {"role": "system", "content": system_prompt},
    ]
    # Define the task parameters
    task_kwargs = {
        "task": task.input,
        "abilities": self.abilities.list_abilities_for_prompt(),
    }

    # Load the task prompt with the defined task parameters
    task_prompt = prompt_engine.load_prompt("task-step", **task_kwargs)

    # Append the task prompt to the messages list
    messages.append({"role": "user", "content": task_prompt})

    try:
        # Define the parameters for the chat completion request
        chat_completion_kwargs = {
            "messages": messages,
            "model": "gpt-3.5-turbo",
        }
        # Make the chat completion request and parse the response
        chat_response = await chat_completion_request(**chat_completion_kwargs)
        answer = json.loads(chat_response.choices[0].message.content)

        # Log the answer for debugging purposes
        LOG.info(pprint.pformat(answer))

    except json.JSONDecodeError as e:
        # Handle JSON decoding errors
        LOG.error(f"Unable to decode chat response: {chat_response}")
    except Exception as e:
        # Handle other exceptions
        LOG.error(f"Unable to generate chat response: {e}")

    # Extract the ability from the answer
    ability = answer["ability"]

    # Run the ability and get the output
    # We don't actually use the output in this example
    output = await self.abilities.run_action(
        task_id, ability["name"], **ability["args"]
    )

    # Set the step output to the "speak" part of the answer
    step.output = answer["thoughts"]["speak"]

    # Return the completed step
    return step
```

----------------------------------------

TITLE: Creating LLM Prompt Messages - Python
DESCRIPTION: Initializes a list of messages for an LLM chat completion request, including system and user prompts. This list follows the standard format required by many chat-based LLM APIs.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_7

LANGUAGE: Python
CODE:
```
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": task_prompt}
]
```

----------------------------------------

TITLE: Configuring Docker Compose Volumes for Data Persistence YAML
DESCRIPTION: Demonstrates how to add named volume configurations to the 'docker-compose.yml' file for PostgreSQL and Redis services. Volumes ensure that data stored by these services persists across container restarts or removals.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_19

LANGUAGE: YAML
CODE:
```
services:
  postgres:
    # ... other configurations ...
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    # ... other configurations ...
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

----------------------------------------

TITLE: Defining Agent Components and Dependencies (Python)
DESCRIPTION: Illustrates how to define custom components by inheriting `AgentComponent`. Shows how agents automatically discover components assigned to `self` during initialization and how to inject dependencies between components via the constructor.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/components/README.md#_snippet_0

LANGUAGE: python
CODE:
```
from forge.agent import BaseAgent
from forge.agent.components import AgentComponent

class HelloComponent(AgentComponent):
    pass

class SomeComponent(AgentComponent):
    def __init__(self, hello_component: HelloComponent):
        self.hello_component = hello_component

class MyAgent(BaseAgent):
    def __init__(self):
        # These components will be automatically discovered and used
        self.hello_component = HelloComponent()
        # We pass HelloComponent to SomeComponent
        self.some_component = SomeComponent(self.hello_component)
```

----------------------------------------

TITLE: Loading Simple Prompt Template with PromptEngine (Python)
DESCRIPTION: This code snippet demonstrates how to load a basic prompt template using the `PromptEngine`. It calls the `load_prompt` method with the name of the template ("system-format"), which retrieves and processes the corresponding template file, returning the final prompt string.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_4

LANGUAGE: python
CODE:
```
system_prompt = prompt_engine.load_prompt("system-format")
```

----------------------------------------

TITLE: Starting AutoGPT Agent
DESCRIPTION: Executes the run script to start the specified AutoGPT agent. This command typically launches the agent and its associated frontend/tasking server, usually on localhost:8000.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/001_getting_started.md#_snippet_3

LANGUAGE: bash
CODE:
```
./run agent start YOUR_AGENT_NAME
```

----------------------------------------

TITLE: Starting AutoGPT Agent via Command Line - Bash
DESCRIPTION: This command executes the AutoGPT agent with the specified name 'SmartAgent'. It is the initial step required to get the agent running and make it accessible via the UI and command line interaction. Prerequisites include having the AutoGPT project set up and the './run' script available and executable.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_16

LANGUAGE: bash
CODE:
```
./run agent start SmartAgent.
```

----------------------------------------

TITLE: Cloning AutoGPT Forge Repository
DESCRIPTION: Clones the user's newly forked AutoGPT repository from GitHub to the local system using the Git command-line tool. Requires Git to be installed and the URL of the forked repository.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/001_getting_started.md#_snippet_0

LANGUAGE: bash
CODE:
```
# replace the url with the one for your forked repo
git clone https://github.com/<YOUR REPO PATH HERE>
```

----------------------------------------

TITLE: Executing Agent Ability using Action Register - Python
DESCRIPTION: Calls the `run_action` method on the agent's ability register to execute the ability specified in the LLM's response. It uses the `task_id`, ability name, and extracted arguments to invoke the correct action function.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_13

LANGUAGE: Python
CODE:
```
# Run the ability and get the output
# We don't actually use the output in this example
output = await self.abilities.run_action(
    task_id, ability["name"], **ability["args"]
)
```

----------------------------------------

TITLE: Accessing API Key Credentials in Block Run Method Python
DESCRIPTION: Illustrates how to define the `run` method to accept `APIKeyCredentials` via the `credentials` keyword argument. This allows the block's logic to access the provided API key for making authenticated calls.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_9

LANGUAGE: python
CODE:
```
    # ...

    def run(
        self,
        input_data: Input,
        *,
        credentials: APIKeyCredentials,
        **kwargs,
    ) -> BlockOutput:
        ...
```

----------------------------------------

TITLE: Raising ComponentEndpointError in AutoGPT Component (Python)
DESCRIPTION: This example demonstrates how to raise a `ComponentEndpointError` within an agent component method (`get_messages`) that implements the `MessageProvider` protocol. Raising this specific error signals a failure within a single endpoint, prompting the agent to retry the execution of that endpoint for the component. Dependencies include importing `ComponentEndpointError` from `forge.agent.components` and `MessageProvider` from `forge.agent.protocols`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/components/README.md#_snippet_5

LANGUAGE: python
CODE:
```
from forge.agent.components import ComponentEndpointError
from forge.agent.protocols import MessageProvider

# Example of raising an error
class MyComponent(MessageProvider):
    def get_messages(self) -> Iterator[ChatMessage]:
        # This will cause the component to always fail 
        # and retry 3 times before re-raising the exception
        raise ComponentEndpointError("Endpoint error!")
```

----------------------------------------

TITLE: Running Project Setup (Shell)
DESCRIPTION: Initiates the project setup process by running the `setup` command, which installs necessary dependencies for your system.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_2

LANGUAGE: sh
CODE:
```
./run setup
```

----------------------------------------

TITLE: Installing Dependencies with Poetry Shell
DESCRIPTION: Runs the `poetry install` command to download and install all required Python dependencies specified in the project's `pyproject.toml` file. This command should be executed in the project's root directory.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_1

LANGUAGE: Shell
CODE:
```
poetry install
```

----------------------------------------

TITLE: Defining Input and Output Schemas for Block Python
DESCRIPTION: Defines the `Input` and `Output` schemas for a block using `BlockSchema`. The `Input` schema specifies expected input fields (e.g., `topic`), and the `Output` schema defines the structure of the block's result (e.g., `summary`, `error`).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_2

LANGUAGE: python
CODE:
```
class Input(BlockSchema):
    topic: str  # The topic to get the Wikipedia summary for

class Output(BlockSchema):
    summary: str  # The summary of the topic from Wikipedia
    error: str  # Any error message if the request fails, error field needs to be named `error`.
```

----------------------------------------

TITLE: Installing Poetry Dependencies - Bash
DESCRIPTION: This command installs all project dependencies specified in the `pyproject.toml` file using Poetry within the active virtual environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_14

LANGUAGE: bash
CODE:
```
poetry install
```

----------------------------------------

TITLE: Sending Chat Completion Request and Processing Response - Python
DESCRIPTION: Sends the constructed message list to an LLM via `chat_completion_request`, expecting a JSON response. It attempts to parse the LLM's output and handles potential JSON decoding or request errors.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_8

LANGUAGE: Python
CODE:
```
try:
    # Set the parameters for the chat completion
    chat_completion_kwargs = {
        "messages": messages,
        "model": "gpt-3.5-turbo",
    }
    # Get the LLM's response and interpret it
    chat_response = await chat_completion_request(**chat_completion_kwargs)
    answer = json.loads(chat_response.choices[0].message.content)

    # Log the answer for reference
    LOG.info(pprint.pformat(answer))

except json.JSONDecodeError as e:
    # Handle JSON decoding errors
    LOG.error(f"Can't decode chat response: {chat_response}")
except Exception as e:
    # Handle other errors
    LOG.error(f"Can't get chat response: {e}")
```

----------------------------------------

TITLE: Implementing ExecutionFailure for Logging Error - Python Example
DESCRIPTION: This example demonstrates implementing the `ExecutionFailure` protocol to log errors when a command execution fails. The `execution_failure` method receives the `Exception` and uses a `logger` to record the failure details.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_9

LANGUAGE: Python
CODE:
```
class LoggerComponent(ExecutionFailure):
    def execution_failure(self, error: Exception) -> None:
        logger.error(f"Command execution failed: {error}")
```

----------------------------------------

TITLE: Install Project Dependencies with Poetry sh
DESCRIPTION: Installs all project dependencies specified in the `pyproject.toml` and locked in `poetry.lock` within the active Poetry virtual environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_9

LANGUAGE: sh
CODE:
```
poetry install
```

----------------------------------------

TITLE: Loading Parameterized Prompt Template with PromptEngine (Python)
DESCRIPTION: This snippet shows how to load a prompt template that requires dynamic data. It creates a dictionary `task_kwargs` holding the task input and a list of agent abilities. This dictionary is then unpacked (`**task_kwargs`) and passed to `load_prompt`, allowing the Jinja2 template to be rendered with the specific task details and available abilities.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_5

LANGUAGE: python
CODE:
```
# Define the task parameters
task_kwargs = {
    "task": task.input,
    "abilities": self.abilities.list_abilities_for_prompt(),
}

# Load the task prompt with those parameters
task_prompt = prompt_engine.load_prompt("task-step", **task_kwargs)
```

----------------------------------------

TITLE: Implementing Block Run Method with Error Handling Python
DESCRIPTION: Implements the core `run` method of a block, which contains the main business logic. It takes input data, performs an action (like an API call), handles potential errors using try/except, and yields results using the `yield` keyword.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_4

LANGUAGE: python
CODE:
```
def run(self, input_data: Input, **kwargs) -> BlockOutput:
    try:
        topic = input_data.topic
        url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{topic}"

        response = self.get_request(url, json=True)
        yield "summary", response['extract']

    except requests.exceptions.HTTPError as http_err:
        raise RuntimeError(f"HTTP error occurred: {http_err}")
```

----------------------------------------

TITLE: Defining AfterExecute Protocol Interface - Python
DESCRIPTION: This snippet defines the abstract `AfterExecute` protocol, an interface for `AgentComponent`s. Components implementing this protocol have their `after_execute` method called after a command initiated by the agent has been successfully executed, receiving the `ActionResult`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_10

LANGUAGE: Python
CODE:
```
class AfterExecute(AgentComponent):
    def after_execute(self, result: ActionResult) -> None:
        ...
```

----------------------------------------

TITLE: Initializing Block with Schemas, Test Data, and Mocks Python
DESCRIPTION: Implements the `__init__` method for a block, assigning the input/output schemas, providing a unique ID, defining `test_input` and `test_output` for testing, and setting up a `test_mock` for external dependencies like network requests.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_3

LANGUAGE: python
CODE:
```
def __init__(self):
    super().__init__(
        # Unique ID for the block, used across users for templates
        # If you are an AI leave it as is or change to "generate-proper-uuid"
        id="xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
        input_schema=WikipediaSummaryBlock.Input,  # Assign input schema
        output_schema=WikipediaSummaryBlock.Output,  # Assign output schema

            # Provide sample input, output and test mock for testing the block

        test_input={"topic": "Artificial Intelligence"},
        test_output=("summary", "summary content"),
        test_mock={"get_request": lambda url, json: {"extract": "summary content"}},
    )
```

----------------------------------------

TITLE: Run AutoGPT with Docker Compose (Serve Mode) - Shell
DESCRIPTION: This command runs the 'auto-gpt' service in 'serve' mode, which typically starts a server interface. The `--rm` flag removes the container upon exit.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_6

LANGUAGE: shell
CODE:
```
docker compose run --rm auto-gpt serve
```

----------------------------------------

TITLE: Launching Ollama Service (Bash)
DESCRIPTION: This command launches the Ollama server with a specific language model. If the model isn't already downloaded, Ollama will download it first. The command starts the service and keeps the terminal session active, serving the model.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/ollama.md#_snippet_0

LANGUAGE: bash
CODE:
```
ollama run llama3.2
```

----------------------------------------

TITLE: Run AutoGPT Container (Vanilla Docker) - Shell
DESCRIPTION: This command runs a container based on the 'autogpt' image in interactive TTY mode (`-it`). It mounts the current directory (`$PWD`) to `/app` inside the container and uses the `.env` file for environment variables.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_10

LANGUAGE: shell
CODE:
```
docker run -it --env-file=.env -v $PWD:/app autogpt
```

----------------------------------------

TITLE: Building Docker Compose Services Shell
DESCRIPTION: Builds or rebuilds service images based on the Dockerfiles and build contexts defined in 'docker-compose.yml'. This is necessary after making changes to the service code or configuration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_10

LANGUAGE: Shell
CODE:
```
docker compose build
```

----------------------------------------

TITLE: Defining CMake Project
DESCRIPTION: Defines the CMake project with the name 'runner' and specifies that it uses the CXX (C++) language. This sets up the basic project structure for CMake.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_1

LANGUAGE: CMake
CODE:
```
project(runner LANGUAGES CXX)
```

----------------------------------------

TITLE: Implementing Configurable Agent Components in Python
DESCRIPTION: This Python snippet shows how to create an Agent Component that accepts configuration using a Pydantic `BaseModel`. By inheriting from `ConfigurableComponent[BM]`, the component gains a `config` attribute holding the configuration instance, which can be accessed within the component's methods.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_1

LANGUAGE: Python
CODE:
```
from pydantic import BaseModel
from forge.agent.components import ConfigurableComponent

class MyConfig(BaseModel):
    some_value: str

class MyComponent(AgentComponent, ConfigurableComponent[MyConfig]):
    def __init__(self, config: MyConfig):
        super().__init__(config)
        # This has the same effect as above:
        # self.config = config

    def get_some_value(self) -> str:
        # Access the configuration like a regular model
        return self.config.some_value
```

----------------------------------------

TITLE: Handling Task Creation in AutoGPT Agent (Python)
DESCRIPTION: This function overrides the default `create_task` from the base agent class. It logs the task creation event with the task ID and input before delegating the actual task creation logic to the superclass. It serves as a hook to add custom logic during the task initialization phase.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_0

LANGUAGE: python
CODE:
```
async def create_task(self, task_request: TaskRequestBody) -> Task:
    """
    The agent protocol, which is the core of the Forge, works by creating a task and then
    executing steps for that task. This method is called when the agent is asked to create
    a task.

    We are hooking into function to add a custom log message. Though you can do anything you
    want here.
    """
    task = await super().create_task(task_request)
    LOG.info(
        f"ðŸ“¦ Task created: {task.task_id} input: {task.input[:40]}{'...' if len(task.input) > 40 else ''}"
    )
    return task
```

----------------------------------------

TITLE: Initializing PromptEngine for Specific LLM (Python)
DESCRIPTION: This line instantiates the `PromptEngine` class, passing the string "gpt-3.5-turbo" as an argument. This initializes the engine, likely loading prompts specifically tailored for or compatible with the `gpt-3.5-turbo` language model.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_3

LANGUAGE: python
CODE:
```
prompt_engine = PromptEngine("gpt-3.5-turbo")
```

----------------------------------------

TITLE: Running AutoGPT with Docker Shell
DESCRIPTION: These shell commands demonstrate how to run AutoGPT using Docker Compose. The first command runs AutoGPT with a specific AI settings file, and the second starts AutoGPT in server mode. This is the recommended usage for Docker environments.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_1

LANGUAGE: shell
CODE:
```
docker compose run --rm auto-gpt --ai-settings <filename>
docker compose run --rm auto-gpt serve
```

----------------------------------------

TITLE: Defining BLOCKED_IP_NETWORKS for SSRF Prevention - Python
DESCRIPTION: The secure requests wrapper prevents connections to specific IP address ranges commonly used for local networks or cloud provider metadata services. This list defines the blocked CIDR networks to prevent SSRF attacks targeting internal resources.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_23

LANGUAGE: python
CODE:
```
# Taken from autogpt_platform/backend/backend/util/request.py

# IP networks that are blocked for requests to prevent SSRF attacks
# Includes private IP ranges and AWS metadata IP
BLOCKED_IP_NETWORKS = [
    "10.0.0.0/8",     # Private-Use Networks
    "172.16.0.0/12",  # Private-Use Networks
    "192.168.0.0/16", # Private-Use Networks
    "127.0.0.0/8",    # Loopback
    "169.254.0.0/16", # Link-Local
    "0.0.0.0/8",      # Current network (usually used for defaults)
    "100.64.0.0/10",  # Shared Address Space
    # AWS Metadata IP (specific to AWS, common SSRF target)
    # This IP is technically link-local but often targeted
    "169.254.169.254/32" # Specific AWS metadata service endpoint
]
```

----------------------------------------

TITLE: Run All Tests using pytest (Shell)
DESCRIPTION: Executes all tests defined in the project using the pytest command-line tool. This command assumes pytest is installed and accessible in the system's PATH.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/testing.md#_snippet_0

LANGUAGE: shell
CODE:
```
pytest
```

----------------------------------------

TITLE: Example Playwright Test File (TypeScript)
DESCRIPTION: Provides a partial example of a Playwright test file (`build.spec.ts`) in TypeScript. It shows the basic structure using `test.describe`, `test.beforeEach` for setup (like login), initializing a Page Object (`buildPage`), defining a test case (`test("user can add a block")`), and using assertions (`test.expect`) to validate page state.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_7

LANGUAGE: typescript
CODE:
```
test.describe("Build Page", () => {
  let buildPage: BuildPage;

  test.beforeEach(async ({ page, loginPage, testUser }) => {
    // Login before each test
    await page.goto("/login");
    await loginPage.login(testUser.email, testUser.password);
    await test.expect(page).toHaveURL("/");
  });

  test("user can add a block", async ({ page }) => {
    // Ensure build page is loaded
    await test.expect(buildPage.isLoaded()).resolves.toBeTruthy();
    await test.expect(page).toHaveURL(new RegExp("/.*build"));

    // Close tutorial and open blocks panel
    await buildPage.closeTutorial();
    await buildPage.openBlocksPanel();

    // Add a block
    const block = { name: "Example Block" }; // Placeholder for actual block data
    await buildPage.addBlock(block);

    // Close blocks panel and verify block is added
    await buildPage.closeBlocksPanel();
    await test.expect(buildPage.hasBlock(block)).resolves.toBeTruthy();
  });
});
```

----------------------------------------

TITLE: Installing Frontend Dependencies and Starting Dev Server - Bash
DESCRIPTION: These commands install the necessary Node.js packages for the frontend using npm and then start the frontend application in development mode, typically accessible via a local server.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_8

LANGUAGE: bash
CODE:
```
npm install
npm run dev
```

----------------------------------------

TITLE: Installing and Running Frontend (Yarn) Shell
DESCRIPTION: Installs frontend dependencies using Yarn and then starts the frontend application in development mode. This provides an alternative method to the NPM commands for running the frontend.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_6

LANGUAGE: Shell
CODE:
```
yarn install && yarn dev
```

----------------------------------------

TITLE: Getting Flutter Dependencies (Flutter)
DESCRIPTION: Fetches and installs all the required Dart and Flutter packages (dependencies) specified in the 'pubspec.yaml' file located in the current directory. This step ensures that all necessary libraries and tools are available for the project to build and run correctly.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/README.md#_snippet_2

LANGUAGE: Flutter
CODE:
```
flutter pub get
```

----------------------------------------

TITLE: Using Credential Auth Header Shortcut for API Calls (Python)
DESCRIPTION: Illustrates the use of the convenient `credentials.auth_header()` method available on credential objects. This method simplifies adding authentication to API requests by automatically retrieving the correct token type (API key or access token) and formatting the appropriate `Authorization` header.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_12

LANGUAGE: python
CODE:
```
# credentials: APIKeyCredentials | OAuth2Credentials
response = requests.post(
    url,
    headers={"Authorization": credentials.auth_header()},
)
```

----------------------------------------

TITLE: Defining AutoGPT Command with Decorator - Python
DESCRIPTION: Shows how to use the `@command` decorator to turn a class method into an agent command. It configures the command's parameters, including their type (`INTEGER`), description, and whether they are required, using `JSONSchema`. The method `multiply` performs the calculation and returns the result as a string.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/commands.md#_snippet_1

LANGUAGE: python
CODE:
```
@command(
    parameters={
        "a": JSONSchema(
            type=JSONSchema.Type.INTEGER,
            description="The first number",
            required=True,
        ),
        "b": JSONSchema(
            type=JSONSchema.Type.INTEGER,
            description="The second number",
            required=True,
        )})`
`def multiply(self, a: int, b: int) -> str:`
`    """
    Multiplies two numbers.
    
    Args:
        a: First number
        b: Second number

    Returns:
        Result of multiplication
    """
    return str(a * b)
```

----------------------------------------

TITLE: Defining AutoGPT CommandProvider Protocol - Python
DESCRIPTION: Defines the abstract base class or protocol `CommandProvider` that components must inherit or implement. It specifies the `get_commands` method, which is expected to return an iterator of `Command` objects available from the provider. This serves as the contract for components contributing commands to the agent.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/commands.md#_snippet_0

LANGUAGE: python
CODE:
```
class CommandProvider(Protocol):
    def get_commands(self) -> Iterator[Command]:
        ...
```

----------------------------------------

TITLE: Defining CommandProvider Protocol Interface - Python
DESCRIPTION: This snippet defines the abstract `CommandProvider` protocol interface. Components implementing this protocol are responsible for providing executable commands to the agent via the `get_commands` method, which should return an iterator of `Command` objects.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_2

LANGUAGE: Python
CODE:
```
class CommandProvider(AgentComponent):
    def get_commands(self) -> Iterator[Command]:
        ...
```

----------------------------------------

TITLE: Creating Configurable Agent Components (Python)
DESCRIPTION: Demonstrates how to make components configurable using a Pydantic `BaseModel`. Components must inherit `ConfigurableComponent[BM]` where `BM` is the config model type. The configuration is accessible via the `self.config` attribute.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/components/README.md#_snippet_1

LANGUAGE: python
CODE:
```
from pydantic import BaseModel
from forge.agent.components import ConfigurableComponent

class MyConfig(BaseModel):
    some_value: str

class MyComponent(AgentComponent, ConfigurableComponent[MyConfig]):
    def __init__(self, config: MyConfig):
        super().__init__(config)
        # This has the same effect as above:
        # self.config = config

    def get_some_value(self) -> str:
        # Access the configuration like a regular model
        return self.config.some_value
```

----------------------------------------

TITLE: Yielding Decorated AutoGPT Command - Python
DESCRIPTION: Demonstrates how a `CommandProvider` makes a command defined with the `@command` decorator available to the agent. The `get_commands` method yields `self.multiply`, which is the bound method decorated as a command, allowing the agent to discover and use it.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/commands.md#_snippet_3

LANGUAGE: python
CODE:
```
def get_commands(self) -> Iterator[Command]:
    yield self.multiply
```

----------------------------------------

TITLE: Including Webhook Payload Field in Input Schema - Python
DESCRIPTION: The block's input schema must include a field to receive the raw webhook payload. This field's name isn't strictly defined by `webhook_config`, but `payload` is a common convention. The payload is typically a dictionary (`Dict[str, Any]`) containing the data sent by the webhook provider.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_16

LANGUAGE: python
CODE:
```
# Example taken from autogpt_platform/backend/backend/blocks/github/triggers.py
# This code snippet shows the addition of the payload field to the input schema

from pydantic import BaseModel
from typing import Any, Dict

# Assuming necessary imports for BlockInputSchema are present

class GitHubTriggerBaseInput(BlockInputSchema):
    # Existing fields...
    payload: Dict[str, Any] # Field to receive the webhook payload
    # Other input fields...
```

----------------------------------------

TITLE: Starting AutoGPT Backend with Docker Compose (Bash)
DESCRIPTION: Navigates to the AutoGPT platform's backend directory and starts the necessary services defined in the docker-compose.yml file. The `-d` flag runs containers in detached mode (in the background), and `--build` ensures images are built or rebuilt if necessary.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/ollama.md#_snippet_1

LANGUAGE: bash
CODE:
```
cd autogpt_platform
docker compose up -d --build
```

----------------------------------------

TITLE: Starting Backend Services with Docker Compose Shell
DESCRIPTION: Starts all necessary backend services defined in the 'docker-compose.yml' file in detached mode (-d). This command brings up the backend infrastructure required for the platform.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_2

LANGUAGE: Shell
CODE:
```
docker compose up -d
```

----------------------------------------

TITLE: Full GitHub Webhook Trigger Example - Python
DESCRIPTION: This is a complete example showing the implementation of a GitHub webhook trigger block. It includes the input schema definition with event filtering and payload, the `__init__` method setting up the webhook configuration, and potentially the `run` method (though the specific linked section isn't fully shown here) for processing the payload.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_20

LANGUAGE: python
CODE:
```
# Example taken from autogpt_platform/backend/backend/blocks/github/triggers.py
# This snippet represents the full GitHub Trigger block example

from pydantic import BaseModel
from typing import Any, Dict, List

# Assuming imports for Block, BlockInputSchema, BlockWebhookConfig, BlockOutput

class GitHubEventsFilter(BaseModel):
    pull_request: bool = True
    # ... potentially other github events

class GitHubTriggerInput(BlockInputSchema):
    events: GitHubEventsFilter
    payload: Dict[str, Any]
    credentials: Dict[str, Any] # Credentials needed for manager API calls

# Output schema example
class GitHubTriggerOutput(BlockOutput):
    payload: Dict[str, Any]
    # ... other extracted fields like sender, event, number, pull_request

class GitHubPullRequestTriggerBlock(Block):
    def __init__(self):
        super().__init__(
            id="github_pull_request_trigger",
            name="GitHub Pull Request Trigger",
            description="Triggers on GitHub pull request events.",
            input_schema=GitHubTriggerInput,
            output_schema=GitHubTriggerOutput,
            webhook_config=BlockWebhookConfig(provider='github', event_filter_input='events'),
            # Optional test data
            # test_input=...,
            # test_output=...,
        )

    async def run(self, input_data: GitHubTriggerInput, **kwargs) -> BlockOutput:
        # Logic to process input_data.payload and yield results
        # Example output based on previous snippet:
        yield "payload", input_data.payload
        yield "sender", input_data.payload.get("sender")
        yield "event", input_data.payload.get("action")
        yield "number", input_data.payload.get("number")
        yield "pull_request", input_data.payload.get("pull_request")
        # Note: Real implementation might need more robust error handling and data access

```

----------------------------------------

TITLE: Setting Groq Smart LLM Env
DESCRIPTION: Sets the `SMART_LLM` environment variable in the `.env` file to specify which Groq model should be used by AutoGPT for tasks requiring higher intelligence or complexity. Replace the example model name with the desired Groq model ID.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_8

LANGUAGE: INI
CODE:
```
SMART_LLM=llama3-70b-8192
```

----------------------------------------

TITLE: Configuring OpenAI API Key Env
DESCRIPTION: Sets the `OPENAI_API_KEY` environment variable in the `.env` file with your secret OpenAI API key. This key is required to authenticate with the OpenAI API for accessing models like GPT-4 or GPT-3.5. The key should be provided directly after the equals sign without quotes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_3

LANGUAGE: INI
CODE:
```
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

----------------------------------------

TITLE: Defining File Writing Ability with Action Decorator - Python
DESCRIPTION: Defines a file writing ability function using the `@action` decorator. The decorator registers the function and specifies its name, description, required parameters (`file_path`, `data`), and return type (`None`).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_10

LANGUAGE: Python
CODE:
```
@action(
    name="write_file",
    description="Write data to a file",
    parameters=[
        {
            "name": "file_path",
            "description": "Path to the file",
            "type": "string",
            "required": True,
        },
        {
            "name": "data",
            "description": "Data to write to the file",
            "type": "bytes",
            "required": True,
        },
    ],
    output_type="None",
)
async def write_file(agent, task_id: str, file_path: str, data: bytes) -> None:
    pass
```

----------------------------------------

TITLE: Copy .env.example File for Setup sh
DESCRIPTION: Copies the example environment file (`.env.example`) to the standard `.env` file as part of the step-by-step setup process. This creates a configurable environment file for the project.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_10

LANGUAGE: sh
CODE:
```
cp .env.example .env
```

----------------------------------------

TITLE: Writing Integration Test Challenge - AutoGPT Testing - Python
DESCRIPTION: This Python function `test_information_retrieval_challenge_a` provides an example of a `pytest` integration test for an AutoGPT agent challenge. It uses a generator and `monkeypatch` to simulate user input, runs the agent's interaction loop, and then asserts that the output file (`kube.yaml`) contains specific keywords and is valid YAML, confirming the agent successfully completed the task. The test is currently skipped and requires VCR and an OpenAI API key.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/building_challenges.md#_snippet_1

LANGUAGE: python
CODE:
```
import contextlib
from functools import wraps
from typing import Generator

import pytest
import yaml

from autogpt.commands.file_operations import read_file, write_to_file
from tests.integration.agent_utils import run_interaction_loop
from tests.challenges.utils import run_multiple_times

def input_generator(input_sequence: list) -> Generator[str, None, None]:
    """
    Creates a generator that yields input strings from the given sequence.

    :param input_sequence: A list of input strings.
    :return: A generator that yields input strings.
    """
    yield from input_sequence


@pytest.mark.skip("This challenge hasn't been beaten yet.")
@pytest.mark.vcr
@pytest.mark.requires_openai_api_key
def test_information_retrieval_challenge_a(kubernetes_agent, monkeypatch) -> None:
    """
    Test the challenge_a function in a given agent by mocking user inputs
    and checking the output file content.

    :param get_company_revenue_agent: The agent to test.
    :param monkeypatch: pytest's monkeypatch utility for modifying builtins.
    """
    input_sequence = ["s", "s", "s", "s", "s", "EXIT"]
    gen = input_generator(input_sequence)
    monkeypatch.setattr("autogpt.utils.session.prompt", lambda _: next(gen))

    with contextlib.suppress(SystemExit):
        run_interaction_loop(kubernetes_agent, None)

    # here we load the output file
    file_path = str(kubernetes_agent.workspace.get_path("kube.yaml"))
    content = read_file(file_path)

    # then we check if it's including keywords from the kubernetes deployment config
    for word in ["apiVersion", "kind", "metadata", "spec"]:
        assert word in content, f"Expected the file to contain {word}"

    content = yaml.safe_load(content)
    for word in ["Service", "Deployment", "Pod"]:
        assert word in content["kind"], f"Expected the file to contain {word}"


```

----------------------------------------

TITLE: Defining Credentials Inputs for Blocks (Python)
DESCRIPTION: Shows how to define input fields for service credentials within AutoGPT blocks using `CredentialsMetaInput` and `CredentialsField`. It illustrates configurations for OAuth2-only and combined API Key/OAuth2 authentication for a provider like GitHub, including specifying required scopes and user-facing descriptions within the block's Input schema.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_10

LANGUAGE: python
CODE:
```
# OAuth:
class BlockWithOAuth(Block):
    class Input(BlockSchema):
        # Note that the type hint below is require or you will get a type error.
        # The first argument is the provider name, the second is the credential type.
        credentials: CredentialsMetaInput[
            Literal[ProviderName.GITHUB], Literal["oauth2"]
        ] = CredentialsField(
            required_scopes={"repo"},
            description="The GitHub integration can be used with OAuth.",
        )

    # ...

    def run(
        self,
        input_data: Input,
        *,
        credentials: OAuth2Credentials,
        **kwargs,
    ) -> BlockOutput:
        ...

# API Key auth + OAuth:
class BlockWithAPIKeyAndOAuth(Block):
    class Input(BlockSchema):
        # Note that the type hint below is require or you will get a type error.
        # The first argument is the provider name, the second is the credential type.
        credentials: CredentialsMetaInput[
            Literal[ProviderName.GITHUB], Literal["api_key", "oauth2"]
        ] = CredentialsField(
            required_scopes={"repo"},
            description="The GitHub integration can be used with OAuth, "
            "or any API key with sufficient permissions for the blocks it is used on.",
        )

    # ...

    def run(
        self,
        input_data: Input,
        *,
        credentials: Credentials,
        **kwargs,
    ) -> BlockOutput:
        ...
```

----------------------------------------

TITLE: Starting Backend Services with Docker Compose - Bash
DESCRIPTION: This command starts the backend services defined in the Docker Compose file. The `-d` flag runs containers in detached mode, and `--build` ensures images are built before starting.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_5

LANGUAGE: bash
CODE:
```
docker compose up -d --build
```

----------------------------------------

TITLE: Processing Webhook Payload in Block run Method - Python
DESCRIPTION: Inside the block's `run` method, access the received webhook payload from the input data. Process the payload to extract relevant information and `yield` key pieces as block output. The example demonstrates extracting various fields from a GitHub pull request payload.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_17

LANGUAGE: python
CODE:
```
def run(self, input_data: Input, **kwargs) -> BlockOutput:
    # Assuming Input has a 'payload' attribute of type Dict[str, Any]
    yield "payload", input_data.payload
    # Accessing specific fields from the payload
    yield "sender", input_data.payload["sender"]
    yield "event", input_data.payload["action"]
    yield "number", input_data.payload["number"]
    yield "pull_request", input_data.payload["pull_request"]
```

----------------------------------------

TITLE: Creating AutoGPT Agent Template
DESCRIPTION: Uses the built-in run script to generate a new agent template within the AutoGPT Forge project. Requires a unique name for the agent.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/001_getting_started.md#_snippet_2

LANGUAGE: bash
CODE:
```
./run agent create YOUR_AGENT_NAME
```

----------------------------------------

TITLE: Running Application with Docker Compose - Bash
DESCRIPTION: This command starts all services defined in the Docker Compose file, running the entire application within Docker containers.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_23

LANGUAGE: bash
CODE:
```
docker compose up
```

----------------------------------------

TITLE: Creating a New Agent (Shell)
DESCRIPTION: Uses the `agent create` command with a specified name ('my_agent' in this example) to create a new agent and switch to its newly created directory.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_4

LANGUAGE: sh
CODE:
```
./run agent create my_agent
```

----------------------------------------

TITLE: Using Secure Requests Wrapper - Python
DESCRIPTION: When a block needs to make HTTP requests, it must use the platform's secure `requests` wrapper from `backend.util.request`. This wrapper automatically enforces security measures like blocking requests to private IP ranges and validating URLs, mitigating Server-Side Request Forgery (SSRF) risks.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_22

LANGUAGE: python
CODE:
```
from backend.util.request import requests

class MyNetworkBlock(Block):
    # Assuming Input has a 'url' attribute
    def run(self, input_data: Input, **kwargs) -> BlockOutput:
        try:
            # The requests wrapper automatically validates URLs and blocks dangerous requests
            response = requests.get(input_data.url)
            # raise_for_status() is true by default in the wrapper
            yield "result", response.text
        except ValueError as e:
            # URL validation failed by the wrapper
            raise RuntimeError(f"Invalid URL provided: {e}")
        except requests.exceptions.RequestException as e:
            # Request failed for other reasons (network, http error etc.)
            raise RuntimeError(f"Request failed: {e}")
```

----------------------------------------

TITLE: Running Frontend Development Server - Bash
DESCRIPTION: These commands start the local development server for the frontend application. After running the installation command, use one of these commands to launch the application, typically accessible at http://localhost:3000.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/README.md#_snippet_1

LANGUAGE: bash
CODE:
```
npm run dev
```

LANGUAGE: bash
CODE:
```
yarn dev
```

LANGUAGE: bash
CODE:
```
pnpm dev
```

LANGUAGE: bash
CODE:
```
bun dev
```

----------------------------------------

TITLE: Sample Benchmark Challenge Data JSON
DESCRIPTION: This JSON snippet provides a concrete example of the data structure used to define a benchmark challenge. It illustrates the category, task, dependencies, ground, and info fields, demonstrating how to specify a basic file-writing task, its expected output and evaluation criteria, and additional metadata. It shows how to use the eval sub-field to define the evaluation method and its parameters.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/challenges/CHALLENGE.md#_snippet_0

LANGUAGE: json
CODE:
```
{
  "category": ["basic"],
  "task": "Print the capital of America to a .txt file",
  "dependencies": ["TestWriteFile"], 
  "ground": {
    "answer": "Washington",
    "should_contain": ["Washington"],
    "should_not_contain": ["New York", "Los Angeles", "San Francisco"],
    "files": [".txt"],
    "eval": {
      "type": "llm" or "file" or "python",
      "scoring": "percentage" or "scale" or "binary", 
      "template": "rubric" or "reference" or "custom" 
    }
  },
  "info": {
    "difficulty": "basic",
    "description": "Tests the writing to file",
    "side_effects": ["tests if there is in fact an LLM attached"]
  }
}
```

----------------------------------------

TITLE: Configuring Azure OpenAI YAML
DESCRIPTION: Defines the mapping between standard model names (like `gpt-3.5-turbo`, `gpt-4-turbo`) and their corresponding deployment IDs on your Azure OpenAI instance. This configuration is required when using AutoGPT with an Azure-hosted GPT model instead of the standard OpenAI API endpoint.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_4

LANGUAGE: YAML
CODE:
```
# Please specify all of these values as double-quoted strings
# Replace string in angled brackets (<>) to your own deployment Name
azure_model_map:
    gpt-3.5-turbo: "<gpt-35-turbo-deployment-id>"
    gpt-4-turbo: "<gpt-4-turbo-deployment-id>"
    ...
```

----------------------------------------

TITLE: Run Playwright Tests Headless
DESCRIPTION: Executes the full suite of Playwright tests in headless mode, meaning browsers are not visually opened. This is the standard command for running tests and is typically used in CI environments.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_0

LANGUAGE: bash
CODE:
```
yarn test
```

----------------------------------------

TITLE: Configuring Anthropic API Key Env
DESCRIPTION: Sets the `ANTHROPIC_API_KEY` environment variable in the `.env` file with your secret Anthropic API key. This key is necessary to authenticate with the Anthropic API for accessing models like Claude 3. The key should be provided directly after the equals sign without quotes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_5

LANGUAGE: INI
CODE:
```
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

----------------------------------------

TITLE: Scaling Docker Compose Service Instances Shell
DESCRIPTION: Scales the number of running instances for a specific service ('executor') to a desired count (3) and starts them in detached mode. Useful for distributing load or increasing processing capacity.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_15

LANGUAGE: Shell
CODE:
```
docker compose up -d --scale executor=3
```

----------------------------------------

TITLE: Start AutoGPT Benchmark for Agent - Shell
DESCRIPTION: Initiates the benchmarking process for a specific agent by executing the command `./run benchmark start` followed by the agent's name (`YOUR_AGENT_NAME`). This command runs the agent against the predefined benchmark tests to measure its performance and effectiveness.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_11

LANGUAGE: Shell
CODE:
```
./run benchmark start YOUR_AGENT_NAME
```

----------------------------------------

TITLE: Defining MessageProvider Protocol Interface - Python
DESCRIPTION: This snippet defines the abstract `MessageProvider` protocol interface. Components implementing this protocol provide messages that will be included in the agent's prompt, allowing them to influence the LLM's context using `ChatMessage.user()` or `ChatMessage.system()`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_4

LANGUAGE: Python
CODE:
```
class MessageProvider(AgentComponent):
    def get_messages(self) -> Iterator[ChatMessage]:
        ...
```

----------------------------------------

TITLE: Cloning and Navigating Repository Shell
DESCRIPTION: Clones the AutoGPT repository from GitHub and changes the current directory to the 'autogpt_platform' subfolder. This is the initial step required to access the project files.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_0

LANGUAGE: Shell
CODE:
```
git clone <https://github.com/Significant-Gravitas/AutoGPT.git | git@github.com:Significant-Gravitas/AutoGPT.git>
cd AutoGPT/autogpt_platform
```

----------------------------------------

TITLE: Checking Running Docker Containers (Bash)
DESCRIPTION: Executes the standard Docker command to list currently running containers. This is a crucial step for troubleshooting Docker-related issues, ensuring that the AutoGPT backend services have successfully started and are operational.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/ollama.md#_snippet_4

LANGUAGE: bash
CODE:
```
docker ps
```

----------------------------------------

TITLE: Stopping Docker Compose Services Shell
DESCRIPTION: Stops running services without removing their containers. The state of the containers is preserved, allowing for quicker restarts.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_8

LANGUAGE: Shell
CODE:
```
docker compose stop
```

----------------------------------------

TITLE: Handling Sensitive Component Configuration (Python)
DESCRIPTION: Shows how to define configuration fields for sensitive data using Pydantic's `SecretStr` and AutoGPT's `UserConfigurable`. Setting `from_env` loads the value from an environment variable, and `exclude=True` prevents serialization.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/components/README.md#_snippet_2

LANGUAGE: python
CODE:
```
from pydantic import BaseModel, SecretStr
from forge.models.config import UserConfigurable

class SensitiveConfig(BaseModel):
    api_key: SecretStr = UserConfigurable(from_env="API_KEY", exclude=True)
```

----------------------------------------

TITLE: Defining BaseWebhooksManager Interface - Python
DESCRIPTION: To add support for a new webhook provider, create a class that implements the `BaseWebhooksManager` interface. This base class defines the required methods (e.g., `subscribe`, `unsubscribe`, `process_webhook`) that a provider-specific manager must implement to handle webhook subscriptions and incoming payloads.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_18

LANGUAGE: python
CODE:
```
# Combined code representing the BaseWebhooksManager definition
# Taken from autogpt_platform/backend/backend/integrations/webhooks/_base.py

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Tuple

class BaseWebhooksManager(ABC):
    provider: str

    @abstractmethod
    async def subscribe(
        self,
        webhook_id: str,
        callback_url: str,
        events: List[str],
        credentials: Dict[str, Any] | None,
    ) -> None:
        """Creates a webhook subscription with the provider."""
        pass

    @abstractmethod
    async def unsubscribe(
        self,
        webhook_id: str,
        credentials: Dict[str, Any] | None,
    ) -> None:
        """Removes a webhook subscription with the provider."""
        pass

    @abstractmethod
    async def process_webhook(
        self,
        webhook_id: str,
        headers: Dict[str, str],
        payload: Dict[str, Any] | bytes,
        credentials: Dict[str, Any] | None,
    ) -> Tuple[str, Dict[str, Any]]:
        """Validates and processes the incoming webhook payload."""
        pass

    @abstractmethod
    async def list_supported_events(self, credentials: Dict[str, Any] | None) -> List[str]:
        """Lists events that can be subscribed to."""
        pass

    @abstractmethod
    def get_credentials_schema(self) -> Dict[str, Any]:
        """Returns the Pydantic schema for the credentials required by this provider."""
        pass
```

----------------------------------------

TITLE: Defining Webhook Event Filter Input - Python
DESCRIPTION: Include a Pydantic model field in the block's input schema specifically for filtering webhook events. The name of this field must match `webhook_config.event_filter_input`, and the filter model itself must only contain boolean fields, allowing users to enable or disable specific event types.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_15

LANGUAGE: python
CODE:
```
# Example taken from autogpt_platform/backend/backend/blocks/github/triggers.py
# This code snippet shows the definition of the event filter input field

from pydantic import BaseModel

# Assuming necessary imports for BlockInputSchema are present

class GitHubEventsFilter(BaseModel):
    pull_request: bool = True
    # Add other github event types as boolean fields

class GitHubTriggerBlockInput(BlockInputSchema):
    events: GitHubEventsFilter
    # Other input fields...
```

----------------------------------------

TITLE: Starting Docker Compose Services Detached Shell
DESCRIPTION: Starts the services defined in 'docker-compose.yml' in detached mode. Containers run in the background, freeing up the terminal.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_7

LANGUAGE: Shell
CODE:
```
docker compose up -d
```

----------------------------------------

TITLE: Disabling Commands in AutoGPT Config INI
DESCRIPTION: This configuration snippet shows how to disable specific commands within the AutoGPT `.env` file by setting the `DISABLED_COMMANDS` variable. Command names are provided as a comma-separated list, effectively preventing the agent from executing them.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_8

LANGUAGE: ini
CODE:
```
DISABLED_COMMANDS=execute_python_code,execute_python_file
```

----------------------------------------

TITLE: Defining ExecutionFailure Protocol Interface - Python
DESCRIPTION: This snippet defines the abstract `ExecutionFailure` protocol, an interface for `AgentComponent`s. Components implementing this protocol have their `execution_failure` method called when the execution of a command initiated by the agent fails, receiving the `Exception` that occurred.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_8

LANGUAGE: Python
CODE:
```
class ExecutionFailure(AgentComponent):
    @abstractmethod
    def execution_failure(self, error: Exception) -> None:
        ...
```

----------------------------------------

TITLE: Ordering Individual Agent Components using run_after in Python
DESCRIPTION: This Python snippet demonstrates how to explicitly control the execution order of individual components by chaining the `run_after()` method when assigning the component attribute. This ensures that a component runs only after a specified component (or its type) has completed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_5

LANGUAGE: Python
CODE:
```
class MyAgent(Agent):
    def __init__(self):
        self.hello_component = HelloComponent()
        self.calculator_component = CalculatorComponent().run_after(self.hello_component)
        # This is equivalent to passing a type:
        # self.calculator_component = CalculatorComponent().run_after(HelloComponent)
```

----------------------------------------

TITLE: Building Docker Images - Bash
DESCRIPTION: This command builds all Docker images defined in the project's Docker Compose file, preparing them for execution.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_22

LANGUAGE: bash
CODE:
```
docker compose build
```

----------------------------------------

TITLE: Raising Component Endpoint Error in Python
DESCRIPTION: This snippet demonstrates how to raise a ComponentEndpointError within a component method (get_messages) that implements the MessageProvider protocol. Raising this specific error signals that a single endpoint execution failed, causing the agent to retry the execution of this endpoint on the component multiple times before potentially re-raising the exception if it persists. It requires importing ComponentEndpointError and defining a class inheriting from a relevant protocol like MessageProvider.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_9

LANGUAGE: python
CODE:
```
from forge.agent.components import ComponentEndpointError
from forge.agent.protocols import MessageProvider

# Example of raising an error
class MyComponent(MessageProvider):
    def get_messages(self) -> Iterator[ChatMessage]:
        # This will cause the component to always fail 
        # and retry 3 times before re-raising the exception
        raise ComponentEndpointError("Endpoint error!")
```

----------------------------------------

TITLE: Run Flake8 Linter (Shell)
DESCRIPTION: Runs the flake8 static analysis tool on the current directory ('.') to check source code for style guide compliance and programming errors. Requires flake8 to be installed and accessible in the system's PATH.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/testing.md#_snippet_5

LANGUAGE: shell
CODE:
```
flake8 .
```

----------------------------------------

TITLE: Installing Frontend Dependencies - Bash
DESCRIPTION: These commands are used to install the necessary project dependencies. Choose one of the package managers (npm, yarn, pnpm, or bun) and run the corresponding command once after cloning the repository or updating from git.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
npm install
```

LANGUAGE: bash
CODE:
```
yarn install
```

LANGUAGE: bash
CODE:
```
pnpm install
```

LANGUAGE: bash
CODE:
```
bun install
```

----------------------------------------

TITLE: Defining AutoGPT Command with Explicit Decorator Params - Python
DESCRIPTION: Illustrates an alternative way to use the `@command` decorator by explicitly setting the command `names` and `description` arguments. This allows the underlying method name (`multiply_command` in this case) to differ from the command name seen by the agent (`multiply`). Parameters are defined using `JSONSchema` similar to the previous example.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/commands.md#_snippet_2

LANGUAGE: python
CODE:
```
@command(
    names=["multiply"],
    description="Multiplies two numbers.",
    parameters={
        "a": JSONSchema(
            type=JSONSchema.Type.INTEGER,
            description="The first number",
            required=True,
        ),
        "b": JSONSchema(
            type=JSONSchema.Type.INTEGER,
            description="The second number",
            required=True,
        )})`
`    def multiply_command(self, a: int, b: int) -> str:`
`        return str(a * b)
```

----------------------------------------

TITLE: Cloning AutoGPT Repository (Shell)
DESCRIPTION: Clones the AutoGPT project repository from GitHub to your local machine. This is the first step in setting up the documentation development environment. Requires Git to be installed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/contribute/index.md#_snippet_0

LANGUAGE: shell
CODE:
```
git clone github.com/Significant-Gravitas/AutoGPT.git
```

----------------------------------------

TITLE: Run Tests Excluding Slow Integration Tests (Shell)
DESCRIPTION: Executes all tests except those specifically marked or categorized as slow integration tests. This provides a middle ground for faster test runs while still including standard integration checks. Requires pytest and relevant test markers configured.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/testing.md#_snippet_3

LANGUAGE: shell
CODE:
```
pytest --without-slow-integration
```

----------------------------------------

TITLE: Run AutoGPT Project Setup - Shell
DESCRIPTION: Executes the main project setup script located at `./run setup`. This command initiates the guided setup process which includes installing project dependencies, setting up prerequisites like Flutter and Chrome, and configuring necessary tokens (e.g., GitHub access token). It is a critical step after cloning the repository and resolving any initial environmental issues.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_4

LANGUAGE: Shell
CODE:
```
./run setup
```

----------------------------------------

TITLE: Implementing MessageProvider with User Message - Python Example
DESCRIPTION: This example shows a simple implementation of the `MessageProvider` protocol. It demonstrates how a component can add a specific message, in this case a user message "Hello World!", to the agent's prompt by yielding a `ChatMessage.user()` object from the `get_messages` method.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_5

LANGUAGE: Python
CODE:
```
class HelloComponent(MessageProvider):
    def get_messages(self) -> Iterator[ChatMessage]:
        yield ChatMessage.user("Hello World!")
```

----------------------------------------

TITLE: Adding Dependency using Poetry
DESCRIPTION: Adds a new package as a dependency to the project using Poetry and updates the `pyproject.toml` and `poetry.lock` files. Replace `requirement` with the package name.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_12

LANGUAGE: Shell
CODE:
```
poetry add requirement
```

----------------------------------------

TITLE: Specifying Component Configuration File (Shell)
DESCRIPTION: Provides a command-line example demonstrating how to launch AutoGPT and specify a custom JSON configuration file for components using the `--component-config-file` option.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/components/README.md#_snippet_3

LANGUAGE: shell
CODE:
```
./autogpt.sh run --component-config-file config.json
```

----------------------------------------

TITLE: Start Docker Compose Services sh
DESCRIPTION: Changes directory to `autogpt_platform/` and starts the services defined in the `docker-compose.yml` file in detached mode (`-d`). This command brings up essential services like the database.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_13

LANGUAGE: sh
CODE:
```
cd autogpt_platform/
docker compose up -d
```

----------------------------------------

TITLE: Starting DB in Docker, App Locally - Bash
DESCRIPTION: This sequence of commands starts only the necessary dependency services (like the database) using Docker Compose in detached mode and then navigates to the backend directory to run the application locally using Poetry.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_21

LANGUAGE: bash
CODE:
```
docker compose --profile local up deps --build --detach
cd backend
poetry run app
```

----------------------------------------

TITLE: Running Tests with Poetry - Bash
DESCRIPTION: This command executes the project's test suite using the configured test runner via Poetry, verifying the correctness of the code.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_30

LANGUAGE: bash
CODE:
```
poetry run test
```

----------------------------------------

TITLE: Starting Benchmark for an Agent (Shell)
DESCRIPTION: Uses the `benchmark start` command followed by the agent's name ('my_agent') to run the benchmark tests using the specified agent and display the results.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_10

LANGUAGE: sh
CODE:
```
./run benchmark start my_agent
```

----------------------------------------

TITLE: Setting Anthropic Smart LLM Env
DESCRIPTION: Sets the `SMART_LLM` environment variable in the `.env` file to specify which Anthropic model should be used by AutoGPT for tasks requiring higher intelligence or complexity. Replace the example model name with the desired Claude 3 model ID.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_6

LANGUAGE: INI
CODE:
```
SMART_LLM=claude-3-opus-20240229
```

----------------------------------------

TITLE: Run AutoGPT Container with Args (Vanilla Docker) - Shell
DESCRIPTION: This command runs a container based on the 'autogpt' image with specific AutoGPT arguments (`--gpt3only`, `--continuous`). It also runs in interactive TTY mode, mounts the current directory, uses the `.env` file, and removes the container on exit (`--rm`).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_11

LANGUAGE: shell
CODE:
```
docker run -it --env-file=.env -v $PWD:/app --rm autogpt --gpt3only --continuous
```

----------------------------------------

TITLE: Generate Prisma Client for PostgreSQL bash
DESCRIPTION: Executes the Prisma client generation command using Poetry, specifically targeting the PostgreSQL schema file (`postgres/schema.prisma`). This command creates the necessary client code to interact with the PostgreSQL database.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_3

LANGUAGE: bash
CODE:
```
poetry run prisma generate --schema postgres/schema.prisma
```

----------------------------------------

TITLE: Configuring Groq API Key Env
DESCRIPTION: Sets the `GROQ_API_KEY` environment variable in the `.env` file with your secret Groq API key. This key is required to authenticate with the Groq API for accessing models like Llama 3. The key should be provided directly after the equals sign without quotes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_7

LANGUAGE: INI
CODE:
```
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

----------------------------------------

TITLE: Defining DirectiveProvider Protocol Interface - Python
DESCRIPTION: This snippet defines the abstract `DirectiveProvider` protocol, which is an interface for `AgentComponent`s. Components implementing this protocol provide static information like constraints, resources, and best practices to the agent, primarily for use by the LLM when building prompts.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_0

LANGUAGE: Python
CODE:
```
class DirectiveProvider(AgentComponent):
    def get_constraints(self) -> Iterator[str]:
        return iter([])

    def get_resources(self) -> Iterator[str]:
        return iter([])

    def get_best_practices(self) -> Iterator[str]:
        return iter([])
```

----------------------------------------

TITLE: Launching AutoGPT with Component Configuration File using Shell
DESCRIPTION: This shell command demonstrates how to launch the `autogpt.sh` script and specify a custom JSON file (e.g., `config.json`) to load component-specific configurations using the `--component-config-file` CLI option.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_3

LANGUAGE: shell
CODE:
```
./autogpt.sh run --component-config-file config.json
```

----------------------------------------

TITLE: Customizing Secure Requests Wrapper Configuration - Python
DESCRIPTION: You can create a custom instance of the `Requests` wrapper if specific configuration is needed, such as whitelisting trusted origins, overriding default behaviors like `raise_for_status`, or adding default headers. This allows fine-grained control while retaining the built-in SSRF protections.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_24

LANGUAGE: python
CODE:
```
from backend.util.request import Requests

# Create a custom requests instance with specific trusted origins
custom_requests = Requests(
    trusted_origins=["api.trusted-service.com"], # Allow requests only to these domains
    raise_for_status=True, # Ensure exceptions are raised for bad status codes (default)
    extra_headers={
        "User-Agent": "MyBlock/1.0", # Add a custom User-Agent header
        "X-Custom-Header": "value"
    }
)

# Use the custom instance
# try:
#     response = custom_requests.get("https://api.trusted-service.com/data")
#     # Process response...
# except Exception as e:
#     # Handle errors...

```

----------------------------------------

TITLE: Implementing DirectiveProvider for Resources - Python Example
DESCRIPTION: This example shows how to implement the `DirectiveProvider` protocol to provide resource information to the agent. It demonstrates yielding a string describing internet access as a resource, while implicitly skipping other `get_` methods if not needed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_1

LANGUAGE: Python
CODE:
```
class WebSearchComponent(DirectiveProvider):
    def get_resources(self) -> Iterator[str]:
        yield "Internet access for searches and information gathering."
    # We can skip "get_constraints" and "get_best_practices" if they aren't needed
```

----------------------------------------

TITLE: Start AutoGPT Server Application with Poetry sh
DESCRIPTION: Executes the main application entry point (`app`) using Poetry's run command (`poetry run app`). This starts the AutoGPT server within the configured virtual environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_15

LANGUAGE: sh
CODE:
```
poetry run app
```

----------------------------------------

TITLE: Running Auto-GPT Benchmarks
DESCRIPTION: Executes the `agbenchmark` command-line tool to start running the benchmark tests. This is the basic command after installing the package and setting up the agent boilerplate.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_1

LANGUAGE: Shell
CODE:
```
agbenchmark
```

----------------------------------------

TITLE: Defining Webhook Configuration in Block __init__ - Python
DESCRIPTION: To make a block triggerable by a webhook, define the `webhook_config` attribute in the block's `__init__` method. This configuration links the block to a specific webhook provider and specifies which input field will hold the event filter.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_13

LANGUAGE: python
CODE:
```
# Example taken from autogpt_platform/backend/backend/blocks/github/triggers.py
# This code snippet shows how webhook_config is defined in the __init__ method

# Assuming necessary imports are present

class GitHubPullRequestTriggerBlock(Block):
    def __init__(self):
        super().__init__()
        self.webhook_config = BlockWebhookConfig(provider='github', event_filter_input='events')
```

----------------------------------------

TITLE: Listing Available Agents (Shell)
DESCRIPTION: Uses the `agent list` command to display all agents that are currently available within the project.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_3

LANGUAGE: sh
CODE:
```
./run agent list
```

----------------------------------------

TITLE: Migrating Database with Prisma - Bash
DESCRIPTION: This command uses Prisma, executed via Poetry, to deploy database migrations, setting up the database schema required by the application.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_19

LANGUAGE: bash
CODE:
```
poetry run prisma migrate deploy
```

----------------------------------------

TITLE: Registering Webhooks Manager in load_webhook_managers - Python
DESCRIPTION: After creating a concrete implementation of `BaseWebhooksManager` for a new provider, register it by adding its class to the dictionary returned by the `load_webhook_managers` function. The dictionary key should be the manager's `provider` string.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_19

LANGUAGE: python
CODE:
```
# Example taken from autogpt_platform/backend/backend/integrations/webhooks/__init__.py
# This code shows how to register a new WebhooksManager

# Assuming necessary imports for BaseWebhooksManager and specific managers

def load_webhook_managers() -> Dict[str, BaseWebhooksManager]:
    """Loads and initializes all available webhook managers."""
    # Existing managers...
    managers = {
        # ... existing managers
        # Register your new manager here:
        "your_provider": YourWebhooksManagerClass(),
        # Assuming YourWebhooksManagerClass.provider == "your_provider"
    }
    return managers
```

----------------------------------------

TITLE: Installing and Running Frontend (NPM) Shell
DESCRIPTION: Installs frontend dependencies using NPM and then starts the frontend application in development mode. This makes the user interface accessible via a web browser.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_5

LANGUAGE: Shell
CODE:
```
npm install
npm run dev
```

----------------------------------------

TITLE: Explicitly Ordering All Agent Components in Python
DESCRIPTION: This Python snippet shows an alternative method for controlling component order by explicitly defining the `self.components` list within the agent's `__init__` method. This overrides the default alphabetical ordering and any `run_after` calls, giving full control over the execution sequence.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_6

LANGUAGE: Python
CODE:
```
class MyAgent(Agent):
    def __init__(self):
        self.hello_component = HelloComponent()
        self.calculator_component = CalculatorComponent()
        # Explicitly set components list
        self.components = [self.hello_component, self.calculator_component]
```

----------------------------------------

TITLE: Installing Development Dependencies - Bash
DESCRIPTION: This command installs project dependencies using Poetry, including those specified for the 'dev' group, needed for development tasks like formatting and linting.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_27

LANGUAGE: bash
CODE:
```
poetry install --with dev
```

----------------------------------------

TITLE: Example AutoGPT Component Configuration JSON File
DESCRIPTION: This JSON snippet provides an example structure and content for a component configuration file (`config.json`). It shows how to define configuration values for various built-in AutoGPT components like `CodeExecutorConfiguration`, `FileManagerConfiguration`, `WebSearchConfiguration`, etc.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_4

LANGUAGE: json
CODE:
```
{
    "CodeExecutorConfiguration": {
        "execute_local_commands": false,
        "shell_command_control": "allowlist",
        "shell_allowlist": ["cat", "echo"],
        "shell_denylist": [],
        "docker_container_name": "agent_sandbox"
    },
    "FileManagerConfiguration": {
        "storage_path": "agents/AutoGPT/",
        "workspace_path": "agents/AutoGPT/workspace"
    },
    "GitOperationsConfiguration": {
        "github_username": null
    },
    "ActionHistoryConfiguration": {
        "llm_name": "gpt-3.5-turbo",
        "max_tokens": 1024,
        "spacy_language_model": "en_core_web_sm"
    },
    "ImageGeneratorConfiguration": {
        "image_provider": "dalle",
        "huggingface_image_model": "CompVis/stable-diffusion-v1-4",
        "sd_webui_url": "http://localhost:7860"
    },
    "WebSearchConfiguration": {
        "duckduckgo_max_attempts": 3
    },
    "WebSeleniumConfiguration": {
        "llm_name": "gpt-3.5-turbo",
        "web_browser": "chrome",
        "headless": true,
        "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36",
        "browse_spacy_language_model": "en_core_web_sm"
    }
}
```

----------------------------------------

TITLE: Create a New AutoGPT Agent Template - Shell
DESCRIPTION: Runs the command `./run agent create` followed by the desired name for the new agent (`YOUR_AGENT_NAME`). This action generates the necessary files and structure for a new agent template, preparing it for customization and subsequent execution.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_5

LANGUAGE: Shell
CODE:
```
./run agent create YOUR_AGENT_NAME
```

----------------------------------------

TITLE: Running agbenchmark Tool (Shell)
DESCRIPTION: This command executes the agbenchmark tool, which is presented as a simplified way to identify and solve challenges within AutoGPT.
Running this command initiates the benchmarking process to test AutoGPT against various challenges and track progress.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/introduction.md#_snippet_0

LANGUAGE: Shell
CODE:
```
agbenchmark
```

----------------------------------------

TITLE: Run Tests Excluding Integration Tests (Shell)
DESCRIPTION: Executes all tests except those explicitly marked or categorized as integration tests. This allows for faster test runs by skipping longer-running integration checks. Requires pytest and relevant test markers configured.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/testing.md#_snippet_2

LANGUAGE: shell
CODE:
```
pytest --without-integration
```

----------------------------------------

TITLE: Stopping, Updating, and Restarting Entire Docker Compose System Shell
DESCRIPTION: Performs a sequence of commands to stop all services, forcibly remove containers, pull the latest images for all services, and then restart the entire system in detached mode. Used for a full system refresh.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_16

LANGUAGE: Shell
CODE:
```
docker compose stop
docker compose rm -f
docker compose pull
docker compose up -d
```

----------------------------------------

TITLE: Defining Agent Fixture - AutoGPT Testing - Python
DESCRIPTION: This Python fixture `kubernetes_agent` creates and configures an `Agent` instance for use in integration tests, specifically tailored for generating Kubernetes deployment templates. It sets up command registries for file operations and app logic, defines the AI profile (name, role, goals), and initializes the Agent with the necessary configuration. It's designed to be used within the `pytest` framework for challenge creation.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/building_challenges.md#_snippet_0

LANGUAGE: python
CODE:
```
def kubernetes_agent(
    agent_test_config, workspace: Workspace
):
    # Please choose the commands your agent will need to beat the challenges, the full list is available in the main.py
    # (we 're working on a better way to design this, for now you have to look at main.py)
    command_registry = CommandRegistry()
    command_registry.import_commands("autogpt.commands.file_operations")
    command_registry.import_commands("autogpt.app")

    # Define all the settings of our challenged agent
    ai_profile = AIProfile(
        ai_name="Kubernetes",
        ai_role="an autonomous agent that specializes in creating Kubernetes deployment templates.",
        ai_goals=[
            "Write a simple kubernetes deployment file and save it as a kube.yaml.",
        ],
    )
    ai_profile.command_registry = command_registry

    system_prompt = ai_profile.construct_full_prompt()
    agent_test_config.set_continuous_mode(False)
    agent = Agent(
        command_registry=command_registry,
        config=ai_profile,
        next_action_count=0,
        triggering_prompt=DEFAULT_TRIGGERING_PROMPT,
    )

    return agent
```

----------------------------------------

TITLE: Start the AutoGPT Agent - Shell
DESCRIPTION: Executes the command `./run agent start` followed by the name of the agent to be started (`YOUR_AGENT_NAME`). This initiates the agent's process, typically making its web interface accessible at `http://localhost:8000/`. The specified agent must have been previously created.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_6

LANGUAGE: Shell
CODE:
```
./run agent start YOUR_AGENT_NAME
```

----------------------------------------

TITLE: Entering Poetry Shell - Bash
DESCRIPTION: This command activates the virtual environment managed by Poetry, allowing execution of project scripts and dependencies within that isolated environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_13

LANGUAGE: bash
CODE:
```
poetry shell
```

----------------------------------------

TITLE: Generating Prisma Client - Bash
DESCRIPTION: This command uses Prisma, executed via Poetry, to generate the database client code based on the Prisma schema, required for database interactions.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_16

LANGUAGE: bash
CODE:
```
poetry run prisma generate
```

----------------------------------------

TITLE: Generating Encryption Key (Python) - Python
DESCRIPTION: This Python code snippet uses the `cryptography` library to generate a new Fernet encryption key, which can be used to secure sensitive data in the application's environment configuration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_9

LANGUAGE: python
CODE:
```
from cryptography.fernet import Fernet;Fernet.generate_key().decode()
```

----------------------------------------

TITLE: Copying Backend Environment File - Bash
DESCRIPTION: This command copies the example environment file (`.env.example`) to the active environment file (`.env`) in the `autogpt_platform` directory. The `.env` file is used to configure backend settings and secrets.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_4

LANGUAGE: bash
CODE:
```
cp .env.example .env
```

----------------------------------------

TITLE: Defining Union Field with Discriminator Python
DESCRIPTION: Demonstrates how to define a field using `Union` (or `oneOf`) with a `discriminator` parameter in `SchemaField`. This allows the field to accept one of several predefined types, identified by a specific field within the input data.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_5

LANGUAGE: python
CODE:
```
attachment: Union[Media, DeepLink, Poll, Place, Quote] = SchemaField(
    discriminator='discriminator',
    description="Attach either media, deep link, poll, place or quote - only one can be used"
)
```

----------------------------------------

TITLE: Defining Optional Union Field with Discriminator Python
DESCRIPTION: Illustrates how to define a field that is an optional `Union` (or `OptionalOneOf`) using `| None`. This allows the field to be one of several types or entirely absent (`None`).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_7

LANGUAGE: python
CODE:
```
attachment: Union[Media, DeepLink, Poll, Place, Quote] | None = SchemaField(
    discriminator='discriminator',
    description="Optional attachment - can be media, deep link, poll, place, quote or None"
)
```

----------------------------------------

TITLE: Run Playwright Tests with UI
DESCRIPTION: Launches the Playwright UI test runner, which provides a visual interface to see test execution, inspect locators, and debug tests interactively. Useful for developing and debugging tests.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_1

LANGUAGE: bash
CODE:
```
yarn test-ui
```

----------------------------------------

TITLE: Installing Docs Dependencies with Python3 Pip (Shell)
DESCRIPTION: Installs the necessary Python dependencies for building and serving the documentation using pip, explicitly calling the `python3` executable. The dependencies are read from `docs/requirements.txt`. Useful when multiple Python versions are installed. Requires Python 3 and pip.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/contribute/index.md#_snippet_2

LANGUAGE: shell
CODE:
```
python3 -m pip install -r docs/requirements.txt
```

----------------------------------------

TITLE: Dynamically Disabling Agent Components in Python
DESCRIPTION: This Python snippet illustrates how to disable an Agent Component by setting its internal `_enabled` attribute to `False` or a callable function that returns a boolean. It also shows how to provide a `_disabled_reason` string that will be visible in debug output.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_7

LANGUAGE: Python
CODE:
```
class DisabledComponent(MessageProvider):
    def __init__(self):
        # Disable this component
        self._enabled = False
        self._disabled_reason = "This component is disabled because of reasons."

        # Or disable based on some condition, either statically...:
        self._enabled = self.some_property is not None
        # ... or dynamically:
        self._enabled = lambda: self.some_property is not None

    # This method will never be called
    def get_messages(self) -> Iterator[ChatMessage]:
        yield ChatMessage.user("This message won't be seen!")

    def some_condition(self) -> bool:
        return False
```

----------------------------------------

TITLE: Run All Tests using python -m pytest (Shell)
DESCRIPTION: Executes all tests by running pytest as a Python module. This method is useful if the pytest executable is not directly in the system's PATH but Python is installed. Requires python and the pytest package to be installed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/testing.md#_snippet_1

LANGUAGE: shell
CODE:
```
python -m pytest
```

----------------------------------------

TITLE: Configure Poetry Virtual Environment Location sh
DESCRIPTION: Configures Poetry to create virtual environments directly within the project directory under a `.venv` folder (`virtualenvs.in-project true`), rather than in a centralized location. This is useful for project isolation.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_7

LANGUAGE: sh
CODE:
```
poetry config virtualenvs.in-project true
```

----------------------------------------

TITLE: Installing Docs Dependencies with Pip (Shell)
DESCRIPTION: Installs the necessary Python dependencies for building and serving the documentation using pip. The dependencies are read from the `docs/requirements.txt` file. Requires Python and pip to be installed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/contribute/index.md#_snippet_1

LANGUAGE: shell
CODE:
```
python -m pip install -r docs/requirements.txt
```

----------------------------------------

TITLE: Running AutoGPT with Custom Prompt Settings Shell
DESCRIPTION: This shell command shows how to run AutoGPT using a specific prompt settings file via the `--prompt-settings` argument. This allows users to customize aspects of the prompt structure or content loaded by the agent.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_6

LANGUAGE: shell
CODE:
```
./autogpt.sh --prompt-settings <filename>
```

----------------------------------------

TITLE: Run Tests with Coverage Excluding Integration (Shell)
DESCRIPTION: Executes tests while also calculating code coverage statistics, excluding both standard and slow integration tests. Requires pytest and the pytest-cov plugin installed. The coverage report will be generated for the 'autogpt' package.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/testing.md#_snippet_4

LANGUAGE: shell
CODE:
```
pytest --cov=autogpt --without-integration --without-slow-integration
```

----------------------------------------

TITLE: Run Prisma Development Migrations bash
DESCRIPTION: Changes directory to the `backend` folder and applies Prisma database migrations in development mode (`migrate dev`), using the specified PostgreSQL schema file (`postgres/schema.prisma`). This prepares the database structure for development use.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_5

LANGUAGE: bash
CODE:
```
cd ../backend
prisma migrate dev --schema postgres/schema.prisma
```

----------------------------------------

TITLE: Starting AutoGPT Frontend with npm (Bash)
DESCRIPTION: Navigates to the AutoGPT platform's frontend directory and starts the development server using npm. This command is typically used during local development to serve the user interface, making it accessible via a web browser.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/ollama.md#_snippet_2

LANGUAGE: bash
CODE:
```
cd autogpt_platform/frontend
npm run dev
```

----------------------------------------

TITLE: Pull Latest AutoGPT Docker Image - Shell
DESCRIPTION: This command downloads the latest version of the AutoGPT Docker image from Docker Hub. It ensures you are running AutoGPT with the most recent updates.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_4

LANGUAGE: shell
CODE:
```
docker pull significantgravitas/auto-gpt
```

----------------------------------------

TITLE: Stopping AutoGPT Agent
DESCRIPTION: Uses the run script to forcefully stop the currently running AutoGPT agent process. This is an alternative to using Ctrl+C in the terminal.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/001_getting_started.md#_snippet_4

LANGUAGE: bash
CODE:
```
./run agent stop
```

----------------------------------------

TITLE: Updating Git Submodules
DESCRIPTION: Initializes, updates, and retrieves the latest commits for all Git submodules within the repository, including the `agent` submodule which contains reference agents.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_9

LANGUAGE: Shell
CODE:
```
git submodule update --init --remote --recursive
```

----------------------------------------

TITLE: Configuring Poetry Virtual Environment - Bash
DESCRIPTION: This command configures Poetry to create and manage virtual environments directly within the project directory (`.venv`), isolating project dependencies.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_12

LANGUAGE: bash
CODE:
```
poetry config virtualenvs.in-project true
```

----------------------------------------

TITLE: Updating and Restarting Specific Docker Compose Service Shell
DESCRIPTION: Rebuilds the image for a specific service ('api_srv') and then restarts only that service in detached mode, ignoring its dependencies. Useful for targeted updates or fixes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_13

LANGUAGE: Shell
CODE:
```
docker compose build api_srv
docker compose up -d --no-deps api_srv
```

----------------------------------------

TITLE: Styling Storybook Page Layout - CSS
DESCRIPTION: Defines CSS rules for styling the overall layout of a Storybook page. It includes styles for containers, flexible sections, grid layouts for features and socials, and a specialized 'addon' section with complex positioning and responsive adjustments for different screen sizes (max-width: 800px and 600px).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/src/stories/Configure.mdx#_snippet_3

LANGUAGE: CSS
CODE:
```
.sb-container {
    margin-bottom: 48px;
  }

  .sb-section {
    width: 100%;
    display: flex;
    flex-direction: row;
    gap: 20px;
  }

  img {
    object-fit: cover;
  }

  .sb-section-title {
    margin-bottom: 32px;
  }

  .sb-section a:not(h1 a, h2 a, h3 a) {
    font-size: 14px;
  }

  .sb-section-item, .sb-grid-item {
    flex: 1;
    display: flex;
    flex-direction: column;
  }

  .sb-section-item-heading {
    padding-top: 20px !important;
    padding-bottom: 5px !important;
    margin: 0 !important;
  }
  .sb-section-item-paragraph {
    margin: 0;
    padding-bottom: 10px;
  }

  .sb-chevron {
    margin-left: 5px;
  }

  .sb-features-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    grid-gap: 32px 20px;
  }

  .sb-socials {
    display: grid;
    grid-template-columns: repeat(4, 1fr);
  }

  .sb-socials p {
    margin-bottom: 10px;
  }

  .sb-explore-image {
    max-height: 32px;
    align-self: flex-start;
  }

  .sb-addon {
    width: 100%;
    display: flex;
    align-items: center;
    position: relative;
    background-color: #EEF3F8;
    border-radius: 5px;
    border: 1px solid rgba(0, 0, 0, 0.05);
    background: #EEF3F8;
    height: 180px;
    margin-bottom: 48px;
    overflow: hidden;
  }

  .sb-addon-text {
    padding-left: 48px;
    max-width: 240px;
  }

  .sb-addon-text h4 {
    padding-top: 0px;
  }

  .sb-addon-img {
    position: absolute;
    left: 345px;
    top: 0;
    height: 100%;
    width: 200%;
    overflow: hidden;
  }

  .sb-addon-img img {
    width: 650px;
    transform: rotate(-15deg);
    margin-left: 40px;
    margin-top: -72px;
    box-shadow: 0 0 1px rgba(255, 255, 255, 0);
    backface-visibility: hidden;
  }

  @media screen and (max-width: 800px) {
    .sb-addon-img {
      left: 300px;
    }
  }

  @media screen and (max-width: 600px) {
    .sb-section {
      flex-direction: column;
    }

    .sb-features-grid {
      grid-template-columns: repeat(1, 1fr);
    }

    .sb-socials {
      grid-template-columns: repeat(2, 1fr);
    }

    .sb-addon {
      height: 280px;
      align-items: flex-start;
      padding-top: 32px;
      overflow: hidden;
    }

    .sb-addon-text {
      padding-left: 24px;
    }

    .sb-addon-img {
      right: 0;
      left: 0;
      top: 130px;
      bottom: 0;
      overflow: hidden;
      height: auto;
      width: 124%;
    }

    .sb-addon-img img {
      width: 1200px;
      transform: rotate(-12deg);
      margin-left: 0;
      margin-top: 48px;
      margin-bottom: -40px;
      margin-left: -24px;
    }
  }
```

----------------------------------------

TITLE: Running Auto-GPT Benchmarks by Category
DESCRIPTION: Executes the benchmark specifically for challenges belonging to a specified category. Replace `challenge_category` with the desired category name to focus tests.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_2

LANGUAGE: Shell
CODE:
```
agbenchmark --category challenge_category
```

----------------------------------------

TITLE: Removing Stopped Docker Compose Containers Shell
DESCRIPTION: Removes containers that have been stopped. This frees up disk space and other resources consumed by stopped containers.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_9

LANGUAGE: Shell
CODE:
```
docker compose rm
```

----------------------------------------

TITLE: Stopping the Running Agent (Shell)
DESCRIPTION: Uses the `agent stop` command to terminate the currently running agent process. Note that this command is documented to terminate any process running on port 8000.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_6

LANGUAGE: sh
CODE:
```
./run agent stop
```

----------------------------------------

TITLE: Installing agbenchmark Package (Shell)
DESCRIPTION: This command installs the `agbenchmark` package using pip, the Python package installer. This package is required to use the challenge library and its features. It assumes you have Python and pip installed and configured in your environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/challenges/README.md#_snippet_0

LANGUAGE: Shell
CODE:
```
pip install agbenchmark
```

----------------------------------------

TITLE: Starting Uvicorn Server with Reload
DESCRIPTION: Starts a local web server using Uvicorn to serve the application, likely for the mock testing environment. The `--reload` flag enables automatic server restarts on code changes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_10

LANGUAGE: Shell
CODE:
```
uvicorn server:app --reload
```

----------------------------------------

TITLE: Cloning AutoGPT Classic Repository Bash
DESCRIPTION: This command sequence clones the entire AutoGPT Git repository from GitHub and then navigates into the 'classic' subdirectory. This is the necessary first step to access the specific version of the AutoGPT Classic codebase discussed in this document for historical or educational purposes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
git clone https://github.com/Significant-Gravitas/AutoGPT.git\ncd classic
```

----------------------------------------

TITLE: Stop the AutoGPT Agent Process - Shell
DESCRIPTION: Runs the command `./run agent stop`. This command is designed to terminate the process that is currently occupying port 8000, which is assumed to be the running agent instance. It provides a method to cleanly shut down the agent, especially if a standard interruption like Ctrl-C is ineffective.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_7

LANGUAGE: Shell
CODE:
```
./run agent stop
```

----------------------------------------

TITLE: Install Windows Subsystem for Linux (WSL) - Powershell/CMD
DESCRIPTION: Executes the command to install the necessary components for Windows Subsystem for Linux (WSL). This command enables required features, downloads the latest kernel, sets WSL 2 as the default version, and installs a default Linux distribution like Ubuntu. It is a prerequisite for running the project on Windows systems.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_0

LANGUAGE: Powershell
CODE:
```
wsl --install
```

----------------------------------------

TITLE: Installing Auto-GPT Benchmarks Python Package
DESCRIPTION: Installs the `auto-gpt-benchmarks` package from PyPI using pip. This is the standard way for users to install the benchmark tool for running tests against their agents.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_0

LANGUAGE: Shell
CODE:
```
pip install auto-gpt-benchmarks
```

----------------------------------------

TITLE: Copy .env.example File bash
DESCRIPTION: Command to copy the example environment file (`.env.example`) to the standard `.env` file, providing a starting point for server configuration. This is a common step in setting up projects that use `.env` files.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_1

LANGUAGE: bash
CODE:
```
# Copy the .env.example file to .env
cp .env.example .env
```

----------------------------------------

TITLE: Copying Environment File (Alternative Setup) - Bash
DESCRIPTION: This command copies the example environment file (`.env.example`) to the active `.env` file, necessary for configuring settings for the alternative backend setup using Poetry.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_15

LANGUAGE: bash
CODE:
```
cp .env.example .env
```

----------------------------------------

TITLE: Copying Backend Environment File Shell
DESCRIPTION: Copies the '.env.example' file to '.env' in the root of the 'autogpt_platform' directory. The '.env' file is used to configure environment variables for the backend services.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_1

LANGUAGE: Shell
CODE:
```
cp .env.example .env
```

----------------------------------------

TITLE: Installing Poetry - Bash
DESCRIPTION: This command installs Poetry, a dependency management and packaging tool for Python, which is used for the alternative backend setup steps.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_11

LANGUAGE: bash
CODE:
```
pip install poetry
```

----------------------------------------

TITLE: Shutting Down Docker Containers - Bash
DESCRIPTION: This command gracefully stops and removes containers, networks, and volumes created by Docker Compose.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_25

LANGUAGE: bash
CODE:
```
docker compose down
```

----------------------------------------

TITLE: Setting Up Flutter Assemble Target CMake
DESCRIPTION: Configures the `flutter_assemble` target responsible for running the Flutter tool backend script (`tool_backend.bat`). It uses a 'phony' output to ensure the command runs every time, executing the script with the appropriate environment variables and configuration to generate build artifacts like the Flutter engine and wrapper sources. The `flutter_assemble` custom target is then defined with dependencies on these generated outputs.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_7

LANGUAGE: cmake
CODE:
```
# === Flutter tool backend ===
# _phony_ is a non-existent file to force this command to run every time,
# since currently there's no way to get a full input/output list from the
# flutter tool.
set(PHONY_OUTPUT "${CMAKE_CURRENT_BINARY_DIR}/_phony_")
set_source_files_properties("${PHONY_OUTPUT}" PROPERTIES SYMBOLIC TRUE)
add_custom_command(
  OUTPUT ${FLUTTER_LIBRARY} ${FLUTTER_LIBRARY_HEADERS}
    ${CPP_WRAPPER_SOURCES_CORE} ${CPP_WRAPPER_SOURCES_PLUGIN}
    ${CPP_WRAPPER_SOURCES_APP}
    ${PHONY_OUTPUT}
  COMMAND ${CMAKE_COMMAND} -E env
    ${FLUTTER_TOOL_ENVIRONMENT}
    "${FLUTTER_ROOT}/packages/flutter_tools/bin/tool_backend.bat"
      windows-x64 $<CONFIG>
  VERBATIM
)
add_custom_target(flutter_assemble DEPENDS
  "${FLUTTER_LIBRARY}"
  ${FLUTTER_LIBRARY_HEADERS}
  ${CPP_WRAPPER_SOURCES_CORE}
  ${CPP_WRAPPER_SOURCES_PLUGIN}
  ${CPP_WRAPPER_SOURCES_APP}
)
```

----------------------------------------

TITLE: Displaying CLI Help Shell
DESCRIPTION: Executes the `autogpt.sh` script with the `--help` flag to show the available commands, options, and arguments for running AutoGPT from the command line. This helps users understand how to interact with the application.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_2

LANGUAGE: Shell
CODE:
```
./autogpt.sh --help
```

----------------------------------------

TITLE: Displaying Specific Command Help (Shell)
DESCRIPTION: Appends the `--help` flag to any specific command to display detailed help information, including a list of any additional options and arguments it accepts.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_1

LANGUAGE: sh
CODE:
```
./run COMMAND --help
```

----------------------------------------

TITLE: Displaying AutoGPT Run Help Shell
DESCRIPTION: This shell command displays the help message specifically for the `run` subcommand of AutoGPT. It lists all options and arguments applicable when running AutoGPT in CLI mode, such as `--continuous`, `--speak`, `--debug`, and various configuration overrides.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_2

LANGUAGE: shell
CODE:
```
$ ./autogpt.sh run --help
Usage: python -m autogpt run [OPTIONS]

  Sets up and runs an agent, based on the task specified by the user, or
  resumes an existing agent.

Options:
  -c, --continuous                Enable Continuous Mode
  -y, --skip-reprompt             Skips the re-prompting messages at the
                                  beginning of the script
  -l, --continuous-limit INTEGER  Defines the number of times to run in
                                  continuous mode
  --speak                         Enable Speak Mode
  --debug                         Enable Debug Mode
  --gpt3only                      Enable GPT3.5 Only Mode
  --gpt4only                      Enable GPT4 Only Mode
  --skip-news                     Specifies whether to suppress the output of
                                  latest news on startup.
  --install-plugin-deps           Installs external dependencies for 3rd party
                                  plugins.
  --ai-name TEXT                  AI name override
  --ai-role TEXT                  AI role override
  --constraint TEXT               Add or override AI constraints to include in
                                  the prompt; may be used multiple times to
                                  pass multiple constraints
  --resource TEXT                 Add or override AI resources to include in
                                  the prompt; may be used multiple times to
                                  pass multiple resources
  --best-practice TEXT            Add or override AI best practices to include
                                  in the prompt; may be used multiple times to
                                  pass multiple best practices
  --override-directives           If specified, --constraint, --resource and
                                  --best-practice will override the AI's
                                  directives instead of being appended to them
  --component-config-file TEXT    Path to the json configuration file.
  --help                          Show this message and exit.
```

----------------------------------------

TITLE: Integrating Flutter Tool Backend (CMake)
DESCRIPTION: Defines a custom command that invokes the Flutter tool backend script to generate necessary build outputs (Flutter library and headers) and a custom target `flutter_assemble` that depends on these generated outputs, ensuring the script runs during the build process.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/linux/flutter/CMakeLists.txt#_snippet_6

LANGUAGE: cmake
CODE:
```
# _phony_ is a non-existent file to force this command to run every time,
# since currently there's no way to get a full input/output list from the
# flutter tool.
add_custom_command(
  OUTPUT ${FLUTTER_LIBRARY} ${FLUTTER_LIBRARY_HEADERS}
    ${CMAKE_CURRENT_BINARY_DIR}/_phony_
  COMMAND ${CMAKE_COMMAND} -E env
    ${FLUTTER_TOOL_ENVIRONMENT}
    "${FLUTTER_ROOT}/packages/flutter_tools/bin/tool_backend.sh"
      ${FLUTTER_TARGET_PLATFORM} ${CMAKE_BUILD_TYPE}
  VERBATIM
)
add_custom_target(flutter_assemble DEPENDS
  "${FLUTTER_LIBRARY}"
  ${FLUTTER_LIBRARY_HEADERS}
)
```

----------------------------------------

TITLE: Formatting Code with Poetry - Bash
DESCRIPTION: This command executes the code formatter configured in the project via Poetry, ensuring code adheres to standard formatting rules.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_28

LANGUAGE: bash
CODE:
```
poetry run format
```

----------------------------------------

TITLE: Update APT Package List - Shell
DESCRIPTION: Runs the `apt update` command with root privileges (`sudo`) to refresh the list of available packages and their versions from the configured repositories. This step is crucial before installing new software to ensure the package manager has access to the latest package information.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_1

LANGUAGE: Shell
CODE:
```
sudo apt update
```

----------------------------------------

TITLE: Run Playwright Tests in View Mode (Debug)
DESCRIPTION: Adds the `--debug` flag to the test command, preventing browsers from closing after the test finishes. The browser windows remain open, allowing inspection of the final state of the page. Can be combined with `yarn test` or `yarn test-ui`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_2

LANGUAGE: bash
CODE:
```
yarn test --debug
```

----------------------------------------

TITLE: Developing with Docker Compose Watch Shell
DESCRIPTION: Initiates the 'watch' mode for Docker Compose, which monitors specified directories for code changes and automatically rebuilds or restarts services as needed. Streamlines the development feedback loop.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_17

LANGUAGE: Shell
CODE:
```
docker compose watch
```

----------------------------------------

TITLE: Watching Code Changes with Docker Compose - Bash
DESCRIPTION: This command, run in a separate terminal, uses Docker Compose's watch feature to automatically rebuild and restart services when code changes are detected.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_24

LANGUAGE: bash
CODE:
```
docker compose watch
```

----------------------------------------

TITLE: Forceful Docker Compose Shutdown/Restart - Bash
DESCRIPTION: This command performs a forceful shutdown, removing volumes and orphaned containers, followed by a recreate and restart, useful for resolving issues with dangling resources.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_26

LANGUAGE: bash
CODE:
```
docker compose down --volumes --remove-orphans && docker-compose up --force-recreate --renew-anon-volumes --remove-orphans
```

----------------------------------------

TITLE: Running Llamafile Server Shell
DESCRIPTION: This shell command sequence starts the downloaded llamafile executable in server mode. It includes options to prevent opening a browser (--nobrowser), set the context size based on the model's configuration (--ctx-size 0), and limit the maximum prediction length (--n-predict 1024).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/llm/providers/llamafile/README.md#_snippet_1

LANGUAGE: shell
CODE:
```
LLAMAFILE="./mistral-7b-instruct-v0.2.Q5_K_M.llamafile"

"${LLAMAFILE}" \
--server \
--nobrowser \
--ctx-size 0 \
--n-predict 1024

# note: ctx-size=0 means the prompt context size will be set directly from the
# underlying model configuration. This may cause slow response times or consume
# a lot of memory.
```

----------------------------------------

TITLE: Starting Storybook Development Server - Bash
DESCRIPTION: This command launches the Storybook development server. Storybook provides an isolated environment for building and testing UI components, typically available at http://localhost:6006 after starting.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/README.md#_snippet_2

LANGUAGE: bash
CODE:
```
npm run storybook
```

----------------------------------------

TITLE: Installing Python Requirements from File
DESCRIPTION: Installs dependencies listed in a `requirements.txt` file using pip. This is used when setting up agents like mini-agi that might not use Poetry.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_11

LANGUAGE: Shell
CODE:
```
pip install -r requirements.txt
```

----------------------------------------

TITLE: Watching Docker Compose Services for Changes Shell
DESCRIPTION: Watches for changes in the local codebase or configuration and automatically updates the corresponding services. This is particularly useful for development workflows.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_12

LANGUAGE: Shell
CODE:
```
docker compose watch
```

----------------------------------------

TITLE: Installing Project Dependencies with Poetry
DESCRIPTION: Installs all dependencies listed in the project's `pyproject.toml` file within the active Poetry virtual environment. Required after cloning the repository and starting the shell.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_7

LANGUAGE: Shell
CODE:
```
poetry install
```

----------------------------------------

TITLE: Defining Models for Union Field with Discriminator Python
DESCRIPTION: Provides examples of models (`Media`, `DeepLink`) used within a `Union` field with a discriminator. Each model includes a `discriminator` field with a distinct `Literal` value to identify its type.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_6

LANGUAGE: python
CODE:
```
class Media(BaseModel):
    discriminator: Literal['media']
    media_ids: List[str]

class DeepLink(BaseModel):
    discriminator: Literal['deep_link']
    direct_message_deep_link: str
```

----------------------------------------

TITLE: Cloning AutoGPT Repository - Bash
DESCRIPTION: This command clones the official AutoGPT repository from GitHub to your local machine, which contains all the project code required for self-hosting.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_2

LANGUAGE: bash
CODE:
```
git clone https://github.com/Significant-Gravitas/AutoGPT.git
```

----------------------------------------

TITLE: Starting Poetry Shell Environment
DESCRIPTION: Activates the virtual environment managed by Poetry for the current project. All subsequent commands in this shell will use the project's isolated dependencies.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_6

LANGUAGE: Shell
CODE:
```
poetry shell
```

----------------------------------------

TITLE: Executing Hardcoded File Write Step in AutoGPT Agent (Python)
DESCRIPTION: This `execute_step` implementation demonstrates a simple, hardcoded task execution. It creates a database record for the step, marks it as the last step, writes the string "Washington D.C." to `output.txt` in the workspace, records the created file as an artifact, sets the step's output, and logs the completion.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_1

LANGUAGE: python
CODE:
```
async def execute_step(self, task_id: str, step_request: StepRequestBody) -> Step:
    # An example that
      step = await self.db.create_step(
          task_id=task_id, input=step_request, is_last=True
      )

      self.workspace.write(task_id=task_id, path="output.txt", data=b"Washington D.C")

      await self.db.create_artifact(
          task_id=task_id,
          step_id=step.step_id,
          file_name="output.txt",
          relative_path="",
          agent_created=True,
      )
      
      step.output = "Washington D.C"

      LOG.info(f"\tâœ… Final Step completed: {step.step_id}")

      return step
```

----------------------------------------

TITLE: Run Flake8 Linter via python -m (Shell)
DESCRIPTION: Runs the flake8 linter by executing it as a Python module. Use this command if the flake8 executable is not directly in the system's PATH. It checks code in the current directory and requires python and the flake8 package to be installed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/testing.md#_snippet_6

LANGUAGE: shell
CODE:
```
python -m flake8 .
```

----------------------------------------

TITLE: Manually Pulling Ollama Model (Bash)
DESCRIPTION: This command explicitly downloads a specific language model from the Ollama library to the local machine. It's useful for troubleshooting 'Model Not Found' errors or pre-downloading models before attempting to run them.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/ollama.md#_snippet_3

LANGUAGE: bash
CODE:
```
ollama pull llama3.2
```

----------------------------------------

TITLE: Show AutoGPT CLI Usage - Shell
DESCRIPTION: This shell command demonstrates how to invoke the main AutoGPT command-line interface script './run' without any arguments to display its usage information. It lists the available global options and main commands like 'agent', 'benchmark', and 'setup' that are used to interact with various parts of the AutoGPT project.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/README.md#_snippet_0

LANGUAGE: shell
CODE:
```
$ ./run
Usage: cli.py [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  agent      Commands to create, start and stop agents
  benchmark  Commands to start the benchmark and list tests and categories
  setup      Installs dependencies needed for your system.
```

----------------------------------------

TITLE: Displaying Main AutoGPT Help Shell
DESCRIPTION: This shell command shows the main help message for the AutoGPT script, listing available options and sub-commands like `run` and `serve`. It's useful for discovering the top-level commands supported by the AutoGPT CLI.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_0

LANGUAGE: shell
CODE:
```
$ ./autogpt.sh --help
Usage: python -m autogpt [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  run    Sets up and runs an agent, based on the task specified by the...
  serve  Starts an Agent Protocol compliant AutoGPT server, which creates...
```

----------------------------------------

TITLE: Downloading and Verifying Llamafile Shell
DESCRIPTION: This snippet provides the shell commands required to download a specific quantized Mistral model in llamafile format, make the downloaded file executable, and verify its successful download and functionality by checking its version.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/llm/providers/llamafile/README.md#_snippet_0

LANGUAGE: shell
CODE:
```
wget -nc https://huggingface.co/jartine/Mistral-7B-Instruct-v0.2-llamafile/resolve/main/mistral-7b-instruct-v0.2.Q5_K_M.llamafile
chmod +x mistral-7b-instruct-v0.2.Q5_K_M.llamafile
./mistral-7b-instruct-v0.2.Q5_K_M.llamafile --version
```

----------------------------------------

TITLE: Listing Benchmark Tests (Shell)
DESCRIPTION: Uses the `benchmark tests list` command to display all available individual benchmark tests within the project.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_8

LANGUAGE: sh
CODE:
```
./run benchmark tests list
```

----------------------------------------

TITLE: Enter Poetry Virtual Environment Shell sh
DESCRIPTION: Activates the virtual environment managed by Poetry for the current shell session. This allows subsequent commands to use the project's specific Python interpreter and installed dependencies.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_8

LANGUAGE: sh
CODE:
```
poetry shell
```

----------------------------------------

TITLE: Run AutoGPT with Docker Compose (Install Plugin Deps) - Shell
DESCRIPTION: This command runs the 'auto-gpt' service in TTY mode and executes the command to install dependencies for all active plugins. This is useful when developing or updating plugins.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_8

LANGUAGE: shell
CODE:
```
docker compose run --rm auto-gpt run --install-plugin-deps
```

----------------------------------------

TITLE: Setting Flutter Library Paths and Headers (CMake)
DESCRIPTION: Defines CMake variables for the Flutter engine library path, ICU data file path, project build directory, AOT library path, and a list of Flutter library header files, making some available to parent scopes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/linux/flutter/CMakeLists.txt#_snippet_4

LANGUAGE: cmake
CODE:
```
set(FLUTTER_LIBRARY "${EPHEMERAL_DIR}/libflutter_linux_gtk.so")

# Published to parent scope for install step.
set(FLUTTER_LIBRARY ${FLUTTER_LIBRARY} PARENT_SCOPE)
set(FLUTTER_ICU_DATA_FILE "${EPHEMERAL_DIR}/icudtl.dat" PARENT_SCOPE)
set(PROJECT_BUILD_DIR "${PROJECT_DIR}/build/" PARENT_SCOPE)
set(AOT_LIBRARY "${PROJECT_DIR}/build/lib/libapp.so" PARENT_SCOPE)

list(APPEND FLUTTER_LIBRARY_HEADERS
  "fl_basic_message_channel.h"
  "fl_binary_codec.h"
  "fl_binary_messenger.h"
  "fl_dart_project.h"
  "fl_engine.h"
  "fl_json_message_codec.h"
  "fl_json_method_codec.h"
  "fl_message_codec.h"
  "fl_method_call.h"
  "fl_method_channel.h"
  "fl_method_codec.h"
  "fl_method_response.h"
  "fl_plugin_registrar.h"
  "fl_plugin_registry.h"
  "fl_standard_message_codec.h"
  "fl_standard_method_codec.h"
  "fl_string_codec.h"
  "fl_value.h"
  "fl_view.h"
  "flutter_linux.h"
)
list_prepend(FLUTTER_LIBRARY_HEADERS "${EPHEMERAL_DIR}/flutter_linux/")
```

----------------------------------------

TITLE: Setting AGENT_NAME Environment Variable
DESCRIPTION: Sets the `AGENT_NAME` environment variable, which is used by the benchmark runner to identify and load a specific agent implementation for testing.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_13

LANGUAGE: Shell
CODE:
```
AGENT_NAME=mini-agi
```

----------------------------------------

TITLE: Initializing Custom Agent AutoGPT Python
DESCRIPTION: This snippet demonstrates how to create a custom agent in AutoGPT by subclassing the base `Agent` class. It shows the `__init__` method calling the parent class's constructor using `super()` to inherit default components and logic, and then adding a custom component (`MyComponent`) to the new agent instance. This is the recommended approach for building custom agents with added functionality while reusing the core AutoGPT agent structure.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/original_autogpt/autogpt/agents/README.md#_snippet_0

LANGUAGE: python
CODE:
```
class MyComponent(AgentComponent):
    pass

class MyAgent(Agent):
    def __init__(
        self,
        settings: AgentSettings,
        llm_provider: MultiProvider
        file_storage: FileStorage,
        app_config: AppConfig,
    ):
        # Call the parent constructor to bring in the default components
        super().__init__(settings, llm_provider, file_storage, app_config)
        # Add your custom component
        self.my_component = MyComponent()
```

----------------------------------------

TITLE: Copying Frontend Environment File Shell
DESCRIPTION: Copies the '.env.example' file to '.env.local' in the 'frontend' directory. The '.env.local' file is used to configure environment variables specifically for the frontend application.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_4

LANGUAGE: Shell
CODE:
```
cp .env.example .env.local
```

----------------------------------------

TITLE: Reading Test Info in Playwright Test (TypeScript)
DESCRIPTION: This snippet demonstrates how to access data that has been previously stored on the `testInfo` object within a standard Playwright `test` function. The `testInfo` object is provided as a parameter to the test callback, allowing the test to retrieve information passed from setup hooks like `beforeAll`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_8

LANGUAGE: typescript
CODE:
```
  test("test can read the agent id", async ({ page }, testInfo) => {
    --8<-- "autogpt_platform/frontend/src/tests/monitor.spec.ts:ReadAgentId"
    /// ... Do something with the agent id here
  });
});
```

----------------------------------------

TITLE: Listing Benchmark Categories (Shell)
DESCRIPTION: Uses the `benchmark categories list` command to display all available categories that benchmark tests are organized under.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_7

LANGUAGE: sh
CODE:
```
./run benchmark categories list
```

----------------------------------------

TITLE: Define Docker Compose Config (> v0.4.7) - YAML
DESCRIPTION: This YAML configuration defines a service named 'auto-gpt' for Docker Compose, intended for AutoGPT versions greater than v0.4.7. It specifies the Docker image, environment file, profile exclusion, volume mounts for data and logs, and optionally maps port 8000.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_3

LANGUAGE: yaml
CODE:
```
version: "3.9"
services:
  auto-gpt:
    image: significantgravitas/auto-gpt
    env_file:
      - .env
    ports:
      - "8000:8000"  # remove this if you just want to run a single agent in TTY mode
    profiles: ["exclude-from-up"]
    volumes:
      - ./data:/app/data
      ## allow auto-gpt to write logs to disk
      - ./logs:/app/logs
      ## uncomment following lines if you want to make use of these files
      ## you must have them existing in the same folder as this docker-compose.yml
      ## component configuration file
      #- type: bind
      #  source: ./config.json
      #  target: /app/config.json
```

----------------------------------------

TITLE: Starting Database Container (Alternative Setup) - Bash
DESCRIPTION: This command uses Docker Compose to start only the database service (`db`) in detached mode (`-d`), which is a prerequisite for running database migrations.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_18

LANGUAGE: bash
CODE:
```
docker compose up db -d
```

----------------------------------------

TITLE: Generating Encryption Key (Poetry CLI) - Bash
DESCRIPTION: This command uses the AutoGPT backend's command-line interface, executed via Poetry, to generate a new encryption key for the application's environment configuration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_10

LANGUAGE: bash
CODE:
```
poetry run cli gen-encrypt-key
```

----------------------------------------

TITLE: Defining Standard Compilation Settings Function in CMake
DESCRIPTION: Defines a CMake function `APPLY_STANDARD_SETTINGS` that takes a target name. This function applies C++17 standard compliance, sets compiler options like warning level (/W4), treats warnings as errors (/WX), disables specific warnings (/wd"4100"), enables standard exception handling (/EHsc), disables C++ exceptions for the target, and defines _DEBUG for the Debug configuration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_4

LANGUAGE: CMake
CODE:
```
function(APPLY_STANDARD_SETTINGS TARGET)
  target_compile_features(${TARGET} PUBLIC cxx_std_17)
  target_compile_options(${TARGET} PRIVATE /W4 /WX /wd"4100")
  target_compile_options(${TARGET} PRIVATE /EHsc)
  target_compile_definitions(${TARGET} PRIVATE "_HAS_EXCEPTIONS=0")
  target_compile_definitions(${TARGET} PRIVATE "$<$<CONFIG:Debug>:_DEBUG>")
endfunction()
```

----------------------------------------

TITLE: Creating AutoGPT Command Object Directly - Python
DESCRIPTION: Provides an alternative method to define commands by directly instantiating a `Command` object. It links the raw method (`self.multiply`) to the command definition and explicitly lists parameters using `CommandParameter` with `JSONSchema` specifications. This approach bypasses the `@command` decorator but requires manual definition of command metadata.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/commands.md#_snippet_4

LANGUAGE: python
CODE:
```
def multiply(self, a: int, b: int) -> str:`
`        return str(a * b)`

`def get_commands(self) -> Iterator[Command]:`
`    yield Command(`
`        names=["multiply"],`
`        description="Multiplies two numbers.",`
`        method=self.multiply,`
`        parameters=[`
`            CommandParameter(name="a", spec=JSONSchema(`
`                type=JSONSchema.Type.INTEGER,`
`                description="The first number",`
`                required=True,`
`            )),`
`            CommandParameter(name="b", spec=JSONSchema(`
`                type=JSONSchema.Type.INTEGER,`
`                description="The second number",`
`                required=True,`
`            )),`
`        ],`
`    )
```

----------------------------------------

TITLE: Starting an Agent (Shell)
DESCRIPTION: Uses the `agent start` command followed by the agent's name ('my_agent') to start the specified agent, which typically initializes its server on port 8000.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_5

LANGUAGE: sh
CODE:
```
./run agent start my_agent
```

----------------------------------------

TITLE: Setting Step Output from LLM Response - Python
DESCRIPTION: Sets the `output` property of the current step object using the natural language summary from the LLM's response (`answer["thoughts"]["speak"]`). Finally, it returns the completed step object to signal the end of processing for this step.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_14

LANGUAGE: Python
CODE:
```
# Set the step output to the "speak" part of the answer
step.output = answer["thoughts"]["speak"]

# Return the completed step
return step
```

----------------------------------------

TITLE: Running Storybook CI Tests - Bash
DESCRIPTION: This command runs Storybook tests specifically configured for Continuous Integration (CI) environments. It's used in automated workflows to validate component behavior and appearance upon code changes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/README.md#_snippet_5

LANGUAGE: bash
CODE:
```
npm run test-storybook:ci
```

----------------------------------------

TITLE: Defining SVG Arrow Component - React/JSX
DESCRIPTION: Defines a reusable React functional component `RightArrow` that renders a small SVG arrow icon. This component is used inline within `<a>` tags throughout the MDX content to provide a visual indicator next to links.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/src/stories/Configure.mdx#_snippet_1

LANGUAGE: javascript
CODE:
```
export const RightArrow = () => (
  <svg
    viewBox="0 0 14 14"
    width="8px"
    height="14px"
    style={{
      marginLeft: "4px",
      display: "inline-block",
      shapeRendering: "inherit",
      verticalAlign: "middle",
      fill: "currentColor",
      "path fill": "currentColor",
    }}
  >
    <path d="m11.1 7.35-5.5 5.5a.5.5 0 0 1-.7-.7L10.04 7 4.9 1.85a.5.5 0 1 1 .7-.7l5.5 5.5c.2.2.2.5 0 .7Z" />
  </svg>
);
```

----------------------------------------

TITLE: Building MkDocs Site (Shell)
DESCRIPTION: Builds the static HTML documentation site from the source files. This command is used here specifically to check for warnings, including broken links, in the build output. Requires MkDocs to be installed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/contribute/index.md#_snippet_4

LANGUAGE: shell
CODE:
```
mkdocs build
```

----------------------------------------

TITLE: Running Information Retrieval Challenge Test with Pytest (Shell)
DESCRIPTION: Executes the pytest test suite specifically for the Information Retrieval Challenge B test file. This command is used to verify the agent's ability to find and write information about the 2010 Nobel Physics laureates. The `-s` flag displays standard output from the test.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/information_retrieval/challenge_b.md#_snippet_0

LANGUAGE: Shell
CODE:
```
pytest -s tests/challenges/information_retrieval/test_information_retrieval_challenge_b.py
```

----------------------------------------

TITLE: Adding API Key Credentials to Block Input Schema Python
DESCRIPTION: Shows how to include an `APIKeyCredentials` field in the block's `Input` schema using `CredentialsMetaInput` and `CredentialsField`. This declares that the block requires an API key credential for a specific provider.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_8

LANGUAGE: python
CODE:
```
from backend.data.model import (
    APIKeyCredentials,
    OAuth2Credentials,
    Credentials,
)

from backend.data.block import Block, BlockOutput, BlockSchema
from backend.data.model import CredentialsField
from backend.integrations.providers import ProviderName


# API Key auth:
class BlockWithAPIKeyAuth(Block):
    class Input(BlockSchema):
        # Note that the type hint below is require or you will get a type error.
        # The first argument is the provider name, the second is the credential type.
        credentials: CredentialsMetaInput[
            Literal[ProviderName.GITHUB], Literal["api_key"]
        ] = CredentialsField(
            description="The GitHub integration can be used with "
            "any API key with sufficient permissions for the blocks it is used on.",
        )
```

----------------------------------------

TITLE: Implementing CommandProvider with Command Decorator - Python Example
DESCRIPTION: This example demonstrates implementing `CommandProvider` to provide a `multiply` command using the `@command` decorator. It shows how to define command parameters with descriptions and types using `JSONSchema` and make the command available to the agent via `get_commands`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_3

LANGUAGE: Python
CODE:
```
from forge.agent import CommandProvider, Component
from forge.command import command
from forge.models.json_schema import JSONSchema


class CalculatorComponent(CommandProvider):
    get_commands(self) -> Iterator[Command]:
        yield self.multiply

    @command(parameters={
            "a": JSONSchema(
                type=JSONSchema.Type.INTEGER,
                description="The first number",
                required=True,
            ),
            "b": JSONSchema(
                type=JSONSchema.Type.INTEGER,
                description="The second number",
                required=True,
            )})
    def multiply(self, a: int, b: int) -> str:
        """
        Multiplies two numbers.
        
        Args:
            a: First number
            b: Second number

        Returns:
            Result of multiplication
        """
        return str(a * b)
```

----------------------------------------

TITLE: Show AutoGPT Benchmark CLI Usage - Shell
DESCRIPTION: Displays the help information and command structure for the AutoGPT benchmark command-line interface. It outlines the available subcommands like `categories`, `start`, and `tests`, and how to access further details or list options for each.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_8

LANGUAGE: Shell
CODE:
```
./run benchmark
Usage: cli.py benchmark [OPTIONS] COMMAND [ARGS]...

  Commands to start the benchmark and list tests and categories

Options:
  --help  Show this message and exit.

Commands:
  categories  Benchmark categories group command
  start       Starts the benchmark command
  tests       Benchmark tests group command
./run benchmark categories
Usage: cli.py benchmark categories [OPTIONS] COMMAND [ARGS]...

  Benchmark categories group command

Options:
  --help  Show this message and exit.

Commands:
  list  List benchmark categories command
./run benchmark tests
Usage: cli.py benchmark tests [OPTIONS] COMMAND [ARGS]...

  Benchmark tests group command

Options:
  --help  Show this message and exit.

Commands:
  details  Benchmark test details command
  list     List benchmark tests command
```

----------------------------------------

TITLE: Configuring Installation Directories and Default Install in CMake
DESCRIPTION: Defines variables for the build bundle directory, sets the installation step to be included in the default build for Visual Studio, and sets the default installation prefix to the build bundle directory. It also defines variables for the data and library subdirectories within the installation prefix.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_6

LANGUAGE: CMake
CODE:
```
# === Installation ===
# Support files are copied into place next to the executable, so that it can
# run in place. This is done instead of making a separate bundle (as on Linux)
# so that building and running from within Visual Studio will work.
set(BUILD_BUNDLE_DIR "$<TARGET_FILE_DIR:${BINARY_NAME}>")
# Make the "install" step default, as it's required to run.
set(CMAKE_VS_INCLUDE_INSTALL_TO_DEFAULT_BUILD 1)
if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT)
  set(CMAKE_INSTALL_PREFIX "${BUILD_BUNDLE_DIR}" CACHE PATH "..." FORCE)
endif()

set(INSTALL_BUNDLE_DATA_DIR "${CMAKE_INSTALL_PREFIX}/data")
set(INSTALL_BUNDLE_LIB_DIR "${CMAKE_INSTALL_PREFIX}")
```

----------------------------------------

TITLE: Executing AutoGPT CLI - Shell
DESCRIPTION: This snippet demonstrates how to execute the main AutoGPT command-line interface using the `./run` script. Running the script without arguments displays the available top-level commands, such as `agent`, `benchmark`, and `setup`, along with their brief descriptions. It requires the AutoGPT project structure with an executable `./run` script.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/index.md#_snippet_0

LANGUAGE: shell
CODE:
```
$ ./run
Usage: cli.py [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  agent      Commands to create, start and stop agents
  benchmark  Commands to start the benchmark and list tests and categories
  setup      Installs dependencies needed for your system.
```

----------------------------------------

TITLE: Removing Inherited Agent Components in Python
DESCRIPTION: This Python snippet shows how to effectively remove an Agent Component that is inherited from a parent class by setting the corresponding attribute to `None` within the agent's `__init__` method. This prevents the component from being included in the agent's active components.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/components.md#_snippet_8

LANGUAGE: Python
CODE:
```
class MyAgent(Agent):
    def __init__(self):
        super().__init__(...)
        # Disable WatchdogComponent that is in the parent class
        self.watchdog = None
```

----------------------------------------

TITLE: Configuring Application Wrapper Library CMake
DESCRIPTION: Adds a STATIC library target named 'flutter_wrapper_app' using the core and application wrapper source files. It applies standard settings, links it publicly to the 'flutter' interface library, sets its public include directories, and adds a dependency on the `flutter_assemble` target. This library is typically used by the application runner.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_6

LANGUAGE: cmake
CODE:
```
# Wrapper sources needed for the runner.
add_library(flutter_wrapper_app STATIC
  ${CPP_WRAPPER_SOURCES_CORE}
  ${CPP_WRAPPER_SOURCES_APP}
)
apply_standard_settings(flutter_wrapper_app)
target_link_libraries(flutter_wrapper_app PUBLIC flutter)
target_include_directories(flutter_wrapper_app PUBLIC
  "${WRAPPER_ROOT}/include"
)
add_dependencies(flutter_wrapper_app flutter_assemble)
```

----------------------------------------

TITLE: List AutoGPT Benchmark Tests - Shell
DESCRIPTION: Runs the command `./run benchmark tests list` to show a comprehensive list of all individual benchmark tests available within the AutoGPT benchmarking system. Users can use this list to identify specific tests they might want to run.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_10

LANGUAGE: Shell
CODE:
```
./run benchmark tests list
```

----------------------------------------

TITLE: Starting MkDocs Development Server (Shell)
DESCRIPTION: Starts a local HTTP server using MkDocs that serves the documentation website. The server provides live reloading, automatically refreshing the browser when source files are modified. Requires MkDocs to be installed and the project configured.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/contribute/index.md#_snippet_3

LANGUAGE: shell
CODE:
```
mkdocs serve
```

----------------------------------------

TITLE: Running Memory Challenge Test with Pytest (Shell)
DESCRIPTION: Executes the specified pytest file (`tests/challenges/memory/test_memory_challenge_d.py`) to run the memory challenge test. The `--level=1` flag indicates that only level 1 of the challenge is run. This command requires pytest to be installed and configured for the project.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/memory/challenge_d.md#_snippet_0

LANGUAGE: shell
CODE:
```
pytest -s tests/challenges/memory/test_memory_challenge_d.py --level=1
```

----------------------------------------

TITLE: Defining BlockWebhookConfig Model - Python
DESCRIPTION: The `BlockWebhookConfig` Pydantic model specifies the configuration required for a webhook-triggered block. It includes the `provider` string (identifying the webhook source, e.g., 'github') and `event_filter_input` string (the name of the input field used to filter events).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_14

LANGUAGE: python
CODE:
```
# Example taken from autogpt_platform/backend/backend/data/block.py
# This code defines the Pydantic model for webhook configuration

from pydantic import BaseModel

class BlockWebhookConfig(BaseModel):
    provider: str
    event_filter_input: str
```

----------------------------------------

TITLE: Convert Script Line Endings with dos2unix - Shell
DESCRIPTION: Applies the `dos2unix` utility to the `./run` script to convert its line endings from Windows (CRLF) to Unix/Linux (LF). This action is a common fix for `FileNotFoundError` or 'No such file or directory' errors encountered when trying to execute the script in WSL due to line ending compatibility issues.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_3

LANGUAGE: Shell
CODE:
```
dos2unix ./run
```

----------------------------------------

TITLE: Accessing Credential Tokens Directly for API Calls (Python)
DESCRIPTION: Demonstrates how to manually access the raw API key or access token from `APIKeyCredentials` or `OAuth2Credentials` objects, respectively, using the `.get_secret_value()` method. This allows for constructing standard HTTP `Authorization` headers for making authenticated requests to external services.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_11

LANGUAGE: python
CODE:
```
# credentials: APIKeyCredentials
response = requests.post(
    url,
    headers={
        "Authorization": f"Bearer {credentials.api_key.get_secret_value()})",
    },
)

# credentials: OAuth2Credentials
response = requests.post(
    url,
    headers={
        "Authorization": f"Bearer {credentials.access_token.get_secret_value()})",
    },
)
```

----------------------------------------

TITLE: Finding System Dependencies (GTK, GLIB, GIO) (CMake)
DESCRIPTION: Uses `find_package` and `pkg_check_modules` with PkgConfig to locate required system libraries like GTK 3.0, GLib 2.0, and GIO 2.0, creating imported targets for linking.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/linux/flutter/CMakeLists.txt#_snippet_3

LANGUAGE: cmake
CODE:
```
find_package(PkgConfig REQUIRED)
pkg_check_modules(GTK REQUIRED IMPORTED_TARGET gtk+-3.0)
pkg_check_modules(GLIB REQUIRED IMPORTED_TARGET glib-2.0)
pkg_check_modules(GIO REQUIRED IMPORTED_TARGET gio-2.0)
```

----------------------------------------

TITLE: Example Agent Component Configuration (JSON)
DESCRIPTION: Provides a sample JSON structure for configuring various built-in AutoGPT components. Configuration settings are nested under the component's configuration class name.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/forge/components/README.md#_snippet_4

LANGUAGE: json
CODE:
```
{
    "CodeExecutorConfiguration": {
        "execute_local_commands": false,
        "shell_command_control": "allowlist",
        "shell_allowlist": ["cat", "echo"],
        "shell_denylist": [],
        "docker_container_name": "agent_sandbox"
    },
    "FileManagerConfiguration": {
        "storage_path": "agents/AutoGPT/",
        "workspace_path": "agents/AutoGPT/workspace"
    },
    "GitOperationsConfiguration": {
        "github_username": null
    },
    "ActionHistoryConfiguration": {
        "llm_name": "gpt-3.5-turbo",
        "max_tokens": 1024,
        "spacy_language_model": "en_core_web_sm"
    },
    "ImageGeneratorConfiguration": {
        "image_provider": "dalle",
        "huggingface_image_model": "CompVis/stable-diffusion-v1-4",
        "sd_webui_url": "http://localhost:7860"
    },
    "WebSearchConfiguration": {
        "duckduckgo_max_attempts": 3
    },
    "WebSeleniumConfiguration": {
        "llm_name": "gpt-3.5-turbo",
        "web_browser": "chrome",
        "headless": true,
        "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36",
        "browse_spacy_language_model": "en_core_web_sm"
    }
}
```

----------------------------------------

TITLE: Uninstalling Global Prisma - Bash
DESCRIPTION: This command is a potential mitigation step to uninstall a globally installed Prisma package using pip if Prisma generates the client outside the intended Poetry virtual environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_17

LANGUAGE: bash
CODE:
```
pip uninstall prisma
```

----------------------------------------

TITLE: Load Playwright Session for Test Generation
DESCRIPTION: Runs the test generation tool (`gentests`) with the `--load-storage` flag, loading a previously saved authenticated user session from the specified JSON file. This enables test generation or execution without requiring a manual login step each time.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_5

LANGUAGE: bash
CODE:
```
yarn gentests --load-storage .auth/gentest-user.json
```

----------------------------------------

TITLE: Enabling Text-to-Speech for AutoGPT using Shell
DESCRIPTION: This command starts the AutoGPT application with the Text-to-Speech feature enabled, allowing AutoGPT to vocalize its output. It is passed as a flag to the main AutoGPT script.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/configuration/voice.md#_snippet_0

LANGUAGE: shell
CODE:
```
./autogpt.sh --speak
```

----------------------------------------

TITLE: Running Pytest for Memory Challenge C (Shell)
DESCRIPTION: This shell command executes the Pytest suite specifically designed for Memory Challenge C. It uses the -s flag to show standard output and targets the test_memory_challenge_c.py file, setting the challenge difficulty level to 2. This is used to run the test and evaluate the agent's performance on the challenge.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/memory/challenge_c.md#_snippet_0

LANGUAGE: shell
CODE:
```
pytest -s tests/challenges/memory/test_memory_challenge_c.py --level=2
```

----------------------------------------

TITLE: Executing Information Retrieval Challenge A Test - Shell
DESCRIPTION: This shell command executes the pytest test suite specifically designed for the Information Retrieval Challenge A within the AutoGPT project. It targets the `test_information_retrieval_challenge_a.py` file and sets the challenge difficulty level to 2 using the `--level=2` flag. This is used to test the agent's performance on the specified challenge level.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/information_retrieval/challenge_a.md#_snippet_0

LANGUAGE: Shell
CODE:
```
pytest -s tests/challenges/information_retrieval/test_information_retrieval_challenge_a.py --level=2
```

----------------------------------------

TITLE: Installing Poetry Package Manager
DESCRIPTION: Installs Poetry, a Python dependency manager, which is used for development and contribution to the `auto-gpt-benchmarks` project. It manages project dependencies and virtual environments.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_5

LANGUAGE: Shell
CODE:
```
pip install poetry
```

----------------------------------------

TITLE: Defining AfterParse Protocol Interface - Python
DESCRIPTION: This snippet defines the abstract `AfterParse` protocol, an interface for `AgentComponent`s. Components implementing this protocol have their `after_parse` method called after the agent's response from the LLM has been successfully parsed, receiving the parsed `ThoughtProcessOutput`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_6

LANGUAGE: Python
CODE:
```
class AfterParse(AgentComponent):
    def after_parse(self, response: ThoughtProcessOutput) -> None:
        ...
```

----------------------------------------

TITLE: Running Flutter Web App (Flutter)
DESCRIPTION: Builds and launches the Flutter application targeting the Chrome browser as a web application on port 5000. The commented lines provide an optional configuration step specifically for Linux users who use Chromium, helping to locate the executable if needed.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/README.md#_snippet_3

LANGUAGE: Flutter
CODE:
```
#For chromium users on linux:\n#export CHROME_EXECUTABLE=/usr/bin/chromium\nflutter run -d chrome --web-port 5000
```

----------------------------------------

TITLE: Start Docker Compose with Build bash
DESCRIPTION: Changes directory to `autogpt_platform/` and runs the `docker compose up` command in detached mode (`-d`) with the `--build` flag. This command starts the services defined in `docker-compose.yml` (like PostgreSQL) and builds images if necessary.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_4

LANGUAGE: bash
CODE:
```
cd autogpt_platform/
docker compose up -d --build
```

----------------------------------------

TITLE: Executing Pytest for Memory Challenge B
DESCRIPTION: This shell command runs the specific Pytest test file for 'Memory Challenge B' within the AutoGPT project. The `--level=3` flag specifies the difficulty level for the challenge instance. The `-s` flag likely ensures that standard output is displayed during the test execution.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/memory/challenge_b.md#_snippet_0

LANGUAGE: shell
CODE:
```
pytest -s tests/challenges/memory/test_memory_challenge_b.py --level=3
```

----------------------------------------

TITLE: Implementing AfterParse for Logging Response - Python Example
DESCRIPTION: This example demonstrates implementing the `AfterParse` protocol to log the agent's response after it has been parsed. The `after_parse` method receives the `ThoughtProcessOutput` and uses a `logger` to record its content.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_7

LANGUAGE: Python
CODE:
```
class LoggerComponent(AfterParse):
    def after_parse(self, response: ThoughtProcessOutput) -> None:
        logger.info(f"Response: {response}")
```

----------------------------------------

TITLE: Cloning AutoGPT Repository (Git)
DESCRIPTION: Clones the official AutoGPT repository from GitHub to your local machine. This command initiates the download of the entire project codebase, which is the first step required before navigating to the frontend directory and setting up the client.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/README.md#_snippet_0

LANGUAGE: Git
CODE:
```
git clone https://github.com/Significant-Gravitas/AutoGPT.git
```

----------------------------------------

TITLE: Including Generated Configuration CMake
DESCRIPTION: Includes a CMake configuration file (`generated_config.cmake`) produced by the Flutter tool, which provides build-specific variables. It also sets the WRAPPER_ROOT variable pointing to the location of the C++ client wrapper source code.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_1

LANGUAGE: cmake
CODE:
```
include(${EPHEMERAL_DIR}/generated_config.cmake)

# TODO: Move the rest of this into files in ephemeral. See
# https://github.com/flutter/flutter/issues/57146.
set(WRAPPER_ROOT "${EPHEMERAL_DIR}/cpp_client_wrapper")
```

----------------------------------------

TITLE: Running AutoGPT with Custom AI Settings Shell
DESCRIPTION: This shell command demonstrates how to start AutoGPT using a specific AI settings file provided via the `--ai-settings` argument. This allows users to define the AI's configuration (name, role, goals, etc.) in an external file.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_5

LANGUAGE: shell
CODE:
```
./autogpt.sh --ai-settings <filename>
```

----------------------------------------

TITLE: Example Playwright Page Object (TypeScript)
DESCRIPTION: Illustrates a partial example of a Playwright Page Object class (`ProfilePage`) in TypeScript. It demonstrates extending a `BasePage` and defines placeholders for page-specific locators and interaction methods, adhering to the Page Object Model pattern for test organization.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_6

LANGUAGE: typescript
CODE:
```
class ProfilePage extends BasePage {
  // Example locators and methods for the Profile page
  // ...
}
```

----------------------------------------

TITLE: Running AutoGPT in Continuous Mode Shell
DESCRIPTION: This shell command starts AutoGPT in continuous mode, where the AI operates without requiring explicit user authorization for each action. This mode is potentially dangerous and should be used with caution, typically for testing in sandboxed environments.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_3

LANGUAGE: shell
CODE:
```
./autogpt.sh --continuous
```

----------------------------------------

TITLE: Implementing AfterExecute for Logging Result - Python Example
DESCRIPTION: This example demonstrates implementing the `AfterExecute` protocol to log the result after a command is successfully executed. The `after_execute` method receives the `ActionResult` and uses a `logger` to record the result details.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/forge/components/protocols.md#_snippet_11

LANGUAGE: Python
CODE:
```
class LoggerComponent(AfterExecute):
    def after_execute(self, result: ActionResult) -> None:
        logger.info(f"Result: {result}")
```

----------------------------------------

TITLE: Run Llamafile Serve Script (Standard) Shell
DESCRIPTION: Executes the main 'serve.py' script located in the AutoGPT repository to start the llamafile server. The first execution downloads the model file. The optional '--use-gpu' argument can be added to leverage GPU acceleration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_13

LANGUAGE: shell
CODE:
```
python3 ./scripts/llamafile/serve.py
```

----------------------------------------

TITLE: Setting Page Metadata - Storybook/MDX
DESCRIPTION: Uses the Storybook-provided `Meta` component within an MDX file to set page-specific metadata. In this case, it sets the `title` property, which typically controls the display name of this documentation page in the Storybook sidebar.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/src/stories/Configure.mdx#_snippet_2

LANGUAGE: mdx
CODE:
```
<Meta title="Configure your project" />
```

----------------------------------------

TITLE: Run AutoGPT with Docker Compose (TTY Continuous) - Shell
DESCRIPTION: This command runs the 'auto-gpt' service in interactive TTY mode with the `--continuous` flag, allowing it to run autonomously without requiring manual input for each action.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_7

LANGUAGE: shell
CODE:
```
docker compose run --rm auto-gpt run --continuous
```

----------------------------------------

TITLE: Adding Unicode Definitions in CMake
DESCRIPTION: Adds preprocessor definitions -DUNICODE and -D_UNICODE to all compilation units. This ensures that the application is built with Unicode support enabled, which is important for handling international characters.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_3

LANGUAGE: CMake
CODE:
```
add_definitions(-DUNICODE -D_UNICODE)
```

----------------------------------------

TITLE: Linking Libraries (Flutter & Windows)
DESCRIPTION: Links the executable target against required libraries. This includes the Flutter engine library, the Flutter wrapper library for the application, and the Windows Desktop Window Manager API library (dwmapi.lib).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_6

LANGUAGE: CMake
CODE:
```
target_link_libraries(${BINARY_NAME} PRIVATE flutter flutter_wrapper_app)
target_link_libraries(${BINARY_NAME} PRIVATE "dwmapi.lib")
```

----------------------------------------

TITLE: Run AutoGPT with Docker Compose (Basic) - Shell
DESCRIPTION: This command runs the 'auto-gpt' service defined in the docker-compose.yml file. The `--rm` flag ensures the container is automatically removed after it exits, keeping the system clean.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_5

LANGUAGE: shell
CODE:
```
docker compose run --rm auto-gpt
```

----------------------------------------

TITLE: Configuring Project and Binary Name in CMake
DESCRIPTION: Sets the minimum required CMake version, defines the project name and language, assigns the desired executable binary name, and explicitly enables modern CMake policies to ensure compatibility and avoid warnings.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.14)
project(auto_gpt_flutter_client LANGUAGES CXX)

# The name of the executable created for the application. Change this to change
# the on-disk name of your application.
set(BINARY_NAME "auto_gpt_flutter_client")

# Explicitly opt in to modern CMake behaviors to avoid warnings with recent
# versions of CMake.
cmake_policy(SET CMP0063 NEW)
```

----------------------------------------

TITLE: List AutoGPT Benchmark Categories - Shell
DESCRIPTION: Executes the command `./run benchmark categories list` to display the names of the different categories under which benchmark tests are grouped. This command helps users discover the various areas of agent capability that can be evaluated.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_9

LANGUAGE: Shell
CODE:
```
./run benchmark categories list
```

----------------------------------------

TITLE: Extracting Ability Details from LLM Response - Python
DESCRIPTION: Accesses the parsed JSON response from the LLM (`answer`) to extract the details of the ability the LLM decided to execute. It retrieves the dictionary located under the "ability" key.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_12

LANGUAGE: Python
CODE:
```
# Extract the ability from the answer
ability = answer["ability"]
```

----------------------------------------

TITLE: Running Auto-GPT Benchmark Mock Tests
DESCRIPTION: Executes only the mock tests within the benchmark suite. This flag is useful for quickly testing infrastructure or agent responses against predefined mock data without requiring full agent execution.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_3

LANGUAGE: Shell
CODE:
```
agbenchmark --mock
```

----------------------------------------

TITLE: Generate Default Prisma Client with Poetry sh
DESCRIPTION: Executes the default Prisma client generation command (`prisma generate`) using Poetry within the virtual environment. This command generates the client code based on the primary `schema.prisma` file.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_11

LANGUAGE: sh
CODE:
```
poetry run prisma generate
```

----------------------------------------

TITLE: Example Secret File Content bash
DESCRIPTION: Shows the structure of a secret file located in the `./secrets` directory, where the server automatically loads secrets. This example depicts the content for a secret named `my_secret` for secure configuration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_2

LANGUAGE: bash
CODE:
```
# ./secrets/my_secret
my_secret_value
```

----------------------------------------

TITLE: Run Prisma Deployment Migrations sh
DESCRIPTION: Changes directory to the `backend` folder and applies Prisma database migrations using the `migrate deploy` command. This command is used for applying migrations in production or deployment environments.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_14

LANGUAGE: sh
CODE:
```
cd ../backend
prisma migrate deploy
```

----------------------------------------

TITLE: Viewing Docker Compose Service Logs Shell
DESCRIPTION: Displays and follows the output logs for specified services ('api_srv', 'ws_srv'). This is essential for monitoring service behavior, debugging issues, and understanding runtime events.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_14

LANGUAGE: Shell
CODE:
```
docker compose logs -f api_srv ws_srv
```

----------------------------------------

TITLE: Get WSL Host IP Address Shell
DESCRIPTION: Executes shell commands within the WSL environment to determine the IP address of the Windows host machine. This IP is needed to allow AutoGPT running in WSL to connect to the llamafile server running on Windows.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_10

LANGUAGE: shell
CODE:
```
ip route | grep default | awk '{print \$3}'
```

----------------------------------------

TITLE: Creating Env File Shell
DESCRIPTION: Copies the `.env.template` file to `.env` using the `cp` command in a shell or terminal. This is the standard way to create the configuration file from the provided template on Linux/macOS or WSL.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_0

LANGUAGE: Shell
CODE:
```
cp .env.template .env
```

----------------------------------------

TITLE: Adding Include Directories
DESCRIPTION: Adds the source directory of the project to the include paths for the executable target. This allows source files to include headers located within the project's main source tree.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_7

LANGUAGE: CMake
CODE:
```
target_include_directories(${BINARY_NAME} PRIVATE "${CMAKE_SOURCE_DIR}")
```

----------------------------------------

TITLE: Checking Docker & Docker Compose Version - Bash
DESCRIPTION: These commands check the installed versions of Docker and Docker Compose. Docker is used to containerize applications, and Docker Compose orchestrates multi-container applications, both essential for running AutoGPT services.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_1

LANGUAGE: bash
CODE:
```
docker -v
docker compose -v
```

----------------------------------------

TITLE: Install Poetry Dependency Manager sh
DESCRIPTION: Uses `pip` to install the Poetry package manager, which is used to manage project dependencies for the AutoGPT server. This is the initial step in setting up the Python environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_6

LANGUAGE: sh
CODE:
```
pip install poetry
```

----------------------------------------

TITLE: Importing Base Block Classes Python
DESCRIPTION: Imports the necessary base classes `Block`, `BlockSchema`, and `BlockOutput` required for defining a custom block component within the AutoGPT backend framework.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_0

LANGUAGE: python
CODE:
```
from backend.data.block import Block, BlockSchema, BlockOutput
```

----------------------------------------

TITLE: Example Environment Variables .env bash
DESCRIPTION: Illustrates the structure of a `.env` file used to configure the AutoGPT server by defining key-value pairs as environment variables. This file is automatically loaded by the server on startup.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_0

LANGUAGE: bash
CODE:
```
# .env
KEY1=value1
KEY2=value2
```

----------------------------------------

TITLE: Linting Code with Poetry - Bash
DESCRIPTION: This command executes the code linter configured in the project via Poetry, checking for potential errors, stylistic issues, and adherence to coding standards.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_29

LANGUAGE: bash
CODE:
```
poetry run lint
```

----------------------------------------

TITLE: Build AutoGPT Docker Image (Vanilla Docker) - Shell
DESCRIPTION: This command builds a Docker image from a Dockerfile in the current directory and tags it as 'autogpt'. This is an alternative to using the pre-built image from Docker Hub.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_9

LANGUAGE: shell
CODE:
```
docker build -t autogpt .
```

----------------------------------------

TITLE: Debug Specific Playwright Test with UI
DESCRIPTION: Uses the `--debug` flag and `--test-name-pattern` to open a specific test file or test case matching the provided pattern in the Playwright test editor with debug mode enabled. Facilitates focused debugging of individual tests.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_3

LANGUAGE: bash
CODE:
```
yarn test --debug --test-name-pattern="test-name"
```

----------------------------------------

TITLE: Adding Build Dependencies
DESCRIPTION: Sets up build dependencies for the executable target. It ensures that the 'flutter_assemble' target (which handles Flutter-specific build steps like asset bundling and code generation) is built before the runner executable.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_8

LANGUAGE: CMake
CODE:
```
add_dependencies(${BINARY_NAME} flutter_assemble)
```

----------------------------------------

TITLE: Save Playwright Session for Test Generation
DESCRIPTION: Runs the test generation tool (`gentests`) with the `--save-storage` flag to record user interactions and save the authenticated session state to a specified JSON file. This allows subsequent test generation or runs to start from a logged-in state.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/contributing/tests.md#_snippet_4

LANGUAGE: bash
CODE:
```
yarn gentests --save-storage .auth/gentest-user.json
```

----------------------------------------

TITLE: Importing PromptEngine from SDK (Python)
DESCRIPTION: This import statement makes the `PromptEngine` class available for use within the current Python file. It imports the class from a relative path, suggesting it's located within a local package structure, likely an SDK provided by the AutoGPT Forge framework.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_2

LANGUAGE: python
CODE:
```
from .sdk import PromptEngine
```

----------------------------------------

TITLE: Initializing Agent Action Register - Python
DESCRIPTION: Creates an instance of the `ActionRegister` class, passing the agent instance (`self`). This register manages the agent's available abilities and is typically accessed through `self.abilities`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/003_crafting_agent_logic.md#_snippet_9

LANGUAGE: Python
CODE:
```
self.abilities = ActionRegister(self)
```

----------------------------------------

TITLE: Running Storybook Tests - Bash
DESCRIPTION: This command executes tests configured for the Storybook components. It is used to ensure the components function correctly and maintain visual integrity.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/README.md#_snippet_4

LANGUAGE: bash
CODE:
```
npm run test-storybook
```

----------------------------------------

TITLE: Showing Benchmark Test Details (Shell)
DESCRIPTION: Uses the `benchmark tests details` command followed by the test name ('TestWriteFile') to display detailed information about that specific benchmark test.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_9

LANGUAGE: sh
CODE:
```
./run benchmark tests details TestWriteFile
```

----------------------------------------

TITLE: Check Docker Compose Version - Shell
DESCRIPTION: This command checks the installed version of Docker Compose on your system. A specific version (1.29.0 or later) is required for compatibility with the Docker Compose file format used.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_0

LANGUAGE: shell
CODE:
```
docker compose version
```

----------------------------------------

TITLE: Checking Docker Compose Service Status Shell
DESCRIPTION: Lists the current status of all services defined in the 'docker-compose.yml' file. Provides an overview of which containers are running, stopped, or in other states.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_18

LANGUAGE: Shell
CODE:
```
docker compose ps
```

----------------------------------------

TITLE: Changing Directory to AutoGPT Project
DESCRIPTION: Navigates into the local directory created by cloning the AutoGPT repository. This is a necessary step before running project-specific commands.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/forge/tutorials/001_getting_started.md#_snippet_1

LANGUAGE: bash
CODE:
```
# The name of the directory will match the name you gave your fork. The default is AutoGPT
cd AutoGPT
```

----------------------------------------

TITLE: Checking Node.js & NPM Version - Bash
DESCRIPTION: These commands check the installed versions of Node.js and npm. Node.js is required for the frontend, and npm is its package manager, included with Node.js.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_0

LANGUAGE: bash
CODE:
```
node -v
npm -v
```

----------------------------------------

TITLE: Stopping and Removing Docker Compose System Shell
DESCRIPTION: Stops and removes containers, networks, and volumes defined in 'docker-compose.yml'. This command is used to completely tear down the running system.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_11

LANGUAGE: Shell
CODE:
```
docker compose down
```

----------------------------------------

TITLE: Copying Environment Example File
DESCRIPTION: Copies the example environment configuration file `.env_example` to `.env`. The `.env` file is used to store configuration variables like API keys and model names.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_8

LANGUAGE: Shell
CODE:
```
cp .env_example .env
```

----------------------------------------

TITLE: Copying Frontend Environment File - Bash
DESCRIPTION: This command copies the example environment file (`.env.example`) to the active environment file (`.env`) in the 'frontend' directory, used for configuring frontend-specific settings.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_7

LANGUAGE: bash
CODE:
```
cp .env.example .env
```

----------------------------------------

TITLE: Building Static Storybook - Bash
DESCRIPTION: This command generates a static build of the Storybook component library. The resulting static files can be deployed to showcase components independently.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/README.md#_snippet_3

LANGUAGE: bash
CODE:
```
npm run build-storybook
```

----------------------------------------

TITLE: Navigating to Frontend Directory Shell
DESCRIPTION: Changes the current directory to the 'frontend' subfolder within the 'autogpt_platform' directory. This step is required before setting up and running the frontend application.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/README.md#_snippet_3

LANGUAGE: Shell
CODE:
```
cd frontend
```

----------------------------------------

TITLE: Navigating to Frontend Directory - Bash
DESCRIPTION: This command changes the current directory to the 'frontend' folder, located within the 'autogpt_platform' directory, to set up and run the frontend application.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_6

LANGUAGE: bash
CODE:
```
cd frontend
```

----------------------------------------

TITLE: Displaying CLI Help Message (Shell)
DESCRIPTION: Executes the main CLI entry point without any arguments to display the general help message, listing available commands and options.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/CLI-USAGE.md#_snippet_0

LANGUAGE: sh
CODE:
```
./run
```

----------------------------------------

TITLE: Applying Standard Build Settings
DESCRIPTION: Applies a standard set of build settings to the executable target. This is a common practice in Flutter projects to ensure consistent build configurations.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_3

LANGUAGE: CMake
CODE:
```
apply_standard_settings(${BINARY_NAME})
```

----------------------------------------

TITLE: Setting Minimum CMake Version
DESCRIPTION: Specifies the minimum required version of CMake to build the project. This ensures that the build environment supports the necessary CMake commands and features used in the script.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.14)
```

----------------------------------------

TITLE: Uninstall Global Prisma Package sh
DESCRIPTION: Removes the globally installed `prisma` package using `pip`. This is suggested as a mitigation step if Poetry runs Prisma from the global environment instead of the project's virtual environment.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/advanced_setup.md#_snippet_12

LANGUAGE: sh
CODE:
```
pip uninstall prisma
```

----------------------------------------

TITLE: Importing Dependencies and Assets - React/JSX
DESCRIPTION: Imports necessary React components (`Meta`, `Image` from Next.js/Storybook) and local SVG/PNG assets used throughout the page layout. These imports are prerequisites for rendering the visual content and metadata within the MDX file.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/autogpt_platform/frontend/src/stories/Configure.mdx#_snippet_0

LANGUAGE: javascript
CODE:
```
import { Meta } from "@storybook/blocks";
import Image from "next/image";

import Github from "./assets/github.svg";
import Discord from "./assets/discord.svg";
import Youtube from "./assets/youtube.svg";
import Tutorials from "./assets/tutorials.svg";
import Styling from "./assets/styling.png";
import Context from "./assets/context.png";
import Assets from "./assets/assets.png";
import Docs from "./assets/docs.png";
import Share from "./assets/share.png";
import FigmaPlugin from "./assets/figma-plugin.png";
import Testing from "./assets/testing.png";
import Accessibility from "./assets/accessibility.png";
import Theming from "./assets/theming.png";
import AddonLibrary from "./assets/addon-library.png";
```

----------------------------------------

TITLE: Including Flutter and Runner Build Rules in CMake
DESCRIPTION: Sets the path to the Flutter-managed directory and includes subdirectories for the Flutter build rules and the application's runner (native shell). It also includes the generated CMake file for managing plugins.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_5

LANGUAGE: CMake
CODE:
```
# Flutter library and tool build rules.
set(FLUTTER_MANAGED_DIR "${CMAKE_CURRENT_SOURCE_DIR}/flutter")
add_subdirectory(${FLUTTER_MANAGED_DIR})

# Application build; see runner/CMakeLists.txt.
add_subdirectory("runner")


# Generated plugin build rules, which manage building the plugins and adding
# them to the application.
include(flutter/generated_plugins.cmake)
```

----------------------------------------

TITLE: Adding Executable Target
DESCRIPTION: Defines the executable target named by the ${BINARY_NAME} variable. It lists all the source files required to build the Windows application, including core files, utilities, and generated plugin registration.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_2

LANGUAGE: CMake
CODE:
```
add_executable(${BINARY_NAME} WIN32
  "flutter_window.cpp"
  "main.cpp"
  "utils.cpp"
  "win32_window.cpp"
  "${FLUTTER_MANAGED_DIR}/generated_plugin_registrant.cc"
  "Runner.rc"
  "runner.exe.manifest"
)
```

----------------------------------------

TITLE: Defining Flutter Interface Library (CMake)
DESCRIPTION: Creates an INTERFACE library target named `flutter` which specifies include directories and links required libraries (the Flutter engine library and system dependencies found via PkgConfig) for targets that depend on it.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/linux/flutter/CMakeLists.txt#_snippet_5

LANGUAGE: cmake
CODE:
```
add_library(flutter INTERFACE)
target_include_directories(flutter INTERFACE
  "${EPHEMERAL_DIR}"
)
target_link_libraries(flutter INTERFACE "${FLUTTER_LIBRARY}")
target_link_libraries(flutter INTERFACE
  PkgConfig::GTK
  PkgConfig::GLIB
  PkgConfig::GIO
)
add_dependencies(flutter flutter_assemble)
```

----------------------------------------

TITLE: Running Auto-GPT Benchmark Skipping Regressions
DESCRIPTION: Runs the benchmark while skipping any tests that have previously passed. This is intended to help focus on new or currently failing tests during development.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/benchmark/agbenchmark/README.md#_snippet_4

LANGUAGE: Shell
CODE:
```
agbenchmark --noreg
```

----------------------------------------

TITLE: Configuring Plugin Wrapper Library CMake
DESCRIPTION: Adds a STATIC library target named 'flutter_wrapper_plugin' using the core and plugin wrapper source files. It applies standard settings, sets compiler properties for position-independent code and visibility, links it publicly to the 'flutter' interface library, sets its public include directories, and adds a dependency on the `flutter_assemble` target.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_5

LANGUAGE: cmake
CODE:
```
# Wrapper sources needed for a plugin.
add_library(flutter_wrapper_plugin STATIC
  ${CPP_WRAPPER_SOURCES_CORE}
  ${CPP_WRAPPER_SOURCES_PLUGIN}
)
apply_standard_settings(flutter_wrapper_plugin)
set_target_properties(flutter_wrapper_plugin PROPERTIES
  POSITION_INDEPENDENT_CODE ON)
set_target_properties(flutter_wrapper_plugin PROPERTIES
  CXX_VISIBILITY_PRESET hidden)
target_link_libraries(flutter_wrapper_plugin PUBLIC flutter)
target_include_directories(flutter_wrapper_plugin PUBLIC
  "${WRAPPER_ROOT}/include"
)
add_dependencies(flutter_wrapper_plugin flutter_assemble)
```

----------------------------------------

TITLE: Install Click Dependency Shell
DESCRIPTION: Installs the 'click' Python package using pip. This library is a required dependency for the 'serve.py' script used to run the llamafile server locally.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_9

LANGUAGE: shell
CODE:
```
pip install click
```

----------------------------------------

TITLE: Run Llamafile Serve Script (WSL Workaround) Shell
DESCRIPTION: Starts the 'serve.py' script on the Windows host machine to run the llamafile server. This command is used as part of the WSL workaround, requiring the host IP address obtained from WSL using the '--host' argument. A custom port can optionally be specified with '--port'.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_11

LANGUAGE: shell
CODE:
```
python3 serve.py --host {WSL_HOST_ADDR}
```

----------------------------------------

TITLE: Setting Compile Definitions (Flutter Version)
DESCRIPTION: Adds preprocessor definitions to the compilation process for the executable target. These definitions expose Flutter version information (major, minor, patch, build) as macros available in the C++ source files.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_4

LANGUAGE: CMake
CODE:
```
target_compile_definitions(${BINARY_NAME} PRIVATE "FLUTTER_VERSION=\"${FLUTTER_VERSION}\"")
target_compile_definitions(${BINARY_NAME} PRIVATE "FLUTTER_VERSION_MAJOR=${FLUTTER_VERSION_MAJOR}")
target_compile_definitions(${BINARY_NAME} PRIVATE "FLUTTER_VERSION_MINOR=${FLUTTER_VERSION_MINOR}")
target_compile_definitions(${BINARY_NAME} PRIVATE "FLUTTER_VERSION_PATCH=${FLUTTER_VERSION_PATCH}")
target_compile_definitions(${BINARY_NAME} PRIVATE "FLUTTER_VERSION_BUILD=${FLUTTER_VERSION_BUILD}")
```

----------------------------------------

TITLE: Defining C++ Wrapper Source Lists CMake
DESCRIPTION: Defines lists of source files for different components of the C++ wrapper (core, plugin, app). It appends the filenames to lists and then transforms these lists by prepending the WRAPPER_ROOT path to create full paths to the source files.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_4

LANGUAGE: cmake
CODE:
```
# === Wrapper ===
list(APPEND CPP_WRAPPER_SOURCES_CORE
  "core_implementations.cc"
  "standard_codec.cc"
)
list(TRANSFORM CPP_WRAPPER_SOURCES_CORE PREPEND "${WRAPPER_ROOT}/")
list(APPEND CPP_WRAPPER_SOURCES_PLUGIN
  "plugin_registrar.cc"
)
list(TRANSFORM CPP_WRAPPER_SOURCES_PLUGIN PREPEND "${WRAPPER_ROOT}/")
list(APPEND CPP_WRAPPER_SOURCES_APP
  "flutter_engine.cc"
  "flutter_view_controller.cc"
)
list(TRANSFORM CPP_WRAPPER_SOURCES_APP PREPEND "${WRAPPER_ROOT}/")
```

----------------------------------------

TITLE: Enabling AutoGPT Debug Logs Shell
DESCRIPTION: This shell command starts AutoGPT with debug logging enabled by including the `--debug` flag. This is useful for troubleshooting, analyzing agent behavior, and reporting issues by providing detailed log output.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_7

LANGUAGE: shell
CODE:
```
./autogpt.sh --debug
```

----------------------------------------

TITLE: Setting CMake Minimum Version and Ephemeral Directory (CMake)
DESCRIPTION: Sets the minimum required CMake version for the project and defines the path to the ephemeral build directory where generated files are stored.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/linux/flutter/CMakeLists.txt#_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.10)

set(EPHEMERAL_DIR "${CMAKE_CURRENT_SOURCE_DIR}/ephemeral")
```

----------------------------------------

TITLE: Opening Flutter iOS Xcode Workspace - Shell
DESCRIPTION: This shell command opens the Xcode workspace file for the iOS portion of a Flutter project. It is a necessary step to use Xcode for graphically managing project settings, including asset catalogs for the launch screen. The command assumes Xcode is installed and the user is in the project's root directory.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/ios/Runner/Assets.xcassets/LaunchImage.imageset/README.md#_snippet_0

LANGUAGE: Shell
CODE:
```
open ios/Runner.xcworkspace
```

----------------------------------------

TITLE: Displaying AutoGPT Serve Help Shell
DESCRIPTION: This shell command shows the help message for the `serve` subcommand, which starts AutoGPT as an Agent Protocol compliant server with a frontend UI. It lists options relevant to server mode, such as `--debug`, `--gpt3only`, and `--install-plugin-deps`.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/usage.md#_snippet_4

LANGUAGE: shell
CODE:
```
$ ./autogpt.sh serve --help
Usage: python -m autogpt serve [OPTIONS]

  Starts an Agent Protocol compliant AutoGPT server, which creates a custom
  agent for every task.

Options:
  --debug                     Enable Debug Mode
  --gpt3only                  Enable GPT3.5 Only Mode
  --gpt4only                  Enable GPT4 Only Mode
  --install-plugin-deps       Installs external dependencies for 3rd party
                              plugins.
  --help                      Show this message and exit.
```

----------------------------------------

TITLE: Install dos2unix Utility - Shell
DESCRIPTION: Installs the `dos2unix` utility using the `apt` package manager with root privileges (`sudo`). This utility is used to convert text file line endings from the Windows format (CRLF) to the Unix/Linux format (LF), which is necessary to resolve script execution issues in WSL caused by incompatible line endings.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/FORGE-QUICKSTART.md#_snippet_2

LANGUAGE: Shell
CODE:
```
sudo apt install dos2unix
```

----------------------------------------

TITLE: Configuring Flutter Interface Library CMake
DESCRIPTION: Appends Flutter header filenames to a list, transforms them into absolute paths, and defines an INTERFACE library target named 'flutter'. This target represents the Flutter engine dependency, specifying its include directories and linking against the generated Flutter engine library (`flutter_windows.dll.lib`). It also adds a dependency on the `flutter_assemble` target.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_3

LANGUAGE: cmake
CODE:
```
list(APPEND FLUTTER_LIBRARY_HEADERS
  "flutter_export.h"
  "flutter_windows.h"
  "flutter_messenger.h"
  "flutter_plugin_registrar.h"
  "flutter_texture_registrar.h"
)
list(TRANSFORM FLUTTER_LIBRARY_HEADERS PREPEND "${EPHEMERAL_DIR}/")
add_library(flutter INTERFACE)
target_include_directories(flutter INTERFACE
  "${EPHEMERAL_DIR}"
)
target_link_libraries(flutter INTERFACE "${FLUTTER_LIBRARY}.lib")
add_dependencies(flutter flutter_assemble)
```

----------------------------------------

TITLE: Defining Wikipedia Summary Block Class Structure Python
DESCRIPTION: Defines the `WikipediaSummaryBlock` class, inheriting from the base `Block` class and a `GetRequest` utility. This sets up the fundamental structure for the new block.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/new_blocks.md#_snippet_1

LANGUAGE: python
CODE:
```
from backend.data.block import Block, BlockSchema, BlockOutput
from backend.utils.get_request import GetRequest
import requests

class WikipediaSummaryBlock(Block, GetRequest):
    # Block implementation will go here
```

----------------------------------------

TITLE: Navigating to Backend Platform Directory - Bash
DESCRIPTION: This command changes the current directory to the 'autogpt_platform' folder within the cloned AutoGPT repository, where the main backend configuration and services are located.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_3

LANGUAGE: bash
CODE:
```
cd AutoGPT/autogpt_platform
```

----------------------------------------

TITLE: Define Docker Compose Config (<= v0.4.7) - YAML
DESCRIPTION: This YAML configuration defines a service named 'auto-gpt' for Docker Compose, intended for AutoGPT versions up to v0.4.7. It specifies the Docker image, environment file, profile exclusion, and volume mounts for workspace, data, and logs.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_2

LANGUAGE: yaml
CODE:
```
version: "3.9"
services:
  auto-gpt:
    image: significantgravitas/auto-gpt
    env_file:
      - .env
    profiles: ["exclude-from-up"]
    volumes:
      - ./auto_gpt_workspace:/app/auto_gpt_workspace
      - ./data:/app/data
      ## allow auto-gpt to write logs to disk
      - ./logs:/app/logs
      ## uncomment following lines if you want to make use of these files
      ## you must have them existing in the same folder as this docker-compose.yml
      #- type: bind
      #  source: ./azure.yaml
      #  target: /app/azure.yaml
```

----------------------------------------

TITLE: Defining CMake Build Configuration Types
DESCRIPTION: Detects if the build generator is multi-config (like Visual Studio). If so, it forces the build types to Debug, Profile, and Release. Otherwise, it sets the default build type to Debug if not already specified.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_1

LANGUAGE: CMake
CODE:
```
get_property(IS_MULTICONFIG GLOBAL PROPERTY GENERATOR_IS_MULTI_CONFIG)
if(IS_MULTICONFIG)
  set(CMAKE_CONFIGURATION_TYPES "Debug;Profile;Release"
    CACHE STRING "" FORCE)
elif(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES)
  set(CMAKE_BUILD_TYPE "Debug" CACHE
    STRING "Flutter build mode" FORCE)
  set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS
    "Debug" "Profile" "Release")
endif()
```

----------------------------------------

TITLE: Defining Installation Rules for Flutter Application in CMake
DESCRIPTION: Specifies the installation rules for the executable target, Flutter ICU data file, Flutter library, bundled plugin libraries, assets directory (ensuring it's re-copied on each build), and the AOT library for Profile and Release configurations.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_7

LANGUAGE: CMake
CODE:
```
install(TARGETS ${BINARY_NAME} RUNTIME DESTINATION "${CMAKE_INSTALL_PREFIX}"
  COMPONENT Runtime)

install(FILES "${FLUTTER_ICU_DATA_FILE}" DESTINATION "${INSTALL_BUNDLE_DATA_DIR}"
  COMPONENT Runtime)

install(FILES "${FLUTTER_LIBRARY}" DESTINATION "${INSTALL_BUNDLE_LIB_DIR}"
  COMPONENT Runtime)

if(PLUGIN_BUNDLED_LIBRARIES)
  install(FILES "${PLUGIN_BUNDLED_LIBRARIES}"
    DESTINATION "${INSTALL_BUNDLE_LIB_DIR}"
    COMPONENT Runtime)
endif()

# Fully re-copy the assets directory on each build to avoid having stale files
# from a previous install.
set(FLUTTER_ASSET_DIR_NAME "flutter_assets")
install(CODE "
  file(REMOVE_RECURSE \"${INSTALL_BUNDLE_DATA_DIR}/${FLUTTER_ASSET_DIR_NAME}\")
  " COMPONENT Runtime)
install(DIRECTORY "${PROJECT_BUILD_DIR}/${FLUTTER_ASSET_DIR_NAME}"
  DESTINATION "${INSTALL_BUNDLE_DATA_DIR}" COMPONENT Runtime)

# Install the AOT library on non-Debug builds only.
install(FILES "${AOT_LIBRARY}" DESTINATION "${INSTALL_BUNDLE_DATA_DIR}"
  CONFIGURATIONS Profile;Release
  COMPONENT Runtime)
```

----------------------------------------

TITLE: Defining Flutter Artifact Variables CMake
DESCRIPTION: Defines CMake variables (FLUTTER_LIBRARY, FLUTTER_ICU_DATA_FILE, PROJECT_BUILD_DIR, AOT_LIBRARY) pointing to essential Flutter build artifacts and directories. These variables are exported to the parent CMake scope using PARENT_SCOPE for use in other parts of the build configuration, such as the install step.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_2

LANGUAGE: cmake
CODE:
```
# === Flutter Library ===
set(FLUTTER_LIBRARY "${EPHEMERAL_DIR}/flutter_windows.dll")

# Published to parent scope for install step.
set(FLUTTER_LIBRARY ${FLUTTER_LIBRARY} PARENT_SCOPE)
set(FLUTTER_ICU_DATA_FILE "${EPHEMERAL_DIR}/icudtl.dat" PARENT_SCOPE)
set(PROJECT_BUILD_DIR "${PROJECT_DIR}/build/" PARENT_SCOPE)
set(AOT_LIBRARY "${PROJECT_DIR}/build/windows/app.so" PARENT_SCOPE)
```

----------------------------------------

TITLE: Disabling Windows Macros (NOMINMAX)
DESCRIPTION: Adds a preprocessor definition to disable specific Windows macros (like min and max) that can collide with C++ standard library functions. This helps prevent compilation errors.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/runner/CMakeLists.txt#_snippet_5

LANGUAGE: CMake
CODE:
```
target_compile_definitions(${BINARY_NAME} PRIVATE "NOMINMAX")
```

----------------------------------------

TITLE: Defining Expected Character Beliefs Structure (JSON)
DESCRIPTION: Specifies the correct belief states for different characters regarding marble locations across various challenge levels. This JSON structure is used by the test framework to compare against the AI's generated belief output to determine if the AI has correctly tracked character perspectives and event consequences. It outlines the expected nested structure: level -> character -> marble -> location.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/challenges/memory/challenge_d.md#_snippet_1

LANGUAGE: json
CODE:
```
expected_beliefs = {
    1: {
        'Sally': {
            'marble A': 'basket S',
        },
        'Anne': {
            'marble A': 'basket A',
        }
    },
    2: {
        'Sally': {
            'marble A': 'sofa',  # Because Charlie told her
        },
        'Anne': {
            'marble A': 'green box',  # Because she moved it there
            'marble B': 'basket A',  # Because Bob put it there and she was in the room
        },
        'Bob': {
            'B': 'basket A',  # Last place he put it
        },
        'Charlie': {
            'A': 'sofa',  # Because Anne told him to tell Sally so
        }
    },...
```

----------------------------------------

TITLE: Including Generated Flutter Configuration (CMake)
DESCRIPTION: Includes a CMake configuration file generated by the Flutter tool, which provides necessary variables and settings for the build.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/linux/flutter/CMakeLists.txt#_snippet_1

LANGUAGE: cmake
CODE:
```
include(${EPHEMERAL_DIR}/generated_config.cmake)
```

----------------------------------------

TITLE: Setting Basic CMake Configuration CMake
DESCRIPTION: Sets the minimum required CMake version for the project and defines the EPHEMERAL_DIR variable, which points to the directory containing temporary or generated build files used by the Flutter tool.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/flutter/CMakeLists.txt#_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.14)

set(EPHEMERAL_DIR "${CMAKE_CURRENT_SOURCE_DIR}/ephemeral")
```

----------------------------------------

TITLE: Configuring Profile Build Flags in CMake
DESCRIPTION: Copies the compiler and linker flags configured for the Release build type to the Profile build type. This ensures consistency in optimization and settings between these two build modes.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/windows/CMakeLists.txt#_snippet_2

LANGUAGE: CMake
CODE:
```
set(CMAKE_EXE_LINKER_FLAGS_PROFILE "${CMAKE_EXE_LINKER_FLAGS_RELEASE}")
set(CMAKE_SHARED_LINKER_FLAGS_PROFILE "${CMAKE_SHARED_LINKER_FLAGS_RELEASE}")
set(CMAKE_C_FLAGS_PROFILE "${CMAKE_C_FLAGS_RELEASE}")
set(CMAKE_CXX_FLAGS_PROFILE "${CMAKE_CXX_FLAGS_RELEASE}")
```

----------------------------------------

TITLE: Defining list_prepend Function (CMake)
DESCRIPTION: Defines a custom CMake function `list_prepend` to prepend a prefix to each element in a list, providing functionality similar to `list(TRANSFORM ... PREPEND ...)` for older CMake versions (before 3.10).
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/linux/flutter/CMakeLists.txt#_snippet_2

LANGUAGE: cmake
CODE:
```
function(list_prepend LIST_NAME PREFIX)
    set(NEW_LIST "")
    foreach(element ${${LIST_NAME}})
        list(APPEND NEW_LIST "${PREFIX}${element}")
    endforeach(element)
    set(${LIST_NAME} "${NEW_LIST}" PARENT_SCOPE)
endfunction()
```

----------------------------------------

TITLE: Set Llamafile API Base URL in WSL Shell
DESCRIPTION: Sets the 'LLAMAFILE_API_BASE' environment variable within the WSL environment's '.env' file. This configures AutoGPT to point to the specific network address and port where the llamafile server is running on the Windows host.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/index.md#_snippet_12

LANGUAGE: shell
CODE:
```
LLAMAFILE_API_BASE=http://{WSL_HOST_ADDR}:8080/v1
```

----------------------------------------

TITLE: Navigating to Project Directory (Bash)
DESCRIPTION: Changes the current working directory in your terminal to the 'frontend' subdirectory within the newly cloned AutoGPT repository. This directory contains the source code for the Flutter client, and subsequent commands like getting dependencies must be run from here.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/classic/frontend/README.md#_snippet_1

LANGUAGE: Bash
CODE:
```
cd AutoGPT/frontend
```

----------------------------------------

TITLE: Create and Enter Project Directory - Shell
DESCRIPTION: These commands create a new directory named 'AutoGPT' for the project files and then change the current directory to the newly created folder. This is a standard step before creating configuration files.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/classic/setup/docker.md#_snippet_1

LANGUAGE: shell
CODE:
```
mkdir AutoGPT
cd AutoGPT
```

----------------------------------------

TITLE: Navigating Up Directory - Bash
DESCRIPTION: This command navigates one directory level up from the current location, useful for moving between subdirectories like 'autogpt_platform' and its parent 'AutoGPT'.
SOURCE: https://github.com/significant-gravitas/autogpt/blob/master/docs/content/platform/getting-started.md#_snippet_20

LANGUAGE: bash
CODE:
```
cd ..
```