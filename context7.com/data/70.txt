TITLE: Generating a Disparity (Depth) Map from Stereo Images with OpenCV in Python
DESCRIPTION: This Python code snippet demonstrates how to compute a disparity map (which is inversely proportional to depth) from a pair of stereo images using the OpenCV library\'s StereoBM block matching algorithm. Dependencies required are numpy, matplotlib, and the OpenCV (cv2) library. The function reads two rectified grayscale images, initializes the StereoBM matcher with preset numDisparities and blockSize parameters, computes the disparity map, and displays the result using matplotlib. Key parameters controlling the quality and performance include numDisparities, blockSize, and others that can be accessed via setters (e.g., setTextureThreshold, setSpeckleRange, setUniquenessRatio). Input images should be precalibrated and rectified for best results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_depthmap/py_depthmap.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

imgL = cv.imread('tsukuba_l.png', cv.IMREAD_GRAYSCALE)
imgR = cv.imread('tsukuba_r.png', cv.IMREAD_GRAYSCALE)

stereo = cv.StereoBM.create(numDisparities=16, blockSize=15)
disparity = stereo.compute(imgL,imgR)
plt.imshow(disparity,'gray')
plt.show()
```

----------------------------------------

TITLE: Thresholding Operations Initialization in OpenCV (C++, Full Example)
DESCRIPTION: This C++ code demonstrates loading an image, converting it to grayscale, creating a display window, setting up interactive trackbars for threshold type and value, and applying different threshold operations via the cv::threshold function. The program leverages OpenCV 3.0 or later and requires linking its core and highgui/imgproc modules. Inputs include an image file path, user-selected threshold value, and threshold type; outputs are thresholded images displayed in real-time as the user interacts with the controls. The sample handles edge-cases such as BGR-to-gray conversion and coordinates threshold updates through event callbacks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/imgproc.hpp>\n#include <opencv2/highgui.hpp>\nusing namespace cv;\n\nMat src, src_gray, dst;\nint threshold_value = 0;\nint threshold_type = 3;\nint const max_value = 255;\nint const max_type = 4;\nint const max_BINARY_value = 255;\n\nconst char* window_name = "Threshold Demo";\n\nvoid Threshold_Demo( int, void* )\n{\n  /* 0: Binary\n     1: Binary Inverted\n     2: Truncate\n     3: To Zero\n     4: To Zero Inverted\n   */\n  threshold( src_gray, dst, threshold_value, max_BINARY_value,threshold_type );\n  imshow( window_name, dst );\n}\n\nint main( int argc, char** argv )\n{\n  // Load an image\n  src = imread( argc >=2 ? argv[1] : "chicky_512.png", IMREAD_COLOR );\n  if( src.empty() )\n  {\n    printf("Error opening image\n");\n    return -1;\n  }\n\n  cvtColor( src, src_gray, COLOR_BGR2GRAY );\n  namedWindow( window_name, WINDOW_AUTOSIZE );\n\n  // Create Trackbars\n  createTrackbar( "Type:\n 0:Binary \n 1:BinaryInv \n 2:Trunc \n 3:ToZero \n 4:ToZeroInv",\n                 window_name, &threshold_type, max_type, Threshold_Demo );\n  createTrackbar( "Value",\n                 window_name, &threshold_value, max_value, Threshold_Demo );\n\n  Threshold_Demo( 0, 0 );\n  waitKey(0);\n  return 0;\n}
```

----------------------------------------

TITLE: Applying Morphological Transformations with Interactive Trackbars in OpenCV (C++)
DESCRIPTION: This C++ code sample demonstrates interactive application of several morphological operations (Opening, Closing, Gradient, Top Hat, Black Hat) using OpenCV. The code loads an image, creates a GUI with three trackbars for selecting operation type, structuring element, and kernel size, and updates the output in real time using cv::morphologyEx and user-defined trackbar callbacks. Dependencies include OpenCV 3.0+ and a valid image input; inputs come from user-adjusted trackbars and an image path. Output is a GUI window with the transformed image, reacting dynamically to user input. The code requires a system with OpenCV GUI support, and some functions assume grayscale or single-channel images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/imgproc.hpp>\n#include <opencv2/highgui.hpp>\n#include <iostream>\n\nusing namespace cv;\nusing namespace std;\n\nMat src, dst;\nint morph_operator = 0;\nint morph_elem = 0;\nint morph_size = 0;\nint const max_operator = 4;\nint const max_elem = 2;\nint const max_kernel_size = 21;\n\nconst char* window_name = "Morphology Transformations";\n\nvoid Morphology_Operations(int, void*)\n{\n    int operation = morph_operator + 2;\n    Mat element = getStructuringElement(morph_elem,\n              Size(2 * morph_size + 1, 2 * morph_size + 1),\n              Point(morph_size, morph_size));\n    morphologyEx(src, dst, operation, element);\n    imshow(window_name, dst);\n}\n\nint main(int argc, char** argv)\n{\n    CommandLineParser parser(argc, argv, "{@input | baboon.png | }");\n    src = imread(parser.get<String>("@input"), IMREAD_COLOR);\n    if(src.empty())\n    {\n        cout << "Cannot load image!" << endl;\n        return -1;\n    }\n\n    namedWindow(window_name, WINDOW_AUTOSIZE);\n\n    createTrackbar("Operator:\n 0: Opening\n 1: Closing\n 2: Gradient\n 3: Top Hat\n 4: Black Hat", window_name, &morph_operator, max_operator, Morphology_Operations);\n    createTrackbar("Element:\n 0: Rect\n 1: Cross\n 2: Ellipse", window_name, &morph_elem, max_elem, Morphology_Operations);\n    createTrackbar("Kernel size:\n 2n+1", window_name, &morph_size, max_kernel_size, Morphology_Operations);\n\n    Morphology_Operations(0, 0);\n    waitKey(0);\n    return 0;\n}\n
```

----------------------------------------

TITLE: Normalizing Histogram Results in Python
DESCRIPTION: Python snippet normalizing the calculated histograms (`b_hist`, `g_hist`, `r_hist`) using `cv.normalize`. It scales the histogram values to fit within the range 0 to `histImage.shape[0]` (the height of the display image) using the `cv.NORM_MINMAX` method.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_26

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Normalize the result to ( 0, histImage.rows )
```

----------------------------------------

TITLE: Detecting Corners using Harris Corner Detector in OpenCV (Python)
DESCRIPTION: This code snippet demonstrates how to use OpenCV's cv.cornerHarris() function to detect corners in a grayscale image. It involves converting an image to a grayscale float32 format, applying the Harris Corner Detection, and marking the detected corners on the image. Dependencies include the OpenCV and NumPy libraries. The main parameters are blockSize, ksize, and k, which define the neighborhood size, aperture parameter, and Harris detector's free parameter, respectively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

filename = 'chessboard.png'
img = cv.imread(filename)
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)

gray = np.float32(gray)
dst = cv.cornerHarris(gray,2,3,0.04)

#result is dilated for marking the corners, not important
dst = cv.dilate(dst,None)

# Threshold for an optimal value, it may vary depending on the image.
img[dst>0.01*dst.max()]=[0,0,255]

cv.imshow('dst',img)
if cv.waitKey(0) & 0xff == 27:
    cv.destroyAllWindows()
```

----------------------------------------

TITLE: Accessing Pixel Values in an OpenCV Image using NumPy Indexing in Python
DESCRIPTION: Shows how to retrieve the BGR pixel value at coordinates (100, 100) and how to access only the Blue channel value (index 0) at the same location using NumPy array indexing on the OpenCV image object (`img`). For BGR images, it returns a [Blue, Green, Red] array; for grayscale, it returns the intensity.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
>>> px = img[100,100]
>>> print( px )
[157 166 200]

# accessing only blue pixel
>>> blue = img[100,100,0]
>>> print( blue )
157
```

----------------------------------------

TITLE: Converting BGR Image to Grayscale with OpenCV in Python
DESCRIPTION: Demonstrates color-to-grayscale conversion in Python OpenCV with cv2.cvtColor and COLOR_BGR2GRAY. Input is BGR image array, output is single-channel intensity array.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_36

LANGUAGE: Python
CODE:
```
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
```

----------------------------------------

TITLE: Reading Calibration Settings from File using OpenCV FileStorage in C++
DESCRIPTION: This C++ snippet reference points to code that reads camera calibration settings from an XML or YAML file using OpenCV's FileStorage class. It reads various configuration parameters and includes a post-processing step to validate the input, setting a flag `goodInput` accordingly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp file_read
```

----------------------------------------

TITLE: Initializing Kalman Filter Parameters in C++ (OpenCV)
DESCRIPTION: Defines the `initKalmanFilter` function in C++ using OpenCV. It initializes a `cv::KalmanFilter` object (`KF`) with specified state, measurement, and input dimensions (`nStates`, `nMeasurements`, `nInputs`) using double precision (`CV_64F`). It sets initial process noise (`processNoiseCov`), measurement noise (`measurementNoiseCov`), and error covariance (`errorCovPost`) matrices to identity matrices scaled by small values. It then configures the `transitionMatrix` based on a dynamic model incorporating time step `dt` (likely constant velocity/acceleration for both position and orientation) and the `measurementMatrix` to map state variables (position x, y, z and orientation roll, pitch, yaw) directly to measurements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_22

LANGUAGE: cpp
CODE:
```
void initKalmanFilter(cv::KalmanFilter &KF, int nStates, int nMeasurements, int nInputs, double dt)
{

  KF.init(nStates, nMeasurements, nInputs, CV_64F);                 // init Kalman Filter

  cv::setIdentity(KF.processNoiseCov, cv::Scalar::all(1e-5));       // set process noise
  cv::setIdentity(KF.measurementNoiseCov, cv::Scalar::all(1e-4));   // set measurement noise
  cv::setIdentity(KF.errorCovPost, cv::Scalar::all(1));             // error covariance


                 /* DYNAMIC MODEL */

  //  [1 0 0 dt  0  0 dt2   0   0 0 0 0  0  0  0   0   0   0]
  //  [0 1 0  0 dt  0   0 dt2   0 0 0 0  0  0  0   0   0   0]
  //  [0 0 1  0  0 dt   0   0 dt2 0 0 0  0  0  0   0   0   0]
  //  [0 0 0  1  0  0  dt   0   0 0 0 0  0  0  0   0   0   0]
  //  [0 0 0  0  1  0   0  dt   0 0 0 0  0  0  0   0   0   0]
  //  [0 0 0  0  0  1   0   0  dt 0 0 0  0  0  0   0   0   0]
  //  [0 0 0  0  0  0   1   0   0 0 0 0  0  0  0   0   0   0]
  //  [0 0 0  0  0  0   0   1   0 0 0 0  0  0  0   0   0   0]
  //  [0 0 0  0  0  0   0   0   1 0 0 0  0  0  0   0   0   0]
  //  [0 0 0  0  0  0   0   0   0 1 0 0 dt  0  0 dt2   0   0]
  //  [0 0 0  0  0  0   0   0   0 0 1 0  0 dt  0   0 dt2   0]
  //  [0 0 0  0  0  0   0   0   0 0 0 1  0  0 dt   0   0 dt2]
  //  [0 0 0  0  0  0   0   0   0 0 0 0  1  0  0  dt   0   0]
  //  [0 0 0  0  0  0   0   0   0 0 0 0  0  1  0   0  dt   0]
  //  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  1   0   0  dt]
  //  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  0   1   0   0]
  //  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  0   0   1   0]
  //  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  0   0   0   1]

  // position
  KF.transitionMatrix.at<double>(0,3) = dt;
  KF.transitionMatrix.at<double>(1,4) = dt;
  KF.transitionMatrix.at<double>(2,5) = dt;
  KF.transitionMatrix.at<double>(3,6) = dt;
  KF.transitionMatrix.at<double>(4,7) = dt;
  KF.transitionMatrix.at<double>(5,8) = dt;
  KF.transitionMatrix.at<double>(0,6) = 0.5*pow(dt,2);
  KF.transitionMatrix.at<double>(1,7) = 0.5*pow(dt,2);
  KF.transitionMatrix.at<double>(2,8) = 0.5*pow(dt,2);

  // orientation
  KF.transitionMatrix.at<double>(9,12) = dt;
  KF.transitionMatrix.at<double>(10,13) = dt;
  KF.transitionMatrix.at<double>(11,14) = dt;
  KF.transitionMatrix.at<double>(12,15) = dt;
  KF.transitionMatrix.at<double>(13,16) = dt;
  KF.transitionMatrix.at<double>(14,17) = dt;
  KF.transitionMatrix.at<double>(9,15) = 0.5*pow(dt,2);
  KF.transitionMatrix.at<double>(10,16) = 0.5*pow(dt,2);
  KF.transitionMatrix.at<double>(11,17) = 0.5*pow(dt,2);


       /* MEASUREMENT MODEL */

  //  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
  //  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
  //  [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
  //  [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
  //  [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]
  //  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]

  KF.measurementMatrix.at<double>(0,0) = 1;  // x
  KF.measurementMatrix.at<double>(1,1) = 1;  // y
  KF.measurementMatrix.at<double>(2,2) = 1;  // z
  KF.measurementMatrix.at<double>(3,9) = 1;  // roll
  KF.measurementMatrix.at<double>(4,10) = 1; // pitch
  KF.measurementMatrix.at<double>(5,11) = 1; // yaw

}
```

----------------------------------------

TITLE: Setup Image in OpenCV C++
DESCRIPTION: This snippet demonstrates opening an image, converting it to grayscale, and applying a blur to reduce noise using OpenCV in C++. It requires the OpenCV library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>

// Load an image and convert it to grayscale
cv::Mat src = cv::imread("image.jpg");
cv::Mat gray;
cv::cvtColor(src, gray, cv::COLOR_BGR2GRAY);
cv::blur(gray, gray, cv::Size(3, 3));
```

----------------------------------------

TITLE: Loading an Image from File with OpenCV in C++
DESCRIPTION: Demonstrates how to load an image from file using OpenCV's imread function in C++. Requires OpenCV installed and properly linked. The sample loads the image as a cv::Mat object, with the resulting image defaulting to 3-channel BGR for color images. Input is a file path, output is a cv::Mat containing image data. The operation depends on file format support in the OpenCV build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>\ncv::Mat img = cv::imread("my_image.jpg");
```

----------------------------------------

TITLE: Thresholding Operations Initialization in OpenCV (Python, Full Example)
DESCRIPTION: This Python code sample shows how to load an image, convert it to grayscale if needed, display it in a window, and use OpenCV's trackbar GUI widgets for interactivity over the threshold type and value. The thresholding is performed via cv2.threshold, and the window updates whenever the user changes a slider. The script depends on OpenCV-Python (cv2). It takes an image file path as input from the command line or defaults, applies the selected threshold, and displays the output window; user actions trigger instant processing. Edge handling for missing or incorrect files is included.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2 as cv\nimport sys\n\nmax_value = 255\nmax_type = 4\nmax_BINARY_value = 255\nwindow_name = 'Threshold Demo'\n\n# [load]\nsrc = cv.imread(sys.argv[1] if len(sys.argv) > 1 else 'chicky_512.png')\nif src is None:\n    print('Error opening image')\n    sys.exit(-1)\nsrc_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n# [load]\n\ndef Threshold_Demo(*args):\n    threshold_type = cv.getTrackbarPos('Type', window_name)\n    threshold_value = cv.getTrackbarPos('Value', window_name)\n    ret, dst = cv.threshold(src_gray, threshold_value, max_BINARY_value, threshold_type)\n    cv.imshow(window_name, dst)\n\ncv.namedWindow(window_name)\n\n# [trackbar]\ncv.createTrackbar('Type', window_name, 3, max_type, Threshold_Demo)\ncv.createTrackbar('Value', window_name, 0, max_value, Threshold_Demo)\n# [trackbar]\n\nThreshold_Demo()\ncv.waitKey(0)
```

----------------------------------------

TITLE: Loading an Image from File with OpenCV in Python
DESCRIPTION: Shows how to read an image file using OpenCV's cv2.imread in Python. Requires the cv2 (opencv-python) module installed. Loads the file at the given path as a NumPy array, using BGR color order by default for JPEGs. The file path is input; NumPy ndarray with image data is output. Image is loaded with 3 channels for color images unless changed by a flag.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2\nimg = cv2.imread('my_image.jpg')
```

----------------------------------------

TITLE: Matching Extracted Face Features - OpenCV DNN C++
DESCRIPTION: This snippet demonstrates how to compute the similarity or distance between two extracted face features in C++. Metric functions are called with the feature vectors to get cosine or normL2 distances for identity verification. The output is a scalar similarity or distance value, which can be compared to pre-selected thresholds for face matching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_8

LANGUAGE: C++
CODE:
```
// Compare two extracted face features
float cosineScore = recognizer->match(feature1, feature2, cv::FaceRecognizerSF::DisType::FR_COSINE);
float l2Score = recognizer->match(feature1, feature2, cv::FaceRecognizerSF::DisType::FR_NORM_L2);
// Use thresholds from model evaluation to determine match/non-match
```

----------------------------------------

TITLE: Implementing 2D Convolution with Custom Kernel in OpenCV Python
DESCRIPTION: This code demonstrates how to apply a custom averaging filter kernel to an image using cv.filter2D(). It creates a 5x5 normalized kernel and applies it to an image for basic smoothing, then displays both original and filtered results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_filtering/py_filtering.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('opencv_logo.png')
assert img is not None, "file could not be read, check with os.path.exists()"

kernel = np.ones((5,5),np.float32)/25
dst = cv.filter2D(img,-1,kernel)

plt.subplot(121),plt.imshow(img),plt.title('Original')
plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(dst),plt.title('Averaging')
plt.xticks([]), plt.yticks([])
plt.show()
```

----------------------------------------

TITLE: Optimizing Array Size for DFT using OpenCV and Numpy - Python
DESCRIPTION: This code demonstrates how to determine and use the optimal size for FFT/DFT operations to maximize performance using OpenCV and Numpy. It reads a grayscale image, computes optimal DFT sizes, and displays them. Dependencies: OpenCV (cv), Numpy (np). Inputs: image filepath ('messi5.jpg') and image array. Outputs: the original and optimal (padded) array sizes printed to standard output. Assumes the image file exists in the path. This is suitable for notebook use, leveraging IPython input format and assertions for file presence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
In [15]: img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)
In [16]: assert img is not None, "file could not be read, check with os.path.exists()"
In [17]: rows,cols = img.shape
In [18]: print("{} {}".format(rows,cols))
342 548

In [19]: nrows = cv.getOptimalDFTSize(rows)
In [20]: ncols = cv.getOptimalDFTSize(cols)
In [21]: print("{} {}".format(nrows,ncols))
360 576
```

----------------------------------------

TITLE: Calculating Solidity using OpenCV.js
DESCRIPTION: Determines the solidity of a contour, defined as the ratio of the contour's area to the area of its convex hull. Requires a contour (`cnt`). Uses `cv.contourArea` for both the contour and its hull area, and `cv.convexHull` to compute the convex hull.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_properties/js_contour_properties.markdown#2025-04-22_snippet_2

LANGUAGE: javascript
CODE:
```
let area = cv.contourArea(cnt, false);
cv.convexHull(cnt, hull, false, true);
let hullArea = cv.contourArea(hull, false);
let solidity = area / hullArea;
```

----------------------------------------

TITLE: Single Object Template Matching with Multiple Methods in OpenCV Python
DESCRIPTION: Demonstrates template matching to find a single face in an image using six different comparison methods. The code loads source and template images, applies different matching methods, and visualizes the results using matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_template_matching/py_template_matching.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
img2 = img.copy()
template = cv.imread('template.jpg', cv.IMREAD_GRAYSCALE)
assert template is not None, "file could not be read, check with os.path.exists()"
w, h = template.shape[::-1]

# All the 6 methods for comparison in a list
methods = ['TM_CCOEFF', 'TM_CCOEFF_NORMED', 'TM_CCORR',
            'TM_CCORR_NORMED', 'TM_SQDIFF', 'TM_SQDIFF_NORMED']

for meth in methods:
    img = img2.copy()
    method = getattr(cv, meth)

    # Apply template Matching
    res = cv.matchTemplate(img,template,method)
    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)

    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum
    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:
        top_left = min_loc
    else:
        top_left = max_loc
    bottom_right = (top_left[0] + w, top_left[1] + h)

    cv.rectangle(img,top_left, bottom_right, 255, 2)

    plt.subplot(121),plt.imshow(res,cmap = 'gray')
    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])
    plt.subplot(122),plt.imshow(img,cmap = 'gray')
    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])
    plt.suptitle(meth)

    plt.show()
```

----------------------------------------

TITLE: Displaying 32F Image by Conversion to 8U for imshow with OpenCV in Python
DESCRIPTION: In Python, float images are converted to 8-bit using (img * 255).astype(np.uint8) for display via cv2.imshow. If the dynamic range is not [0,1] normalization may be required. The window rendering expects 8U data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_45

LANGUAGE: Python
CODE:
```
img8u = (img * 255).astype(np.uint8)\ncv2.imshow('Window', img8u)\ncv2.waitKey(0)
```

----------------------------------------

TITLE: Implementing Dense Optical Flow in Python
DESCRIPTION: Python implementation of dense optical flow using Farneback's algorithm (cv.calcOpticalFlowFarneback()). The code computes optical flow for all points in the frame and visualizes the flow field using HSV color coding where hue represents direction and value represents magnitude.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/optical_flow.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
import argparse

parser = argparse.ArgumentParser(description='This sample demonstrates Farneback Optical Flow calculation. \n'
                                     'The example file can be downloaded from: \n'
                                     'https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4')
parser.add_argument('image', type=str, help='path to image file')
args = parser.parse_args()

cap = cv.VideoCapture(args.image)

ret, frame1 = cap.read()
prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)
hsv = np.zeros_like(frame1)
hsv[..., 1] = 255

while(1):
    ret, frame2 = cap.read()
    if not ret:
        print('No frames grabbed!')
        break

    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)

    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)

    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])
    hsv[..., 0] = ang*180/np.pi/2
    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)
    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)

    cv.imshow('frame2', bgr)
    k = cv.waitKey(30) & 0xff
    if k == 27:
        break
    elif k == ord('s'):
        cv.imwrite('opticalfb.png', frame2)
        cv.imwrite('opticalhsv.png', bgr)
    prvs = next

cv.destroyAllWindows()
```

----------------------------------------

TITLE: Implementing Image Dilation with OpenCV Python
DESCRIPTION: Shows how to perform dilation on an image. Dilation increases the white region in the image and is often used after erosion to restore object size while maintaining noise removal.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
dilation = cv.dilate(img,kernel,iterations = 1)
```

----------------------------------------

TITLE: Creating and Activating Python Virtual Environment - Console
DESCRIPTION: These commands demonstrate the setup of a Python3.7+ virtual environment to isolate dependencies for the conversion and inference scripts. They use the 'virtualenv' tool and activate the environment, which is a prerequisite for clean library installation and reproducibility.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_0

LANGUAGE: console
CODE:
```
virtualenv -p /usr/bin/python3.7 <env_dir_path>\nsource <env_dir_path>/bin/activate
```

----------------------------------------

TITLE: Configuring OpenCV Python 2 Module Dependencies and Settings in CMake
DESCRIPTION: This CMake snippet first checks if the `PYTHON2_INCLUDE_PATH` and `PYTHON2_NUMPY_INCLUDE_DIRS` variables are set. If either is missing, it disables the `python2` OpenCV module using `ocv_module_disable`. It then defines several variables: `the_description` for the module, `MODULE_NAME` as `python2`, `MODULE_INSTALL_SUBDIR` as empty (indicating installation to the root library directory, often required by build systems like Buildbot), and `PYTHON` as `PYTHON2`. Finally, it includes a common CMake configuration file located in the parent directory (`../common.cmake`) and unsets the locally defined `MODULE_NAME` and `MODULE_INSTALL_SUBDIR` variables to avoid polluting the parent scope.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/python2/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(NOT PYTHON2_INCLUDE_PATH OR NOT PYTHON2_NUMPY_INCLUDE_DIRS)
  ocv_module_disable(python2)
endif()

set(the_description "The python2 bindings")
set(MODULE_NAME python2)
# Buildbot requires Python 2 to be in root lib dir
set(MODULE_INSTALL_SUBDIR "")

set(PYTHON PYTHON2)

include(../common.cmake)

unset(MODULE_NAME)
unset(MODULE_INSTALL_SUBDIR)
```

----------------------------------------

TITLE: Executing GrabCut Algorithm in OpenCV with JavaScript
DESCRIPTION: This JavaScript code snippet demonstrates the usage of the GrabCut function within OpenCV to perform foreground extraction on an 8-bit 3-channel image. Dependencies include OpenCV configured for JavaScript. Parameters include 'image' for the input, 'mask' for marking the foreground and background, and 'rect' for the region of interest. Temporary arrays 'bgdModel' and 'fgdModel' are used for background and foreground modeling respectively. 'iterCount' specifies the number of iterations, and 'mode' determines the operation mode. The function outputs a refined segmentation of the foreground and background.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_grabcut/js_grabcut.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
cv.grabCut (image, mask, rect, bgdModel, fgdModel, iterCount, mode = cv.GC_EVAL)
```

----------------------------------------

TITLE: Text Detection Inference in C++
DESCRIPTION: This C++ snippet performs text detection inference using a configured TextDetectionModel. It processes the input image and visualizes the detected text regions using polylines thanks to OpenCV's DNN API. The expected input is a preprocessed image, and the output is a visualization of detected texts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
std::vector<std::vector<Point>> detResults;
model.detect(detResults);

// Visualization
polylines(frame, results, true, Scalar(0, 255, 0), 2);
imshow("Text Detection", image);
waitKey();
```

----------------------------------------

TITLE: Calculating Image Histogram Demo in C++ (Full Code)
DESCRIPTION: Complete C++ program demonstrating how to load an image, split it into B, G, R channels, calculate the histogram for each channel using `cv::calcHist`, normalize the results, and display the histograms in a window. Depends on the OpenCV library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
@include samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp
```

----------------------------------------

TITLE: Implementing Canny Edge Detector in Java
DESCRIPTION: Complete implementation of the Canny Edge Detector in Java using OpenCV. This code creates a window with a trackbar to adjust the lower threshold for the Canny algorithm, applies the detector to an input image, and displays the result showing edges overlaid on the original image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import java.util.ArrayList;
import java.util.List;

import org.opencv.core.*;
import org.opencv.core.Core.MinMaxLocResult;
import org.opencv.highgui.HighGui;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;

class CannyDetectorDemo {
    private Mat src = new Mat();
    private Mat srcBlur = new Mat();
    private Mat detectedEdges = new Mat();
    private Mat dst = new Mat();
    private int lowThresh = 0;
    private static final int MAX_LOW_THRESH = 100;
    private static final int RATIO = 3;
    private static final int KERNEL_SIZE = 3;
    private static final Size BLUR_SIZE = new Size(3, 3);
    private JSlider cannyThresholdSlider;
    private int cannyThresholdSliderValue = 0;
    private JLabel cannyThresholdLabel;
    private JLabel radiusLabel;
    private JLabel iLabel;
    private static final String WINDOW_NAME = "Edge Map";

    public CannyDetectorDemo(String[] args) {
        String imagePath = args.length > 0 ? args[0] : "../data/fruits.jpg";
        src = Imgcodecs.imread(imagePath);
        if (src.empty()) {
            System.out.println("Error opening image!");
            System.out.println("Program Arguments: [image_name -- default ../data/fruits.jpg] \n");
            System.exit(-1);
        }
        dst = Mat.zeros(src.size(), src.type());
        Imgproc.cvtColor(src, detectedEdges, Imgproc.COLOR_BGR2GRAY);
        
        // Create and set up the window.
        final JFrame frame = new JFrame(WINDOW_NAME);
        frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
        // Set up the content pane.
        Image img = HighGui.toBufferedImage(dst);
        final JLabel imgLabel = new JLabel(new ImageIcon(img));
        frame.getContentPane().add(imgLabel, BorderLayout.CENTER);
        
        //Create and set up the panel.
        final JPanel sliderPanel = new JPanel();
        sliderPanel.setLayout(new BoxLayout(sliderPanel, BoxLayout.PAGE_AXIS));
        
        //Create the slider.
        cannyThresholdLabel = new JLabel("Min Threshold: " + cannyThresholdSliderValue);
        cannyThresholdSlider = new JSlider(0, MAX_LOW_THRESH, cannyThresholdSliderValue);
        cannyThresholdSlider.setMajorTickSpacing(20);
        cannyThresholdSlider.setMinorTickSpacing(10);
        cannyThresholdSlider.setPaintTicks(true);
        cannyThresholdSlider.setPaintLabels(true);
        cannyThresholdSlider.addChangeListener(new ChangeListener() {
            @Override
            public void stateChanged(ChangeEvent e) {
                JSlider source = (JSlider) e.getSource();
                cannyThresholdSliderValue = source.getValue();
                cannyThresholdLabel.setText("Min Threshold: " + cannyThresholdSliderValue);
                update();
                Image img = HighGui.toBufferedImage(dst);
                imgLabel.setIcon(new ImageIcon(img));
                frame.repaint();
            }
        });
        
        sliderPanel.add(cannyThresholdLabel);
        sliderPanel.add(cannyThresholdSlider);
        
        frame.getContentPane().add(sliderPanel, BorderLayout.PAGE_END);
        // Display the window.
        frame.pack();
        frame.setLocationRelativeTo(null);
        frame.setVisible(true);
        update();
    }

    private void update() {
        /// Reduce noise with a kernel 3x3
        Imgproc.blur(detectedEdges, detectedEdges, BLUR_SIZE);

        /// Canny detector
        Imgproc.Canny(detectedEdges, detectedEdges, cannyThresholdSliderValue, cannyThresholdSliderValue * RATIO,
                KERNEL_SIZE, false);

        /// Using Canny's output as a mask, we display our result
        dst = Mat.zeros(src.size(), src.type());
        src.copyTo(dst, detectedEdges);

    }

    public static void main(String[] args) {
        // Load the native OpenCV library
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
        
        // Schedule a job for the event dispatch thread:
        // creating and showing this application's GUI.
        javax.swing.SwingUtilities.invokeLater(new Runnable() {
            @Override
            public void run() {
                new CannyDetectorDemo(args);
            }
        });
    }
}
```

----------------------------------------

TITLE: Running Face Detection Inference - OpenCV DNN C++
DESCRIPTION: This snippet shows how to perform face detection using the initialized FaceDetectorYN object in C++. It runs inference on an input image and stores detection results in a cv::Mat. The main dependency is OpenCV. The primary parameter is the image to process, and the output is a matrix of detected face bounding boxes and landmarks according to the ONNX model output format.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
// Detect faces in an image
cv::Mat faces;
detector->detect(image, faces);
// 'faces' is a matrix where each row describes one detection (bounding box + landmarks)
```

----------------------------------------

TITLE: Calculating Image Histogram Demo in Python (Full Code)
DESCRIPTION: Complete Python script demonstrating how to load an image, split it into B, G, R channels using `cv.split`, calculate the histogram for each channel using `cv.calcHist`, normalize the results using `cv.normalize`, and display the histograms using Matplotlib or OpenCV drawing functions. Depends on OpenCV Python bindings (`cv2`) and potentially NumPy and Matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
@include samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py
```

----------------------------------------

TITLE: Accessing Image Shape (Dimensions) using OpenCV in Python
DESCRIPTION: Demonstrates retrieving the shape of an image using the `img.shape` attribute. It returns a tuple containing the number of rows, columns, and channels (for color images). For grayscale images, the tuple only contains rows and columns, which can be used to check if an image is color or grayscale.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
>>> print( img.shape )
(342, 548, 3)
```

----------------------------------------

TITLE: Implementing Harris Corner Detector in Java
DESCRIPTION: This Java code demonstrates how to use the Imgproc.cornerHarris function to detect corners in an image using the Harris-Stephens method. It processes the input image, applies the corner detection algorithm, and visualizes the results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;
import org.opencv.highgui.HighGui;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;

class CornerHarrisDemo {
    private Mat src = new Mat();
    private Mat srcGray = new Mat();
    private Mat dst = new Mat();
    private Mat dstNorm = new Mat();
    private Mat dstNormScaled = new Mat();
    private int thresh = 200;
    private int maxThresh = 255;

    public void run(String[] args) {
        String filename = args.length > 0 ? args[0] : "../data/building.jpg";
        src = Imgcodecs.imread(filename);
        if (src.empty()) {
            System.err.println("Cannot read image: " + filename);
            System.exit(0);
        }

        Imgproc.cvtColor(src, srcGray, Imgproc.COLOR_BGR2GRAY);

        HighGui.namedWindow("Source image");
        HighGui.createTrackbar("Threshold: ", "Source image", new int[]{thresh}, maxThresh, this::cornerHarris);
        HighGui.imshow("Source image", src);

        cornerHarris(0, null);

        HighGui.waitKey();
        System.exit(0);
    }

    private void cornerHarris(int, Void) {
        int blockSize = 2;
        int apertureSize = 3;
        double k = 0.04;

        Imgproc.cornerHarris(srcGray, dst, blockSize, apertureSize, k);

        Core.normalize(dst, dstNorm, 0, 255, Core.NORM_MINMAX, CvType.CV_32FC1, new Mat());
        Core.convertScaleAbs(dstNorm, dstNormScaled);

        for (int i = 0; i < dstNorm.rows(); i++) {
            for (int j = 0; j < dstNorm.cols(); j++) {
                if ((int) dstNorm.get(i, j)[0] > thresh) {
                    Imgproc.circle(dstNormScaled, new Point(j, i), 5, new Scalar(0), 2, 8, 0);
                }
            }
        }

        HighGui.imshow("Corners detected", dstNormScaled);
    }
}

public class CornerHarrisDemoRun {
    public static void main(String[] args) {
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
        new CornerHarrisDemo().run(args);
    }
}
```

----------------------------------------

TITLE: Setup Image in OpenCV Java
DESCRIPTION: In Java, reads an image, converts it to grayscale, and applies a Gaussian blur using OpenCV. OpenCV library is required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
Mat src = Imgcodecs.imread("image.jpg");
Mat gray = new Mat();
Imgproc.cvtColor(src, gray, Imgproc.COLOR_BGR2GRAY);
Imgproc.blur(gray, gray, new Size(3, 3));
```

----------------------------------------

TITLE: Creating Display Windows in C++
DESCRIPTION: Sets up windows to display both the captured frames and the thresholded frames using OpenCV in C++. This allows users to visualize input and processed images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cv::namedWindow("Display Image", cv::WINDOW_AUTOSIZE);
```

----------------------------------------

TITLE: Selecting and Copying an Image ROI using NumPy Slicing in Python
DESCRIPTION: Shows how to select a rectangular Region of Interest (ROI) using NumPy array slicing (`img[start_row:end_row, start_col:end_col]`). In this example, a section containing a ball is selected and then copied to another location within the same image using another slice assignment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_6

LANGUAGE: python
CODE:
```
>>> ball = img[280:340, 330:390]
>>> img[273:333, 100:160] = ball
```

----------------------------------------

TITLE: Accessing a Single Image Channel using NumPy Slicing in Python
DESCRIPTION: Shows an alternative, often faster method to access a single image channel (in this case, the Blue channel, index 0) using NumPy array slicing (`img[:, :, channel_index]`) instead of the `cv.split()` function. This accesses all rows and columns for the specified channel index.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
>>> b = img[:,:,0]
```

----------------------------------------

TITLE: Calculating Aspect Ratio using OpenCV.js
DESCRIPTION: Calculates the aspect ratio of a contour, defined as the ratio of the width to the height of its bounding rectangle. Requires a contour (`cnt`) as input. Uses `cv.boundingRect` to get the rectangle dimensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_properties/js_contour_properties.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
let rect = cv.boundingRect(cnt);
let aspectRatio = rect.width / rect.height;
```

----------------------------------------

TITLE: Loading and Transforming Image in C++ with OpenCV
DESCRIPTION: This snippet demonstrates how to load an image and apply an affine transformation and rotation using OpenCV in C++. It includes calculating a transform matrix from point sets and applying it to the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
@snippet samples/cpp/tutorial_code/ImgTrans/Geometric_Transforms_Demo.cpp Load the image
```

----------------------------------------

TITLE: Detecting Vertical Lines using Morphology in OpenCV (C++/Java/Python)
DESCRIPTION: Detects vertical lines in the binary image. A vertical structuring element (kernel) is created using `getStructuringElement` with `MORPH_RECT`. The size is chosen based on the expected line height. Erosion followed by dilation (morphological opening) is applied using this kernel to isolate vertical structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
//![vert]
// Specify size on vertical axis
int vertical_size = vertical.rows / 30;

// Create structure element for extracting vertical lines through morphology operations
Mat verticalStructure = getStructuringElement(MORPH_RECT, Size(1, vertical_size));

// Apply morphology operations
erode(vertical, vertical, verticalStructure, Point(-1, -1));
dilate(vertical, vertical, verticalStructure, Point(-1, -1));

// Show extracted vertical lines
show_wait_destroy("vertical", vertical);
//![vert]
```

LANGUAGE: java
CODE:
```
//![vert]
// Specify size on vertical axis
int vertical_size = vertical.rows() / 30;

// Create structure element for extracting vertical lines through morphology operations
Mat verticalStructure = Imgproc.getStructuringElement(Imgproc.MORPH_RECT, new Size( 1, vertical_size));

// Apply morphology operations
Imgproc.erode(vertical, vertical, verticalStructure, new Point(-1, -1));
Imgproc.dilate(vertical, vertical, verticalStructure, new Point(-1, -1));

// Show extracted vertical lines
showWaitDestroy("vertical", vertical);
//![vert]
```

LANGUAGE: python
CODE:
```
#![vert]
# Specify size on vertical axis
rows = vertical.shape[0]
verticalsize = rows // 30

# Create structure element for extracting vertical lines through morphology operations
verticalStructure = cv.getStructuringElement(cv.MORPH_RECT, (1, verticalsize))

# Apply morphology operations
vertical = cv.erode(vertical, verticalStructure)
vertical = cv.dilate(vertical, verticalStructure)

# Show extracted vertical lines
show_wait_destroy("vertical", vertical)
#![vert]
```

----------------------------------------

TITLE: Triggering the Model Conversion Script - Console
DESCRIPTION: This command runs a Python module that converts a PyTorch ResNet-50 model to ONNX format. It leverages the module system via the '-m' flag, invoking the conversion for reproducibility. Ensure all dependencies are installed and that the module path matches the project structure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_2

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_resnet50_onnx
```

----------------------------------------

TITLE: Drawing Detected Lines from Hough Transform in OpenCV (C++)
DESCRIPTION: This C++ snippet iterates over (rho, theta) lines detected by HoughLines and draws them on an output image. For each line, it calculates points for drawing and uses cv::line. Inputs are the lines vector and output image; output is an image with detected lines visualized. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
for( size_t i = 0; i < lines.size(); i++ )\n{\n  float rho = lines[i][0], theta = lines[i][1];\n  Point pt1, pt2;\n  double a = cos(theta), b = sin(theta);\n  double x0 = a*rho, y0 = b*rho;\n  pt1.x = cvRound(x0 + 1000*(-b));\n  pt1.y = cvRound(y0 + 1000*(a));\n  pt2.x = cvRound(x0 - 1000*(-b));\n  pt2.y = cvRound(y0 - 1000*(a));\n  line( cdst, pt1, pt2, Scalar(0,0,255), 3, LINE_AA);\n}\n
```

----------------------------------------

TITLE: Inpainting with OpenCV in Python
DESCRIPTION: This snippet demonstrates how to apply inpainting using the OpenCV library in Python. It uses a mask to specify the regions of the image that need to be restored, employing the Fast Marching Method by setting the flag cv.INPAINT_TELEA. Key dependencies include numpy and OpenCV libraries, and the input includes a degraded image and a corresponding mask. The output is displayed using OpenCV's imshow function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_inpainting/py_inpainting.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('messi_2.jpg')
mask = cv.imread('mask2.png', cv.IMREAD_GRAYSCALE)

dst = cv.inpaint(img,mask,3,cv.INPAINT_TELEA)

cv.imshow('dst',dst)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Parallel Convolution Implementation using OpenCV
DESCRIPTION: This snippet illustrates a parallel implementation of convolution using OpenCV's parallel_for_ framework. It demonstrates splitting the image into stripes and applying convolution concurrently, optimizing performance by leveraging multiple processor cores. The example provides custom class definition for handling the parallel execution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_new/how_to_use_OpenCV_parallel_for_new.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp convolution-parallel
```

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp overload-full
```

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp convolution-parallel-function
```

----------------------------------------

TITLE: Saving Video with OpenCV in Python
DESCRIPTION: This snippet demonstrates how to capture video from a camera, flip each frame vertically, and save it to a file using OpenCV. It uses cv.VideoWriter() to create an output video file with specified codec, FPS, and frame size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_video_display/py_video_display.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

# Define the codec and create VideoWriter object
fourcc = cv.VideoWriter_fourcc(*'XVID')
out = cv.VideoWriter('output.avi', fourcc, 20.0, (640,  480))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    frame = cv.flip(frame, 0)

    # write the flipped frame
    out.write(frame)

    cv.imshow('frame', frame)
    if cv.waitKey(1) == ord('q'):
        break

# Release everything if job is finished
cap.release()
out.release()
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Setting up Trackbars for Threshold Parameters (Python)
DESCRIPTION: In Python, this code creates two OpenCV trackbars on the thresholding result window for type and value, each triggering Threshold_Demo when changed. It enables real-time UI parameter tuning without restarting the program. Depends on cv2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
# [trackbar]\ncv.createTrackbar('Type', window_name, 3, max_type, Threshold_Demo)\ncv.createTrackbar('Value', window_name, 0, max_value, Threshold_Demo)\n# [trackbar]
```

----------------------------------------

TITLE: Implementing Shi-Tomasi Corner Detection using goodFeaturesToTrack() in OpenCV Python
DESCRIPTION: This code demonstrates how to detect corners in an image using the Shi-Tomasi method with OpenCV's goodFeaturesToTrack() function. It loads an image, converts it to grayscale, finds the 25 best corners with a quality threshold of 0.01 and minimum distance of 10 pixels, and visualizes the results by drawing circles at corner positions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_shi_tomasi/py_shi_tomasi.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('blox.jpg')
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)

corners = cv.goodFeaturesToTrack(gray,25,0.01,10)
corners = np.int0(corners)

for i in corners:
    x,y = i.ravel()
    cv.circle(img,(x,y),3,255,-1)

plt.imshow(img),plt.show()
```

----------------------------------------

TITLE: Applying Blur Filter with OpenCV in Python
DESCRIPTION: This Python snippet demonstrates using OpenCV's blur() function to apply a normalized box filter for smoothing images. Dependencies include OpenCV, and it takes image parameters, kernel size, and anchor point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/Smoothing/smoothing.py blur
```

----------------------------------------

TITLE: Simple Thresholding Implementation in OpenCV Python
DESCRIPTION: Demonstrates different types of simple thresholding techniques using cv.threshold function. Compares BINARY, BINARY_INV, TRUNC, TOZERO, and TOZERO_INV thresholding methods with visualization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

img = cv.imread('gradient.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)
ret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)
ret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)
ret,thresh4 = cv.threshold(img,127,255,cv.THRESH_TOZERO)
ret,thresh5 = cv.threshold(img,127,255,cv.THRESH_TOZERO_INV)

titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']
images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]

for i in range(6):
    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray',vmin=0,vmax=255)
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])

plt.show()
```

----------------------------------------

TITLE: Complete Example: Loading, Processing, and Displaying Image with OpenCV.js (HTML/JavaScript)
DESCRIPTION: Provides a full HTML page integrating all previous steps. It includes HTML for file input and image/canvas display, JavaScript for handling file selection, asynchronously loading OpenCV.js (`opencv.js`), updating a status message via the Emscripten `Module.onRuntimeInitialized` callback, reading the uploaded image into a `cv.Mat` using `cv.imread` upon image load, displaying the `cv.Mat` on a canvas using `cv.imshow`, and explicitly releasing the memory allocated for the `cv.Mat` using `mat.delete()`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_usage/js_usage.markdown#2025-04-22_snippet_6

LANGUAGE: html
CODE:
```
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<p id="status">OpenCV.js is loading...</p>
<div>
  <div class="inputoutput">
    <img id="imageSrc" alt="No Image" />
    <div class="caption">imageSrc <input type="file" id="fileInput" name="file" /></div>
  </div>
  <div class="inputoutput">
    <canvas id="canvasOutput" ></canvas>
    <div class="caption">canvasOutput</div>
  </div>
</div>
<script type="text/javascript">
let imgElement = document.getElementById('imageSrc');
let inputElement = document.getElementById('fileInput');
inputElement.addEventListener('change', (e) => {
  imgElement.src = URL.createObjectURL(e.target.files[0]);
}, false);

imgElement.onload = async function() {
  cv = (cv instanceof Promise) ? await cv : cv;
  let mat = cv.imread(imgElement);
  cv.imshow('canvasOutput', mat);
  mat.delete();
};

var Module = {
  // https://emscripten.org/docs/api_reference/module.html#Module.onRuntimeInitialized
  onRuntimeInitialized() {
    document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
  }
};
</script>
<script async src="opencv.js" type="text/javascript"></script>
</body>
</html>
```

----------------------------------------

TITLE: Loading an Image from File in Grayscale with OpenCV in Python
DESCRIPTION: Illustrates image loading in grayscale via imread with cv2.IMREAD_GRAYSCALE in Python OpenCV. Requires opencv-python package. File path is input; single-channel NumPy array is output. Particularly useful for processing algorithms needing intensity only.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
img_gray = cv2.imread('my_image.jpg', cv2.IMREAD_GRAYSCALE)
```

----------------------------------------

TITLE: Extracting Face Features for Recognition - OpenCV DNN C++
DESCRIPTION: This snippet shows how to extract features from a face image using a FaceRecognizerSF object in C++. After detecting and cropping the face region, the extractFeature method is called. It requires the input image and face bounding box. The method returns a floating-point vector (feature) representing the face for downstream comparison.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
// Extract features for recognition
cv::Mat faceFeature;
recognizer->feature(image, faceBox, faceFeature); // or extractFeature()
// 'faceFeature' now contains the vector representation of the face
```

----------------------------------------

TITLE: Detecting Faces and Eyes with Haar Cascades in Java using OpenCV
DESCRIPTION: This Java code snippet utilizes OpenCV's Java bindings to perform face and eye detection. It initializes `CascadeClassifier` objects and loads the necessary Haar cascade XML files using the `load` method. The code captures frames from a video source, converts the frame to grayscale, and uses the `detectMultiScale` method to identify face locations. Subsequently, it searches for eyes within the detected face regions using another `detectMultiScale` call. Rectangles are drawn around the detected faces and eyes before displaying the output. Requires the OpenCV Java library, the native OpenCV library to be loaded, and the specified Haar cascade XML files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/cascade_classifier.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
// This tutorial code's is shown lines below. You can also download it from
// [here](https://github.com/opencv/opencv/tree/4.x/samples/java/tutorial_code/objectDetection/cascade_classifier/ObjectDetectionDemo.java)
@include samples/java/tutorial_code/objectDetection/cascade_classifier/ObjectDetectionDemo.java
```

----------------------------------------

TITLE: Applying Sobel Operator in Python
DESCRIPTION: This Python code snippet shows how to apply the Sobel operator using OpenCV to detect edges in an image. Key steps include reading an image, noise reduction with Gaussian blur, converting to grayscale, applying the Sobel function for gradients in both directions, and displaying the result using matplotlib. OpenCV and matplotlib are required dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread('lena.jpg', 0) // Load source image
```

LANGUAGE: python
CODE:
```
img = cv2.GaussianBlur(img, (3, 3), 0) // Reduce noise
```

LANGUAGE: python
CODE:
```
sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3) // Apply Sobel for x-gradient
sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3) // Apply Sobel for y-gradient
```

LANGUAGE: python
CODE:
```
abs_sobelx = cv2.convertScaleAbs(sobelx) 
abs_sobely = cv2.convertScaleAbs(sobely)
```

LANGUAGE: python
CODE:
```
gradient = cv2.addWeighted(abs_sobelx, 0.5, abs_sobely, 0.5, 0) // Approximate the gradient
```

LANGUAGE: python
CODE:
```
plt.imshow(gradient, cmap='gray') // Display results
plt.title('Sobel Demo')
plt.show()
```

----------------------------------------

TITLE: Performing Canny Edge Detection with OpenCV in Python
DESCRIPTION: This code snippet demonstrates how to use OpenCV's cv.Canny() function to perform edge detection on a grayscale image. It also shows how to display the original and edge-detected images side by side using matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_canny/py_canny.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
edges = cv.Canny(img,100,200)

plt.subplot(121),plt.imshow(img,cmap = 'gray')
plt.title('Original Image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(edges,cmap = 'gray')
plt.title('Edge Image'), plt.xticks([]), plt.yticks([])

plt.show()
```

----------------------------------------

TITLE: Simple Mouse Event Handling for Circle Drawing in OpenCV with Python
DESCRIPTION: This code snippet shows a simple application that draws a circle on an image where the user double-clicks. It demonstrates the use of cv.setMouseCallback() to handle mouse events and cv.circle() to draw shapes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_mouse_handling/py_mouse_handling.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

# mouse callback function
def draw_circle(event,x,y,flags,param):
    if event == cv.EVENT_LBUTTONDBLCLK:
        cv.circle(img,(x,y),100,(255,0,0),-1)

# Create a black image, a window and bind the function to window
img = np.zeros((512,512,3), np.uint8)
cv.namedWindow('image')
cv.setMouseCallback('image',draw_circle)

while(1):
    cv.imshow('image',img)
    if cv.waitKey(20) & 0xFF == 27:
        break
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Detecting Barcodes using OpenCV C++
DESCRIPTION: Illustrates the use of cv::barcode::BarcodeDetector::detect in OpenCV, which leverages gradient coherence to identify barcodes. It employs multiscale patch analysis to detect barcodes of various sizes. The output is a set of rectangles outlining detected barcodes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/barcode_detect_and_decode.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
@snippet cpp/barcode.cpp detect
```

----------------------------------------

TITLE: Gradient Structure Tensor Calculation in Python
DESCRIPTION: This Python code segment performs anisotropic image segmentation using gradient structure tensor. OpenCV is a required library. Key operations are the same as in C++: calculating orientation and coherency, thresholding, and result combination. Input involves image data and window size, resulting in a segmented image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/anisotropic_image_segmentation/anisotropic_image_segmentation.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
@add_toggle_python
    @include samples/python/tutorial_code/imgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.py
@end_toggle
```

LANGUAGE: Python
CODE:
```
@add_toggle_python
    @snippet samples/python/tutorial_code/imgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.py main
@end_toggle
```

LANGUAGE: Python
CODE:
```
@add_toggle_python
    @snippet samples/python/tutorial_code/imgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.py calcGST
@end_toggle
```

LANGUAGE: Python
CODE:
```
@add_toggle_python
    @snippet samples/python/tutorial_code/imgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.py thresholding
@end_toggle
```

LANGUAGE: Python
CODE:
```
@add_toggle_python
    @snippet samples/python/tutorial_code/imgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.py combining
@end_toggle
```

----------------------------------------

TITLE: Implementing Canny Edge Detector in Python
DESCRIPTION: Complete implementation of the Canny Edge Detector in Python using OpenCV. This code creates a window with a trackbar to adjust the lower threshold for the Canny algorithm, applies the detector to an input image, and displays the result showing edges overlaid on the original image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
from __future__ import print_function
import cv2 as cv
import argparse

max_lowThreshold = 100
window_name = 'Edge Map'
ratio = 3
kernel_size = 3

def CannyThreshold(val):
    low_threshold = val
    img_blur = cv.blur(src_gray, (3,3))
    detected_edges = cv.Canny(img_blur, low_threshold, low_threshold*ratio, kernel_size)
    mask = detected_edges != 0
    dst = src * (mask[:,:,None].astype(src.dtype))
    cv.imshow(window_name, dst)

parser = argparse.ArgumentParser(description='Code for Canny Edge Detector tutorial.')
parser.add_argument('--input', help='Path to input image.', default='fruits.jpg')
args = parser.parse_args()

src = cv.imread(cv.samples.findFile(args.input))
if src is None:
    print('Could not open or find the image: ', args.input)
    exit(0)

src_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)

cv.namedWindow(window_name)
cv.createTrackbar('Min Threshold:', window_name, 0, max_lowThreshold, CannyThreshold)

CannyThreshold(0)

cv.waitKey()
```

----------------------------------------

TITLE: Establishing Histogram Bin Count in Java
DESCRIPTION: Java snippet defining the number of bins for the histogram calculation. A `MatOfInt` object named `histSize` is created and initialized with a single value (e.g., 256), specifying the number of bins for the histogram.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_10

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Establish the number of bins
```

----------------------------------------

TITLE: Including Necessary Headers in OpenCV C++
DESCRIPTION: This snippet demonstrates how to include necessary headers for using OpenCV in a C++ project. It covers the inclusion of core, imgcodecs, and highgui modules, along with the iostream for console input/output operations. Using namespace cv is declared for ease of access to library functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/core.hpp>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/highgui.hpp>
#include <iostream>

using namespace cv;
```

----------------------------------------

TITLE: Calculating Re-projection Error for Camera Calibration in OpenCV with Python
DESCRIPTION: This code calculates the re-projection error to evaluate the accuracy of camera calibration parameters. It projects 3D object points to 2D image points using the calibration parameters and compares them with the actual detected image points to compute the mean error.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
mean_error = 0
for i in range(len(objpoints)):
    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)
    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)
    mean_error += error

print( "total error: {}".format(mean_error/len(objpoints)) )
```

----------------------------------------

TITLE: Thresholding Operations Initialization in OpenCV (Java, Full Example)
DESCRIPTION: This Java code example achieves thresholding through image loading, grayscale conversion (if needed), and real-time interactivity via graphical sliders for threshold type and value using OpenCV's Java API. It defines listeners for slider events to update the displayed thresholded image automatically. The code expects OpenCV 3.0+ and appropriate Java bindings. Input is the path to the image and user actions on the sliders; output is a live window reflecting threshold changes. Window and trackbar management, as well as type/value mappings, are shown in the main method and associated callbacks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;\nimport org.opencv.highgui.*;\nimport org.opencv.imgproc.*;\n\npublic class Threshold {\n    static Mat src, src_gray, dst;\n    static int threshold_value = 0;\n    static int threshold_type = 3;\n    static final int max_value = 255;\n    static final int max_type = 4;\n    static final int max_BINARY_value = 255;\n    static String window_name = "Threshold Demo";\n\n    public static void main(String[] args) {\n        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);\n        src = Highgui.imread(args.length > 0 ? args[0] : "chicky_512.png");\n        if (src.empty()) {\n            System.out.println("Error opening image");\n            return;\n        }\n        Imgproc.cvtColor(src, src_gray = new Mat(), Imgproc.COLOR_BGR2GRAY);\n        HighGui.namedWindow(window_name);\n\n        // Create Trackbars\n        HighGui.createTrackbar("Type:\n 0:Binary \n 1:BinaryInv \n 2:Trunc \n 3:ToZero \n 4:ToZeroInv", window_name, new int[]{threshold_type}, max_type, (pos)->{\n            threshold_type = pos;\n            update();\n        });\n        HighGui.createTrackbar("Value", window_name, new int[]{threshold_value}, max_value, (pos)->{\n            threshold_value = pos;\n            update();\n        });\n        update();\n        HighGui.waitKey(0);\n    }\n\n    static void update() {\n        Imgproc.threshold(src_gray, dst = new Mat(), threshold_value, max_BINARY_value, threshold_type);\n        HighGui.imshow(window_name, dst);\n    }\n}
```

----------------------------------------

TITLE: Normalizing Template Matching Results (Python)
DESCRIPTION: Applies normalization to the result matrix from `cv2.matchTemplate` using `cv2.normalize`. It scales the correlation values to the range 0-1 using the `cv2.NORM_MINMAX` method, which aids in consistent visualization and thresholding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_27

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py normalize
```

----------------------------------------

TITLE: Selecting Region of Interest (ROI) with OpenCV in Java
DESCRIPTION: Shows extracting a submatrix ROI from an image using Java's OpenCV Mat.submat method. Input is a Mat and region bounds. Submat shares storage with original image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_32

LANGUAGE: Java
CODE:
```
Mat roi = img.submat(y, y + h, x, x + w);
```

----------------------------------------

TITLE: Pose Estimation with RANSAC in PnPProblem Using C++
DESCRIPTION: Implements the estimatePoseRANSAC function of the PnPProblem class to calculate rotation and translation matrices through RANSAC. It requires a set of 2D/3D correspondences, selected PnP method, output inliers container, and RANSAC parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_17

LANGUAGE: cpp
CODE:
```
// Estimate the pose given a list of 2D/3D correspondences with RANSAC and the method to use

void PnPProblem::estimatePoseRANSAC( const std::vector<cv::Point3f> &list_points3d,        // list with model 3D coordinates
                                     const std::vector<cv::Point2f> &list_points2d,        // list with scene 2D coordinates
                                     int flags, cv::Mat &inliers, int iterationsCount,     // PnP method; inliers container
                                     float reprojectionError, float confidence )           // RANSAC parameters
{
    cv::Mat distCoeffs = cv::Mat::zeros(4, 1, CV_64FC1);    // vector of distortion coefficients
    cv::Mat rvec = cv::Mat::zeros(3, 1, CV_64FC1);          // output rotation vector
    cv::Mat tvec = cv::Mat::zeros(3, 1, CV_64FC1);          // output translation vector

    bool useExtrinsicGuess = false;   // if true the function uses the provided rvec and tvec values as
                                      // initial approximations of the rotation and translation vectors

    cv::solvePnPRansac( list_points3d, list_points2d, _A_matrix, distCoeffs, rvec, tvec,
                        useExtrinsicGuess, iterationsCount, reprojectionError, confidence,
                        inliers, flags );

    Rodrigues(rvec,_R_matrix);                   // converts Rotation Vector to Matrix
    _t_matrix = tvec;                            // set translation matrix

    this->set_P_matrix(_R_matrix, _t_matrix);    // set rotation-translation matrix

}
```

----------------------------------------

TITLE: Converting BGR Image to Grayscale with OpenCV in Java
DESCRIPTION: Shows converting a 3-channel BGR image to grayscale using Imgproc.cvtColor in Java OpenCV. Input/Output are Mat objects. Grayscale output has single channel.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_35

LANGUAGE: Java
CODE:
```
Mat gray = new Mat();\nImgproc.cvtColor(img, gray, Imgproc.COLOR_BGR2GRAY);
```

----------------------------------------

TITLE: Marker Creation for Watershed Algorithm
DESCRIPTION: Creates and labels markers for watershed segmentation using connected components. Marks known regions with different positive integers and unknown regions with zero.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_watershed/py_watershed.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
# Marker labelling
ret, markers = cv.connectedComponents(sure_fg)

# Add one to all labels so that sure background is not 0, but 1
markers = markers+1

# Now, mark the region of unknown with zero
markers[unknown==255] = 0
```

----------------------------------------

TITLE: Reading and Initializing ONNX Model using OpenCV DNN - C++
DESCRIPTION: This C++ statement uses OpenCV's deep learning module to read an ONNX model into the Net object. It optionally accepts config and framework strings. The 'model' variable should be an ONNX file path, matching prior export output. This is the initial step before preprocessing and inference.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
Net net = readNet(model, config, framework);
```

----------------------------------------

TITLE: Drawing Detected Lines from Hough Transform in OpenCV (Java)
DESCRIPTION: This Java snippet draws lines found by HoughLines onto an output image using OpenCV Java drawing functions. For each line in the Mat, it computes the line endpoints from (rho, theta) and uses Imgproc.line to visualize it. Requires output Mat and valid lines Mat.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_10

LANGUAGE: Java
CODE:
```
for (int i = 0; i < lines.rows(); i++) {\n  double[] data = lines.get(i, 0);\n  double rho = data[0], theta = data[1];\n  double a = Math.cos(theta), b = Math.sin(theta);\n  double x0 = a*rho, y0 = b*rho;\n  Point pt1 = new Point(Math.round(x0 + 1000*(-b)), Math.round(y0 + 1000*(a)));\n  Point pt2 = new Point(Math.round(x0 - 1000*(-b)), Math.round(y0 - 1000*(a)));\n  Imgproc.line(color_dst, pt1, pt2, new Scalar(0, 0, 255), 3, Imgproc.LINE_AA);\n}\n
```

----------------------------------------

TITLE: Feature Matching with FLANN in Java
DESCRIPTION: This Java implementation demonstrates how to use the FlannBasedMatcher for efficient feature matching with SURF descriptors. It loads two images, detects and describes features, matches them using FLANN, and filters the matches using Lowe's distance ratio test.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_flann_matcher/feature_flann_matcher.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
import java.util.ArrayList;
import java.util.List;

import org.opencv.core.Core;
import org.opencv.core.CvType;
import org.opencv.core.DMatch;
import org.opencv.core.Mat;
import org.opencv.core.MatOfByte;
import org.opencv.core.MatOfDMatch;
import org.opencv.core.MatOfKeyPoint;
import org.opencv.core.Scalar;
import org.opencv.features2d.DescriptorMatcher;
import org.opencv.features2d.Features2d;
import org.opencv.highgui.HighGui;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.xfeatures2d.SURF;

class SURFFLANNMatchingDemo {
    public void run(String[] args) {
        String filename1 = args.length > 1 ? args[0] : "../data/box.png";
        String filename2 = args.length > 1 ? args[1] : "../data/box_in_scene.png";
        Mat img1 = Imgcodecs.imread(filename1, Imgcodecs.IMREAD_GRAYSCALE);
        Mat img2 = Imgcodecs.imread(filename2, Imgcodecs.IMREAD_GRAYSCALE);
        if (img1.empty() || img2.empty()) {
            System.err.println("Cannot read images!");
            System.exit(0);
        }

        //-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors
        double hessianThreshold = 400;
        int nOctaves = 4, nOctaveLayers = 3;
        boolean extended = false, upright = false;
        SURF detector = SURF.create(hessianThreshold, nOctaves, nOctaveLayers, extended, upright);
        MatOfKeyPoint keypoints1 = new MatOfKeyPoint(), keypoints2 = new MatOfKeyPoint();
        Mat descriptors1 = new Mat(), descriptors2 = new Mat();
        detector.detectAndCompute(img1, new Mat(), keypoints1, descriptors1);
        detector.detectAndCompute(img2, new Mat(), keypoints2, descriptors2);

        //-- Step 2: Matching descriptor vectors using FLANN matcher
        DescriptorMatcher matcher = DescriptorMatcher.create(DescriptorMatcher.FLANNBASED);
        List<MatOfDMatch> knnMatches = new ArrayList<>();
        matcher.knnMatch(descriptors1, descriptors2, knnMatches, 2);

        //-- Filter matches using the Lowe's ratio test
        float ratioThresh = 0.7f;
        List<DMatch> listOfGoodMatches = new ArrayList<>();
        for (int i = 0; i < knnMatches.size(); i++) {
            if (knnMatches.get(i).rows() > 1) {
                DMatch[] matches = knnMatches.get(i).toArray();
                if (matches[0].distance < ratioThresh * matches[1].distance) {
                    listOfGoodMatches.add(matches[0]);
                }
            }
        }
        MatOfDMatch goodMatches = new MatOfDMatch();
        goodMatches.fromList(listOfGoodMatches);

        //-- Draw matches
        Mat imgMatches = new Mat();
        Features2d.drawMatches(img1, keypoints1, img2, keypoints2, goodMatches, imgMatches, Scalar.all(-1),
                Scalar.all(-1), new MatOfByte(), Features2d.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS);

        //-- Show detected matches
        HighGui.imshow("Good Matches", imgMatches);
        HighGui.waitKey(0);

        System.exit(0);
    }
}

public class SURFFLANNMatchingDemo {
    public static void main(String[] args) {
        // Load the native OpenCV library
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);

        new SURFFLANNMatchingDemo().run(args);
    }
}
```

----------------------------------------

TITLE: Implementing Canny Edge Detector in C++
DESCRIPTION: Complete implementation of the Canny Edge Detector in C++ using OpenCV. This code creates a window with a trackbar to adjust the lower threshold for the Canny algorithm, applies the detector to an input image, and displays the result showing edges overlaid on the original image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>
#include <iostream>

using namespace cv;
using namespace std;

//![variables]
Mat src, src_gray;
Mat dst, detected_edges;

int lowThreshold = 0;
const int max_lowThreshold = 100;
const int ratio = 3;
const int kernel_size = 3;
const char* window_name = "Edge Map";
//![variables]

static void CannyThreshold(int, void*)
{
    //![reduce_noise]
    /// Reduce noise with a kernel 3x3
    blur( src_gray, detected_edges, Size(3,3) );
    //![reduce_noise]

    //![canny]
    /// Canny detector
    Canny( detected_edges, detected_edges, lowThreshold, lowThreshold*ratio, kernel_size );
    //![canny]

    //![fill]
    /// Using Canny's output as a mask, we display our result
    dst = Scalar::all(0);
    //![fill]

    //![copyto]
    src.copyTo( dst, detected_edges);
    //![copyto]

    //![display]
    imshow( window_name, dst );
    //![display]
}

int main( int argc, char** argv )
{
    //![load]
    CommandLineParser parser( argc, argv, "{@input | fruits.jpg | input image}" );
    src = imread( samples::findFile( parser.get<String>( "@input" ) ), IMREAD_COLOR );

    if( src.empty() )
    {
        std::cout << "Could not open or find the image!\n" << std::endl;
        std::cout << "Usage: " << argv[0] << " <Input image>" << std::endl;
        return -1;
    }
    //![load]

    //![create_mat]
    /// Create a matrix of the same type and size as src (for dst)
    dst.create( src.size(), src.type() );
    //![create_mat]

    //![convert_to_gray]
    cvtColor( src, src_gray, COLOR_BGR2GRAY );
    //![convert_to_gray]

    //![create_window]
    namedWindow( window_name, WINDOW_AUTOSIZE );
    //![create_window]

    //![create_trackbar]
    /// Create a Trackbar for user to enter threshold
    createTrackbar( "Min Threshold:", window_name, &lowThreshold, max_lowThreshold, CannyThreshold );
    //![create_trackbar]

    /// Show the image
    CannyThreshold(0, 0);

    /// Wait until user exit program by pressing a key
    waitKey(0);

    return 0;
}
```

----------------------------------------

TITLE: Calculating Homography Using OpenCV in C++
DESCRIPTION: This C++ code sample calculates the homography matrix using OpenCV for stitching operations. Dependencies include the OpenCV library. Inputs are camera parameters and image views, and the output is the homography matrix necessary for stitching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_34

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>

void computeHomography(cv::Mat image1, cv::Mat image2) {
    // Code to compute homography
    // ...
}
```

----------------------------------------

TITLE: Extracting Foreground Mask with apply() Method in OpenCV.js - JavaScript
DESCRIPTION: Illustrates how to obtain the foreground mask from a video frame using the apply() method of BackgroundSubtractorMOG2 in OpenCV.js. Requires two cv.Mat objects: 'image' (input frame in [0,255] pixel range) and 'fgmask' (output mask). The optional 'learningRate' parameter tunes the adaptation speed of the background model. Outputs an 8-bit binary mask; remember to properly initialize 'image' and 'fgmask' before use.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_video/js_bg_subtraction/js_bg_subtraction.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
// Assume bgSubtractor, 'image', and 'fgmask' (both cv.Mat) are already initialized
let learningRate = -1; // use -1 for auto learning rate
// Process the next framegSubtractor.apply(image, fgmask, learningRate);
// 'fgmask' now contains the binary foreground mask
```

----------------------------------------

TITLE: Allocating/Resizing Output Mat using create() in OpenCV in C++
DESCRIPTION: Creates or resizes a cv::Mat output buffer with desired size/type using create in C++. This function allocates storage when needed and preserves storage if already appropriately sized. Input is output Mat and target size/type. Avoids unnecessary reallocation. No copy of input data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_25

LANGUAGE: C++
CODE:
```
output.create(input.rows, input.cols, input.type());
```

----------------------------------------

TITLE: Robust Matching Function Implementation in C++
DESCRIPTION: Implements the robustMatch function of the RobustMatcher class to match descriptor pairs, apply a ratio test, and ensure symmetry in matched pairs to filter for robustness.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_11

LANGUAGE: cpp
CODE:
```
void RobustMatcher::robustMatch( const cv::Mat& frame, std::vector<cv::DMatch>& good_matches,
                                 std::vector<cv::KeyPoint>& keypoints_frame,
                                 const std::vector<cv::KeyPoint>& keypoints_model, const cv::Mat& descriptors_model )
{

    // 1a. Detection of the ORB features
    this->computeKeyPoints(frame, keypoints_frame);

    // 1b. Extraction of the ORB descriptors
    cv::Mat descriptors_frame;
    this->computeDescriptors(frame, keypoints_frame, descriptors_frame);

    // 2. Match the two image descriptors
    std::vector<std::vector<cv::DMatch> > matches12, matches21;

    // 2a. From image 1 to image 2
    matcher_->knnMatch(descriptors_frame, descriptors_model, matches12, 2); // return 2 nearest neighbours

    // 2b. From image 2 to image 1
    matcher_->knnMatch(descriptors_model, descriptors_frame, matches21, 2); // return 2 nearest neighbours

    // 3. Remove matches for which NN ratio is > than threshold
    // clean image 1 -> image 2 matches
    int removed1 = ratioTest(matches12);
    // clean image 2 -> image 1 matches
    int removed2 = ratioTest(matches21);

    // 4. Remove non-symmetrical matches
    symmetryTest(matches12, matches21, good_matches);

}
```

----------------------------------------

TITLE: Drawing a Rook Chess Piece in C++
DESCRIPTION: Drawing a rook chess piece using lines, rectangles, and polygons in OpenCV C++. Demonstrates creating a complex shape by combining multiple basic drawing functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
/// 2. Draw a rook
/// ------------------

/// 2.a. Create a convex polygon
MyPolygon( rook_image );

/// 2.b. Creating rectangles
rectangle( rook_image,
       Point( 0, 7*w/8 ),
       Point( w, w),
       Scalar( 0, 255, 255 ),
       FILLED,
       LINE_8 );

/// 2.c. Create a few lines
MyLine( rook_image, Point( 0, 15*w/16 ), Point( w, 15*w/16 ) );
MyLine( rook_image, Point( w/4, 7*w/8 ), Point( w/4, w ) );
MyLine( rook_image, Point( w/2, 7*w/8 ), Point( w/2, w ) );
MyLine( rook_image, Point( 3*w/4, 7*w/8 ), Point( 3*w/4, w ) );
```

----------------------------------------

TITLE: Registering Custom Layer OpenCV C++
DESCRIPTION: Snippet illustrating how to register a custom layer before importing the model in OpenCV's deep learning engine.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp Register a custom layer
```

----------------------------------------

TITLE: Calculating Convex Hull in Python using OpenCV
DESCRIPTION: This Python script utilizes the OpenCV library (`cv2`) to load an image, apply thresholding to find contours using `cv.findContours`, calculate the convex hull for each detected contour with `cv.convexHull`, and then draw both the contours and their corresponding hulls on a blank image. It requires `cv2` and `numpy`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/hull/hull.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
@add_toggle_python
This tutorial code's is shown lines below. You can also download it from
[here](https://github.com/opencv/opencv/tree/4.x/samples/python/tutorial_code/ShapeDescriptors/hull/hull_demo.py)
@include samples/python/tutorial_code/ShapeDescriptors/hull/hull_demo.py
@end_toggle
```

----------------------------------------

TITLE: Performing Image Blurring with cv.blur in C++
DESCRIPTION: Explains how to use cv.blur() to apply a normalized box filter for image blurring. The blurring reduces image noise by averaging pixel values. Requires OpenCV, with parameters including source image, destination image, and kernel size. This approach uses a 3x3 normalized box filter.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_filtering/js_filtering.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cv::blur(src, dst, cv::Size(ksize, ksize), cv::Point(-1, -1), cv::BORDER_DEFAULT);
```

----------------------------------------

TITLE: Modifying Pixel Values in an OpenCV Image using NumPy Indexing in Python
DESCRIPTION: Illustrates modifying the pixel value at coordinates (100, 100) to white ([255, 255, 255]) using NumPy array assignment. It then prints the new value to confirm the change. Direct modification using NumPy indexing is possible but iterating through all pixels this way is discouraged for performance reasons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
>>> img[100,100] = [255,255,255]
>>> print( img[100,100] )
[255 255 255]
```

----------------------------------------

TITLE: Probabilistic Hough Line Transform Implementation in Python OpenCV
DESCRIPTION: Shows the implementation of Probabilistic Hough Transform using cv.HoughLinesP(), which is an optimized version that uses random sampling of points. It directly returns line endpoints and includes parameters for minimum line length and maximum line gap.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
@include probabilistic_hough_line_transform.py
```

----------------------------------------

TITLE: Measuring Execution Time with OpenCV Timing Functions in Python
DESCRIPTION: Illustrates how to use cv.getTickCount and cv.getTickFrequency to measure code execution time in Python. The snippet captures the number of clock cycles before and after code execution and reports the elapsed time in seconds. Requires OpenCV (cv2) installed and assumes the presence of a valid image file. Inputs include the image file path and kernel size range, while the output is the elapsed time for median filtering. This approach is limited to global time measurement and does not provide function-level profiling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_optimization/py_optimization.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
e1 = cv.getTickCount()
# your code execution
e2 = cv.getTickCount()
time = (e2 - e1)/ cv.getTickFrequency()
```

----------------------------------------

TITLE: Running TensorFlow MobileNet Evaluation via OpenCV dnn CLI (Console)
DESCRIPTION: Shows the exact command to evaluate a TensorFlow MobileNet model with the dnn_model_runner evaluation script. This command triggers data loading, evaluation, and result logging for the selected model. Dependencies include Python and an available MobileNet model properly referenced as 'mobilenet'. Parameters must align with available input data, and outputs are written as log files with measured metrics.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_2

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.classification.py_to_py_cls --model_name mobilenet
```

----------------------------------------

TITLE: Scaling Images with OpenCV in Python
DESCRIPTION: Demonstrates how to resize an image using cv.resize() with two different approaches: specifying scaling factors or explicit dimensions. Includes options for different interpolation methods like INTER_CUBIC for better quality when zooming.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('messi5.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"

res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC)

#OR

height, width = img.shape[:2]
res = cv.resize(img,(2*width, 2*height), interpolation = cv.INTER_CUBIC)
```

----------------------------------------

TITLE: Drawing Back Projection in Python with OpenCV
DESCRIPTION: This snippet illustrates how to display the back projection result using OpenCV in Python. It creates a window and shows the back projection image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
cv.imshow('BackProj', backproj)
```

----------------------------------------

TITLE: FLANN-based Feature Matching in Python
DESCRIPTION: Shows implementation of Fast Library for Approximate Nearest Neighbors (FLANN) based matcher with SIFT features. Includes index and search parameters configuration, ratio test, and match visualization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_matcher/py_matcher.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt

img1 = cv.imread('box.png',cv.IMREAD_GRAYSCALE)          # queryImage
img2 = cv.imread('box_in_scene.png',cv.IMREAD_GRAYSCALE) # trainImage

# Initiate SIFT detector
sift = cv.SIFT_create()

# find the keypoints and descriptors with SIFT
kp1, des1 = sift.detectAndCompute(img1,None)
kp2, des2 = sift.detectAndCompute(img2,None)

# FLANN parameters
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks=50)   # or pass empty dictionary

flann = cv.FlannBasedMatcher(index_params,search_params)

matches = flann.knnMatch(des1,des2,k=2)

# Need to draw only good matches, so create a mask
matchesMask = [[0,0] for i in range(len(matches))]

# ratio test as per Lowe's paper
for i,(m,n) in enumerate(matches):
    if m.distance < 0.7*n.distance:
        matchesMask[i]=[1,0]

draw_params = dict(matchColor = (0,255,0),
                   singlePointColor = (255,0,0),
                   matchesMask = matchesMask,
                   flags = cv.DrawMatchesFlags_DEFAULT)

img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)

plt.imshow(img3,),plt.show()
```

----------------------------------------

TITLE: Performing Forward Pass with OpenCV in C++
DESCRIPTION: This snippet demonstrates a forward pass in the neural network to produce outputs using OpenCV's DNN module. It computes layer outputs, focusing on obtaining results from the last layer for classification purposes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
@snippet dnn/classification.cpp Make forward pass
```

----------------------------------------

TITLE: Downsampling an Image with cv.pyrDown in OpenCV.js
DESCRIPTION: This function signature shows how to downsample an input image (`src`) to create a lower-resolution output image (`dst`). It blurs the image and downsamples it. The `dstsize` parameter specifies the desired size for the output image (defaults to half the input dimensions if Size(0,0)). `borderType` specifies the pixel extrapolation method, with cv.BORDER_CONSTANT being unsupported.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_pyramids/js_pyramids.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.pyrDown (src, dst, dstsize = new cv.Size(0, 0), borderType  = cv.BORDER_DEFAULT)
```

----------------------------------------

TITLE: Displaying an Image with OpenCV in C++
DESCRIPTION: This C++ snippet demonstrates how to load and display an image using OpenCV. It checks for the required command-line argument (image file path), loads the image into a cv::Mat object, displays it in a window, and handles error conditions if the file cannot be loaded. Dependencies: OpenCV library (cv and highgui modules). Inputs: path to the image file as an argument. Outputs: Opens a display window showing the image; error printed if conditions not met. Key limitation: requires OpenCV installed and linked properly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_gcc_cmake/linux_gcc_cmake.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <stdio.h>\n#include <opencv2/opencv.hpp>\n\nusing namespace cv;\n\nint main(int argc, char** argv )\n{\n    if ( argc != 2 )\n    {\n        printf("usage: DisplayImage.out <Image_Path>\n");\n        return -1;\n    }\n\n    Mat image;\n    image = imread( argv[1], IMREAD_COLOR );\n\n    if ( !image.data )\n    {\n        printf("No image data \n");\n        return -1;\n    }\n    namedWindow("Display Image", WINDOW_AUTOSIZE );\n    imshow("Display Image", image);\n\n    waitKey(0);\n\n    return 0;\n}
```

----------------------------------------

TITLE: Applying Gaussian Blur with OpenCV in Python
DESCRIPTION: This Python snippet illustrates using the OpenCV's GaussianBlur() function to apply a Gaussian filter for image smoothing. Dependencies include OpenCV, requiring parameters such as kernel size and standard deviations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/Smoothing/smoothing.py gaussianblur
```

----------------------------------------

TITLE: Computing Transformed Corner Coordinates with OpenCV - C++
DESCRIPTION: This C++ code computes the new coordinates of source points after mapping them through the estimated homography using perspectiveTransform. Requires OpenCV Mat vectors for input/output and a valid homography. Outputs an array of transformed points corresponding to the desired perspective.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_17

LANGUAGE: cpp
CODE:
```
@snippet perspective_correction.cpp compute-transformed-corners
```

----------------------------------------

TITLE: FAST Corner Detection Pixel Comparison Logic in C++
DESCRIPTION: This code segment implements part of the FAST corner detection algorithm, comparing pixel values against brightness thresholds (c_b and cb) to determine if a point is a corner. The algorithm examines pixels at various offsets around a candidate point and makes decisions based on these intensity comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
goto is_not_a_corner;
else
  goto is_not_a_corner;
else
if(ptr[offset5] < c_b)
  if(ptr[offset7] > cb)
    if(ptr[offset14] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              if(ptr[offset12] > cb)
                if(ptr[offset13] > cb)
                  if(ptr[offset6] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset15] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
    if(ptr[offset14] < c_b)
      if(ptr[offset15] < c_b)
        if(ptr[offset1] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset6] < c_b)
              goto is_a_corner;
            else
              if(ptr[offset13] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset8] < c_b)
            if(ptr[offset9] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset12] < c_b)
                    if(ptr[offset13] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
  if(ptr[offset7] < c_b)
    if(ptr[offset3] < c_b)
      if(ptr[offset1] < c_b)
        if(ptr[offset6] < c_b)
          if(ptr[offset8] < c_b)
            goto is_a_corner;
          else
            if(ptr[offset15] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset13] < c_b)
            if(ptr[offset14] < c_b)
              if(ptr[offset15] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset8] < c_b)
          if(ptr[offset9] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset6] < c_b)
                goto is_a_corner;
              else
                if(ptr[offset11] < c_b)
                  if(ptr[offset12] < c_b)
                    if(ptr[offset13] < c_b)
                      if(ptr[offset14] < c_b)
                        if(ptr[offset15] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          if(ptr[offset12] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset9] < c_b)
                if(ptr[offset6] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset13] < c_b)
                    if(ptr[offset14] < c_b)
                      if(ptr[offset15] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset1] < c_b)
                  if(ptr[offset13] < c_b)
                    if(ptr[offset14] < c_b)
                      if(ptr[offset15] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset1] < c_b)
                if(ptr[offset13] < c_b)
                  if(ptr[offset14] < c_b)
                    if(ptr[offset15] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset14] < c_b)
      if(ptr[offset15] < c_b)
        if(ptr[offset1] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset6] < c_b)
              goto is_a_corner;
            else
              if(ptr[offset13] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset8] < c_b)
            if(ptr[offset9] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset12] < c_b)
                    if(ptr[offset13] < c_b)
                      goto is_a_corner;
                    else
```

----------------------------------------

TITLE: Accessing Pixel in Floating Point Image with OpenCV in C++
DESCRIPTION: Shows reading a pixel value as a floating point number from a single-channel float image (type CV_32F) in C++. cv::Mat::at<float>(y, x) gives direct access. Useful for results of filters like Sobel. Input must have appropriate data type or access may yield incorrect values or crash.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_15

LANGUAGE: C++
CODE:
```
float intensity = img.at<float>(y, x);
```

----------------------------------------

TITLE: Loading Image in OpenCV
DESCRIPTION: Code snippets showing how to load an input image across different languages using OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
Mat src = imread(samples::findFile("smarties.png"));
```

LANGUAGE: Java
CODE:
```
Mat src = Imgcodecs.imread("smarties.png");
```

LANGUAGE: Python
CODE:
```
src = cv.imread(cv.samples.findFile("smarties.png"))
```

----------------------------------------

TITLE: Finding Chessboard Corners using OpenCV - Python
DESCRIPTION: This Python snippet shows how to detect chessboard corners in source and target images for perspective correction using OpenCV's cv2.findChessboardCorners. Prerequisites include cv2 and Numpy libraries, valid image files, and board dimensions. Outputs are arrays of detected corner coordinates used for later homography calculations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_9

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/features2D/Homography/perspective_correction.py find-corners
```

----------------------------------------

TITLE: Selecting Region of Interest (ROI) with OpenCV in Python
DESCRIPTION: Extracts a region of interest by NumPy slicing in Python. img[y:y+h, x:x+w] returns a subarray; changes propagate to parent. Efficient and requires only NumPy/OPENCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_33

LANGUAGE: Python
CODE:
```
roi = img[y:y+h, x:x+w]
```

----------------------------------------

TITLE: Decomposing Homography Matrix in OpenCV C++
DESCRIPTION: This snippet focuses on decomposing a homography matrix into rotations, translations, and plane normals using the OpenCV function cv::decomposeHomographyMat. The aim is to analyze multiple possible solutions, each represented by different combinations of decomposed vectors, and identify the one closest to the actual camera displacement. Required dependencies include OpenCV libraries. Input includes the computed homography matrix, and output involves sets of rotation vectors, translation vectors, and plane normals.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_27

LANGUAGE: C++
CODE:
```
@snippet decompose_homography.cpp decompose-homography-from-camera-displacement
```

----------------------------------------

TITLE: Retrieving TensorFlow SSD MobileNetV1 Frozen Graph Path - Python
DESCRIPTION: This Python snippet demonstrates retrieval of a TensorFlow SSD MobileNetV1 model and extraction of its frozen graph using a utility function. It prints out the path to the frozen graph (protobuf file) for inspection. Dependencies include a functional extract_tf_frozen_graph, proper imports, and write permissions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
    tf_model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n    graph_extraction_dir = "./"\n    frozen_graph_path = extract_tf_frozen_graph(tf_model_name, graph_extraction_dir)\n    print("Frozen graph path for {}: {}".format(tf_model_name, frozen_graph_path))
```

----------------------------------------

TITLE: Defining the cv.findContours Function Signature in OpenCV.js
DESCRIPTION: Defines the signature for the `cv.findContours` function in OpenCV.js, used to detect contours in an 8-bit single-channel binary image. Key parameters include the input image, output contour storage, hierarchy information, retrieval mode, approximation method, and an optional offset. It's recommended to use binary images (e.g., after thresholding or Canny edge detection) for better accuracy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contours_begin/js_contours_begin.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.findContours (image, contours, hierarchy, mode, method, offset = new cv.Point(0, 0))
@param image         source, an 8-bit single-channel image. Non-zero pixels are treated as 1's. Zero pixels remain 0's, so the image is treated as binary.
@param contours      detected contours.
@param hierarchy     containing information about the image topology. It has as many elements as the number of contours.
@param mode          contour retrieval mode(see cv.RetrievalModes).
@param method        contour approximation method(see cv.ContourApproximationModes).
@param offset        optional offset by which every contour point is shifted. This is useful if the contours are extracted from the image ROI and then they should be analyzed in the whole image context.
```

----------------------------------------

TITLE: Setting Input and Forward Pass in OpenCV DNN - C++
DESCRIPTION: These C++ lines set the preprocessed blob as network input and run a forward pass in the loaded ONNX model. The result, 'prob', contains the class scores for postprocessing. This is required after completing input preprocessing in inference workflows.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_13

LANGUAGE: cpp
CODE:
```
net.setInput(blob);\nMat prob = net.forward();
```

----------------------------------------

TITLE: Detailed Image Stitching with Configurable Parameters C++
DESCRIPTION: This snippet provides detailed image stitching using configurable parameters in C++. It allows experimenting with different settings such as feature detection, matcher, estimator, and blending methods. Dependencies include OpenCV with C++ support, and it is configured via command-line options to perform detailed stitching for complex scenarios.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/stitcher.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
int main(int argc, char* argv[]) {
    std::vector<std::string> img_names = {"boat1.jpg", "boat2.jpg", ...};
    // Command-line parsing and OpenCV setup
    cv::Stitcher::Mode mode = cv::Stitcher::SCANS;
    std::vector<cv::Mat> imgs;
    // Load images
    for (const auto& name : img_names) {
        imgs.push_back(cv::imread(name));
    }
    cv::Ptr<cv::Stitcher> stitcher = cv::Stitcher::create(mode);
    stitcher->setFeaturesFinder(cv::makePtr<cv::AKAZE>());
    stitcher->setBlender(cv::detail::Blender::createDefault(cv::detail::Blender::MULTI_BAND, true));
    cv::Mat pano;
    cv::Stitcher::Status status = stitcher->stitch(imgs, pano);
    if (status == cv::Stitcher::OK) {
        cv::imwrite("result_detailed.jpg", pano);
    }
    return 0;
}
```

----------------------------------------

TITLE: Setting Parameters for Text Detection (DB) in C++
DESCRIPTION: This C++ snippet configures parameters for a DB-based text detection model in OpenCV. It sets thresholds for binarization and polygon detection, candidates limit, and unclip ratio, along with normalization parameters and input shape. It is crucial for achieving accurate detection results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
// Load model weights
TextDetectionModel_DB model("/path/to/DB_TD500_resnet50.onnx");

// Post-processing parameters
float binThresh = 0.3;
float polyThresh = 0.5;
uint maxCandidates = 200;
double unclipRatio = 2.0;
model.setBinaryThreshold(binThresh)
     .setPolygonThreshold(polyThresh)
     .setMaxCandidates(maxCandidates)
     .setUnclipRatio(unclipRatio)
;

// Normalization parameters
double scale = 1.0 / 255.0;
Scalar mean = Scalar(122.67891434, 116.66876762, 104.00698793);

// The input shape
Size inputSize = Size(736, 736);

model.setInputParams(scale, inputSize, mean);
```

----------------------------------------

TITLE: Normalizing Template Matching Results (Java)
DESCRIPTION: Normalizes the result matrix from `matchTemplate` to a standard range (typically 0 to 1) using `Core.normalize`. This uses the `NORM_MINMAX` normalization type, scaling the values linearly. Normalization improves visualization and comparison.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_26

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java normalize
```

----------------------------------------

TITLE: Finding Chessboard Corners using OpenCV - C++
DESCRIPTION: This snippet demonstrates using OpenCV functions in C++ to detect chessboard corners within both source and desired images as preparation for perspective correction. It requires the OpenCV C++ library, proper image loading, and specification of chessboard size. Detected points are used for subsequent homography computation. Inputs are image file paths; outputs are sets of corner coordinates.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
@snippet perspective_correction.cpp find-corners
```

----------------------------------------

TITLE: Creating Image for Histogram Display in Python
DESCRIPTION: Python snippet creating a blank NumPy array (`histImage`) using `np.zeros` for histogram visualization. It defines width (`hist_w`) and height (`hist_h`), specifies 3 channels and `uint8` data type, and calculates the width per bin (`bin_w`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_23

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Draw the histograms for B, G and R
```

----------------------------------------

TITLE: Computing Camera Poses for Homography Displacement - C++
DESCRIPTION: This C++ snippet uses OpenCV's solvePnP function to estimate camera pose from 3D-2D correspondences. It produces Rodrigues rotation (rvec) and translation (tvec) vectors, necessary to derive camera displacements and further homography calculations from physical scene changes. Requires calibration parameters and matching points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_20

LANGUAGE: cpp
CODE:
```
@snippet homography_from_camera_displacement.cpp compute-poses
```

----------------------------------------

TITLE: Finding Chessboard Corners using OpenCV - Java
DESCRIPTION: This Java snippet detects chessboard corners in the provided source and destination images leveraging OpenCV's Java API. Requires OpenCV Java library and valid Mat image objects. Output consists of MatOfPoint2f containing the coordinates needed for homography estimation. Board size parameters must be properly set.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_10

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/features2D/Homography/PerspectiveCorrection.java find-corners
```

----------------------------------------

TITLE: Reference Counting Example with OpenCV Mat in C++
DESCRIPTION: Shows reference sharing in OpenCV cv::Mat. Submatrix or reshaped views use the same underlying storage, increasing reference count. This avoids copying data. Requires C++ OpenCV; lifetimes must be managed manually to avoid dangling pointers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_21

LANGUAGE: C++
CODE:
```
cv::Mat submat = mat.colRange(0, 3);
```

----------------------------------------

TITLE: Performing Inference with OpenCV DNN
DESCRIPTION: This Python snippet executes inference using the loaded OpenCV DNN model (`opencv_net`). It first sets the preprocessed input blob (`preproc_img`) using `opencv_net.setInput()`. Then, `opencv_net.forward()` runs the inference and returns the output tensor (`out`). The output shape is printed, and finally, `np.argmax` is used along the class axis (axis=0, after removing the batch dimension) to get the predicted class ID for each pixel, resulting in a 2D segmentation map (`out_predictions`). Requires `cv2` (OpenCV) and `numpy`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_7

LANGUAGE: python
CODE:
```
# set OpenCV DNN input
opencv_net.setInput(preproc_img)

# OpenCV DNN inference
out = opencv_net.forward()
print("OpenCV DNN segmentation prediction: \n")
print("* shape: ", out.shape)

# get IDs of predicted classes
out_predictions = np.argmax(out[0], axis=0)
```

----------------------------------------

TITLE: Separating Clustered Data Based on Labels in K-Means
DESCRIPTION: This code separates the data points into different clusters based on their assigned labels from the K-means algorithm. Points with label 0 are assigned to array A and points with label 1 to array B.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
A = z[labels==0]
B = z[labels==1]
```

----------------------------------------

TITLE: Finding Contours in a Binary Image with OpenCV Python
DESCRIPTION: This code demonstrates how to read an image, convert it to grayscale, apply thresholding to create a binary image, and then find contours using cv.findContours(). The function returns both the contours and hierarchy information.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

im = cv.imread('test.jpg')
assert im is not None, "file could not be read, check with os.path.exists()"
imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)
ret, thresh = cv.threshold(imgray, 127, 255, 0)
contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
```

----------------------------------------

TITLE: Exporting YOLOX Model to ONNX Using Bash Script
DESCRIPTION: Demonstrates the complete workflow to clone the YOLOX repository, download pre-trained weights, and execute the provided export script to convert the YOLOX model to ONNX format. Dependencies include git, wget, Python 3, PyTorch, and required YOLOX Python dependencies. The main parameters are the exported ONNX file name, network type (-n), pretrained checkpoint (-c), and the decode_in_inference flag to include anchor box creation within the ONNX. Outputs an ONNX model file suitable for OpenCV DNN inference.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
git clone https://github.com/Megvii-BaseDetection/YOLOX.git\ncd YOLOX\nwget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_s.pth # download pre-trained weights\npython3 -m tools.export_onnx --output-name yolox_s.onnx -n yolox-s -c yolox_s.pth --decode_in_inference
```

----------------------------------------

TITLE: Setup Image in OpenCV Python
DESCRIPTION: Loads an image, converts it to grayscale, and applies a blur using Python and OpenCV. OpenCV module is required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_14

LANGUAGE: Python
CODE:
```
import cv2
src = cv2.imread("image.jpg")
gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
gray = cv2.blur(gray, (3, 3))
```

----------------------------------------

TITLE: Edge Detection using Canny Detector in OpenCV (Python)
DESCRIPTION: This snippet shows how to perform edge detection using OpenCV's cv2.Canny in Python. The input image is converted to grayscale, and Canny is applied with threshold values. Input: image array; output: binary edge map. Requires cv2 and numpy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\nedges = cv2.Canny(src_gray, 50, 200, 3)\n
```

----------------------------------------

TITLE: Drawing All Contours on an Image with OpenCV Python
DESCRIPTION: This code shows how to draw all detected contours on an image using cv.drawContours(). It passes -1 as the contour index to draw all contours with a green color and line thickness of 3.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
cv.drawContours(img, contours, -1, (0,255,0), 3)
```

----------------------------------------

TITLE: Detecting SIFT Keypoints and Computing Descriptors in OpenCV Python
DESCRIPTION: This code demonstrates how to detect keypoints and compute their descriptors in a single step using the detectAndCompute() method of the SIFT object. This returns both keypoints and their corresponding descriptors.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
sift = cv.SIFT_create()
kp, des = sift.detectAndCompute(gray,None)
```

----------------------------------------

TITLE: Undistorting Images with Optimal Camera Matrix in Python
DESCRIPTION: This snippet refines a camera matrix and applies undistortion to images using OpenCV functions like cv.getOptimalNewCameraMatrix() and cv.undistort(). It accepts an image and camera parameters, and outputs an undistorted version of the image. The cv.undistort() function is used here with cropping based on ROI.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
img = cv.imread('left12.jpg')
h,  w = img.shape[:2]
newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))

# undistort
dst = cv.undistort(img, mtx, dist, None, newcameramtx)

# crop the image
x, y, w, h = roi
dst = dst[y:y+h, x:x+w]
cv.imwrite('calibresult.png', dst)
```

----------------------------------------

TITLE: Setting a Pixel Value in an Image with OpenCV in Java
DESCRIPTION: Demonstrates updating a pixel value in a Mat using the put(y, x, value) method in Java OpenCV. The input is the Mat, row, column, and new value (as double in array). Alters the underlying Mat data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_17

LANGUAGE: Java
CODE:
```
img.put(y, x, 128);
```

----------------------------------------

TITLE: Calling cv.HoughCircles in OpenCV.js
DESCRIPTION: Demonstrates the function signature for cv.HoughCircles in OpenCV.js. This function detects circles in a grayscale image using the Hough Gradient method. Key parameters include the input image (`image`), output vector for circles (`circles`), detection method (`method`, typically HOUGH_GRADIENT), accumulator resolution ratio (`dp`), minimum distance between centers (`minDist`), Canny edge thresholds (`param1`, `param2`), and radius range (`minRadius`, `maxRadius`). Requires an 8-bit, single-channel, grayscale input image. Outputs a vector of detected circles, each represented as (x, y, radius).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_houghcircles/js_houghcircles.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.HoughCircles (image, circles, method, dp, minDist, param1 = 100, param2 = 100, minRadius = 0, maxRadius = 0)
```

----------------------------------------

TITLE: Orthogonalizing Rotation Matrix with Polar Decomposition in OpenCV C++
DESCRIPTION: Code to ensure the extracted rotation matrix is a valid rotation matrix using SVD-based polar decomposition. This enforces the orthogonality constraint required for rotation matrices.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
cv::Mat w, u, vt;
cv::SVD::compute(R, w, u, vt);
R = u * vt;

// Ensure a proper rotation matrix (det=1)
if (cv::determinant(R) < 0) {
    R = -R;
}
```

----------------------------------------

TITLE: Cloning and Preparing OpenCV and opencv_extra Repositories with Git - Shell
DESCRIPTION: This set of shell commands demonstrates how to clone the official OpenCV and opencv_extra repositories from GitHub, check out the specific v3.1.0 branch, and cherry-pick upstream patches necessary for CUDA 8.0 support and build fixes. This process ensures the developer works with a compatible and patched version of OpenCV required for Tegra platforms. Key git commands (clone, checkout, cherry-pick) are employed, with each patch identified by its commit hash. Expected output after cherry-picking is provided as context for validation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
# Clone the opencv repository locally:
$ git clone https://github.com/opencv/opencv.git
```

LANGUAGE: shell
CODE:
```
$ cd opencv
$ git checkout -b v3.1.0 3.1.0
```

LANGUAGE: shell
CODE:
```
# While still in the opencv directory:
$ git cherry-pick 10896
```

LANGUAGE: shell
CODE:
```
$ git cherry pick cdb9c
```

LANGUAGE: shell
CODE:
```
$ git cherry-pick 24dbb
```

LANGUAGE: shell
CODE:
```
# In the same base directory from which you cloned OpenCV:
$ git clone https://github.com/opencv/opencv_extra.git
```

LANGUAGE: shell
CODE:
```
$ cd opencv_extra
$ git checkout -b v3.1.0 3.1.0
```

----------------------------------------

TITLE: Detailed PyTorch Model Export to ONNX File - Python
DESCRIPTION: This snippet defines the output directory and file name, ensures the directory exists, generates a standard input tensor, and calls 'torch.onnx.export' to export the model. It uses a [batch, channel, height, width] input of size [1, 3, 224, 224] and explicitly sets input/output names and ONNX opset version. Requires os, torch, and torch.onnx modules, as well as appropriate model and directory permissions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
# define the directory for further converted model save\nonnx_model_path = "models"\n# define the name of further converted model\nonnx_model_name = "resnet50.onnx"\n\n# create directory for further converted model\nos.makedirs(onnx_model_path, exist_ok=True)\n\n# get full path to the converted model\nfull_model_path = os.path.join(onnx_model_path, onnx_model_name)\n\n# generate model input\ngenerated_input = Variable(\n    torch.randn(1, 3, 224, 224)\n)\n\n# model export into ONNX format\ntorch.onnx.export(\n    original_model,\n    generated_input,\n    full_model_path,\n    verbose=True,\n    input_names=["input"],\n    output_names=["output"],\n    opset_version=11\n)
```

----------------------------------------

TITLE: Process Contours and Draw Shapes in OpenCV Python
DESCRIPTION: Approximates contours to polygons, draws bounding boxes and enclosing circles using Python and OpenCV. OpenCV is required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_19

LANGUAGE: Python
CODE:
```
for i in range(len(contours)):
    approx_curve = cv2.approxPolyDP(contours[i], 3, True)
    bound_rect = cv2.boundingRect(approx_curve)
    center, radius = cv2.minEnclosingCircle(approx_curve)
```

----------------------------------------

TITLE: Calculating Histograms for HSV Images in OpenCV
DESCRIPTION: Computing normalized histograms for the HSV images to be compared, using the previously defined bin settings, ranges, and channels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
Mat hist_base, hist_half_down, hist_test1, hist_test2;
calcHist( &hsv_base, 1, channels, Mat(), hist_base, 2, histSize, ranges, true, false );
normalize( hist_base, hist_base, 0, 1, NORM_MINMAX, -1, Mat() );
calcHist( &hsv_half_down, 1, channels, Mat(), hist_half_down, 2, histSize, ranges, true, false );
normalize( hist_half_down, hist_half_down, 0, 1, NORM_MINMAX, -1, Mat() );
calcHist( &hsv_test1, 1, channels, Mat(), hist_test1, 2, histSize, ranges, true, false );
normalize( hist_test1, hist_test1, 0, 1, NORM_MINMAX, -1, Mat() );
calcHist( &hsv_test2, 1, channels, Mat(), hist_test2, 2, histSize, ranges, true, false );
normalize( hist_test2, hist_test2, 0, 1, NORM_MINMAX, -1, Mat() );
```

LANGUAGE: java
CODE:
```
Mat hist_base = new Mat();
Mat hist_half_down = new Mat();
Mat hist_test1 = new Mat();
Mat hist_test2 = new Mat();
Imgproc.calcHist(Arrays.asList(hsv_base), histChannels, new Mat(), hist_base, histSize2, histRanges, false);
Core.normalize(hist_base, hist_base, 0, 1, Core.NORM_MINMAX, -1, new Mat());
Imgproc.calcHist(Arrays.asList(hsv_half_down), histChannels, new Mat(), hist_half_down, histSize2, histRanges, false);
Core.normalize(hist_half_down, hist_half_down, 0, 1, Core.NORM_MINMAX, -1, new Mat());
Imgproc.calcHist(Arrays.asList(hsv_test1), histChannels, new Mat(), hist_test1, histSize2, histRanges, false);
Core.normalize(hist_test1, hist_test1, 0, 1, Core.NORM_MINMAX, -1, new Mat());
Imgproc.calcHist(Arrays.asList(hsv_test2), histChannels, new Mat(), hist_test2, histSize2, histRanges, false);
Core.normalize(hist_test2, hist_test2, 0, 1, Core.NORM_MINMAX, -1, new Mat());
```

LANGUAGE: python
CODE:
```
hist_base = cv.calcHist([hsv_base], channels, None, histSize, ranges, accumulate=False)
cv.normalize(hist_base, hist_base, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)
hist_half_down = cv.calcHist([hsv_half_down], channels, None, histSize, ranges, accumulate=False)
cv.normalize(hist_half_down, hist_half_down, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)
hist_test1 = cv.calcHist([hsv_test1], channels, None, histSize, ranges, accumulate=False)
cv.normalize(hist_test1, hist_test1, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)
hist_test2 = cv.calcHist([hsv_test2], channels, None, histSize, ranges, accumulate=False)
cv.normalize(hist_test2, hist_test2, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)
```

----------------------------------------

TITLE: Installing OpenCV on macOS Bash
DESCRIPTION: This Bash script demonstrates the installation process for OpenCV on macOS. Dependencies include Xcode, JDK, and CMake. The script clones the OpenCV repository, checks out a specific version, and compiles the code. The output is a built version of OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
cd ~/\nmkdir opt\ngit clone https://github.com/opencv/opencv.git\ncd opencv\ngit checkout 2.4\nmkdir build\ncd build\ncmake -DBUILD_SHARED_LIBS=OFF ..\n...\n...\nmake -j8\n# optional\n# make install
```

----------------------------------------

TITLE: Performing Brightness and Contrast Adjustment in OpenCV (C++)
DESCRIPTION: The C++ code snippet demonstrates how to perform a linear transformation to adjust the brightness and contrast of an image using OpenCV. It requires OpenCV libraries to compile and run. Users input gain (alpha) and bias (beta) parameters, which adjust contrast and brightness respectively. The snippet also ensures that pixel values remain within valid ranges using `cv::saturate_cast`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;

int main(int argc, char** argv) {
    Mat image = imread(argv[1]);
    Mat new_image = Mat::zeros(image.size(), image.type());
    double alpha = 1.0; // Simple contrast control
    int beta = 0;       // Simple brightness control
    
    cout << " Basic Linear Transforms " << endl;
    cout << "-------------------------" << endl;
    cout << "* Enter the alpha value [1.0-3.0]: ";
    cin >> alpha;
    cout << "* Enter the beta value [0-100]: ";
    cin >> beta;

    for (int y = 0; y < image.rows; y++) {
        for (int x = 0; x < image.cols; x++) {
            for (int c = 0; c < image.channels(); c++) {
                new_image.at<Vec3b>(y, x)[c] = saturate_cast<uchar>(alpha * image.at<Vec3b>(y, x)[c] + beta);
            }
        }
    }

    namedWindow("Original Image", 1);
    imshow("Original Image", image);

    namedWindow("New Image", 1);
    imshow("New Image", new_image);

    waitKey();
    return 0;
}

```

----------------------------------------

TITLE: OpenCV DNN Model Inference
DESCRIPTION: This Python snippet executes inference using the loaded ONNX model with OpenCV's DNN module. It sets the input, runs the forward pass, and retrieves predictions, including class ID and confidence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_6

LANGUAGE: Python
CODE:
```
opencv_net.setInput(preproc_img)
out = opencv_net.forward()
print("OpenCV DNN prediction: \n")
print("* shape: ", out.shape)
imagenet_class_id = np.argmax(out)
confidence = out[0][imagenet_class_id]
print("* class ID: {}, label: {}".format(imagenet_class_id, imagenet_labels[imagenet_class_id]))
print("* confidence: {:.4f}".format(confidence))
```

----------------------------------------

TITLE: Drawing Histogram Lines for Each Channel in Java
DESCRIPTION: Java snippet iterating through the histogram bins (from 1 to `histSize`) and drawing lines on `histImage` using `Imgproc.line`. For each bin `i`, it draws lines connecting the points representing the counts in bin `i-1` and bin `i` for B, G, and R channels, using corresponding colors (blue, green, red). Histogram values (`bHist.get`, `gHist.get`, `rHist.get`) are used to determine the y-coordinates.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_28

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Draw for each channel
```

----------------------------------------

TITLE: Drawing Straight Bounding Rectangle for Contours in Python with OpenCV
DESCRIPTION: This code shows how to compute and draw a straight bounding rectangle for a contour using cv.boundingRect() and cv.rectangle() functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
x,y,w,h = cv.boundingRect(cnt)
cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
```

----------------------------------------

TITLE: Setting Image to Black with OpenCV in Python
DESCRIPTION: Illustrates filling a NumPy image array with zeros in Python. np.zeros_like creates a black image matching the input's shape and dtype. Image is fully reset. Requires numpy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_30

LANGUAGE: Python
CODE:
```
img = np.zeros_like(img)
```

----------------------------------------

TITLE: Displaying Video Frames with Canvas in OpenCV.js
DESCRIPTION: This snippet demonstrates converting and displaying video frames from a camera stream using a canvas element and OpenCV.js. It uses JavaScript to draw frames on a canvas, convert them to grayscale, and display them continuously, optimizing for a 30fps video display.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_video_display/js_video_display.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
let canvasFrame = document.getElementById("canvasFrame"); // canvasFrame is the id of <canvas>
let context = canvasFrame.getContext("2d");
let src = new cv.Mat(height, width, cv.CV_8UC4);
let dst = new cv.Mat(height, width, cv.CV_8UC1);

const FPS = 30;
function processVideo() {
    let begin = Date.now();
    context.drawImage(video, 0, 0, width, height);
    src.data.set(context.getImageData(0, 0, width, height).data);
    cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
    cv.imshow("canvasOutput", dst); // canvasOutput is the id of another <canvas>;
    // schedule next one.
    let delay = 1000/FPS - (Date.now() - begin);
    setTimeout(processVideo, delay);
}

// schedule first one.
setTimeout(processVideo, 0);
```

----------------------------------------

TITLE: Performing Dilation with OpenCV in Python
DESCRIPTION: This Python code snippet demonstrates how to apply morphological dilation to an image using OpenCV. Much like the erosion function, users can specify the kernel shape, size, and anchor point for the operation. Dependencies: OpenCV-Python. Inputs: source image, kernel element. Outputs: dilated image. Advanced parameters (such as multiple iterations, border type, and value) are supported by OpenCV but not used in this snippet. The function is tailored for basic usage with customizability via kernel definition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
@snippet python/tutorial_code/imgProc/erosion_dilatation/morphology_1.py dilation
```

----------------------------------------

TITLE: Distance Transform and Watershed Application
DESCRIPTION: Performs distance transform on binary image and applies watershed algorithm for segmentation
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/distance_transformation/distance_transform.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
distanceTransform(bw, dist, DIST_L2, 3);
normalize(dist, dist, 0, 1.0, NORM_MINMAX);
threshold(dist, dist, 0.4, 1.0, THRESH_BINARY);
watershed(src, markers);
Mat mark = Mat::zeros(markers.size(), CV_8UC3);
for (int i = 0; i < markers.rows; i++) {
    for (int j = 0; j < markers.cols; j++) {
        int index = markers.at<int>(i,j);
        if (index > 0 && index <= contours.size())
            mark.at<Vec3b>(i,j) = colors[index-1];
    }
}
```

LANGUAGE: Python
CODE:
```
dist = cv.distanceTransform(bw, cv.DIST_L2, 3)
cv.normalize(dist, dist, 0, 1.0, cv.NORM_MINMAX)
_, dist = cv.threshold(dist, 0.4, 1.0, cv.THRESH_BINARY)
markers = cv.watershed(src, markers)
mark = np.zeros(markers.shape + (3,), dtype=np.uint8)
for i in range(markers.shape[0]):
    for j in range(markers.shape[1]):
        index = markers[i,j]
        if index > 0 and index <= len(contours):
            mark[i,j] = colors[index-1]
```

----------------------------------------

TITLE: Drawing an Ellipse in C++
DESCRIPTION: Implementation of the MyEllipse function that draws a rotated ellipse in OpenCV C++. The function takes the image and angle, and uses the ellipse() function to draw the shape with specified color and thickness.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_18

LANGUAGE: cpp
CODE:
```
void MyEllipse( Mat img, double angle )
{
  int thickness = 2;
  int lineType = 8;

  ellipse( img,
       Point( w/2, w/2 ),
       Size( w/4, w/16 ),
       angle,
       0,
       360,
       Scalar( 255, 0, 0 ),
       thickness,
       lineType );
}
```

----------------------------------------

TITLE: Copying Mat Data Using clone/copyTo in OpenCV in C++
DESCRIPTION: Demonstrates deep copying of Mat content in OpenCV C++. clone() and copyTo() allocate new storage and copy the data. Essential when input data might go out of scope. Output is independent copy of input image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_22

LANGUAGE: C++
CODE:
```
cv::Mat copy = img.clone();
```

----------------------------------------

TITLE: Setting Up Training Data in C++
DESCRIPTION: Creates and initializes training data arrays for SVM classification with labeled 2D points belonging to two different classes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
float trainingData[N][2] = { {501, 10}, {255, 10}, {501, 255}, {10, 501} };
float labels[N] = {1.0, -1.0, -1.0, -1.0};
```

----------------------------------------

TITLE: Implementing Image Deskewing for Digit Recognition in Python OpenCV
DESCRIPTION: Function that deskews a digit image using second order moments to improve recognition accuracy. Takes an input digit image and returns the deskewed version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_svm/py_svm_opencv/py_svm_opencv.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
def deskew(img):
    m = cv2.moments(img)
    if abs(m['mu02']) < 1e-2:
        return img.copy()
    skew = m['mu11']/m['mu02']
    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])
    img = cv2.warpAffine(img, M, (SZ, SZ), flags=cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR)
    return img
```

----------------------------------------

TITLE: Saving Images with OpenCV in Python
DESCRIPTION: This snippet demonstrates saving an image using OpenCV's cv.imwrite in Python. It shows how to save the image array to a file, conditioned on a specific user input.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_9

LANGUAGE: Python
CODE:
```
if key == ord('s'):
    cv.imwrite('starry_night.jpg', image)
```

----------------------------------------

TITLE: Converting and Displaying Image with OpenCV.js
DESCRIPTION: Shows how to convert image types and display them on a canvas using OpenCV.js. The code involves converting image data, creating a new ImageData object, and updating the canvas with this object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_image_display/js_image_display.markdown#2025-04-22_snippet_2

LANGUAGE: JavaScript
CODE:
```
let dst = new cv.Mat();
// scale and shift are used to map the data to [0, 255].
src.convertTo(dst, cv.CV_8U, scale, shift);
// *** is GRAY, RGB, or RGBA, according to src.channels() is 1, 3 or 4.
cv.cvtColor(dst, dst, cv.COLOR_***2RGBA);
```

LANGUAGE: JavaScript
CODE:
```
let imgData = new ImageData(new Uint8ClampedArray(dst.data), dst.cols, dst.rows);
```

LANGUAGE: JavaScript
CODE:
```
let canvas = document.getElementById(canvasOutputId);
let ctx = canvas.getContext('2d');
ctx.clearRect(0, 0, canvas.width, canvas.height);
canvas.width = imgData.width;
canvas.height = imgData.height;
ctx.putImageData(imgData, 0, 0);
```

----------------------------------------

TITLE: Defining Main Loop for Frame Processing
DESCRIPTION: This JavaScript snippet illustrates the main loop handling continuous frame processing from a camera. The loop initializes upon loading OpenCV.js and downloading the deep learning models, detecting and recognizing faces frame by frame. The snippet requires OpenCV.js and access to a camera device.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_javascript/dnn_javascript.markdown#2025-04-22_snippet_3

LANGUAGE: HTML
CODE:
```
"Define frames processing"
```

----------------------------------------

TITLE: Building Tests and Examples in OpenCV
DESCRIPTION: This snippet specifies options to enable or disable building tests, examples, and applications in OpenCV. Different `cmake` options control accuracy, performance, and application compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_6

LANGUAGE: sh
CODE:
```
cmake \
  -DBUILD_TESTS=ON \
  -DBUILD_PERF_TESTS=ON \
  -DBUILD_EXAMPLES=ON \
  -DBUILD_opencv_apps=ON \
  ../opencv
```

----------------------------------------

TITLE: Creating Color Palette with OpenCV Trackbars in Python
DESCRIPTION: This code creates a window with three trackbars for adjusting RGB values and a switch for turning the color display on/off. It demonstrates the use of cv.createTrackbar(), cv.getTrackbarPos(), and basic OpenCV window manipulation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_trackbar/py_trackbar.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

def nothing(x):
    pass

# Create a black image, a window
img = np.zeros((300,512,3), np.uint8)
cv.namedWindow('image')

# create trackbars for color change
cv.createTrackbar('R','image',0,255,nothing)

cv.createTrackbar('G','image',0,255,nothing)
cv.createTrackbar('B','image',0,255,nothing)

# create switch for ON/OFF functionality
switch = '0 : OFF \n1 : ON'
cv.createTrackbar(switch, 'image',0,1,nothing)

while(1):
    cv.imshow('image',img)
    k = cv.waitKey(1) & 0xFF
    if k == 27:
        break

    # get current positions of four trackbars
    r = cv.getTrackbarPos('R','image')
    g = cv.getTrackbarPos('G','image')
    b = cv.getTrackbarPos('B','image')
    s = cv.getTrackbarPos(switch,'image')

    if s == 0:
        img[:] = 0
    else:
        img[:] = [b,g,r]

cv.destroyAllWindows()
```

----------------------------------------

TITLE: Multi-Threaded Frame Reading from Astra Camera Sensors
DESCRIPTION: Implements threaded reading of frames from both depth and color sensors to prevent blocking. Each stream runs in its own thread, storing frames in lists with timestamps to enable later synchronization between the depth and color data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
list<FrameWithTimestamp> depthFrames, colorFrames;
mutex depthFramesMtx, colorFramesMtx;
condition_variable depthFramesCV, colorFramesCV;
atomic_bool isRunning;

auto readDepth = [&]() {
    Mat frame;
    while (isRunning.load()) {
        if (depthStream.grab()) {
            if (depthStream.retrieve(frame, CAP_OPENNI_DEPTH_MAP)) {
                auto now = chrono::high_resolution_clock::now();
                auto frameWithTimestamp = FrameWithTimestamp(now, frame.clone());
                {
                    lock_guard<mutex> lk(depthFramesMtx);
                    depthFrames.push_back(frameWithTimestamp);
                }
                depthFramesCV.notify_one();
            }
        }
    }
};

auto readColor = [&]() {
    Mat frame;
    while (isRunning.load()) {
        if (colorStream.grab()) {
            if (colorStream.retrieve(frame)) {
                auto now = chrono::high_resolution_clock::now();
                auto frameWithTimestamp = FrameWithTimestamp(now, frame.clone());
                {
                    lock_guard<mutex> lk(colorFramesMtx);
                    colorFrames.push_back(frameWithTimestamp);
                }
                colorFramesCV.notify_one();
            }
        }
    }
};

thread depthThread(readDepth);
thread colorThread(readColor);
```

----------------------------------------

TITLE: Implementing SURF Feature Detection and Homography Matching in Java
DESCRIPTION: This Java code demonstrates how to use SURF features and FLANN matching to detect a known object in an image. It uses Imgproc.findHomography to estimate the transformation and Core.perspectiveTransform to map points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_homography/feature_homography.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;\nimport org.opencv.core.Core.MinMaxLocResult;\nimport org.opencv.features2d.DescriptorMatcher;\nimport org.opencv.features2d.Features2d;\nimport org.opencv.imgcodecs.Imgcodecs;\nimport org.opencv.imgproc.Imgproc;\nimport org.opencv.xfeatures2d.SURF;\n\nclass SURFFLANNMatchingHomographyDemo {\n\n    public void run(String[] args) {\n        if (args.length != 2) {\n            System.out.println(\"Usage: ./SURFFLANNMatchingHomographyDemo <img1> <img2>\");\n            System.exit(-1);\n        }\n\n        Mat img_object = Imgcodecs.imread(args[0], Imgcodecs.IMREAD_GRAYSCALE);\n        Mat img_scene = Imgcodecs.imread(args[1], Imgcodecs.IMREAD_GRAYSCALE);\n\n        if (img_object.empty() || img_scene.empty()) {\n            System.out.println(\"Error reading images!\");\n            System.exit(-1);\n        }\n\n        //-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors\n        int minHessian = 400;\n        SURF detector = SURF.create(minHessian);\n        MatOfKeyPoint keypoints_object = new MatOfKeyPoint();\n        MatOfKeyPoint keypoints_scene = new MatOfKeyPoint();\n        Mat descriptors_object = new Mat();\n        Mat descriptors_scene = new Mat();\n        detector.detectAndCompute(img_object, new Mat(), keypoints_object, descriptors_object);\n        detector.detectAndCompute(img_scene, new Mat(), keypoints_scene, descriptors_scene);\n\n        //-- Step 2: Matching descriptor vectors using FLANN matcher\n        DescriptorMatcher matcher = DescriptorMatcher.create(DescriptorMatcher.FLANNBASED);\n        MatOfDMatch matches = new MatOfDMatch();\n        matcher.match(descriptors_object, descriptors_scene, matches);\n        DMatch[] matchesArr = matches.toArray();\n\n        double max_dist = 0;\n        double min_dist = 100;\n\n        //-- Quick calculation of max and min distances between keypoints\n        for (int i = 0; i < descriptors_object.rows(); i++) {\n            double dist = matchesArr[i].distance;\n            if (dist < min_dist)\n                min_dist = dist;\n            if (dist > max_dist)\n                max_dist = dist;\n        }\n\n        System.out.println(\"-- Max dist : \" + max_dist);\n        System.out.println(\"-- Min dist : \" + min_dist);\n\n        //-- Draw only \"good\" matches (i.e. whose distance is less than 3*min_dist )\n        MatOfDMatch good_matches = new MatOfDMatch();\n        for (int i = 0; i < descriptors_object.rows(); i++) {\n            if (matchesArr[i].distance < 3 * min_dist) {\n                good_matches.push_back(new MatOfDMatch(matchesArr[i]));\n            }\n        }\n\n        Mat img_matches = new Mat();\n        Features2d.drawMatches(img_object, keypoints_object, img_scene, keypoints_scene, good_matches, img_matches);\n\n        //-- Localize the object\n        MatOfPoint2f obj = new MatOfPoint2f();\n        MatOfPoint2f scene = new MatOfPoint2f();\n        KeyPoint[] keypoints_objectArr = keypoints_object.toArray();\n        KeyPoint[] keypoints_sceneArr = keypoints_scene.toArray();\n        DMatch[] good_matchesArr = good_matches.toArray();\n\n        for (int i = 0; i < good_matches.rows(); i++) {\n            //-- Get the keypoints from the good matches\n            obj.push_back(new MatOfPoint2f(keypoints_objectArr[good_matchesArr[i].queryIdx].pt));\n            scene.push_back(new MatOfPoint2f(keypoints_sceneArr[good_matchesArr[i].trainIdx].pt));\n        }\n\n        Mat H = Imgproc.findHomography(obj, scene, Imgproc.RANSAC, 5);\n\n        //-- Get the corners from the image_1 ( the object to be \"detected\" )\n        Mat obj_corners = new Mat(4, 1, CvType.CV_32FC2);\n        Mat scene_corners = new Mat(4, 1, CvType.CV_32FC2);\n        obj_corners.put(0, 0, 0, 0);\n        obj_corners.put(1, 0, img_object.cols(), 0);\n        obj_corners.put(2, 0, img_object.cols(), img_object.rows());\n        obj_corners.put(3, 0, 0, img_object.rows());\n\n        Core.perspectiveTransform(obj_corners, scene_corners, H);\n\n        //-- Draw lines between the corners (the mapped object in the scene - image_2 )\n        Imgproc.line(img_matches, new Point(scene_corners.get(0, 0)), new Point(scene_corners.get(1, 0)), new Scalar(0, 255, 0), 4);\n        Imgproc.line(img_matches, new Point(scene_corners.get(1, 0)), new Point(scene_corners.get(2, 0)), new Scalar(0, 255, 0), 4);\n        Imgproc.line(img_matches, new Point(scene_corners.get(2, 0)), new Point(scene_corners.get(3, 0)), new Scalar(0, 255, 0), 4);\n        Imgproc.line(img_matches, new Point(scene_corners.get(3, 0)), new Point(scene_corners.get(0, 0)), new Scalar(0, 255, 0), 4);\n\n        //-- Show detected matches\n        HighGui.imshow(\"Good Matches & Object detection\", img_matches);\n        HighGui.waitKey(0);\n        System.exit(0);\n    }\n}
```

----------------------------------------

TITLE: Creating an Image and Drawing Text using OpenCV in C++
DESCRIPTION: This C++ code snippet, intended for use with the CMake approach, shows how to create a blank 8-bit unsigned integer image (`Mat`) of size 640x480. It then uses the `putText` function to draw the string "Hello World!" onto the image at a specified position with a specific font, size, and color. Finally, it displays the image in a window named "My Window" using `imshow` and waits for a key press with `waitKey`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
#include <opencv2/opencv.hpp>
using namespace cv;

int main ( int argc, char **argv )
{
  Mat img(480, 640, CV_8U);
  putText(img, "Hello World!", Point( 200, 400 ), FONT_HERSHEY_SIMPLEX | FONT_ITALIC, 1.0, Scalar( 255, 255, 0 ));
  imshow("My Window", img);
  waitKey();
  return 0;
}
```

----------------------------------------

TITLE: Computing Camera Displacement Transformation Matrix - C++
DESCRIPTION: This code calculates the transformation matrix describing camera displacement between two views using matrix multiplication and inversion of pose matrices. Depends on previously solved camera poses. Used as a prerequisite for deriving the homography from physical movement. Inputs are rotation and translation matrices; output is a 4x4 pose matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_21

LANGUAGE: cpp
CODE:
```
@snippet homography_from_camera_displacement.cpp compute-c2Mc1
```

----------------------------------------

TITLE: Generating ArUco Marker Images in C++
DESCRIPTION: Code snippet demonstrating how to generate ArUco marker images using the OpenCV aruco module. This example creates a marker image for marker ID 23 from a predefined dictionary, with a size of 200x200 pixels and a border width of 1.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cv::Mat markerImage;
cv::aruco::Dictionary dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);
cv::aruco::generateImageMarker(dictionary, 23, 200, markerImage, 1);
cv::imwrite("marker23.png", markerImage);
```

----------------------------------------

TITLE: Reading ONNX Model with OpenCV
DESCRIPTION: This Python snippet shows how to load an ONNX model with OpenCV's DNN module. The cv.dnn.readNetFromONNX function imports the previously converted ONNX model, allowing inference operations using OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
opencv_net = cv2.dnn.readNetFromONNX(full_model_path)
```

----------------------------------------

TITLE: Applying Fourier Transform using OpenCV DFT
DESCRIPTION: Illustrates the use of OpenCV's `cv.dft()` to compute the Fourier Transform of an image. It requires OpenCV and Matplotlib. The input image is converted to `np.float32`, then transformed using `cv.dft()`. Magnitude spectrum visualization is achieved using `cv.magnitude()`. Input is a grayscale image, and the output is a magnitude spectrum plot.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"

dft = cv.dft(np.float32(img),flags = cv.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)

magnitude_spectrum = 20*np.log(cv.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))

plt.subplot(121),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')
plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])
plt.show()
```

----------------------------------------

TITLE: Detecting Faces and Eyes with Haar Cascades in Python using OpenCV
DESCRIPTION: This Python script demonstrates face and eye detection using OpenCV's Python bindings. It creates `cv2.CascadeClassifier` objects and loads the pre-trained Haar cascade XML files for faces and eyes. The script reads frames from a video source, converts each frame to grayscale using `cv2.cvtColor`, and then calls `detectMultiScale` to detect faces. For each detected face, it defines a region of interest (ROI) and runs `detectMultiScale` again to find eyes within that ROI. Detected objects are highlighted with rectangles using `cv2.rectangle`, and the resulting frame is shown using `cv2.imshow`. Requires the `cv2` (OpenCV) and `numpy` Python packages, along with the specified Haar cascade XML files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/cascade_classifier.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
# This tutorial code's is shown lines below. You can also download it from
# [here](https://github.com/opencv/opencv/tree/4.x/samples/python/tutorial_code/objectDetection/cascade_classifier/objectDetection.py)
@include samples/python/tutorial_code/objectDetection/cascade_classifier/objectDetection.py
```

----------------------------------------

TITLE: Setting Video Properties with VideoCapture::set in C++
DESCRIPTION: Demonstrates how to modify video properties using the `set()` method of `cv::VideoCapture`, specifically for seeking within a video file. It uses property identifiers like `CAP_PROP_POS_MSEC` (to seek to a specific time in milliseconds) or `CAP_PROP_POS_FRAMES` (to seek to a specific frame number), passing the target position as a double value. Subsequent read operations will retrieve the frame at the newly set position. Requires `<opencv2/videoio.hpp>` header.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
captRefrnc.set(CAP_PROP_POS_MSEC, 1.2);  // go to the 1.2 second in the video
captRefrnc.set(CAP_PROP_POS_FRAMES, 10); // go to the 10th frame of the video
// now a read operation would read the frame at the set position
```

----------------------------------------

TITLE: Homography Check for Matches with OpenCV in C++
DESCRIPTION: The C++ code provides a homography check to verify if matched keypoints fit a specified model, adding robustness to keypoint matching using OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_12

LANGUAGE: C++
CODE:
```
samples/cpp/tutorial_code/features2D/AKAZE_match.cpp homography check
```

----------------------------------------

TITLE: Template Matching Formula: TM_SQDIFF_NORMED (LaTeX)
DESCRIPTION: Mathematical formula for the Normalized Squared Difference (TM_SQDIFF_NORMED) template matching method used in OpenCV's `matchTemplate` function. R(x,y) is the result, T is the template, and I is the image. Normalization makes the result invariant to global intensity changes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_2

LANGUAGE: latex
CODE:
```
\f[R(x,y)= \frac{\sum_{x',y'} (T(x',y')-I(x+x',y+y'))^2}{\sqrt{\sum_{x',y'}T(x',y')^2 \cdot \sum_{x',y'} I(x+x',y+y')^2}}\f]
```

----------------------------------------

TITLE: Drawing Detected Circles
DESCRIPTION: Visualizing the detected circles by drawing them on the original image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
for( size_t i = 0; i < circles.size(); i++ )
{
    Vec3i c = circles[i];
    Point center = Point(c[0], c[1]);
    // circle center
    circle( src, center, 1, Scalar(0,255,0), 3, LINE_AA);
    // circle outline
    int radius = c[2];
    circle( src, center, radius, Scalar(0,0,255), 3, LINE_AA);
}
```

LANGUAGE: Java
CODE:
```
if (circles.rows() > 0) {
    for (int x = 0; x < circles.cols(); x++) {
        double[] c = circles.get(0, x);
        Point center = new Point(Math.round(c[0]), Math.round(c[1]));
        // circle center
        Imgproc.circle(src, center, 1, new Scalar(0,255,0), 3, 8, 0);
        // circle outline
        int radius = (int) Math.round(c[2]);
        Imgproc.circle(src, center, radius, new Scalar(0,0,255), 3, 8, 0);
    }
}
```

LANGUAGE: Python
CODE:
```
if circles is not None:
    circles = np.uint16(np.around(circles))
    for i in circles[0, :]:
        center = (i[0], i[1])
        # circle center
        cv.circle(src, center, 1, (0, 255, 0), 3)
        # circle outline
        radius = i[2]
        cv.circle(src, center, radius, (0, 0, 255), 3)
```

----------------------------------------

TITLE: Drawing 3D Axes on an Image with OpenCV (Python)
DESCRIPTION: Defines a function to render the 3D coordinate axes on an image based on corner points (from cv.findChessboardCorners) and projected 3D points. Uses OpenCV's cv.line to draw colored axes, requiring NumPy for data manipulation and OpenCV for drawing. Accepts an image, the corner array, and projected axis endpoints, and returns an image with overlaid axes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_pose/py_pose.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
def draw(img, corners, imgpts):\n    corner = tuple(corners[0].ravel().astype("int32"))\n    imgpts = imgpts.astype("int32")\n    img = cv.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n    img = cv.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n    img = cv.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n    return img
```

----------------------------------------

TITLE: Applying Blur Filter with OpenCV in C++
DESCRIPTION: This C++ snippet demonstrates the use of OpenCV's blur() function to apply a normalized box filter for image smoothing. It requires OpenCV library and takes source and destination image parameters, kernel size, and anchor point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
@snippet cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp blur
```

----------------------------------------

TITLE: Finding Minimum and Maximum Match Values/Locations (Python)
DESCRIPTION: Calls `cv2.minMaxLoc` on the normalized result matrix. This function returns the minimum value, maximum value, location (coordinates) of the minimum value, and location of the maximum value found in the matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_30

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py best_match
```

----------------------------------------

TITLE: Implementing GrabCut Algorithm with Rectangular Initialization in OpenCV Python
DESCRIPTION: This code snippet demonstrates how to use the cv.grabCut() function with rectangular initialization to extract the foreground from an image. It loads an image, creates a mask, and applies the GrabCut algorithm using a predefined rectangle.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_grabcut/py_grabcut.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('messi5.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (50,50,450,290)
cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
```

----------------------------------------

TITLE: Reading Camera Parameters
DESCRIPTION: Demonstrates how to read camera calibration parameters from file
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
bool readCameraParameters(std::string filename, cv::Mat &camMatrix, cv::Mat &distCoeffs)
```

----------------------------------------

TITLE: Upsampling Image using pyrUp in C++
DESCRIPTION: Upsamples the image `tmp` using the `pyrUp` function. The destination image `dst` will have dimensions double that of `tmp`. The size is explicitly provided.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
        else if( c == 'i' )
        { pyrUp( tmp, dst, Size( tmp.cols*2, tmp.rows*2 ) ); printf("** Zoom In: Image x 2 \n"); }
```

----------------------------------------

TITLE: Implementing Custom Corner Detectors in Python
DESCRIPTION: Python implementation of custom Harris and Shi-Tomasi corner detectors using OpenCV functions. Includes image processing, corner detection, and result visualization with interactive quality level adjustment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/generic_corner_detector/generic_corner_detector.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import numpy as np\nimport cv2 as cv\nfrom math import pow\n\nsource_window = 'Source image'\ncorners_window = 'Corners detected'\nmax_thresh = 255\n\ndef cornerHarris_demo(val):\n    thresh = val\n    # Detector parameters\n    blockSize = 2\n    apertureSize = 3\n    k = 0.04\n    # Detecting corners\n    dst = cv.cornerHarris(src_gray, blockSize, apertureSize, k)\n    # Normalizing\n    dst_norm = np.empty(dst.shape, dtype=np.float32)\n    cv.normalize(dst, dst_norm, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n    dst_norm_scaled = cv.convertScaleAbs(dst_norm)\n    # Drawing a circle around corners\n    for i in range(dst_norm.shape[0]):\n        for j in range(dst_norm.shape[1]):\n            if int(dst_norm[i,j]) > thresh:\n                cv.circle(dst_norm_scaled, (j,i), 5, (0), 2)\n    # Showing the result\n    cv.namedWindow(corners_window)\n    cv.imshow(corners_window, dst_norm_scaled)\n\n# Load source image and convert it to gray\nsrc = cv.imread(cv.samples.findFile('building.jpg'))\nsrc_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n# Create a window and a trackbar\ncv.namedWindow(source_window)\nthresh = 200 # initial threshold\ncv.createTrackbar('Threshold: ', source_window, thresh, max_thresh, cornerHarris_demo)\ncv.imshow(source_window, src)\ncornerHarris_demo(thresh)\ncv.waitKey()\n
```

----------------------------------------

TITLE: Show Images in C++
DESCRIPTION: Displays images within OpenCV windows in a C++ application to allow visualization of processed frames.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
cv::imshow("Window Name", frame);
```

----------------------------------------

TITLE: Preprocessing Input Image for DNN Model using OpenCV
DESCRIPTION: This Python snippet preprocesses an input image for inference with a neural network using OpenCV. It reads an image using `cv2.imread`, converts it to float32, defines preprocessing parameters (mean subtraction values `mean`, scaling factor `scale`, standard deviation values `std`), and uses `cv2.dnn.blobFromImage` to create a 4D blob suitable for network input. The `blobFromImage` function handles resizing, mean subtraction (note the scaling of `mean` by 255.0 to match PyTorch's common practice), scaling, and channel swapping (BGR to RGB). Finally, it performs division by the standard deviation element-wise. Requires `cv2` (OpenCV) and `numpy`. The specific mean and std values ([0.485, 0.456, 0.406] and [0.229, 0.224, 0.225]) are standard for models pre-trained on ImageNet.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
# read the image
input_img = cv2.imread(img_path, cv2.IMREAD_COLOR)
input_img = input_img.astype(np.float32)

# target image sizes
img_height = input_img.shape[0]
img_width = input_img.shape[1]

# define preprocess parameters
mean = np.array([0.485, 0.456, 0.406]) * 255.0
scale = 1 / 255.0
std = [0.229, 0.224, 0.225]

# prepare input blob to fit the model input:
# 1. subtract mean
# 2. scale to set pixel values from 0 to 1
input_blob = cv2.dnn.blobFromImage(
    image=input_img,
    scalefactor=scale,
    size=(img_width, img_height),  # img target size
    mean=mean,
    swapRB=True,  # BGR -> RGB
    crop=False  # center crop
)
# 3. divide by std
input_blob[0] /= np.asarray(std, dtype=np.float32).reshape(3, 1, 1)
```

----------------------------------------

TITLE: Comparing Arithmetic Performance in Python and Numpy Using IPython
DESCRIPTION: Uses IPython's %timeit magic to benchmark different methods for squaring a value in Python: native Python arithmetic, numpy uint8 arrays, and numpy's np.square function. Demonstrates that simple Python scalars are significantly faster for single-value operations than corresponding NumPy methods. Requires IPython, numpy, and OpenCV if using cv2 arrays. Inputs: scalar or numpy array values. Outputs: measured execution speed. Mainly targets performance comparison scenarios.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_optimization/py_optimization.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
In [10]: x = 5

In [11]: %timeit y=x**2
10000000 loops, best of 3: 73 ns per loop

In [12]: %timeit y=x*x
10000000 loops, best of 3: 58.3 ns per loop

In [15]: z = np.uint8([5])

In [17]: %timeit y=z*z
1000000 loops, best of 3: 1.25 us per loop

In [19]: %timeit y=np.square(z)
1000000 loops, best of 3: 1.16 us per loop
```

----------------------------------------

TITLE: Checking Image Load Success in OpenCV C++
DESCRIPTION: This code checks whether an image was successfully loaded in C++ utilizing the empty method of the cv::Mat class. If the image is empty, error handling can be performed accordingly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
if(image.empty()) {
    std::cerr << "Could not open or find the image!" << std::endl;
    return -1;
}
```

----------------------------------------

TITLE: Custom Serialization Usage with FileStorage for Custom Classes - OpenCV C++
DESCRIPTION: These snippets show how to use custom read and write functions for a user-defined class (MyData) with OpenCV FileStorage. The << operator is used for writing and >> for reading, leveraging the serialization support implemented in the class. The code assumes all methods are previously defined.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_16

LANGUAGE: C++
CODE:
```
MyData m1;\nfs << "MyData" << m1;\nMyData m2;\nfs["MyData"] >> m2;
```

----------------------------------------

TITLE: Opening Depth and Color Streams with OpenCV for Orbbec Astra Camera
DESCRIPTION: Creates two VideoCapture objects to access the depth sensor through OpenNI2 API and the color sensor through Video4Linux2 interface. This is necessary because the Astra Pro camera requires two different interfaces to access its sensors.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
VideoCapture depthStream(CAP_OPENNI2_ASTRA);
VideoCapture colorStream(0);
```

----------------------------------------

TITLE: Visualizing Matches and Inliers using cv.drawMatches in OpenCV (Python)
DESCRIPTION: This snippet draws the matching keypoints between the two images, highlighting inliers determined by the homography estimation. It leverages cv.drawMatches for visualization and matplotlib for display. Dependencies: Previous computation of good matches and matchesMask, OpenCV, Matplotlib. Key parameters: matching color, which matches to draw, and keypoints. Outputs the visualized result as a displayed image. Intended as the final visualization step following feature matching and homography.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_feature_homography/py_feature_homography.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n                   singlePointColor = None,\n                   matchesMask = matchesMask, # draw only inliers\n                   flags = 2)\n\nimg3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n\nplt.imshow(img3, 'gray'),plt.show()
```

----------------------------------------

TITLE: Projecting Points with Homography in OpenCV C++
DESCRIPTION: Uses the perspectiveTransform function to map points from one image to another using the computed homography matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/detection_of_planar_objects/detection_of_planar_objects.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
Mat points1Projected; perspectiveTransform(Mat(points1), points1Projected, H);
```

----------------------------------------

TITLE: Benchmarking OpenCV and Numpy Array Counting with IPython
DESCRIPTION: Benchmarks the performance of counting nonzero elements in an array using both OpenCV's cv.countNonZero and numpy's np.count_nonzero using IPython's %timeit. Shows that OpenCV's implementation is considerably faster when counting nonzero pixels in an image. Dependencies are OpenCV, numpy, and IPython. Inputs: image/array 'img'. Outputs: execution time for both implementations. Useful for guiding method selection in performance-critical code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_optimization/py_optimization.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
In [35]: %timeit z = cv.countNonZero(img)
100000 loops, best of 3: 15.8 us per loop

In [36]: %timeit z = np.count_nonzero(img)
1000 loops, best of 3: 370 us per loop
```

----------------------------------------

TITLE: Visualizing 2D Histogram using Matplotlib
DESCRIPTION: This code demonstrates how to visualize a 2D histogram using Matplotlib. It calculates a 2D histogram of an image's Hue and Saturation channels, then plots it using matplotlib's imshow function with nearest neighbor interpolation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_2d_histogram/py_2d_histogram.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('home.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"
hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)
hist = cv.calcHist( [hsv], [0, 1], None, [180, 256], [0, 180, 0, 256] )

plt.imshow(hist,interpolation = 'nearest')
plt.show()
```

----------------------------------------

TITLE: Performing Face Recognition and Matching
DESCRIPTION: This JavaScript snippet is part of a face recognition process using OpenCV.js, designed to match a new feature vector with previously registered vectors and return the best match's name. The OpenCV.js library is a required dependency. Inputs include a newly obtained feature vector and a database of registered vectors.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_javascript/dnn_javascript.markdown#2025-04-22_snippet_2

LANGUAGE: HTML
CODE:
```
"Recognize"
```

----------------------------------------

TITLE: Finding HSV Value of a Color using OpenCV in Python
DESCRIPTION: This snippet shows how to convert a BGR array to HSV to determine the HSV representation of a specific color. Requires numpy and OpenCV (cv2). Key parameter is the BGR value assigned to 'green'. Outputs corresponding HSV value, which can be used for color thresholding. Useful in configuring color extraction parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
>>> green = np.uint8([[[0,255,0 ]]])\n>>> hsv_green = cv.cvtColor(green,cv.COLOR_BGR2HSV)\n>>> print( hsv_green )\n[[[ 60 255 255]]]
```

----------------------------------------

TITLE: Calculating Convex Hull in Java using OpenCV
DESCRIPTION: This Java code snippet shows how to use OpenCV bindings to load an image, find contours via thresholding, compute the convex hull for each contour using `Imgproc.convexHull`, and visualize the results by drawing the contours and hulls. It depends on the OpenCV Java library and its native components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/hull/hull.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
@add_toggle_java
This tutorial code's is shown lines below. You can also download it from
[here](https://github.com/opencv/opencv/tree/4.x/samples/java/tutorial_code/ShapeDescriptors/hull/HullDemo.java)
@include samples/java/tutorial_code/ShapeDescriptors/hull/HullDemo.java
@end_toggle
```

----------------------------------------

TITLE: Creating a Simple OpenCV Application (Java)
DESCRIPTION: This Java code defines a simple application named `SimpleSample`. It demonstrates basic OpenCV functionality by loading the native OpenCV library using `System.loadLibrary()`, printing the OpenCV version, creating a 5x10 matrix (`Mat`) initialized with zeros, modifying specific rows and columns, and printing the final matrix data using `m.dump()`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_7

LANGUAGE: java
CODE:
```
    import org.opencv.core.Core;
    import org.opencv.core.Mat;
    import org.opencv.core.CvType;
    import org.opencv.core.Scalar;

    class SimpleSample {

      static{ System.loadLibrary(Core.NATIVE_LIBRARY_NAME); }

      public static void main(String[] args) {
        System.out.println("Welcome to OpenCV " + Core.VERSION);
        Mat m = new Mat(5, 10, CvType.CV_8UC1, new Scalar(0));
        System.out.println("OpenCV Mat: " + m);
        Mat mr1 = m.row(1);
        mr1.setTo(new Scalar(1));
        Mat mc5 = m.col(5);
        mc5.setTo(new Scalar(5));
        System.out.println("OpenCV Mat data:\n" + m.dump());
      }

    }
```

----------------------------------------

TITLE: Extracting Frozen Graph from TensorFlow Model Archive - Python
DESCRIPTION: This code handles the download and extraction of a TensorFlow detection model archive (.tar.gz), specifically extracting the 'frozen_inference_graph.pb' file for further processing. Dependencies include the 'urllib', 'tarfile', and 'os' Python libraries. It manages download errors, prints retrieval status, and searches the archive for the correct graph file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
# define model archive name\ntf_model_tar = model_name + '.tar.gz'\n# define link to retrieve model archive\nmodel_link = DETECTION_MODELS_URL + tf_model_tar\n\ntf_frozen_graph_name = 'frozen_inference_graph'\n\ntry:\n    urllib.request.urlretrieve(model_link, tf_model_tar)\nexcept Exception:\n    print("TF {} was not retrieved: {}".format(model_name, model_link))\n    return\n\nprint("TF {} was retrieved.".format(model_name))\n\ntf_model_tar = tarfile.open(tf_model_tar)\nfrozen_graph_path = ""\n\nfor model_tar_elem in tf_model_tar.getmembers():\n    if tf_frozen_graph_name in os.path.basename(model_tar_elem.name):\n        tf_model_tar.extract(model_tar_elem, extracted_model_path)\n        frozen_graph_path = os.path.join(extracted_model_path, model_tar_elem.name)\n        break\ntf_model_tar.close()
```

----------------------------------------

TITLE: Calculating Object Orientation via PCA in Python using OpenCV
DESCRIPTION: Defines a `getOrientation` function that takes a contour (list of points) and calculates its orientation using PCA (`cv.PCACompute`). It prepares the data, runs PCA, extracts the mean (center), eigenvectors, and eigenvalues, and visualizes the principal components on the input image. Requires the OpenCV Python library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
#! [pca]
# Perform PCA analysis
def getOrientation(pts, img):
    # Construct a buffer used by the PCA analysis
    sz = len(pts)
    data_pts = np.empty((sz, 2), dtype=np.float64)
    for i in range(data_pts.shape[0]):
        data_pts[i,0] = pts[i,0,0]
        data_pts[i,1] = pts[i,0,1]

    # Perform PCA analysis
    mean = np.empty((0))
    mean, eigenvectors, eigenvalues = cv.PCACompute2(data_pts, mean)

    # Store the center of the object
    cntr = (int(mean[0,0]), int(mean[0,1]))

    # Store the eigenvalues and eigenvectors
    eigenvecs = [None]*2
    eigenvals = [None]*2
    eigenvecs[0] = (eigenvectors[0,0], eigenvectors[0,1])
    eigenvecs[1] = (eigenvectors[1,0], eigenvectors[1,1])
    eigenvals[0] = eigenvalues[0,0]
    eigenvals[1] = eigenvalues[1,0]


    # Draw the principal components
    cv.circle(img, cntr, 3, (255, 0, 255), 2)
    p1 = (cntr[0] + 0.02 * eigenvecs[0][0] * eigenvals[0], cntr[1] + 0.02 * eigenvecs[0][1] * eigenvals[0])
    p2 = (cntr[0] - 0.02 * eigenvecs[1][0] * eigenvals[1], cntr[1] - 0.02 * eigenvecs[1][1] * eigenvals[1])
    drawAxis(img, cntr, p1, (0, 255, 0), 1)
    drawAxis(img, cntr, p2, (255, 255, 0), 5)

    angle = atan2(eigenvecs[0][1], eigenvecs[0][0]) # orientation in radians

    return angle
#! [pca]
```

----------------------------------------

TITLE: Running While Loop for Video Processing in C++
DESCRIPTION: Harnesses a while loop to continuously capture and process frames in a C++ OpenCV application until termination by the user. Ensures ongoing video analysis.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
while(true) {\n    // Capture frame-by-frame\n    if(waitKey(30) >= 0) break;\n}
```

----------------------------------------

TITLE: Running Camera Calibration and Saving Results in C++
DESCRIPTION: This snippet demonstrates how to run the camera calibration process and save the results to an XML or YAML file using OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
run_and_save
```

----------------------------------------

TITLE: Extracting 128-Dimensional Feature Vectors for Face Recognition
DESCRIPTION: This snippet uses JavaScript to run a face recognition network with OpenCV.js. It takes an RGB image of a face with a size of 96x96 pixels and returns a 128-dimensional feature vector representing the face as a point on a multidimensional sphere. Dependencies include the OpenCV.js library and a pre-processed face image of the specified dimensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_javascript/dnn_javascript.markdown#2025-04-22_snippet_1

LANGUAGE: HTML
CODE:
```
"Get 128 floating points feature vector"
```

----------------------------------------

TITLE: Converting PyTorch Model to ONNX
DESCRIPTION: This Python snippet demonstrates converting a PyTorch ResNet-50 model to ONNX format. It uses torch.onnx.export function, specifying model input, output paths, and ONNX export options. The resulting ONNX model is ready for integration with OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
original_model = models.resnet50(pretrained=True)

onnx_model_path = "models"
onnx_model_name = "resnet50.onnx"
os.makedirs(onnx_model_path, exist_ok=True)
full_model_path = os.path.join(onnx_model_path, onnx_model_name)

generated_input = Variable(
    torch.randn(1, 3, 224, 224)
)
torch.onnx.export(
    original_model,
    generated_input,
    full_model_path,
    verbose=True,
    input_names=["input"],
    output_names=["output"],
    opset_version=11
)
```

----------------------------------------

TITLE: Setting Parameters for Text Recognition Model in C++
DESCRIPTION: This C++ snippet sets up the parameters for a text recognition model using OpenCV DNN. It is essential to configure normalization parameters and input shape which are crucial for model inference. Scale and mean values are used for input normalization, and input size denotes the image dimensions expected by the model.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
// Normalization parameters
double scale = 1.0 / 127.5;
Scalar mean = Scalar(127.5, 127.5, 127.5);

// The input shape
Size inputSize = Size(100, 32);

model.setInputParams(scale, inputSize, mean);
```

----------------------------------------

TITLE: OpenCV DNN Model Inference Command-Line Execution - Console
DESCRIPTION: This command runs a compiled OpenCV C++ executable to perform inference using the converted ResNet-50 ONNX model on a given input image. All major preprocessing parameters (resize, normalization, cropping, and label file) are set to match the PyTorch pipeline. The command assumes the binary was built with samples enabled; all file and directory paths must be correct.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_9

LANGUAGE: console
CODE:
```
./dnn/example_dnn_classification --model=../dnn/models/resnet50.onnx --input=../data/squirrel_cls.jpg --width=224 --height=224 --rgb=true --scale="0.003921569" --mean="123.675 116.28 103.53" --std="0.229 0.224 0.225" --crop=true --initial_width=256 --initial_height=256 --classes=../data/dnn/classification_classes_ILSVRC2012.txt
```

----------------------------------------

TITLE: Image Preprocessing for PCA using OpenCV in C++
DESCRIPTION: Reads an input image, converts it to grayscale, and then applies binary thresholding. This prepares the image for contour detection, isolating objects of interest from the background. Requires the OpenCV library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
//! [pre-process]
// Load image
Mat src = imread(argv[1]);
// Check if image is loaded successfully
if(src.empty())
{
    cout << "Problem loading image!!!" << endl;
    return 0;
}

imshow("src", src);

// Convert image to grayscale
Mat gray;
cvtColor(src, gray, COLOR_BGR2GRAY);

// Convert image to binary
Mat bw;
threshold(gray, bw, 50, 255, THRESH_BINARY | THRESH_OTSU);
//! [pre-process]
```

----------------------------------------

TITLE: Finding Min/Max Intensity and Locations within Contour Mask in OpenCV Python
DESCRIPTION: This snippet finds the minimum and maximum intensity values, along with their corresponding locations, within a specific region of an image defined by a mask. It uses the `cv.minMaxLoc` function applied to the grayscale image (`imgray`), restricting the search to the area specified by the `mask`. Requires the grayscale image `imgray` and a pre-computed `mask` image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_6

LANGUAGE: python
CODE:
```
min_val, max_val, min_loc, max_loc = cv.minMaxLoc(imgray,mask = mask)
```

----------------------------------------

TITLE: Tonemapping HDR Images to 8-bit Display Range in OpenCV
DESCRIPTION: This code converts the HDR image to an 8-bit range that can be displayed on standard monitors. It uses tonemapping with bilateral filtering and applies gamma correction with a value of 2.2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/hdr_imaging.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
Mat ldr;
Ptr<TonemapDurand> tonemap = createTonemapDurand(2.2f);
tonemap->process(hdr, ldr);
Mat ldr_8bit;
ldr = 255 * ldr;
ldr.convertTo(ldr_8bit, CV_8UC3);
```

LANGUAGE: java
CODE:
```
Mat ldr = new Mat();
TonemapDurand tonemap = Photo.createTonemapDurand(2.2f);
tonemap.process(hdr, ldr);
ldr.convertTo(ldr, ldr.type(), 255, 0);
Mat ldr8bit = new Mat();
ldr.convertTo(ldr8bit, CvType.CV_8UC3);
```

LANGUAGE: python
CODE:
```
tonemap = cv.createTonemapDurand(2.2)
ldr = tonemap.process(hdr)
ldr = 255 * ldr
ldr_8bit = np.clip(ldr, 0, 255).astype('uint8')
```

----------------------------------------

TITLE: Detecting and Filtering Contours in Python using OpenCV
DESCRIPTION: Finds contours in the binary image `bw` using `cv.findContours`. It iterates through the detected contours, filters them by area using `cv.contourArea` to keep only reasonably sized shapes, and then proceeds to find their orientation. Requires the binary image `bw` and the OpenCV Python library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
#! [contours]
# Find all the contours in the thresholded image
contours, _ = cv.findContours(bw, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)

for i, c in enumerate(contours):
    # Calculate the area of each contour
    area = cv.contourArea(c)
    # Ignore contours that are too small or too large
    if area < 1e2 or 1e5 < area:
        continue

    # Draw each contour only for visualisation purposes
    cv.drawContours(src, contours, i, (0, 0, 255), 2)
    # Find the orientation of each shape
    getOrientation(c, src)
#! [contours]
```

----------------------------------------

TITLE: Detecting and Filtering Contours in C++ using OpenCV
DESCRIPTION: Finds contours in a binary image using `findContours`. It then iterates through the detected contours, filtering them based on a minimum area threshold to discard small noise-like contours. Requires a binary input image (bw).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
//! [contours]
// Find all the contours in the thresholded image
vector<vector<Point> > contours;
findContours(bw, contours, RETR_LIST, CHAIN_APPROX_NONE);

for (size_t i = 0; i < contours.size(); ++i)
{
    // Calculate the area of each contour
    double area = contourArea(contours[i]);
    // Ignore contours that are too small or too large
    if (area < 1e2 || 1e5 < area)
        continue;

    // Draw each contour only for visualisation purposes
    drawContours(src, contours, static_cast<int>(i), Scalar(0, 0, 255), 2);
    // Find the orientation of each shape
    getOrientation(contours[i], src);
}
//! [contours]
```

----------------------------------------

TITLE: Solving for Chessboard Pose using solvePnP in OpenCV C++
DESCRIPTION: This snippet uses the solvePnP function to determine the chessboard’s pose relative to the camera. The inputs are the known 3D points and the corresponding 2D image points, along with the camera matrix and distortion coefficients. The rotation (rvec) and translation (tvec) vectors obtained are crucial for further transformations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_square_chess/camera_calibration_square_chess.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
vector<Point3f> boardPoints;
// fill the array
...
solvePnP(Mat(boardPoints), Mat(foundBoardCorners), cameraMatrix,
                         distCoeffs, rvec, tvec, false);
```

----------------------------------------

TITLE: Implementing Lucas-Kanade Optical Flow Tracking in C++
DESCRIPTION: Demonstrates how to track feature points in a video using the Lucas-Kanade optical flow method in C++. The code first detects Shi-Tomasi corner points and then tracks these points through video frames using cv.calcOpticalFlowPyrLK().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/optical_flow.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include <iostream>
#include <opencv2/core.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/video.hpp>

using namespace cv;
using namespace std;

int main() {
    VideoCapture capture(samples::findFile("vtest.avi"));
    if (!capture.isOpened()){
        //error in opening the video input
        cerr << "Unable to open file!" << endl;
        return 0;
    }

    // Create some random colors
    vector<Scalar> colors;
    RNG rng;
    for(int i = 0; i < 100; i++)
    {
        int r = rng.uniform(0, 256);
        int g = rng.uniform(0, 256);
        int b = rng.uniform(0, 256);
        colors.push_back(Scalar(r,g,b));
    }

    Mat old_frame, old_gray;
    vector<Point2f> p0, p1;

    // Take first frame and find corners in it
    capture >> old_frame;
    cvtColor(old_frame, old_gray, COLOR_BGR2GRAY);
    goodFeaturesToTrack(old_gray, p0, 100, 0.3, 7, Mat(), 7, false, 0.04);

    // Create a mask image for drawing purposes
    Mat mask = Mat::zeros(old_frame.size(), old_frame.type());

    while(true){
        Mat frame, frame_gray;
        capture >> frame;
        if (frame.empty())
            break;
        cvtColor(frame, frame_gray, COLOR_BGR2GRAY);

        // calculate optical flow
        vector<uchar> status;
        vector<float> err;
        TermCriteria criteria = TermCriteria((TermCriteria::COUNT) + (TermCriteria::EPS), 10, 0.03);
        calcOpticalFlowPyrLK(old_gray, frame_gray, p0, p1, status, err, Size(15,15), 2, criteria);

        vector<Point2f> good_new;
        for(uint i = 0; i < p0.size(); i++)
        {
            // Select good points
            if(status[i] == 1) {
                good_new.push_back(p1[i]);
                // draw the tracks
                line(mask, p1[i], p0[i], colors[i], 2);
                circle(frame, p1[i], 5, colors[i], -1);
            }
        }
        Mat img;
        add(frame, mask, img);

        imshow("Frame", img);

        int keyboard = waitKey(30);
        if (keyboard == 'q' || keyboard == 27)
            break;

        // Now update the previous frame and previous points
        old_gray = frame_gray.clone();
        p0 = good_new;
    }
}
```

----------------------------------------

TITLE: Core SSIM Calculation Function in C++
DESCRIPTION: Provides overloaded C++ functions named `ssim` for calculating the Mean Structural Similarity Index (MSSIM). One version accepts CPU `Mat` objects, and the other accepts `gpu::GpuMat` objects. Both versions apply Gaussian blurring, calculate means, variances, and covariances, and then compute the SSIM based on the standard formula using constants C1 and C2. The GPU version utilizes functions like `gpu::GaussianBlur`, `gpu::multiply`, `gpu::subtract`, etc., for GPU acceleration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
//![ssim]
Scalar ssim(const Mat& i1, const Mat& i2)
{
    const double C1 = 6.5025, C2 = 58.5225;
    /***************************** INITS **********************************/
    int d = CV_32F;

    Mat I1, I2;
    i1.convertTo(I1, d);            // cannot calculate on one byte large values
    i2.convertTo(I2, d);

    Mat I2_2   = I2.mul(I2);        // I2^2
    Mat I1_2   = I1.mul(I1);        // I1^2
    Mat I1_I2  = I1.mul(I2);        // I1 * I2

    /*************************** END INITS **********************************/

    Mat mu1, mu2;                   // PRELIMINARY COMPUTING
    GaussianBlur(I1, mu1, Size(11, 11), 1.5);
    GaussianBlur(I2, mu2, Size(11, 11), 1.5);

    Mat mu1_2   =   mu1.mul(mu1);
    Mat mu2_2   =   mu2.mul(mu2);
    Mat mu1_mu2 =   mu1.mul(mu2);

    Mat sigma1_2, sigma2_2, sigma12;

    GaussianBlur(I1_2, sigma1_2, Size(11, 11), 1.5);
    sigma1_2 -= mu1_2;

    GaussianBlur(I2_2, sigma2_2, Size(11, 11), 1.5);
    sigma2_2 -= mu2_2;

    GaussianBlur(I1_I2, sigma12, Size(11, 11), 1.5);
    sigma12 -= mu1_mu2;

    ///////////////////////////////// FORMULA ////////////////////////////////
    Mat t1, t2, t3;

    t1 = 2 * mu1_mu2 + C1;
    t2 = 2 * sigma12 + C2;
    t3 = t1.mul(t2);                 // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))

    t1 = mu1_2 + mu2_2 + C1;
    t2 = sigma1_2 + sigma2_2 + C2;
    t1 = t1.mul(t2);                 // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))

    Mat ssim_map;
    divide(t3, t1, ssim_map);        // ssim_map =  t3./t1;

    Scalar mssim = mean(ssim_map);   // mssim = average of ssim map
    return mssim;
}

Scalar ssim(const gpu::GpuMat& i1, const gpu::GpuMat& i2)
{
    const float C1 = 6.5025f, C2 = 58.5225f;
    /***************************** INITS **********************************/
    gpu::GpuMat d_I1, d_I2;
    i1.convertTo(d_I1, CV_32F);
    i2.convertTo(d_I2, CV_32F);

    gpu::GpuMat d_I2_2, d_I1_2, d_I1_I2;
    gpu::multiply(d_I2, d_I2, d_I2_2);        // I2^2
    gpu::multiply(d_I1, d_I1, d_I1_2);        // I1^2
    gpu::multiply(d_I1, d_I2, d_I1_I2);       // I1 * I2

    /*************************** END INITS **********************************/

    gpu::GpuMat d_mu1, d_mu2;   // PRELIMINARY COMPUTING
    gpu::GaussianBlur(d_I1, d_mu1, Size(11, 11), 1.5);
    gpu::GaussianBlur(d_I2, d_mu2, Size(11, 11), 1.5);

    gpu::GpuMat d_mu1_2, d_mu2_2, d_mu1_mu2;
    gpu::multiply(d_mu1, d_mu1, d_mu1_2);
    gpu::multiply(d_mu2, d_mu2, d_mu2_2);
    gpu::multiply(d_mu1, d_mu2, d_mu1_mu2);

    gpu::GpuMat d_sigma1_2, d_sigma2_2, d_sigma12;

    gpu::GaussianBlur(d_I1_2, d_sigma1_2, Size(11, 11), 1.5);
    gpu::subtract(d_sigma1_2, d_mu1_2, d_sigma1_2); // sigma1_2 -= mu1_2;

    gpu::GaussianBlur(d_I2_2, d_sigma2_2, Size(11, 11), 1.5);
    gpu::subtract(d_sigma2_2, d_mu2_2, d_sigma2_2); // sigma2_2 -= mu2_2;

    gpu::GaussianBlur(d_I1_I2, d_sigma12, Size(11, 11), 1.5);
    gpu::subtract(d_sigma12, d_mu1_mu2, d_sigma12); // sigma12 -= mu1_mu2;

    ///////////////////////////////// FORMULA ////////////////////////////////
    gpu::GpuMat d_t1, d_t2, d_t3;

    // t1 = 2 * mu1_mu2 + C1;
    gpu::multiply(d_mu1_mu2, 2, d_t1);
    gpu::add(d_t1, C1, d_t1);

    // t2 = 2 * sigma12 + C2;
    gpu::multiply(d_sigma12, 2, d_t2);
    gpu::add(d_t2, C2, d_t2);

    // t3 = t1 * t2;
    gpu::multiply(d_t1, d_t2, d_t3);

    // t1 = mu1_2 + mu2_2 + C1;
    gpu::add(d_mu1_2, d_mu2_2, d_t1);
    gpu::add(d_t1, C1, d_t1);

    // t2 = sigma1_2 + sigma2_2 + C2;
    gpu::add(d_sigma1_2, d_sigma2_2, d_t2);
    gpu::add(d_t2, C2, d_t2);

    // t1 = t1 * t2;
    gpu::multiply(d_t1, d_t2, d_t1);

    // ssim_map = t3 / t1;
    gpu::GpuMat d_ssim_map;
    gpu::divide(d_t3, d_t1, d_ssim_map);

    Scalar s = gpu::sum(d_ssim_map);
    s.val[0] /= i1.total();
    s.val[1] /= i1.total();
    s.val[2] /= i1.total();
    return s;
}
//![ssim]
```

----------------------------------------

TITLE: Detecting Circles using OpenCV HoughCircles in Python
DESCRIPTION: Demonstrates circle detection in a grayscale image using OpenCV's HoughCircles function. The code loads an image, applies median blur, detects circles using Hough transform, and draws the detected circles with their centers. Uses cv.HOUGH_GRADIENT method with customizable parameters for detection sensitivity.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_houghcircles/py_houghcircles.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('opencv-logo-white.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
img = cv.medianBlur(img,5)
cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)

circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,
                            param1=50,param2=30,minRadius=0,maxRadius=0)

circles = np.uint16(np.around(circles))
for i in circles[0,:]:
    # draw the outer circle
    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)
    # draw the center of the circle
    cv.circle(cimg,(i[0],i[1]),2,(0,0,255),3)

cv.imshow('detected circles',cimg)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Converting PyTorch Model to ONNX Format
DESCRIPTION: This Python snippet demonstrates converting a PyTorch model (`original_model`) to the ONNX (Open Neural Network Exchange) format. It defines the output path and filename (`models/fcnresnet50.onnx`), creates the output directory if it doesn't exist, generates a dummy input tensor (`generated_input`) with the expected shape (1 batch, 3 channels, 500x500 pixels) required for tracing the model graph, and then calls `torch.onnx.export` to perform the conversion. Key parameters include the model, dummy input, output path, input/output names for the ONNX graph, and the ONNX opset version (11). Requires `torch`, `os`, and `torch.autograd.Variable` (or just `torch.randn`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
# define the directory for further converted model save
onnx_model_path = "models"
# define the name of further converted model
onnx_model_name = "fcnresnet50.onnx"

# create directory for further converted model
os.makedirs(onnx_model_path, exist_ok=True)

# get full path to the converted model
full_model_path = os.path.join(onnx_model_path, onnx_model_name)

# generate model input to build the graph
generated_input = Variable(
    torch.randn(1, 3, 500, 500)
)

# model export into ONNX format
torch.onnx.export(
    original_model,
    generated_input,
    full_model_path,
    verbose=True,
    input_names=["input"],
    output_names=["output"],
    opset_version=11
)
```

----------------------------------------

TITLE: Converting Grayscale to Binary Image in OpenCV (C++/Java/Python)
DESCRIPTION: Converts the grayscale image to a binary image using adaptive thresholding. This method is suitable for images with varying illumination. The `adaptiveThreshold` function is used with `ADAPTIVE_THRESH_MEAN_C` and `THRESH_BINARY_INV` flags. The block size and constant C are parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
//![bin]
// Apply adaptiveThreshold at the bitwise_not of gray, notice the ~ symbol
Mat bw;
adaptiveThreshold(~gray, bw, 255, ADAPTIVE_THRESH_MEAN_C, THRESH_BINARY, 15, -2);

// Show binary image
show_wait_destroy("binary", bw);
//![bin]
```

LANGUAGE: java
CODE:
```
//![bin]
// Apply adaptiveThreshold at the bitwise_not of gray, notice the ~ symbol
Mat bw = new Mat();
Core.bitwise_not(gray, gray);
Imgproc.adaptiveThreshold(gray, bw, 255, Imgproc.ADAPTIVE_THRESH_MEAN_C, Imgproc.THRESH_BINARY, 15, -2);

// Show binary image
showWaitDestroy("binary", bw);
//![bin]
```

LANGUAGE: python
CODE:
```
#![bin]
# Apply adaptiveThreshold at the bitwise_not of gray, notice the ~ symbol
gray = cv.bitwise_not(gray)
bw = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 15, -2)

# Show binary image
show_wait_destroy("binary", bw)
#![bin]
```

----------------------------------------

TITLE: Loading an Image into cv.Mat with OpenCV.js (JavaScript)
DESCRIPTION: Illustrates how to read an image displayed in an HTML `<img>` element (`imgElement`) into an OpenCV `cv.Mat` object using `cv.imread()`. This code should be placed within the `onload` event handler of the `img` element to ensure the image is fully loaded before processing. It also handles the case where the `cv` object might initially be a Promise by using `await`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_usage/js_usage.markdown#2025-04-22_snippet_3

LANGUAGE: javascript
CODE:
```
imgElement.onload = await function() {
  cv = (cv instanceof Promise) ? await cv : cv;
  let mat = cv.imread(imgElement);
}
```

----------------------------------------

TITLE: Applying Image Border with copyMakeBorder
DESCRIPTION: Implementation of copyMakeBorder() function to add padding around the image with either constant or replicated border types.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/copyMakeBorder/copyMakeBorder.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
copyMakeBorder(src, dst, top, bottom, left, right, borderType, value);
```

LANGUAGE: Java
CODE:
```
Core.copyMakeBorder(src, dst, top, bottom, left, right, borderType, value);
```

LANGUAGE: Python
CODE:
```
dst = cv.copyMakeBorder(src, top, bottom, left, right, borderType, value=value)
```

----------------------------------------

TITLE: Performing Affine Transformation in OpenCV
DESCRIPTION: Illustrates affine transformations preserving parallel lines. It uses three input points to define how an image aligns to three destination points via cv.getAffineTransform, generating a matrix used by cv.warpAffine.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_geometric_transformations/js_geometric_transformations.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
cv.getAffineTransform(src, dst)
```

----------------------------------------

TITLE: Applying Affine Transformations to Images in OpenCV Python
DESCRIPTION: Shows how to perform an affine transformation using cv.getAffineTransform() and cv.warpAffine(). This transformation preserves parallelism of lines but not their lengths or angles, using three point pairs to define the transformation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
img = cv.imread('drawing.png')
assert img is not None, "file could not be read, check with os.path.exists()"
rows,cols,ch = img.shape

pts1 = np.float32([[50,50],[200,50],[50,200]])
pts2 = np.float32([[10,100],[200,50],[100,250]])

M = cv.getAffineTransform(pts1,pts2)

dst = cv.warpAffine(img,M,(cols,rows))

plt.subplot(121),plt.imshow(img),plt.title('Input')
plt.subplot(122),plt.imshow(dst),plt.title('Output')
plt.show()
```

----------------------------------------

TITLE: Running Face Detection Inference - OpenCV DNN Python
DESCRIPTION: This snippet shows how to perform face detection inference with FaceDetectorYN in Python. The detect method processes an image and returns the detection results as a NumPy array. Inputs include an image, and outputs follow the expected detection array format: bounding boxes and five facial landmarks per face instance.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
# Detect faces in an image
_, faces = detector.detect(image)
# 'faces' is a numpy array with detection results (one row per detected face)
```

----------------------------------------

TITLE: Detecting ArUco Markers in an Image
DESCRIPTION: Code snippet illustrating how to detect ArUco markers in an input image. This example uses the ArucoDetector class to find markers from a predefined dictionary, returning the corners and IDs of detected markers as well as rejected candidates.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
cv::Mat inputImage;
// ... read inputImage ...
std::vector<int> markerIds;
std::vector<std::vector<cv::Point2f>> markerCorners, rejectedCandidates;
cv::aruco::DetectorParameters detectorParams = cv::aruco::DetectorParameters();
cv::aruco::Dictionary dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);
cv::aruco::ArucoDetector detector(dictionary, detectorParams);
detector.detectMarkers(inputImage, markerCorners, markerIds, rejectedCandidates);
```

----------------------------------------

TITLE: Calculating SSIM for Image Similarity in OpenCV Python
DESCRIPTION: This Python implementation of the Structural Similarity Index (SSIM) algorithm calculates image similarity with better perceptual accuracy than PSNR. The algorithm computes luminance, contrast, and structure components separately and combines them into a final similarity index for each channel.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_10

LANGUAGE: Python
CODE:
```
def getMSSIM(i1, i2):
    C1 = 6.5025
    C2 = 58.5225
    # INITS
    I1 = np.float32(i1) # cannot calculate on one byte large values
    I2 = np.float32(i2)
    I2_2 = I2 * I2 # I2^2
    I1_2 = I1 * I1 # I1^2
    I1_I2 = I1 * I2 # I1 * I2
    # END INITS
    # PRELIMINARY COMPUTING
    mu1 = cv.GaussianBlur(I1, (11, 11), 1.5)
    mu2 = cv.GaussianBlur(I2, (11, 11), 1.5)
    mu1_2 = mu1 * mu1
    mu2_2 = mu2 * mu2
    mu1_mu2 = mu1 * mu2
    sigma1_2 = cv.GaussianBlur(I1_2, (11, 11), 1.5)
    sigma1_2 -= mu1_2
    sigma2_2 = cv.GaussianBlur(I2_2, (11, 11), 1.5)
    sigma2_2 -= mu2_2
    sigma12 = cv.GaussianBlur(I1_I2, (11, 11), 1.5)
    sigma12 -= mu1_mu2
    t1 = 2 * mu1_mu2 + C1
    t2 = 2 * sigma12 + C2
    t3 = t1 * t2 # t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))
    t1 = mu1_2 + mu2_2 + C1
    t2 = sigma1_2 + sigma2_2 + C2
    t1 = t1 * t2  # t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))
    ssim_map = cv.divide(t3, t1)  # ssim_map =  t3./t1;
    mssim = cv.mean(ssim_map)  # mssim = average of ssim map
    return mssim
```

----------------------------------------

TITLE: Image Blending Using Pyramids
DESCRIPTION: Complete implementation of image blending using Gaussian and Laplacian pyramids to seamlessly combine two images (apple and orange). Creates pyramids, combines image halves at each level, and reconstructs the final blended image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_pyramids/py_pyramids.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import cv2 as cv
import numpy as np,sys

A = cv.imread('apple.jpg')
B = cv.imread('orange.jpg')
assert A is not None, "file could not be read, check with os.path.exists()"
assert B is not None, "file could not be read, check with os.path.exists()"

# generate Gaussian pyramid for A
G = A.copy()
gpA = [G]
for i in range(6):
    G = cv.pyrDown(G)
    gpA.append(G)

# generate Gaussian pyramid for B
G = B.copy()
gpB = [G]
for i in range(6):
    G = cv.pyrDown(G)
    gpB.append(G)

# generate Laplacian Pyramid for A
lpA = [gpA[5]]
for i in range(5,0,-1):
    GE = cv.pyrUp(gpA[i])
    L = cv.subtract(gpA[i-1],GE)
    lpA.append(L)

# generate Laplacian Pyramid for B
lpB = [gpB[5]]
for i in range(5,0,-1):
    GE = cv.pyrUp(gpB[i])
    L = cv.subtract(gpB[i-1],GE)
    lpB.append(L)

# Now add left and right halves of images in each level
LS = []
for la,lb in zip(lpA,lpB):
    rows,cols,dpt = la.shape
    ls = np.hstack((la[:,0:cols//2], lb[:,cols//2:]))
    LS.append(ls)

# now reconstruct
ls_ = LS[0]
for i in range(1,6):
    ls_ = cv.pyrUp(ls_)
    ls_ = cv.add(ls_, LS[i])

# image with direct connecting each half
real = np.hstack((A[:,:cols//2],B[:,cols//2:]))

cv.imwrite('Pyramid_blending2.jpg',ls_)
cv.imwrite('Direct_blending.jpg',real)
```

----------------------------------------

TITLE: Setting up Trackbars for Threshold Parameters (C++)
DESCRIPTION: In C++, this snippet sets up two OpenCV trackbars within the 'Threshold Demo' window. Users can interactively select the thresholding type and value. Both trackbars invoke the callback function Threshold_Demo upon change. Requires OpenCV's highgui module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
// [trackbar]\ncreateTrackbar( "Type:\n 0:Binary \n 1:BinaryInv \n 2:Trunc \n 3:ToZero \n 4:ToZeroInv",\n               window_name, &threshold_type, max_type, Threshold_Demo );\ncreateTrackbar( "Value",\n               window_name, &threshold_value, max_value, Threshold_Demo );\n// [trackbar]
```

----------------------------------------

TITLE: Example info.dat Format for opencv_createsamples (Text)
DESCRIPTION: Illustrates the format of the description file (`info.dat`) used with the `-info` argument in `opencv_createsamples`. Each line specifies an image path relative to the file, followed by the number of object instances in that image, and then the bounding box coordinates (x, y, width, height) for each object instance.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/traincascade.markdown#2025-04-22_snippet_3

LANGUAGE: text
CODE:
```
img/img1.jpg  1  140 100 45 45
img/img2.jpg  2  100 200 50 50   50 30 25 25
```

----------------------------------------

TITLE: Converting RGB to Grayscale using OpenCV
DESCRIPTION: This C++ code snippet demonstrates the conversion of an RGB image to a grayscale image using the OpenCV function 'cvtColor'. The function requires the source image, destination image, and a color conversion code (cv::COLOR_RGB2GRAY) to perform the operation. The grayscale conversion formula is based on the luminance equation that weights the red, green, and blue channels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/imgproc/doc/colors.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
cvtColor(src, bwsrc, cv::COLOR_RGB2GRAY);
```

----------------------------------------

TITLE: Threshold Operation Callback Function (Python)
DESCRIPTION: This Python callback applies cv.threshold using the parameters currently set by the window trackbars, and refreshes the display window. It's assigned to trackbar events for dynamic updates. Inputs: src_gray, threshold type/value; output: displayed thresholded image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_14

LANGUAGE: Python
CODE:
```
# [Threshold_Demo]\ndef Threshold_Demo(*args):\n    threshold_type = cv.getTrackbarPos('Type', window_name)\n    threshold_value = cv.getTrackbarPos('Value', window_name)\n    ret, dst = cv.threshold(src_gray, threshold_value, max_BINARY_value, threshold_type)\n    cv.imshow(window_name, dst)\n# [Threshold_Demo]
```

----------------------------------------

TITLE: Applying Bilateral Filter with OpenCV in Java
DESCRIPTION: This Java snippet demonstrates the use of OpenCV's bilateralFilter() function for edge-preserving smoothing. Dependencies include OpenCV and requires parameters such as diameter, and standard deviations in color and space.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_10

LANGUAGE: Java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java bilateralfilter
```

----------------------------------------

TITLE: Defining Evaluation Configuration for Classification (Python)
DESCRIPTION: Defines the TestClsConfig Python dataclass that specifies default parameters for evaluation, such as batch size, frame size, image root directory, and label file paths. This must be imported from test_config.py and can be customized for different datasets or model requirements. Key parameters include batch_size, frame_size, bgr_to_rgb, and file paths for input images and class labels. Inputs and outputs are strictly determined by the dataclass fields; limitations depend on dataset structure and available files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
@dataclass
class TestClsConfig:
    batch_size: int = 50
    frame_size: int = 224
    img_root_dir: str = "./ILSVRC2012_img_val"
    # location of image-class matching
    img_cls_file: str = "./val.txt"
    bgr_to_rgb: bool = True
```

----------------------------------------

TITLE: Initializing a Lookup Table (LUT) using cv::Mat in C++
DESCRIPTION: This C++ snippet demonstrates how to create and populate a `cv::Mat` to be used as a lookup table (LUT) for image modification. It initializes a single-row matrix with 256 columns (one for each possible 8-bit pixel value) and sets the desired mapping. This table is intended to be used with the `cv::LUT()` function. Requires the OpenCV library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
@snippet how_to_scan_images.cpp table-init
```

----------------------------------------

TITLE: Multiple Object Template Matching in OpenCV Python
DESCRIPTION: Implements template matching to detect multiple instances of an object (coins in Mario game) using thresholding. The code uses TM_CCOEFF_NORMED method and draws rectangles around all matched locations above a threshold.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_template_matching/py_template_matching.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

img_rgb = cv.imread('mario.png')
assert img_rgb is not None, "file could not be read, check with os.path.exists()"
img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)
template = cv.imread('mario_coin.png', cv.IMREAD_GRAYSCALE)
assert template is not None, "file could not be read, check with os.path.exists()"
w, h = template.shape[::-1]

res = cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)
threshold = 0.8
loc = np.where( res >= threshold)
for pt in zip(*loc[::-1]):
    cv.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)

cv.imwrite('res.png',img_rgb)
```

----------------------------------------

TITLE: Preparing Input Image for Model Inference
DESCRIPTION: This Python code prepares an input image for inference with OpenCV's DNN module. It reads, preprocesses, and formats the image into a blob, which is compatible with the model's input requirements, using mean normalization and standard scaling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
input_img = cv2.imread(img_path, cv2.IMREAD_COLOR)
input_img = input_img.astype(np.float32)

input_img = cv2.resize(input_img, (256, 256))

mean = np.array([0.485, 0.456, 0.406]) * 255.0
scale = 1 / 255.0
std = [0.229, 0.224, 0.225]

input_blob = cv2.dnn.blobFromImage(
    image=input_img,
    scalefactor=scale,
    size=(224, 224),
    mean=mean,
    swapRB=True,
    crop=True
)
input_blob[0] /= np.asarray(std, dtype=np.float32).reshape(3, 1, 1)
```

----------------------------------------

TITLE: PyTorch-style Image Preprocessing in Python - Python
DESCRIPTION: This Python code demonstrates the typical order of image normalization for PyTorch-trained classification models. Pixel values are scaled, mean-centered, and finally standardized per channel. This preprocessing order is necessary for reproducible inference results between PyTorch and OpenCV pipelines.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_12

LANGUAGE: python
CODE:
```
img /= 255.0\nimg -= [0.485, 0.456, 0.406]\nimg /= [0.229, 0.224, 0.225]
```

----------------------------------------

TITLE: Implementing k-Nearest Neighbour Classification with OpenCV and Python
DESCRIPTION: This code creates a simple 2D classification problem with two classes (Red and Blue), trains a kNN model with 25 random data points, and then classifies a new data point. The implementation includes visualization using matplotlib to display the training data and classification results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_knn/py_knn_understanding/py_knn_understanding.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt

# Feature set containing (x,y) values of 25 known/training data
trainData = np.random.randint(0,100,(25,2)).astype(np.float32)

# Label each one either Red or Blue with numbers 0 and 1
responses = np.random.randint(0,2,(25,1)).astype(np.float32)

# Take Red neighbours and plot them
red = trainData[responses.ravel()==0]
plt.scatter(red[:,0],red[:,1],80,'r','^')

# Take Blue neighbours and plot them
blue = trainData[responses.ravel()==1]
plt.scatter(blue[:,0],blue[:,1],80,'b','s')

plt.show()
```

----------------------------------------

TITLE: Initializing Face Recognizer (FaceRecognizerSF) - OpenCV DNN C++
DESCRIPTION: This snippet demonstrates how to initialize a FaceRecognizerSF object in C++ using a pre-trained ONNX model for face recognition. The function requires model path, config (if any), and input size applicable to the model. It depends on the OpenCV face module. Outputs an object ready to extract face features for recognition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
// Initialize FaceRecognizerSF
cv::Ptr<cv::FaceRecognizerSF> recognizer = cv::FaceRecognizerSF::create(
    modelPath,                   // Path to face recognition .onnx model
    "",                          // No config file usually
    cv::Size(112, 112)           // Input size expected by recognition model
);
```

----------------------------------------

TITLE: Text Recognition Inference in C++
DESCRIPTION: The C++ snippet performs text recognition inference with the prepared TextRecognitionModel. It processes the input image and prints the recognized text using OpenCV's DNN module. The expected input is a preprocessed image, and the output is the recognized text string.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
std::string recognitionResult = recognizer.recognize(image);
std::cout << "'" << recognitionResult << "'" << std::endl;
```

----------------------------------------

TITLE: Detecting Lines using Standard Hough Transform in OpenCV.js
DESCRIPTION: Uses the standard Hough Transform algorithm to detect lines in a binary image. It returns lines represented by their polar coordinates (rho, theta). Requires a single-channel 8-bit binary input image. Key parameters include `rho` (distance resolution), `theta` (angle resolution), and `threshold` (minimum votes). Optional parameters allow for multi-scale transforms and angle range limits. Depends on the OpenCV.js library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_houghlines/js_houghlines.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.HoughLines (image, lines, rho, theta, threshold, srn = 0, stn = 0, min_theta = 0, max_theta = Math.PI)
@param image       8-bit, single-channel binary source image. The image may be modified by the function.
@param lines       output vector of lines(cv.32FC2 type). Each line is represented by a two-element vector (ρ,θ) . ρ is the distance from the coordinate origin (0,0). θ is the line rotation angle in radians.
@param rho    	   distance resolution of the accumulator in pixels.
@param theta       angle resolution of the accumulator in radians.
@param threshold   accumulator threshold parameter. Only those lines are returned that get enough votes
@param srn         for the multi-scale Hough transform, it is a divisor for the distance resolution rho . The coarse accumulator distance resolution is rho and the accurate accumulator resolution is rho/srn . If both srn=0 and stn=0 , the classical Hough transform is used. Otherwise, both these parameters should be positive.
@param stn         for the multi-scale Hough transform, it is a divisor for the distance resolution theta.
@param min_theta   for standard and multi-scale Hough transform, minimum angle to check for lines. Must fall between 0 and max_theta.
@param max_theta   for standard and multi-scale Hough transform, maximum angle to check for lines. Must fall between min_theta and CV_PI.
```

----------------------------------------

TITLE: Comparing Shapes with OpenCV's Match Shapes in JavaScript
DESCRIPTION: This function compares two shapes or contours and provides a similarity metric based on Hu moments. Lower values indicate better matches. The cv.matchShapes function requires two contours or grayscale images, a comparison method, and a parameter (currently unsupported).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contours_more_functions/js_contours_more_functions.markdown#2025-04-22_snippet_2



----------------------------------------

TITLE: Implementing CLAHE (Contrast Limited Adaptive Histogram Equalization)
DESCRIPTION: This code demonstrates how to apply Contrast Limited Adaptive Histogram Equalization (CLAHE) in OpenCV. CLAHE improves local contrast by dividing the image into small tiles, equalizing each tile separately, and then using bilinear interpolation to eliminate artifacts at tile boundaries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_equalization/py_histogram_equalization.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('tsukuba_l.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"

# create a CLAHE object (Arguments are optional).
clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
cl1 = clahe.apply(img)

cv.imwrite('clahe_2.jpg',cl1)
```

----------------------------------------

TITLE: Applying Bilateral Filter with OpenCV in C++
DESCRIPTION: This C++ snippet explains the use of OpenCV's bilateralFilter() function to apply a bilateral filter for smoothing images while preserving edges. It requires the OpenCV library and parameters including the diameter, and standard deviations in color and space.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
@snippet cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp bilateralfilter
```

----------------------------------------

TITLE: Implementing USAC Framework in OpenCV C++
DESCRIPTION: This C++ code snippet showcases the integration of the USAC framework within the OpenCV 'calib3d' module. It implements a modular RANSAC-based sampling framework that is independent of any estimation problem, capable of including new solvers and methods easily. The framework introduces numerous sampling and optimization techniques, ensuring flexibility and improved accuracy in model estimation. Key dependencies include OpenCV and support for specific matrix operations such as Eigen decomposition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/usac.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
\nnamespace usac {\n    // Sampling methods\n    enum Sampling {\n        UNIFORM, PROSAC, NAPSAC, PROGRESSIVE_NAPSAC\n    };\n\n    // Score methods\n    enum Score {\n        RANSAC, MSAC, MAGSAC, LMeds\n    };\n\n    // Error metrics\n    enum ErrorMetric {\n        REPROJECTION, SAMPSON, SYMMETRIC_GEOMETRIC\n    };\n\n    // Degeneracy checks\n    enum Degeneracy {\n        DEGENSAC, COLLINEARITY_TEST, ORIENTED_EPIPOLAR\n    };\n\n    // Local Optimization\n    enum LocalOptimization {\n        LORANSAC, GRAPH_CUT, SIGMA_CONSENSUS\n    };\n\n    // Termination methods\n    enum Termination {\n        STANDARD, PROSAC_TERMINATION, SPRT_TERMINATION\n    };\n\n    // Solvers\n    enum Solver {\n        AFFINE2D, HOMOGRAPHY, FUNDAMENTAL, ESSENTIAL, PERSPECTIVE_N_POINT\n    };\n\n    // Neighborhood graph building options\n    enum Neighborhood {\n        NEIGH_FLANN_KNN, NEIGH_FLANN_RADIUS, NEIGH_GRID\n    };\n\n    // USAC Flags\n    const int USAC_DEFAULT = 0;\n    const int USAC_PARALLEL = 1;\n    const int USAC_ACCURATE = 2;\n}\n
```

----------------------------------------

TITLE: Displaying Image using imshow and waitKey in OpenCV in C++
DESCRIPTION: Shows how to display an image in a window using cv::imshow and waitKey in C++. Requires OpenCV and a GUI environment. imshow creates and displays the window. waitKey waits for user input (milliseconds or indefinitely with 0).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_40

LANGUAGE: C++
CODE:
```
cv::imshow("Window", img);\ncv::waitKey(0);
```

----------------------------------------

TITLE: Copying Source Image in Callback (C++)
DESCRIPTION: Inside the trackbar callback function, this snippet creates a copy of the original source image using `img.copyTo(img_display)`. This ensures that drawing operations (like the result rectangle) are performed on a copy, leaving the original image unmodified for subsequent matching operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_19

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp copy_source
```

----------------------------------------

TITLE: Image Preprocessing for PCA using OpenCV in Java
DESCRIPTION: Loads an image using `imread`, converts it to grayscale using `cvtColor`, and applies Otsu's binary thresholding using `threshold`. This preprocessing step isolates potential objects for subsequent analysis. Depends on OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
//! [pre-process]
// Load image
Mat src = Imgcodecs.imread(args.length > 0 ? args[0] : "../data/pca_test1.jpg");
// Check if image is loaded successfully
if(src.empty())
{
    System.out.println("Problem loading image!!!");
    System.exit(-1);
}

HighGui.imshow("src", src);

// Convert image to grayscale
Mat gray = new Mat();
cvtColor(src, gray, COLOR_BGR2GRAY);

// Convert image to binary
Mat bw = new Mat();nthreshold(gray, bw, 50, 255, THRESH_BINARY | THRESH_OTSU);
//! [pre-process]
```

----------------------------------------

TITLE: Finding Extreme Points of a Contour in OpenCV Python using NumPy
DESCRIPTION: This snippet identifies the extreme points (topmost, bottommost, leftmost, rightmost) of a contour using NumPy array indexing. It leverages `argmin()` and `argmax()` on the contour's x (column index 0) and y (column index 1) coordinates to find the indices corresponding to the minimum and maximum values. Requires an existing contour variable `cnt` (assumed to be a NumPy array).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
leftmost = tuple(cnt[cnt[:,:,0].argmin()][0])
rightmost = tuple(cnt[cnt[:,:,0].argmax()][0])
topmost = tuple(cnt[cnt[:,:,1].argmin()][0])
bottommost = tuple(cnt[cnt[:,:,1].argmax()][0])
```

----------------------------------------

TITLE: Implementing Dense Optical Flow in C++
DESCRIPTION: C++ implementation of dense optical flow using Farneback's algorithm (cv.calcOpticalFlowFarneback()). This code calculates the optical flow for all points in the frame and visualizes the flow field using HSV color coding for direction and magnitude.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/optical_flow.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
#include <iostream>
#include <opencv2/core.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/video.hpp>

using namespace cv;
using namespace std;

int main() {
    VideoCapture capture(samples::findFile("vtest.avi"));
    if (!capture.isOpened()){
        //error in opening the video input
        cerr << "Unable to open file!" << endl;
        return 0;
    }

    Mat frame1, prvs;
    capture >> frame1;
    cvtColor(frame1, prvs, COLOR_BGR2GRAY);

    while(true){
        Mat frame2, next;
        capture >> frame2;
        if (frame2.empty())
            break;
        cvtColor(frame2, next, COLOR_BGR2GRAY);

        Mat flow(prvs.size(), CV_32FC2);
        calcOpticalFlowFarneback(prvs, next, flow, 0.5, 3, 15, 3, 5, 1.2, 0);

        // visualization
        Mat flow_parts[2];
        split(flow, flow_parts);
        Mat magnitude, angle, magn_norm;
        cartToPolar(flow_parts[0], flow_parts[1], magnitude, angle, true);
        normalize(magnitude, magn_norm, 0.0f, 1.0f, NORM_MINMAX);
        angle *= ((1.f / 360.f) * (180.f / 255.f));

        //build hsv image
        Mat _hsv[3], hsv, hsv8, bgr;
        _hsv[0] = angle;
        _hsv[1] = Mat::ones(angle.size(), CV_32F);
        _hsv[2] = magn_norm;
        merge(_hsv, 3, hsv);
        hsv.convertTo(hsv8, CV_8U, 255.0);
        cvtColor(hsv8, bgr, COLOR_HSV2BGR);

        imshow("frame2", bgr);

        int keyboard = waitKey(30);
        if (keyboard == 'q' || keyboard == 27)
            break;

        prvs = next;
    }
}
```

----------------------------------------

TITLE: Loading Source Images in Python
DESCRIPTION: This Python snippet uses `cv.imread` to load two images (`src1`, `src2`) for blending. It includes checks using `is None` to ensure the images were loaded successfully and exits if not.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
#![load]
# Read images
src1 = cv.imread(cv.samples.findFile('LinuxLogo.jpg'))
src2 = cv.imread(cv.samples.findFile('WindowsLogo.jpg'))
if src1 is None:
    print('Could not open or find the image: ', args.input1)
    exit(0)
if src2 is None:
    print('Could not open or find the image: ', args.input2)
    exit(0)
#![load]
```

----------------------------------------

TITLE: Calculating Histogram Backprojection with cv.calcBackProject in OpenCV.js
DESCRIPTION: Details the `cv.calcBackProject` function signature from OpenCV.js. This function computes the back projection of a histogram onto an image, which is useful for object detection and segmentation. It requires source images, channel indices, the pre-computed histogram, an output array, bin ranges, and an optional scaling factor.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_histograms/js_histogram_backprojection/js_histogram_backprojection.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.calcBackProject (images, channels, hist, dst, ranges, scale)

@param images       source arrays. They all should have the same depth, cv.CV_8U, cv.CV_16U or cv.CV_32F , and the same size. Each of them can have an arbitrary number of channels.
@param channels     the list of channels used to compute the back projection. The number of channels must match the histogram dimensionality.
@param hist         input histogram that can be dense or sparse.
@param dst          destination back projection array that is a single-channel array of the same size and depth as images[0].
@param ranges       array of arrays of the histogram bin boundaries in each dimension(see cv.calcHist).
@param scale        optional scale factor for the output back projection.
```

----------------------------------------

TITLE: Initializing Caffe Model with OpenCV in C++
DESCRIPTION: This snippet demonstrates how to read and initialize a Caffe model using OpenCV's DNN module. It relies on the presence of a `.prototxt` and a `.caffemodel` file, and the cv::dnn::readNet function is used to load the model. Ensure that the files are in your working directory and correctly named.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
@snippet dnn/classification.cpp Read and initialize network
```

----------------------------------------

TITLE: Detecting Keypoints with AKAZE in OpenCV using Python
DESCRIPTION: This snippet demonstrates using AKAZE in Python via OpenCV to detect keypoints and compute descriptors on images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py AKAZE
```

----------------------------------------

TITLE: Extracting Camera Pose from Homography in OpenCV C++
DESCRIPTION: Code to extract camera rotation and translation from a homography matrix. It decomposes the homography into the camera pose components assuming a planar object at Z=0.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
// Compute the scale factor
double lambda = 1.0 / cv::norm(H.col(0));

// Extract rotation matrix and translation vector
cv::Mat R(3, 3, CV_64F);
cv::Mat t = H.col(2) * lambda;

R.col(0) = H.col(0) * lambda;
R.col(1) = H.col(1) * lambda;
R.col(2) = R.col(0).cross(R.col(1));
```

----------------------------------------

TITLE: Finding Minimum and Maximum Match Values/Locations (C++)
DESCRIPTION: Uses the `cv::minMaxLoc` function to find the minimum and maximum values within the normalized result matrix, along with their corresponding locations (coordinates). Pointers store the minimum/maximum values and `Point` objects store their locations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_28

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp best_match
```

----------------------------------------

TITLE: Drawing a Polygon in C++
DESCRIPTION: Implementation of the MyPolygon function that draws a filled polygon in OpenCV C++. The function creates a set of points to define the polygon vertices and uses the fillPoly() function to draw a white polygon.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_24

LANGUAGE: cpp
CODE:
```
void MyPolygon( Mat img )
{
  int lineType = LINE_8;

  /** Create some points */
  Point rook_points[1][20];
  rook_points[0][0] = Point( w/4, 7*w/8 );
  rook_points[0][1] = Point( 3*w/4, 7*w/8 );
  rook_points[0][2] = Point( 3*w/4, 13*w/16 );
  rook_points[0][3] = Point( 11*w/16, 13*w/16 );
  rook_points[0][4] = Point( 19*w/32, 3*w/8 );
  rook_points[0][5] = Point( 3*w/4, 3*w/8 );
  rook_points[0][6] = Point( 3*w/4, w/8 );
  rook_points[0][7] = Point( 26*w/40, w/8 );
  rook_points[0][8] = Point( 26*w/40, w/4 );
  rook_points[0][9] = Point( 22*w/40, w/4 );
  rook_points[0][10] = Point( 22*w/40, w/8 );
  rook_points[0][11] = Point( 18*w/40, w/8 );
  rook_points[0][12] = Point( 18*w/40, w/4 );
  rook_points[0][13] = Point( 14*w/40, w/4 );
  rook_points[0][14] = Point( 14*w/40, w/8 );
  rook_points[0][15] = Point( w/4, w/8 );
  rook_points[0][16] = Point( w/4, 3*w/8 );
  rook_points[0][17] = Point( 13*w/32, 3*w/8 );
  rook_points[0][18] = Point( 5*w/16, 13*w/16 );
  rook_points[0][19] = Point( w/4, 13*w/16 );

  const Point* ppt[1] = { rook_points[0] };
  int npt[] = { 20 };

  fillPoly( img,
        ppt,
        npt,
        1,
        Scalar( 255, 255, 255 ),
        lineType );
}
```

----------------------------------------

TITLE: Computing Bounding Rotated Boxes and Ellipses in Contours - OpenCV Java
DESCRIPTION: This Java snippet demonstrates contour detection and the calculation of minimum area rectangles and fitting ellipses with the OpenCV Java API. It requires OpenCV for Java, and takes an image as input to find contours, draw the rotated rectangles, and fit ellipses where appropriate (for contours with enough points). Key parameters include the input image file and preprocessing settings. Outputs are graphical overlays of rectangles and ellipses over the detected contours. The code uses Imgproc.findContours, Imgproc.minAreaRect, and Imgproc.fitEllipse.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rotated_ellipses/bounding_rotated_ellipses.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;\nimport org.opencv.imgproc.Imgproc;\nimport org.opencv.highgui.HighGui;\nimport org.opencv.imgcodecs.Imgcodecs;\n\npublic class GeneralContoursDemo2 {\n    public static void main(String[] args) {\n        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);\n        Mat src = Imgcodecs.imread("shapes.png", Imgcodecs.IMREAD_GRAYSCALE);\n        Imgproc.threshold(src, src, 100, 255, Imgproc.THRESH_BINARY);\n        java.util.List<MatOfPoint> contours = new java.util.ArrayList<>();\n        Mat hierarchy = new Mat();\n        Imgproc.findContours(src, contours, hierarchy, Imgproc.RETR_LIST, Imgproc.CHAIN_APPROX_SIMPLE);\n        Mat drawing = Mat.zeros(src.size(), CvType.CV_8UC3);\n        for (int i = 0; i < contours.size(); i++) {\n            RotatedRect box = Imgproc.minAreaRect(new MatOfPoint2f(contours.get(i).toArray()));\n            Point[] vertices = new Point[4];\n            box.points(vertices);\n            for (int j = 0; j < 4; ++j)\n                Imgproc.line(drawing, vertices[j], vertices[(j+1)%4], new Scalar(0,255,0), 2);\n            if (contours.get(i).total() > 5) {\n                RotatedRect ellipseBox = Imgproc.fitEllipse(new MatOfPoint2f(contours.get(i).toArray()));\n                Imgproc.ellipse(drawing, ellipseBox, new Scalar(255,0,0), 2);\n            }\n        }\n        HighGui.imshow("Contours", drawing);\n        HighGui.waitKey();\n    }\n}
```

----------------------------------------

TITLE: Displaying Results with OpenCV imshow in Python
DESCRIPTION: This Python snippet uses cv2.imshow to display the original and processed images in separate named windows. Calls to cv2.waitKey and cv2.destroyAllWindows provide control flow. Requires cv2 installed and available GUI environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_20

LANGUAGE: Python
CODE:
```
cv2.imshow('Source', src)\ncv2.imshow('Detected Lines (in red) - Standard Hough Line Transform', img)\ncv2.imshow('Detected Lines (in green) - Probabilistic Line Transform', imgP)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n
```

----------------------------------------

TITLE: Applying Sobel Operator in C++
DESCRIPTION: This C++ snippet demonstrates how to apply the Sobel operator to detect edges in an image using OpenCV. The operations include loading an image, reducing noise, converting to grayscale, applying the Sobel operator, and displaying the results. The dependencies include OpenCV library and a sample image as input, with output displayed as an edge-highlighted image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include <opencv2/opencv.hpp>
using namespace cv; 

Mat image = imread("lena.jpg"); // Load source image
```

LANGUAGE: cpp
CODE:
```
GaussianBlur(src, src, Size(3, 3), 0, 0, BORDER_DEFAULT); // Reduce noise
```

LANGUAGE: cpp
CODE:
```
cvtColor(src, src_gray, COLOR_BGR2GRAY); // Convert to grayscale
```

LANGUAGE: cpp
CODE:
```
Sobel(src_gray, grad_x, ddepth, 1, 0, 3, scale, delta, BORDER_DEFAULT); // Apply Sobel for x-gradient
Sobel(src_gray, grad_y, ddepth, 0, 1, 3, scale, delta, BORDER_DEFAULT); // Apply Sobel for y-gradient
```

LANGUAGE: cpp
CODE:
```
convertScaleAbs(grad_x, abs_grad_x); 
convertScaleAbs(grad_y, abs_grad_y);
```

LANGUAGE: cpp
CODE:
```
addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0, grad); // Approximate the gradient
```

LANGUAGE: cpp
CODE:
```
imshow("Sobel Demo", grad); // Display results
waitKey(0);
```

----------------------------------------

TITLE: Loading and Displaying an Image using OpenCV in C++
DESCRIPTION: This C++ code demonstrates a basic OpenCV application. It includes the necessary OpenCV header, reads an image file specified by a command-line argument using `imread`, checks if the image data was loaded successfully, creates a window using `namedWindow`, displays the image using `imshow`, and waits for a key press using `waitKey` before exiting.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include <opencv2/opencv.hpp>

using namespace cv;

int main( int argc, char** argv )
{
  Mat image;
  image = imread( argv[1], IMREAD_COLOR );

  if( argc != 2 || !image.data )
    {
      printf( "No image data \n" );
      return -1;
    }

  namedWindow( "Display Image", WINDOW_AUTOSIZE );
  imshow( "Display Image", image );

  waitKey(0);

  return 0;
}
```

----------------------------------------

TITLE: Loading and Transforming Image in Python with OpenCV
DESCRIPTION: This Python code snippet utilizes OpenCV to load an image, derive an affine transformation matrix using point coordinates, apply the transformation, and then execute a rotation on the transformed image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
@snippet samples/python/tutorial_code/ImgTrans/warp_affine/Geometric_Transforms_Demo.py Load the image
```

----------------------------------------

TITLE: Implementing ORB Feature Matching with Brute-Force Matcher in Python
DESCRIPTION: Demonstrates feature matching between two images using ORB descriptors and Brute-Force matcher with NORM_HAMMING distance measurement. Includes image loading, keypoint detection, descriptor computation, and match visualization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_matcher/py_matcher.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt

img1 = cv.imread('box.png',cv.IMREAD_GRAYSCALE)          # queryImage
img2 = cv.imread('box_in_scene.png',cv.IMREAD_GRAYSCALE) # trainImage

# Initiate ORB detector
orb = cv.ORB_create()

# find the keypoints and descriptors with ORB
kp1, des1 = orb.detectAndCompute(img1,None)
kp2, des2 = orb.detectAndCompute(img2,None)
```

LANGUAGE: python
CODE:
```
# create BFMatcher object
bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)

# Match descriptors.
matches = bf.match(des1,des2)

# Sort them in the order of their distance.
matches = sorted(matches, key = lambda x:x.distance)

# Draw first 10 matches.
img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

plt.imshow(img3),plt.show()
```

----------------------------------------

TITLE: Using Smart Pointers with cv::Ptr in OpenCV C++
DESCRIPTION: This snippet shows how to use OpenCV's `cv::Ptr` template class, which is similar to std::shared_ptr, for automatic memory management of user-defined types. It demonstrates allocation and proper memory handling without using raw pointers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
    T* ptr = new T(...);
```

LANGUAGE: cpp
CODE:
```
    Ptr<T> ptr(new T(...));
```

LANGUAGE: cpp
CODE:
```
    Ptr<T> ptr = makePtr<T>(...);
```

----------------------------------------

TITLE: Loading Images in OpenCV for Histogram Equalization
DESCRIPTION: Code snippets for loading source images in C++, Java, and Python as the first step in the histogram equalization process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
CommandLineParser parser( argc, argv, keys );
String filename = parser.get<String>( 0 );

Mat src = imread( samples::findFile( filename ), IMREAD_COLOR );
if (src.empty()) {
    cout << "Cannot read image: " << filename << std::endl;
    return EXIT_FAILURE;
}
```

LANGUAGE: Java
CODE:
```
String filename = args.length > 0 ? args[0] : "../data/lena.jpg";
Mat src = imread(filename, IMREAD_COLOR);
if (src.empty()) {
    System.err.println("Cannot read image: " + filename);
    System.exit(0);
}
```

LANGUAGE: Python
CODE:
```
parser = argparse.ArgumentParser(description='Code for Histogram Equalization tutorial.')
parser.add_argument('--input', help='Path to input image.', default='lena.jpg')
args = parser.parse_args()

src = cv.imread(cv.samples.findFile(args.input))
if src is None:
    print('Could not open or find the image:', args.input)
    exit(0)
```

----------------------------------------

TITLE: Robust Descriptor Matching with Ratio Test in C++
DESCRIPTION: Performs robust matching between model and scene descriptors using either robustMatch or fastRobustMatch. The method depends on computational cost; robustMatch offers higher accuracy through extra tests.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
// -- Step 1: Robust matching between model descriptors and scene descriptors

std::vector<cv::DMatch> good_matches;       // to obtain the model 3D points  in the scene
std::vector<cv::KeyPoint> keypoints_scene;  // to obtain the 2D points of the scene

if(fast_match)
{
    rmatcher.fastRobustMatch(frame, good_matches, keypoints_scene, descriptors_model);
}
else
{
    rmatcher.robustMatch(frame, good_matches, keypoints_scene, descriptors_model);
}
```

----------------------------------------

TITLE: Including Full Template Matching Demo Code (C++)
DESCRIPTION: Reference to include the complete C++ source code file for the OpenCV template matching demonstration. This code loads images, performs matching, normalizes results, finds the best match, and displays the output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
@include samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp
```

----------------------------------------

TITLE: Calculating Histograms for Histogram Backprojection in Python OpenCV
DESCRIPTION: This code demonstrates the first step in histogram backprojection by loading the target and reference images, converting them to HSV color space, and calculating their histograms using OpenCV's calcHist function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_backprojection/py_histogram_backprojection.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cvfrom matplotlib import pyplot as plt

#roi is the object or region of object we need to find
roi = cv.imread('rose_red.png')
assert roi is not None, "file could not be read, check with os.path.exists()"
hsv = cv.cvtColor(roi,cv.COLOR_BGR2HSV)

#target is the image we search in
target = cv.imread('rose.png')
assert target is not None, "file could not be read, check with os.path.exists()"
hsvt = cv.cvtColor(target,cv.COLOR_BGR2HSV)

# Find the histograms using calcHist. Can be done with np.histogram2d also
M = cv.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )
I = cv.calcHist([hsvt],[0, 1], None, [180, 256], [0, 180, 0, 256] )
```

----------------------------------------

TITLE: Detecting Keypoints with AKAZE in OpenCV using C++
DESCRIPTION: This C++ snippet creates an AKAZE object to detect keypoints and compute descriptors for the loaded images, with OpenCV functionality.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
samples/cpp/tutorial_code/features2D/AKAZE_match.cpp AKAZE
```

----------------------------------------

TITLE: Applying Watershed Algorithm in OpenCV
DESCRIPTION: Applies the watershed algorithm to the image using prepared markers and highlights segment boundaries in blue.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_watershed/py_watershed.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
markers = cv.watershed(img,markers)
img[markers == -1] = [255,0,0]
```

----------------------------------------

TITLE: Calculating Wiener Filter in Frequency Domain with OpenCV C++
DESCRIPTION: Computes the Wiener filter `Hw` in the frequency domain based on the provided Point Spread Function `input_h` and the Signal-to-Noise Ratio (SNR). It first computes the Discrete Fourier Transform (DFT) of the PSF, then calculates the filter using the formula `Hw = H* / (|H|^2 + 1/SNR)`, where `H` is the DFT of the PSF and `H*` is its complex conjugate. The result `output_G` is the Wiener filter in the frequency domain. Requires OpenCV `dft`, `mulSpectrums`, `Mat` operations, and complex number handling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/out_of_focus_deblur_filter/out_of_focus_deblur_filter.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
void calcWnrFilter(const Mat& input_h_PSF, Mat& output_G, double nsr)
{
    Mat h_PSF_shifted;
    fftshift(input_h_PSF, h_PSF_shifted);
    Mat planes[2] = { Mat_<float>(h_PSF_shifted.clone()), Mat::zeros(h_PSF_shifted.size(), CV_32F) };
    Mat complexI;
    merge(planes, 2, complexI);
    dft(complexI, complexI);
    split(complexI, planes);
    Mat denom;
    pow(abs(planes[0]), 2, denom);
    denom += nsr;
    divide(planes[0], denom, output_G);
}
```

----------------------------------------

TITLE: Corner Detection Pixel Comparison Logic in C++
DESCRIPTION: Complex nested if-else structure that compares pixel values at different offsets to determine if a point is a corner. Uses pointer arithmetic for pixel access and goto statements for control flow. The code compares pixel intensities against threshold values 'cb' and 'c_b' to classify corners.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_32

LANGUAGE: C++
CODE:
```
if(ptr[offset6] > cb)
  if(ptr[offset3] > cb)
    if(ptr[offset4] > cb)
      if(ptr[offset8] > cb)
        goto is_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    goto is_not_a_corner;
  else
    if(ptr[offset6] > cb)
      if(ptr[offset3] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset8] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset2] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset9] > cb)
        if(ptr[offset1] > cb)
          goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset6] > cb)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset10] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
```

----------------------------------------

TITLE: Calculating PSNR on CPU in C++
DESCRIPTION: Defines a C++ function `getPSNR` that calculates the Peak Signal-to-Noise Ratio (PSNR) between two input images (`I1`, `I2`) using CPU-based OpenCV functions. It computes the squared error between the images and then derives the PSNR value. Assumes `psnr` function is defined elsewhere.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
//![getpsnr]
double getPSNR(const Mat& I1, const Mat& I2)
{
    return psnr(I1, I2);
}
//![getpsnr]
```

----------------------------------------

TITLE: Implementing Camshift in OpenCV.js
DESCRIPTION: This snippet utilizes the cv.CamShift function to adaptively adjust the tracking window size based on the target's size and orientation when using OpenCV.js. Dependencies include the OpenCV.js library. Essential parameters include probImage (back projection of the histogram), window (initial search window), and criteria (stop criteria), resulting in the coordinates and dimensions of a rotated rectangle for tracking the object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_video/js_meanshift/js_meanshift.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
cv.CamShift(probImage, window, criteria);
```

----------------------------------------

TITLE: Otsu's Binarization Implementation in OpenCV Python
DESCRIPTION: Demonstrates Otsu's automatic thresholding method with noise handling. Compares global thresholding, direct Otsu's thresholding, and Otsu's thresholding with Gaussian filtering.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

img = cv.imread('noisy2.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"

# global thresholding
ret1,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)

# Otsu's thresholding
ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)

# Otsu's thresholding after Gaussian filtering
blur = cv.GaussianBlur(img,(5,5),0)
ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)

# plot all the images and their histograms
images = [img, 0, th1,
          img, 0, th2,
          blur, 0, th3]
titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',
          'Original Noisy Image','Histogram',"Otsu's Thresholding",
          'Gaussian filtered Image','Histogram',"Otsu's Thresholding"]

for i in range(3):
    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')
    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])
    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)
    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])
    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')
    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])
plt.show()
```

----------------------------------------

TITLE: Applying Median Blur with OpenCV in Python
DESCRIPTION: The Python snippet demonstrates using OpenCV's medianBlur() for applying a median filter on images. It requires OpenCV and parameters for source image and kernel size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/Smoothing/smoothing.py medianblur
```

----------------------------------------

TITLE: Initializing WebRTC Video Capture in JavaScript
DESCRIPTION: This snippet initializes video capture from the user's camera using WebRTC with JavaScript. It retrieves a media stream and sets it as the source for a video element. This is crucial for capturing live video feed to be processed or displayed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_video_display/js_video_display.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
let video = document.getElementById("videoInput"); // video is the id of video tag
navigator.mediaDevices.getUserMedia({ video: true, audio: false })
    .then(function(stream) {
        video.srcObject = stream;
        video.play();
    })
    .catch(function(err) {
        console.log("An error occurred! " + err);
    });
```

----------------------------------------

TITLE: Setting Up Histogram Parameters for HSV Image Comparison
DESCRIPTION: Configuring histogram parameters for hue and saturation channels, specifying 50 bins for hue and 60 for saturation with appropriate value ranges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
int h_bins = 50; int s_bins = 60;
int histSize[] = { h_bins, s_bins };
// hue varies from 0 to 179, saturation from 0 to 255
float h_ranges[] = { 0, 180 };
float s_ranges[] = { 0, 256 };
const float* ranges[] = { h_ranges, s_ranges };
// Use the o-th and 1-st channels
int channels[] = { 0, 1 };
```

LANGUAGE: java
CODE:
```
int[] histSize = { 50, 60 };
// hue varies from 0 to 179, saturation from 0 to 255
float[] ranges = { 0, 180, 0, 256 };
// Use the 0-th and 1-st channels
MatOfInt histChannels = new MatOfInt(0, 1);
MatOfInt histSize2 = new MatOfInt(histSize);
MatOfFloat histRanges = new MatOfFloat(ranges);
```

LANGUAGE: python
CODE:
```
h_bins = 50
s_bins = 60
histSize = [h_bins, s_bins]
# hue varies from 0 to 179, saturation from 0 to 255
h_ranges = [0, 180]
s_ranges = [0, 256]
ranges = h_ranges + s_ranges # concat lists
# Use the 0-th and 1-st channels
channels = [0, 1]
```

----------------------------------------

TITLE: Visualizing PCA Axis in Python using OpenCV
DESCRIPTION: Defines a function `drawAxis` that draws a line representing a principal component on the image. It calculates the angle and length, scales the axis endpoint `q` relative to the center `p`, and draws the line and arrowhead using `cv.line`. Requires OpenCV Python library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_11

LANGUAGE: python
CODE:
```
#! [visualization]
# Function to draw the axes of the object detected by PCA
def drawAxis(img, p_, q_, colour, scale):
    p = list(p_)
    q = list(q_)

    angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
    hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))

    # Here we lengthen the arrow by a factor of scale
    q[0] = p[0] - scale * hypotenuse * cos(angle)
    q[1] = p[1] - scale * hypotenuse * sin(angle)
    cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv.LINE_AA)

    # create the arrow hooks
    p[0] = q[0] + 9 * cos(angle + pi / 4)
    p[1] = q[1] + 9 * sin(angle + pi / 4)
    cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv.LINE_AA)

    p[0] = q[0] + 9 * cos(angle - pi / 4)
    p[1] = q[1] + 9 * sin(angle - pi / 4)
    cv.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv.LINE_AA)
#! [visualization]
```

----------------------------------------

TITLE: Filling GpuMat with Random Numbers using Thrust
DESCRIPTION: Demonstrates how to fill a GpuMat with random values between 0 and 10 using a Thrust transform operation with a custom random number generator.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_4

LANGUAGE: CUDA
CODE:
```
cv::cuda::GpuMat d_random(512, 512, CV_32FC1);
thrust::device_ptr<float> d_random_ptr((float*)d_random.data);
thrust::transform(
    thrust::counting_iterator<int>(0),
    thrust::counting_iterator<int>(d_random.rows * d_random.cols),
    d_random_ptr,
    prg(0, 10)
);
```

----------------------------------------

TITLE: General CMake Command Format for Flags (Shell)
DESCRIPTION: Illustrates the general syntax for passing configuration flags to CMake. Each flag must be preceded by `-D`, and multiple flags can be specified. The '..' typically points to the parent directory containing the main CMakeLists.txt file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_9

LANGUAGE: sh
CODE:
```
cmake [-D <flag>] [-D <flag>] ..
```

----------------------------------------

TITLE: Creating Image for Histogram Display in C++
DESCRIPTION: C++ snippet creating a blank image (`histImage`) to visualize the calculated histograms. It defines dimensions (`hist_w`, `hist_h`) and initializes a 3-channel (BGR) Mat filled with zeros (black background). A scaling factor (`bin_w`) is calculated to fit the histogram bins horizontally.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_21

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Draw the histograms for B, G and R
```

----------------------------------------

TITLE: Including G-API Fluid Backend Headers in C++
DESCRIPTION: This code snippet demonstrates how to include necessary headers for using the G-API Fluid backend in a C++ application, which are essential for leveraging the memory optimization features of the Fluid backend.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/porting_anisotropic_image_segmentation/porting_anisotropic_image_segmentation_gapi_fluid.cpp fluid_includes
```

----------------------------------------

TITLE: Implementing OCR for Alphabet using kNN in OpenCV
DESCRIPTION: This Python code provides a method to apply kNN for OCR on English alphabets using a letter-recognition dataset. Training and test data are generated from features provided in the data file. The script initiates a kNN classifier to predict alphabet letters and obtains a 93.22% accuracy rate. Dependencies include OpenCV and NumPy. Inputs are the letter-recognition.data file, and outputs are label predictions and accuracy measures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_knn/py_knn_opencv/py_knn_opencv.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np

# Load the data and convert the letters to numbers
data= np.loadtxt('letter-recognition.data', dtype= 'float32', delimiter = ',',
                    converters= {0: lambda ch: ord(ch)-ord('A')})

# Split the dataset in two, with 10000 samples each for training and test sets
train, test = np.vsplit(data,2)

# Split trainData and testData into features and responses
responses, trainData = np.hsplit(train,[1])
labels, testData = np.hsplit(test,[1])

# Initiate the kNN, classify, measure accuracy
knn = cv.ml.KNearest_create()
knn.train(trainData, cv.ml.ROW_SAMPLE, responses)
ret, result, neighbours, dist = knn.findNearest(testData, k=5)

correct = np.count_nonzero(result == labels)
accuracy = correct*100.0/10000
print( accuracy )
```

----------------------------------------

TITLE: Finding Convexity Defects in OpenCV Python
DESCRIPTION: Demonstrates how to find and visualize convexity defects in contours using cv.convexityDefects(). The code loads an image, finds contours, and draws lines between convex hull points with circles at defect points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_more_functions/py_contours_more_functions.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
hull = cv.convexHull(cnt,returnPoints = False)
defects = cv.convexityDefects(cnt,hull)
```

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np

img = cv.imread('star.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"
img_gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)
ret,thresh = cv.threshold(img_gray, 127, 255,0)
contours,hierarchy = cv.findContours(thresh,2,1)
cnt = contours[0]

hull = cv.convexHull(cnt,returnPoints = False)
defects = cv.convexityDefects(cnt,hull)

for i in range(defects.shape[0]):
    s,e,f,d = defects[i,0]
    start = tuple(cnt[s][0])
    end = tuple(cnt[e][0])
    far = tuple(cnt[f][0])
    cv.line(img,start,end,[0,255,0],2)
    cv.circle(img,far,5,[0,0,255],-1)

cv.imshow('img',img)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Retrieving Video Properties with VideoCapture::get in C++
DESCRIPTION: Explains how to retrieve video properties like frame width, height, and total frame count using the `get()` method of `cv::VideoCapture`. It takes a property identifier constant (e.g., `CAP_PROP_FRAME_WIDTH`, `CAP_PROP_FRAME_HEIGHT`, `CAP_PROP_FRAME_COUNT`) and returns a double value. This value often needs to be cast to an integer (`int`) for properties like dimensions or counts. Requires `<iostream>`, `<opencv2/core.hpp>`, and `<opencv2/videoio.hpp>` headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
Size refS = Size((int) captRefrnc.get(CAP_PROP_FRAME_WIDTH),
                 (int) captRefrnc.get(CAP_PROP_FRAME_HEIGHT)),

cout << "Reference frame resolution: Width=" << refS.width << "  Height=" << refS.height
     << " of nr#: " << captRefrnc.get(CAP_PROP_FRAME_COUNT) << endl;
```

----------------------------------------

TITLE: Extracting and Displaying SVM Support Vectors - C++
DESCRIPTION: This C++ snippet retrieves SVM support vectors using OpenCV's cv::ml::SVM::getSupportVectors method and highlights them visually on the plot. The code requires previously trained SVM objects and uses OpenCV C++ libraries. Key parameters include the SVM model and training data. Inputs are the trained model and the display image; outputs are visual markers (e.g., gray rings) around support vectors, distinguishing them from other training points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
// Extracting and displaying support vectors in C++
// ... (full code from samples/cpp/tutorial_code/ml/introduction_to_svm/introduction_to_svm.cpp, show_vectors)
```

----------------------------------------

TITLE: Detecting Horizontal Lines using Morphology in OpenCV (C++/Java/Python)
DESCRIPTION: Detects horizontal lines in the binary image. First, a horizontal structuring element (kernel) is created using `getStructuringElement` with `MORPH_RECT`. The size is chosen based on the expected line width. Then, erosion followed by dilation (morphological opening) is applied using this kernel to isolate horizontal structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
//![horiz]
// Specify size on horizontal axis
int horizontal_size = horizontal.cols / 30;

// Create structure element for extracting horizontal lines through morphology operations
Mat horizontalStructure = getStructuringElement(MORPH_RECT, Size(horizontal_size, 1));

// Apply morphology operations
erode(horizontal, horizontal, horizontalStructure, Point(-1, -1));
dilate(horizontal, horizontal, horizontalStructure, Point(-1, -1));

// Show extracted horizontal lines
show_wait_destroy("horizontal", horizontal);
//![horiz]
```

LANGUAGE: java
CODE:
```
//![horiz]
// Specify size on horizontal axis
int horizontal_size = horizontal.cols() / 30;

// Create structure element for extracting horizontal lines through morphology operations
Mat horizontalStructure = Imgproc.getStructuringElement(Imgproc.MORPH_RECT, new Size(horizontal_size, 1));

// Apply morphology operations
Imgproc.erode(horizontal, horizontal, horizontalStructure, new Point(-1, -1));
Imgproc.dilate(horizontal, horizontal, horizontalStructure, new Point(-1, -1));

// Show extracted horizontal lines
showWaitDestroy("horizontal", horizontal);
//![horiz]
```

LANGUAGE: python
CODE:
```
#![horiz]
# Specify size on horizontal axis
cols = horizontal.shape[1]
horizontal_size = cols // 30

# Create structure element for extracting horizontal lines through morphology operations
horizontalStructure = cv.getStructuringElement(cv.MORPH_RECT, (horizontal_size, 1))

# Apply morphology operations
horizontal = cv.erode(horizontal, horizontalStructure)
horizontal = cv.dilate(horizontal, horizontalStructure)

# Show extracted horizontal lines
show_wait_destroy("horizontal", horizontal)
#![horiz]
```

----------------------------------------

TITLE: Reading Video Frames with OpenCV VideoCapture in C++
DESCRIPTION: Demonstrates reading individual frames from `cv::VideoCapture` objects into `cv::Mat` objects. It shows two equivalent methods: using the overloaded `>>` operator and the `read()` method. Each call attempts to grab and decode the next sequential frame from the respective video source. Requires `<opencv2/core.hpp>` and `<opencv2/videoio.hpp>` headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
Mat frameReference, frameUnderTest;
captRefrnc >> frameReference;
captUndTst.read(frameUnderTest);
```

----------------------------------------

TITLE: Capturing Video Input in OpenCV
DESCRIPTION: Opens a video file or camera feed using VideoCapture. This allows reading frames sequentially from the input source for background subtraction processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/background_subtraction.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
VideoCapture capture;
if (parser.has("input"))
    capture.open(samples::findFileOrKeep(parser.get<String>("input")));
else
    capture.open(parser.get<int>("camera"));
```

LANGUAGE: Java
CODE:
```
VideoCapture capture = new VideoCapture();
if (inputFile.isBlank() == false) {
    capture.open(inputFile);
}
else {
    capture.open(cameraDevice);
}
```

LANGUAGE: Python
CODE:
```
# create a video capture object
cap = cv.VideoCapture(cv.samples.findFileOrKeep(args.input) if args.input else args.camera)
```

----------------------------------------

TITLE: Implementing Lucas-Kanade Optical Flow Tracking in Java
DESCRIPTION: Java implementation of tracking feature points in a video using the Lucas-Kanade optical flow method. The code detects Shi-Tomasi corner points in the first frame and tracks them through subsequent frames using calcOpticalFlowPyrLK().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/optical_flow.markdown#2025-04-22_snippet_2

LANGUAGE: java
CODE:
```
import java.util.ArrayList;
import java.util.List;
import java.util.Random;

import org.opencv.core.Core;
import org.opencv.core.CvType;
import org.opencv.core.Mat;
import org.opencv.core.MatOfByte;
import org.opencv.core.MatOfFloat;
import org.opencv.core.MatOfPoint;
import org.opencv.core.MatOfPoint2f;
import org.opencv.core.Point;
import org.opencv.core.Scalar;
import org.opencv.core.Size;
import org.opencv.core.TermCriteria;
import org.opencv.highgui.HighGui;
import org.opencv.imgproc.Imgproc;
import org.opencv.video.Video;
import org.opencv.videoio.VideoCapture;

class OpticalFlow {
    public void run(String[] args) {
        String filename = args[0];
        VideoCapture capture = new VideoCapture(filename);
        if (!capture.isOpened()) {
            System.out.println("Could not open the input video: " + filename);
            System.exit(0);
        }

        // Create some random colors
        Scalar[] colors = new Scalar[100];
        Random rng = new Random();
        for (int i = 0; i < 100; i++) {
            int r = rng.nextInt(256);
            int g = rng.nextInt(256);
            int b = rng.nextInt(256);
            colors[i] = new Scalar(r, g, b);
        }

        // Take first frame and find corners in it
        Mat old_frame = new Mat();
        capture.read(old_frame);
        Mat old_gray = new Mat();
        Imgproc.cvtColor(old_frame, old_gray, Imgproc.COLOR_BGR2GRAY);
        MatOfPoint p0 = new MatOfPoint();
        Imgproc.goodFeaturesToTrack(old_gray, p0, 100, 0.3, 7, new Mat(), 7, false, 0.04);

        // Create a mask image for drawing purposes
        Mat mask = Mat.zeros(old_frame.size(), old_frame.type());

        while (true) {
            Mat frame = new Mat();
            capture.read(frame);
            if (frame.empty()) {
                break;
            }
            Mat frame_gray = new Mat();
            Imgproc.cvtColor(frame, frame_gray, Imgproc.COLOR_BGR2GRAY);

            // calculate optical flow
            MatOfPoint2f p1 = new MatOfPoint2f();
            MatOfByte status = new MatOfByte();
            MatOfFloat err = new MatOfFloat();
            MatOfPoint2f p0Copy = new MatOfPoint2f();
            p0.convertTo(p0Copy, CvType.CV_32FC2);
            TermCriteria criteria = new TermCriteria(TermCriteria.COUNT + TermCriteria.EPS, 10, 0.03);
            Video.calcOpticalFlowPyrLK(old_gray, frame_gray, p0Copy, p1, status, err, new Size(15, 15), 2, criteria, 0, 0.001);

            byte[] statusArr = status.toArray();
            Point[] p0CopyArr = p0Copy.toArray();
            Point[] p1Arr = p1.toArray();
            List<Point> good_new = new ArrayList<>();

            for (int i = 0; i < statusArr.length; i++) {
                if (statusArr[i] == 1) {
                    good_new.add(p1Arr[i]);
                    Imgproc.line(mask, p1Arr[i], p0CopyArr[i], colors[i], 2);
                    Imgproc.circle(frame, p1Arr[i], 5, colors[i], -1);
                }
            }

            Mat img = new Mat();
            Core.add(frame, mask, img);

            HighGui.imshow("Frame", img);
            int keyboard = HighGui.waitKey(30);
            if (keyboard == 'q' || keyboard == 27) {
                break;
            }

            // Now update the previous frame and previous points
            old_gray = frame_gray.clone();
            MatOfPoint2f good_newMat = new MatOfPoint2f();
            good_newMat.fromList(good_new);
            p0 = new MatOfPoint(good_newMat.toArray());
        }

        System.exit(0);
    }
}

public class OpticalFlowDemo {
    public static void main(String[] args) {
        // Load the native OpenCV library
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);

        new OpticalFlow().run(args);
    }
}
```

----------------------------------------

TITLE: Finding Min/Max Value and Locations using OpenCV.js
DESCRIPTION: Locates the minimum and maximum pixel values and their coordinates within a single-channel array (`src`), potentially restricted to a specific area defined by an optional `mask`. Uses the `cv.minMaxLoc` function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_properties/js_contour_properties.markdown#2025-04-22_snippet_5

LANGUAGE: javascript
CODE:
```
let result = cv.minMaxLoc(src, mask);
let minVal = result.minVal;
let maxVal = result.maxVal;
let minLoc = result.minLoc;
let maxLoc = result.maxLoc;
```

----------------------------------------

TITLE: Drawing Histogram Lines for Each Channel in Python
DESCRIPTION: Python snippet iterating through the histogram bins (from 1 to `histSize`) and drawing lines on `histImage` using `cv.line`. It draws lines connecting the points representing the normalized counts in adjacent bins (`i-1` and `i`) for each color channel (B, G, R) using blue, green, and red colors respectively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_29

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Draw for each channel
```

----------------------------------------

TITLE: Defining a Function for Fading Text Display with OpenCV in C++
DESCRIPTION: Defines the function `Displaying_Big_End` which displays the text "OpenCV forever!" centered on the screen with a fading effect. It first calculates the text size using `cv::getTextSize` to determine the center position (`org`). Inside a loop that iterates from 0 to 255, it subtracts a scalar value `i` from the original image (`image`) to create a progressively darker background (`image2`). The text is then drawn on `image2` with a color whose components also change with `i`, creating a fade-in/color-shift effect. The result is displayed in each loop iteration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
@code{.cpp}
int Displaying_Big_End( Mat image, char* window_name, RNG rng )
{
  Size textsize = getTextSize("OpenCV forever!", FONT_HERSHEY_COMPLEX, 3, 5, 0);
  Point org((window_width - textsize.width)/2, (window_height - textsize.height)/2);
  int lineType = 8;

  Mat image2;

  for( int i = 0; i < 255; i += 2 )
  {
    image2 = image - Scalar::all(i);
    putText( image2, "OpenCV forever!", org, FONT_HERSHEY_COMPLEX, 3,
           Scalar(i, i, 255), 5, lineType );

    imshow( window_name, image2 );
    if( waitKey(DELAY) >= 0 )
      { return -1; }
  }

  return 0;
}
@endcode
```

----------------------------------------

TITLE: Implementing SURF Feature Detection and Homography Matching in C++
DESCRIPTION: This C++ code demonstrates how to use SURF features and FLANN matching to detect a known object in an image. It uses cv::findHomography to estimate the transformation and cv::perspectiveTransform to map points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_homography/feature_homography.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <iostream>\n#include <opencv2/core.hpp>\n#include <opencv2/imgproc.hpp>\n#include <opencv2/highgui.hpp>\n#include <opencv2/features2d.hpp>\n#include <opencv2/xfeatures2d.hpp>\n#include <opencv2/calib3d.hpp>\n\nusing namespace cv;\nusing namespace cv::xfeatures2d;\n\nvoid readme();\n\n/** @function main */\nint main( int argc, char** argv )\n{\n    if( argc != 3 )\n    {\n        readme(); return -1;\n    }\n\n    Mat img_object = imread( argv[1], IMREAD_GRAYSCALE );\n    Mat img_scene = imread( argv[2], IMREAD_GRAYSCALE );\n\n    if( !img_object.data || !img_scene.data )\n    {\n        std::cout<< " --(!) Error reading images " << std::endl; return -1;\n    }\n\n    //-- Step 1: Detect the keypoints and extract descriptors using SURF\n    int minHessian = 400;\n\n    Ptr<SURF> detector = SURF::create( minHessian );\n\n    std::vector<KeyPoint> keypoints_object, keypoints_scene;\n    Mat descriptors_object, descriptors_scene;\n\n    detector->detectAndCompute( img_object, Mat(), keypoints_object, descriptors_object );\n    detector->detectAndCompute( img_scene, Mat(), keypoints_scene, descriptors_scene );\n\n    //-- Step 2: Matching descriptor vectors using FLANN matcher\n    FlannBasedMatcher matcher;\n    std::vector< DMatch > matches;\n    matcher.match( descriptors_object, descriptors_scene, matches );\n\n    double max_dist = 0; double min_dist = 100;\n\n    //-- Quick calculation of max and min distances between keypoints\n    for( int i = 0; i < descriptors_object.rows; i++ )\n    {\n        double dist = matches[i].distance;\n        if( dist < min_dist ) min_dist = dist;\n        if( dist > max_dist ) max_dist = dist;\n    }\n\n    printf("-- Max dist : %f \\n", max_dist );\n    printf("-- Min dist : %f \\n", min_dist );\n\n    //-- Draw only \"good\" matches (i.e. whose distance is less than 3*min_dist )\n    std::vector< DMatch > good_matches;\n\n    for( int i = 0; i < descriptors_object.rows; i++ )\n    {\n        if( matches[i].distance < 3*min_dist )\n        {\n            good_matches.push_back( matches[i]);\n        }\n    }\n\n    Mat img_matches;\n    drawMatches( img_object, keypoints_object, img_scene, keypoints_scene,\n                good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),\n                std::vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS );\n\n    //-- Localize the object\n    std::vector<Point2f> obj;\n    std::vector<Point2f> scene;\n\n    for( size_t i = 0; i < good_matches.size(); i++ )\n    {\n        //-- Get the keypoints from the good matches\n        obj.push_back( keypoints_object[ good_matches[i].queryIdx ].pt );\n        scene.push_back( keypoints_scene[ good_matches[i].trainIdx ].pt );\n    }\n\n    Mat H = findHomography( obj, scene, RANSAC );\n\n    //-- Get the corners from the image_1 ( the object to be \"detected\" )\n    std::vector<Point2f> obj_corners(4);\n    obj_corners[0] = Point2f(0,0);\n    obj_corners[1] = Point2f( (float)img_object.cols, 0 );\n    obj_corners[2] = Point2f( (float)img_object.cols, (float)img_object.rows );\n    obj_corners[3] = Point2f( 0, (float)img_object.rows );\n    std::vector<Point2f> scene_corners(4);\n\n    perspectiveTransform( obj_corners, scene_corners, H);\n\n    //-- Draw lines between the corners (the mapped object in the scene - image_2 )\n    line( img_matches, scene_corners[0] + Point2f( (float)img_object.cols, 0),\n          scene_corners[1] + Point2f( (float)img_object.cols, 0), Scalar(0, 255, 0), 4 );\n    line( img_matches, scene_corners[1] + Point2f( (float)img_object.cols, 0),\n          scene_corners[2] + Point2f( (float)img_object.cols, 0), Scalar( 0, 255, 0), 4 );\n    line( img_matches, scene_corners[2] + Point2f( (float)img_object.cols, 0),\n          scene_corners[3] + Point2f( (float)img_object.cols, 0), Scalar( 0, 255, 0), 4 );\n    line( img_matches, scene_corners[3] + Point2f( (float)img_object.cols, 0),\n          scene_corners[0] + Point2f( (float)img_object.cols, 0), Scalar( 0, 255, 0), 4 );\n\n    //-- Show detected matches\n    imshow( \"Good Matches & Object detection\", img_matches );\n\n    waitKey(0);\n    return 0;\n}\n\n/** @function readme */\nvoid readme()\n{\n    std::cout << \" Usage: ./SURF_FLANN_matching_homography <img1> <img2>\" << std::endl;\n}
```

----------------------------------------

TITLE: Custom Cropping Layer OpenCV Python
DESCRIPTION: Python example showing how to define a custom cropping layer by overriding \'getMemoryShapes\' and \'forward\' methods in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
@snippet dnn/edge_detection.py CropLayer
```

----------------------------------------

TITLE: Executing OpenCV.js Build Script with Emscripten
DESCRIPTION: This shell command executes the Python build script (`build_js.py`) located in the OpenCV source directory (`<opencv_src_dir>/platforms/js/`) using `emcmake`. `emcmake` is an Emscripten tool that wraps CMake to configure the build environment correctly for cross-compiling to JavaScript/WebAssembly. The build output, including the `opencv.js` file, will be placed in the specified `<build_dir>`. Prerequisites include having Emscripten installed and accessible in the system's PATH, and having the OpenCV source code available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/js/README.md#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
emcmake python <opencv_src_dir>/platforms/js/build_js.py <build_dir>
```

----------------------------------------

TITLE: Declaring Global Variables for Template Matching (Python)
DESCRIPTION: Declares global variables used in the Python template matching demo script, including placeholders for the input image, template image, and the selected matching method. Window names are also defined.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_12

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py global_variables
```

----------------------------------------

TITLE: Calculating Back Projection with OpenCV in Python
DESCRIPTION: The Python sample achieves the same tasks: image loading, HSV conversion, Hue extraction, dynamic bin selection via GUI trackbar, and calculation of histogram/back projection using OpenCV Python. It depends on the OpenCV Python package (cv2), requiring the user to supply an input image. Results are shown in cv2 windows. The main parameter is the histogram bins, adjusted via a trackbar. core OpenCV calls include cv2.cvtColor, cv2.calcHist, and cv2.calcBackProject; channel extraction uses cv2.split.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
# Load input image\nimport cv2\nimport numpy as np\nsrc = cv2.imread(filename)\nif src is None:\n    print('Could not open or find the image!')\n    exit()\n
```

LANGUAGE: Python
CODE:
```
# Convert to HSV\nhsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n
```

LANGUAGE: Python
CODE:
```
# Use only the Hue value\nhue = cv2.split(hsv)[0]\n
```

LANGUAGE: Python
CODE:
```
# Create a trackbar for bins\nbins = 30\ndef Hist_and_Backproj(val):\n    # histogram logic here\n    pass\ncv2.createTrackbar('Histogram Bins', 'Source image', bins, 180, Hist_and_Backproj)\n
```

LANGUAGE: Python
CODE:
```
# Show image and wait\ncv2.imshow('Source image', src)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n
```

LANGUAGE: Python
CODE:
```
# Initialize for histogram\ndef Hist_and_Backproj(val):\n    histSize = max(cv2.getTrackbarPos('Histogram Bins', 'Source image'), 2)\n    hue_range = [0, 180]\n    # hist/backproj here\n
```

LANGUAGE: Python
CODE:
```
# Calculate histogram and normalize\nhist = cv2.calcHist([hue], [0], None, [histSize], [0, 180])\ncv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX)\n
```

LANGUAGE: Python
CODE:
```
# Backprojection\nbackproj = cv2.calcBackProject([hue], [0], hist, [0,180], 1)\n
```

----------------------------------------

TITLE: Creating an HTML Input Range Trackbar with JavaScript
DESCRIPTION: This snippet shows how to create an HTML <input type=\"range\"> element programmatically using JavaScript. The created element can be used as a trackbar/slider for user input. No external dependencies except the browser's DOM API. The resulting 'x' variable holds the range input element, which can be attached to the DOM as needed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_trackbar/js_trackbar.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
let x = document.createElement('INPUT');
x.setAttribute('type', 'range');
```

----------------------------------------

TITLE: Ratio Test Filtering in OpenCV using Python
DESCRIPTION: In Python, this snippet implements a ratio test on matched keypoints to filter incorrect matches, enhancing the matching process in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py ratio test filtering
```

----------------------------------------

TITLE: Displaying Results and Drawing Rectangle (Python)
DESCRIPTION: Uses `cv2.rectangle` to draw a rectangle on the display image (`img_display`) marking the best match location. The rectangle spans from `matchLoc` (top-left) to `matchLoc` offset by the template's width and height (bottom-right). The result matrix and the image with the rectangle are shown using `cv2.imshow`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_36

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py imshow
```

----------------------------------------

TITLE: Parallelizing Mandelbrot Generation Using cv::ParallelLoopBody - C++
DESCRIPTION: This snippet defines a custom functor inheriting from cv::ParallelLoopBody and overrides the operator() to update the image Mat in parallel, assigning the respective Mandelbrot value per pixel. Requires OpenCV with parallel support and a previously defined grayscale and Mandelbrot iteration routine. Accepts the range of pixels and a reference to the image; designed for thread-safe, parallel execution by OpenCV's parallel_for_.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
// Parallel Mandelbrot implementation using ParallelLoopBody
class ParallelMandelbrot : public cv::ParallelLoopBody
{
    cv::Mat& image;
    int maxIter;
public:
    ParallelMandelbrot(cv::Mat& img, int maxI) : image(img), maxIter(maxI) {}
    virtual void operator()(const cv::Range& range) const override
    {
        for (int r = range.start; r < range.end; ++r)
        {
            int row = r / image.cols;
            int col = r % image.cols;
            double x0 = (col / (double)image.cols) * 3.0 - 2.0;
            double y0 = (row / (double)image.rows) * 2.0 - 1.0;
            int iter = mandelbrot(cv::Point2d(x0, y0), maxIter);
            image.at<uchar>(row, col) = grayscaleValue(iter, maxIter);
        }
    }
};

```

----------------------------------------

TITLE: Setting Uniform and Accumulate Flags in C++
DESCRIPTION: C++ snippet setting boolean flags for histogram calculation. `uniform` is set to true, indicating that histogram bins have equal sizes. `accumulate` is set to false, meaning the histogram is cleared before calculation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_15

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Set histogram param
```

----------------------------------------

TITLE: Configuring Pose Estimation Parameters in C++ (OpenCV)
DESCRIPTION: This C++ snippet lists example variable declarations and initial values for key parameters used in the pose estimation algorithm. It includes settings for a robust feature matcher (`numKeyPoints`, `ratio`, `fast_match`), RANSAC (`iterationsCount`, `reprojectionError`, `confidence`), and the threshold for updating the Kalman Filter (`minInliersKalman`). These parameters control the behavior and performance of feature matching, robust pose estimation (PnP with RANSAC), and the Kalman filtering stage.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_29

LANGUAGE: cpp
CODE:
```
// Robust Matcher parameters

int numKeyPoints = 2000;      // number of detected keypoints
float ratio = 0.70f;          // ratio test
bool fast_match = true;       // fastRobustMatch() or robustMatch()


// RANSAC parameters

int iterationsCount = 500;    // number of Ransac iterations.
int reprojectionError = 2.0;  // maximum allowed distance to consider it an inlier.
float confidence = 0.95;      // ransac successful confidence.


// Kalman Filter parameters

int minInliersKalman = 30;    // Kalman threshold updating
```

----------------------------------------

TITLE: Predicting with SVM in OpenCV C++
DESCRIPTION: This snippet demonstrates how to use the StatModel::predict method to get raw output from an SVM model for regression, 1-class, or 2-class classification problems.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ml/doc/ml_intro.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
StatModel::predict(samples, results, flags=StatModel::RAW_OUTPUT)
```

----------------------------------------

TITLE: Applying K-Means Clustering to One-Dimensional Data in OpenCV
DESCRIPTION: This code defines termination criteria and applies the K-means algorithm to the one-dimensional data. The criteria stops after 10 iterations or when accuracy reaches 1.0. The algorithm is applied with 2 clusters and random initial centers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
# Define criteria = ( type, max_iter = 10 , epsilon = 1.0 )
criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)

# Set flags (Just to avoid line break in the code)
flags = cv.KMEANS_RANDOM_CENTERS

# Apply KMeans
compactness,labels,centers = cv.kmeans(z,2,None,criteria,10,flags)
```

----------------------------------------

TITLE: Importing Libraries and Loading an Image using OpenCV in Python
DESCRIPTION: Imports the necessary libraries (NumPy as np, OpenCV as cv) and loads an image ('messi5.jpg') using `cv.imread()`. Includes an assertion to ensure the image was loaded successfully, preventing errors if the file path is incorrect or the file doesn't exist.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
>>> import numpy as np
>>> import cv2 as cv

>>> img = cv.imread('messi5.jpg')
>>> assert img is not None, "file could not be read, check with os.path.exists()"
```

----------------------------------------

TITLE: Performing Dilation with OpenCV in Java
DESCRIPTION: This Java snippet demonstrates the process of applying morphological dilation to an image using OpenCV. Users can specify the kernel (structuring element), its size, and the anchor point for the operation. Interactive controls (trackbars/windows) allow adjusting these parameters in real-time, enabling dynamic visualization of the dilation effect. Dependencies: OpenCV Java bindings. Input: Source image; Output: Dilated image; Limitations: Only basic dilation, without advanced parameters like iterations or border handling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_4

LANGUAGE: Java
CODE:
```
@snippet java/tutorial_code/ImgProc/erosion_dilatation/MorphologyDemo1.java dilation
```

----------------------------------------

TITLE: Configuring OpenCV Build with CMake for Make
DESCRIPTION: Command to configure OpenCV build using CMake, generating Makefiles.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_12

LANGUAGE: bash
CODE:
```
cmake ../opencv
```

----------------------------------------

TITLE: Implementing Face Detection Logic in Java using OpenCV
DESCRIPTION: Java code for a simple face detection application. It loads the OpenCV native library, initializes a CascadeClassifier with the LBP cascade file, reads an image (lena.png), performs face detection, draws rectangles around detected faces, and saves the resulting image as 'faceDetection.png'. The main method loads the necessary native library before running the detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_19

LANGUAGE: java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.MatOfRect;
import org.opencv.core.Point;
import org.opencv.core.Rect;
import org.opencv.core.Scalar;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;
import org.opencv.objdetect.CascadeClassifier;

//
// Detects faces in an image, draws boxes around them, and writes the results
// to "faceDetection.png".
//
class DetectFaceDemo {
  public void run() {
    System.out.println("\nRunning DetectFaceDemo");

    // Create a face detector from the cascade file in the resources
    // directory.
    CascadeClassifier faceDetector = new CascadeClassifier(getClass().getResource("/lbpcascade_frontalface.xml").getPath());
    Mat image = Imgcodecs.imread(getClass().getResource("/lena.png").getPath());

    // Detect faces in the image.
    // MatOfRect is a special container class for Rect.
    MatOfRect faceDetections = new MatOfRect();
    faceDetector.detectMultiScale(image, faceDetections);

    System.out.println(String.format("Detected %s faces", faceDetections.toArray().length));

    // Draw a bounding box around each face.
    for (Rect rect : faceDetections.toArray()) {
        Imgproc.rectangle(image, new Point(rect.x, rect.y), new Point(rect.x + rect.width, rect.y + rect.height), new Scalar(0, 255, 0));
    }

    // Save the visualized detection.
    String filename = "faceDetection.png";
    System.out.println(String.format("Writing %s", filename));
    Imgcodecs.imwrite(filename, image);
  }
}

public class HelloOpenCV {
  public static void main(String[] args) {
    System.out.println("Hello, OpenCV");

    // Load the native library.
    System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
    new DetectFaceDemo().run();
  }
}
```

----------------------------------------

TITLE: Adjusting SURF Descriptor Size in OpenCV Python
DESCRIPTION: This snippet demonstrates how to check and modify the SURF descriptor size from 64 to 128 dimensions. Extended descriptors provide more distinctiveness at the cost of increased computation time.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
# Find size of descriptor
>>> print( surf.descriptorSize() )
64

# That means flag, "extended" is False.
>>> surf.getExtended()
 False

# So we make it to True to get 128-dim descriptors.
>>> surf.setExtended(True)
>>> kp, des = surf.detectAndCompute(img,None)
>>> print( surf.descriptorSize() )
128
>>> print( des.shape )
(47, 128)
```

----------------------------------------

TITLE: Creating Custom Layer Instance OpenCV C++
DESCRIPTION: A static method \'create\' that creates an instance of the custom layer and returns a cv::Ptr.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp MyLayer::create
```

----------------------------------------

TITLE: Feature Matching with FLANN in Python
DESCRIPTION: This Python implementation demonstrates how to use the FlannBasedMatcher for efficient feature matching with SURF descriptors. It loads two images, detects and describes features, matches them using FLANN, and filters the matches using Lowe's distance ratio test.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_flann_matcher/feature_flann_matcher.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt

img1 = cv.imread(cv.samples.findFile('box.png'), cv.IMREAD_GRAYSCALE)          # queryImage
img2 = cv.imread(cv.samples.findFile('box_in_scene.png'), cv.IMREAD_GRAYSCALE) # trainImage

# Initiate SURF detector
surf = cv.xfeatures2d.SURF_create()

# Find keypoints and descriptors with SURF
kp1, des1 = surf.detectAndCompute(img1,None)
kp2, des2 = surf.detectAndCompute(img2,None)

# FLANN parameters
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks = 50)   # or pass empty dictionary
flann = cv.FlannBasedMatcher(index_params, search_params)
matches = flann.knnMatch(des1, des2, k=2)

# Need to draw only good matches, so create a mask
matchesMask = [[0,0] for i in range(len(matches))]

# Ratio test as per Lowe's paper
for i,(m,n) in enumerate(matches):
    if m.distance < 0.7*n.distance:
        matchesMask[i]=[1,0]

draw_params = dict(matchColor = (0,255,0),
                   singlePointColor = (255,0,0),
                   matchesMask = matchesMask,
                   flags = cv.DrawMatchesFlags_DEFAULT)
img3 = cv.drawMatchesKnn(img1, kp1, img2, kp2, matches, None, **draw_params)
plt.imshow(img3,), plt.show()
```

----------------------------------------

TITLE: Displaying an Image using OpenCV in C++
DESCRIPTION: This snippet demonstrates how to display an image in a window using OpenCV's cv::imshow in C++. It sets up a window with a title and displays the cv::Mat image until a key is pressed, as monitored by cv::waitKey.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
imshow("Display window", image);
waitKey(0);
```

----------------------------------------

TITLE: Drawing Detected Lines from Hough Transform in OpenCV (Python)
DESCRIPTION: This snippet iterates over returned (rho, theta) pairs from cv2.HoughLines and draws lines onto the output image in Python. It calculates endpoints for each line and uses cv2.line to visualize them. Expects lines as a numpy array. Requires cv2 and numpy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
if lines is not None:\n    for i in range(0, len(lines)):\n        rho = lines[i][0][0]\n        theta = lines[i][0][1]\n        a = np.cos(theta)\n        b = np.sin(theta)\n        x0 = a*rho\n        y0 = b*rho\n        x1 = int(x0 + 1000*(-b))\n        y1 = int(y0 + 1000*(a))\n        x2 = int(x0 - 1000*(-b))\n        y2 = int(y0 - 1000*(a))\n        cv2.line(img, (x1, y1), (x2, y2), (0,0,255), 3, cv2.LINE_AA)\n
```

----------------------------------------

TITLE: Performing Inference with PyTorch Model
DESCRIPTION: This Python snippet performs inference using the original PyTorch segmentation model (`original_net`). It first sets the model to evaluation mode using `original_net.eval()` to disable dropout and batch normalization updates. The preprocessed input image (`preproc_img`), likely a NumPy array, is converted to a PyTorch tensor. Inference is run within a `torch.no_grad()` context to disable gradient calculations, saving memory. The model's output, typically a dictionary for segmentation models from `torchvision`, is accessed using the key 'out'. The output shape is printed, and `argmax(dim=0)` is applied to the output tensor (after removing the batch dimension) to get the predicted class ID for each pixel. Requires the `torch` library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
original_net.eval()
preproc_img = torch.FloatTensor(preproc_img)

with torch.no_grad():
    # obtaining unnormalized probabilities for each class
    out = original_net(preproc_img)['out']

print("\nPyTorch segmentation model prediction: \n")
print("* shape: ", out.shape)

# get IDs of predicted classes
out_predictions = out[0].argmax(dim=0)
```

----------------------------------------

TITLE: Loading Source Image in C++
DESCRIPTION: C++ snippet demonstrating how to load an image from a file using OpenCV's `imread` function. The first command-line argument is expected to be the path to the image file. Includes error handling if the image cannot be loaded.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Load image
```

----------------------------------------

TITLE: Reducing Noise with Gaussian Blur in Java
DESCRIPTION: Applies a 3x3 Gaussian blur to the source image using Imgproc.GaussianBlur to reduce noise. The blurred image replaces the original source image. Requires OpenCV Java bindings (Imgproc).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_10

LANGUAGE: java
CODE:
```
//! [reduce_noise]
// Reduce noise by blurring with a Gaussian filter ( kernel size = 3 )
Imgproc.GaussianBlur( src, src, new Size(3, 3), 0, 0, Core.BORDER_DEFAULT );
//! [reduce_noise]
```

----------------------------------------

TITLE: Loading Images with OpenCV in C++
DESCRIPTION: This snippet shows how to load an image from disk using OpenCV in C++. It makes use of the cv::imread function and typically checks if the image was properly loaded. The primary parameter is the file path and optionally an image read mode; the output is an image matrix object. Requires OpenCV installed and included.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>\n\ncv::Mat src = cv::imread("path_to_image", cv::IMREAD_COLOR);\nif(src.empty()) {\n    std::cout << "Could not open or find the image!" << std::endl;\n    return -1;\n}\n
```

----------------------------------------

TITLE: Calculating SSIM for Image Similarity in OpenCV
DESCRIPTION: This function implements the Structural Similarity Index (SSIM) algorithm to compare image similarity. It breaks down the comparison into luminance, contrast, and structure components for better perceptual accuracy. The function returns a similarity index for each image channel, with values between 0 and 1.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
Scalar getMSSIM( const Mat& i1, const Mat& i2)
{
    const double C1 = 6.5025, C2 = 58.5225;
    /***************************** INITS **********************************/
    int d = CV_32F;

    Mat I1, I2;
    i1.convertTo(I1, d);            // cannot calculate on one byte large values
    i2.convertTo(I2, d);

    Mat I2_2   = I2.mul(I2);        // I2^2
    Mat I1_2   = I1.mul(I1);        // I1^2
    Mat I1_I2  = I1.mul(I2);        // I1 * I2

    /*************************** END INITS **********************************/

    Mat mu1, mu2;                   // PRELIMINARY COMPUTING
    GaussianBlur(I1, mu1, Size(11, 11), 1.5);
    GaussianBlur(I2, mu2, Size(11, 11), 1.5);

    Mat mu1_2   =   mu1.mul(mu1);
    Mat mu2_2   =   mu2.mul(mu2);
    Mat mu1_mu2 =   mu1.mul(mu2);

    Mat sigma1_2, sigma2_2, sigma12;

    GaussianBlur(I1_2, sigma1_2, Size(11, 11), 1.5);
    sigma1_2 -= mu1_2;

    GaussianBlur(I2_2, sigma2_2, Size(11, 11), 1.5);
    sigma2_2 -= mu2_2;

    GaussianBlur(I1_I2, sigma12, Size(11, 11), 1.5);
    sigma12 -= mu1_mu2;

    ///////////////////////////////// FORMULA ////////////////////////////////
    Mat t1, t2, t3;

    t1 = 2 * mu1_mu2 + C1;
    t2 = 2 * sigma12 + C2;
    t3 = t1.mul(t2);                 // t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))

    t1 = mu1_2 + mu2_2 + C1;
    t2 = sigma1_2 + sigma2_2 + C2;
    t1 = t1.mul(t2);                 // t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))

    Mat ssim_map;
    divide(t3, t1, ssim_map);        // ssim_map =  t3./t1;

    Scalar mssim = mean(ssim_map);   // mssim = average of ssim map
    return mssim;
}
```

----------------------------------------

TITLE: Applying Laplacian Operator Full Example in Python
DESCRIPTION: Complete Python code demonstrating loading an image using cv2.imread, applying Gaussian blur with cv2.GaussianBlur, converting to grayscale using cv2.cvtColor, applying the Laplacian operator with cv2.Laplacian, converting the result using cv2.convertScaleAbs, and displaying it with cv2.imshow. This code relies on the OpenCV Python bindings (cv2) and potentially NumPy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
# The tutorial code's is shown lines below. You can also download it from
# [here](https://raw.githubusercontent.com/opencv/opencv/4.x/samples/python/tutorial_code/ImgTrans/LaPlace/laplace_demo.py)
@include samples/python/tutorial_code/ImgTrans/LaPlace/laplace_demo.py
```

----------------------------------------

TITLE: Computing Bounding Rotated Boxes and Ellipses in Contours - OpenCV Python
DESCRIPTION: This Python code uses OpenCV to load a grayscale image, threshold it, find contours, and compute both the minimum area bounding rectangle and best-fit ellipse for each detected contour. The primary dependency is OpenCV (cv2). Input is typically a binary image file, and outputs include displayed images showing retangular and elliptical overlays corresponding to the detected contours. Key logic includes cv2.minAreaRect, cv2.boxPoints, cv2.ellipse, and handling of contours with more than five points for ellipse fitting.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rotated_ellipses/bounding_rotated_ellipses.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2\nimport numpy as np\n\nimg = cv2.imread('shapes.png', 0)\nret,thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\ncontours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\ncolor = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\nfor cnt in contours:\n    rect = cv2.minAreaRect(cnt)\n    box = cv2.boxPoints(rect)\n    box = np.int0(box)\n    cv2.drawContours(color,[box],0,(0,255,0),2)\n    if len(cnt) > 5:\n        ellipse = cv2.fitEllipse(cnt)\n        cv2.ellipse(color,ellipse,(255,0,0),2)\ncv2.imshow("Contours", color)\ncv2.waitKey(0)\ncv2.destroyAllWindows()
```

----------------------------------------

TITLE: Running TensorFlow Segmentation Model Inference
DESCRIPTION: Executes a TensorFlow segmentation model on a preprocessed image and prints the output shape. The model predicts PASCAL VOC class indices for each pixel in the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_6

LANGUAGE: python
CODE:
```
out = tf_session.run(
    output_tensor_name,
    feed_dict={input_tensor_name: [preproc_img]}
)

print("TF segmentation model prediction: \n")
print("* shape: ", out.shape)
```

----------------------------------------

TITLE: Trackbar for Lower HSV Range in C++
DESCRIPTION: Controls the lower HSV range for image thresholding in an OpenCV C++ application. Facilitates real-time adjustment of threshold parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
int low_h = 0;\ncv::createTrackbar("Low H", "Control", &low_h, 179);
```

----------------------------------------

TITLE: Command Line Parameters for ChArUco Calibration in OpenCV
DESCRIPTION: This code snippet shows the command line parameters for running the ChArUco calibration example. It includes parameters for the camera calibration output file, board dimensions, square and marker size, dictionary ID, and image path.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_calibration/aruco_calibration.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
"camera_calib.txt" -w=5 -h=7 -sl=0.04 -ml=0.02 -d=10
-v=path/img_%02d.jpg
```

----------------------------------------

TITLE: Setting an Image Channel to Zero using NumPy Indexing in Python
DESCRIPTION: Demonstrates how to efficiently set all pixel values of a specific channel (the Red channel, index 2) to zero using NumPy array slice assignment (`img[:, :, channel_index] = 0`). This avoids the need to split and merge channels, offering better performance.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_9

LANGUAGE: python
CODE:
```
>>> img[:,:,2] = 0
```

----------------------------------------

TITLE: Determining Best Class Output in C++
DESCRIPTION: This snippet illustrates extracting the predicted class by finding the maximum probability in the output blob's scores. It identifies the index with the highest value, corresponding to the best-guess class from the ILSVRC2012 dataset.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
@snippet dnn/classification.cpp Get a class with a highest score
```

----------------------------------------

TITLE: Complete ArUco Board Detection Implementation in C++
DESCRIPTION: A complete sample showing how to detect an ArUco board from an image or video stream. It includes marker detection, matching image points with the board, and pose estimation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_board_detection/aruco_board_detection.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
cv::Mat imageCopy;
image.copyTo(imageCopy);

cv::aruco::DetectorParameters detectorParams = cv::aruco::DetectorParameters();
cv::aruco::Dictionary dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);
cv::aruco::ArucoDetector detector(dictionary, detectorParams);

std::vector<int> markerIds;
std::vector<std::vector<cv::Point2f>> markerCorners, rejectedCandidates;
detector.detectMarkers(image, markerCorners, markerIds, rejectedCandidates);

// if at least one marker detected
if (markerIds.size() > 0) {
    cv::aruco::drawDetectedMarkers(imageCopy, markerCorners, markerIds);
    std::vector<cv::Point3f> objPoints;
    std::vector<cv::Point2f> imgPoints;
    cv::Mat cameraMatrix, distCoeffs;
    readCameraParameters(parser.get<std::string>("c"), cameraMatrix, distCoeffs);
    cv::Ptr<cv::aruco::Board> board;
    readDetectorParameters(parser.get<std::string>("cd"), board, dictionary);

    // calculate board pose
    int markersOfBoardDetected = 0;
    if (!cameraMatrix.empty()) {
        cv::Vec3d rvec, tvec;

        // call to Board::matchImagePoints requires that board is GridBoard
        cv::Ptr<cv::aruco::GridBoard> gridboard = board.dynamicCast<cv::aruco::GridBoard>();
        if (gridboard) {
            // match image points
            // markerCorners, markerIds -> imagePoints, objPoints
            markersOfBoardDetected = gridboard->matchImagePoints(markerCorners, markerIds, objPoints, imgPoints);
        }
        if(markersOfBoardDetected) {
            // find pose
            cv::solvePnP(objPoints, imgPoints, cameraMatrix, distCoeffs, rvec, tvec);

            // draw axis
            cv::drawFrameAxes(imageCopy, cameraMatrix, distCoeffs, rvec, tvec, 0.1);
        }
    }
}
```

----------------------------------------

TITLE: Edge Detection using Canny Detector in OpenCV (C++)
DESCRIPTION: This snippet applies the Canny edge detector to a grayscale image using OpenCV in C++. It uses cv::Canny with parameters for lower and upper thresholds. Inputs are the source image and threshold values; output is a binary edge-detected image. Requires prior loading and possibly grayscale conversion of the input image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
Mat src_gray, edges;\ncvtColor(src, src_gray, COLOR_BGR2GRAY);\nCanny(src_gray, edges, 50, 200, 3);\n
```

----------------------------------------

TITLE: Finding Chessboard Corners in OpenCV C++
DESCRIPTION: Code to detect chessboard corners in an image using OpenCV's findChessboardCorners function. It attempts to locate the corners of a 9x6 chessboard pattern in a grayscale image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
cv::Mat img = cv::imread(imagePath);
cv::Mat gray;
cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);

const cv::Size patternSize(9, 6);
std::vector<cv::Point2f> corners;
bool patternFound = cv::findChessboardCorners(gray, patternSize, corners);

if (patternFound) {
    cv::cornerSubPix(gray, corners, cv::Size(11, 11), cv::Size(-1, -1), 
        cv::TermCriteria(cv::TermCriteria::EPS + cv::TermCriteria::COUNT, 30, 0.1));
    cv::drawChessboardCorners(img, patternSize, corners, patternFound);
}
```

----------------------------------------

TITLE: Estimating Homography Transformation Using RANSAC in C++
DESCRIPTION: This code estimates the homography transformation between matched points using the RANSAC algorithm. It requires at least 4 matches to compute the transformation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_tracking/akaze_tracking.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
homography = findHomography(Points(matched1), Points(matched2),
                            RANSAC, ransac_thresh, inlier_mask);
```

----------------------------------------

TITLE: Including ArUco Detector Header in C++
DESCRIPTION: Code snippet showing how to include the ArUco detector header in a C++ program. This header provides access to ArUco marker detection functionality in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/objdetect/aruco_detector.hpp>
```

----------------------------------------

TITLE: Inefficient GPU Arithmetic Operation in C++
DESCRIPTION: Illustrates an arithmetic operation (`b.t1 = 2 * b.mu1_mu2 + C1;`) that, while syntactically correct for `GpuMat` objects, can be inefficient on the GPU. This expression implicitly creates a temporary `GpuMat` to store the result of the multiplication (`2 * b.mu1_mu2`) before performing the addition, leading to hidden data transfers and memory allocation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_13

LANGUAGE: cpp
CODE:
```
b.t1 = 2 * b.mu1_mu2 + C1;
```

----------------------------------------

TITLE: Running Detection with Generalized Hough Transform in C++
DESCRIPTION: This code runs the Generalized Hough Transform detection process, which can be time-intensive, especially with larger images or when using the Guil method.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/generalized_hough_ballard_guil/generalized_hough_ballard_guil.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
# Run detection
@snippet samples/cpp/tutorial_code/ImgTrans/generalizedHoughTransform.cpp generalized-hough-transform-run
```

----------------------------------------

TITLE: Finding OpenCV Include Paths using pkg-config in Bash
DESCRIPTION: This Bash command utilizes `pkg-config` to retrieve the compiler flags required for using OpenCV, specifically the include paths (`-I` flags). This helps locate the necessary header files for compiling OpenCV applications in the Eclipse project settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
pkg-config --cflags opencv
```

----------------------------------------

TITLE: Refining GrabCut Results with Mask-based Initialization in OpenCV Python
DESCRIPTION: This code snippet shows how to refine the results of the GrabCut algorithm using mask-based initialization. It loads a manually created mask image to fine-tune the foreground extraction, particularly useful for complex objects or when the rectangular initialization is not sufficient.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_grabcut/py_grabcut.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
# newmask is the mask image I manually labelled
newmask = cv.imread('newmask.png', cv.IMREAD_GRAYSCALE)
assert newmask is not None, "file could not be read, check with os.path.exists()"

# wherever it is marked white (sure foreground), change mask=1
# wherever it is marked black (sure background), change mask=0
mask[newmask == 0] = 0
mask[newmask == 255] = 1

mask, bgdModel, fgdModel = cv.grabCut(img,mask,None,bgdModel,fgdModel,5,cv.GC_INIT_WITH_MASK)

mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask[:,:,np.newaxis]
plt.imshow(img),plt.colorbar(),plt.show()
```

----------------------------------------

TITLE: Drawing a Rectangle in Python
DESCRIPTION: Example of using the rectangle() function in OpenCV Python to draw a filled yellow rectangle. The function specifies two opposite corners of the rectangle along with color and fill options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_29

LANGUAGE: python
CODE:
```
rectangle(rook_image, (0, 7*w//8), (w, w), (0, 255, 255), -1, cv.LINE_8)
```

----------------------------------------

TITLE: Draw Final Matches and Output in OpenCV using C++
DESCRIPTION: A C++ technique to draw the final matched keypoints and output the image, leveraging functions in OpenCV for visualization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_15

LANGUAGE: C++
CODE:
```
samples/cpp/tutorial_code/features2D/AKAZE_match.cpp draw final matches
```

----------------------------------------

TITLE: Applying Box Filter Blur in OpenCV Python
DESCRIPTION: This code shows how to apply box filter blurring using cv.blur(). It takes a simple average of all pixels under the kernel area (5x5 in this example) and replaces the central pixel with the average value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_filtering/py_filtering.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

img = cv.imread('opencv-logo-white.png')
assert img is not None, "file could not be read, check with os.path.exists()"

blur = cv.blur(img,(5,5))

plt.subplot(121),plt.imshow(img),plt.title('Original')
plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(blur),plt.title('Blurred')
plt.xticks([]), plt.yticks([])
plt.show()
```

----------------------------------------

TITLE: Calculating Moments of Contours in Python with OpenCV
DESCRIPTION: This snippet demonstrates how to calculate moments of contours using cv.moments(). It reads an image, applies thresholding, finds contours, and then calculates moments for the first contour.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('star.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
ret,thresh = cv.threshold(img,127,255,0)
contours,hierarchy = cv.findContours(thresh, 1, 2)

cnt = contours[0]
M = cv.moments(cnt)
print( M )
```

----------------------------------------

TITLE: Embedding the Intelligent Scissors Demo via HTML Iframe
DESCRIPTION: This code snippet uses an HTML <iframe> element to embed the Intelligent Scissors JavaScript demo page (js_intelligent_scissors.html) within the documentation or application interface. The iframe is set to occupy full width and automatically adjusts its height based on the document loaded, ensuring the demo is displayed seamlessly. The expected input is the demo HTML file at the relative path, and the output is the rendered interactive frame; the snippet assumes the referenced HTML file exists and is accessible in the environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_intelligent_scissors/js_intelligent_scissors.markdown#2025-04-22_snippet_0

LANGUAGE: HTML
CODE:
```
<iframe src="../../js_intelligent_scissors.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
```

----------------------------------------

TITLE: Retrieving External Contours With RETR_EXTERNAL in OpenCV Python
DESCRIPTION: This snippet demonstrates how to use OpenCV's RETR_EXTERNAL retrieval mode to extract only the outermost contours. All child contours are ignored, thus creating a hierarchy where only top-level contours are represented.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_hierarchy/py_contours_hierarchy.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
>>> hierarchy
array([[[ 1, -1, -1, -1],
        [ 2,  0, -1, -1],
        [-1,  1, -1, -1]]])
```

----------------------------------------

TITLE: Writing and Reading Primitive Types to XML/YAML/JSON - OpenCV Python
DESCRIPTION: This Python snippet demonstrates writing and reading primitive types (integers, floats, strings) to XML/YAML/JSON files in OpenCV. Use FileStorage.write(name, value) to write and fs.getNode('name').real() to read numeric values. The first parameter is the key, and the second is the value. Requires opencv-python installed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
fs = cv2.FileStorage('test.yml', cv2.FileStorage_WRITE)\nfs.write('number', 5)\nfs.release()\n\nfs = cv2.FileStorage('test.yml', cv2.FileStorage_READ)\nread_number = int(fs.getNode('number').real())\nfs.release()
```

----------------------------------------

TITLE: Histogram with Mask
DESCRIPTION: Demonstrates how to calculate and plot histograms for specific image regions using a mask.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
img = cv.imread('home.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"

# create a mask
mask = np.zeros(img.shape[:2], np.uint8)
mask[100:300, 100:400] = 255
masked_img = cv.bitwise_and(img,img,mask = mask)

# Calculate histogram with mask and without mask
# Check third argument for mask
hist_full = cv.calcHist([img],[0],None,[256],[0,256])
hist_mask = cv.calcHist([img],[0],mask,[256],[0,256])

plt.subplot(221), plt.imshow(img, 'gray')
plt.subplot(222), plt.imshow(mask,'gray')
plt.subplot(223), plt.imshow(masked_img, 'gray')
plt.subplot(224), plt.plot(hist_full), plt.plot(hist_mask)
plt.xlim([0,256])

plt.show()
```

----------------------------------------

TITLE: Drawing Histogram Lines for Each Channel in C++
DESCRIPTION: C++ snippet iterating through the histogram bins (from 1 to `histSize`) and drawing lines on `histImage` to represent the normalized histogram values for each channel (B, G, R). It uses `cv::line` with appropriate colors (blue, green, red) to draw vertical bars representing bin counts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_27

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Draw for each channel
```

----------------------------------------

TITLE: Building LLVM on Windows using CMake and MSBuild
DESCRIPTION: This snippet demonstrates how to set up and compile LLVM on Windows using CMake and MSBuild. It involves configuring the build for Visual Studio and is executed in a Developer Command Prompt. Requires LLVM source and Clang source to be set up correctly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
mkdir \\path-to-llvm-build\\ && cd \\path-to-llvm-build\\
cmake.exe -DLLVM_ENABLE_TERMINFO=OFF -DLLVM_TARGETS_TO_BUILD=X86 -DLLVM_ENABLE_ASSERTIONS=ON -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=\\path-to-llvm-install\\ -G "Visual Studio 14 Win64" \\path-to-llvm-src\\
MSBuild.exe /m:4 /t:Build /p:Configuration=Release .\\INSTALL.vcxproj
```

----------------------------------------

TITLE: Running CMake with Documentation Flag in Shell
DESCRIPTION: This shell command configures the build system for OpenCV with included documentation. It requires OpenCV source code and the optional OpenCV_contrib repository. Outputs HTML documentation files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_0

LANGUAGE: sh
CODE:
```
cmake -DBUILD_DOCS=ON ../opencv
```

LANGUAGE: sh
CODE:
```
cmake -DBUILD_DOCS=ON -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules ../opencv
```

----------------------------------------

TITLE: Performing SURF Feature Detection in C++
DESCRIPTION: This C++ code demonstrates how to use OpenCV's SURF detector to find keypoints in an image. It includes loading images, creating a SURF detector, detecting keypoints, and drawing them on the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_detection/feature_detection.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <iostream>\n#include <opencv2/opencv.hpp>\n#include <opencv2/xfeatures2d.hpp>\n\nusing namespace cv;\nusing namespace cv::xfeatures2d;\n\nint main( int argc, char** argv )\n{\n    CommandLineParser parser( argc, argv, "{@input | box.png | input image}" );\n    Mat src = imread( samples::findFile( parser.get<String>( "@input" ) ), IMREAD_GRAYSCALE );\n    if ( src.empty() )\n    {\n        std::cout << "Could not open or find the image!\n" << std::endl;\n        std::cout << "Usage: " << argv[0] << " <Input image>" << std::endl;\n        return -1;\n    }\n\n    //-- Step 1: Detect the keypoints using SURF Detector\n    int minHessian = 400;\n    Ptr<SURF> detector = SURF::create( minHessian );\n    std::vector<KeyPoint> keypoints;\n    detector->detect( src, keypoints );\n\n    //-- Draw keypoints\n    Mat img_keypoints;\n    drawKeypoints( src, keypoints, img_keypoints );\n\n    //-- Show detected (drawn) keypoints\n    imshow("SURF Keypoints", img_keypoints );\n\n    waitKey();\n    return 0;\n}
```

----------------------------------------

TITLE: Basic Depth Map Capture with RealSense
DESCRIPTION: Demonstrates how to capture depth map data from a RealSense camera using VideoCapture's streaming operator. The code runs in a continuous loop until a key is pressed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/intelperc.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
    VideoCapture capture( CAP_REALSENSE );
    for(;;)
    {
        Mat depthMap;
        capture >> depthMap;

        if( waitKey( 30 ) >= 0 )
            break;
    }
```

----------------------------------------

TITLE: Implementing Harris Corner Detector in C++
DESCRIPTION: This C++ code demonstrates how to use the cv::cornerHarris function to detect corners in an image using the Harris-Stephens method. It processes the input image, applies the corner detection algorithm, and visualizes the results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include "opencv2/highgui.hpp"
#include "opencv2/imgproc.hpp"
#include <iostream>

using namespace cv;
using namespace std;

Mat src, src_gray;
int thresh = 200;
int max_thresh = 255;

const char* source_window = "Source image";
const char* corners_window = "Corners detected";

void cornerHarris_demo( int, void* );

int main( int argc, char** argv )
{
    CommandLineParser parser( argc, argv, "{@input | building.jpg | input image}" );
    src = imread( samples::findFile( parser.get<String>( "@input" ) ) );
    if ( src.empty() )
    {
        cout << "Could not open or find the image!\n" << endl;
        cout << "Usage: " << argv[0] << " <Input image>" << endl;
        return -1;
    }

    cvtColor( src, src_gray, COLOR_BGR2GRAY );

    namedWindow( source_window );
    createTrackbar( "Threshold: ", source_window, &thresh, max_thresh, cornerHarris_demo );
    imshow( source_window, src );

    cornerHarris_demo( 0, 0 );

    waitKey();
    return 0;
}

void cornerHarris_demo( int, void* )
{
    int blockSize = 2;
    int apertureSize = 3;
    double k = 0.04;

    Mat dst = Mat::zeros( src.size(), CV_32FC1 );
    cornerHarris( src_gray, dst, blockSize, apertureSize, k );

    Mat dst_norm, dst_norm_scaled;
    normalize( dst, dst_norm, 0, 255, NORM_MINMAX, CV_32FC1, Mat() );
    convertScaleAbs( dst_norm, dst_norm_scaled );

    for( int i = 0; i < dst_norm.rows ; i++ )
    {
        for( int j = 0; j < dst_norm.cols; j++ )
        {
            if( (int) dst_norm.at<float>(i,j) > thresh )
            {
                circle( dst_norm_scaled, Point(j,i), 5,  Scalar(0), 2, 8, 0 );
            }
        }
    }

    namedWindow( corners_window );
    imshow( corners_window, dst_norm_scaled );
}
```

----------------------------------------

TITLE: Performing Ratio-Based Backprojection in Python OpenCV
DESCRIPTION: This code snippet creates a backprojection by calculating the ratio between object and target histograms, and reshaping the result to match the target image dimensions. The backprojection represents probability of pixels belonging to the target object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_backprojection/py_histogram_backprojection.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
h,s,v = cv.split(hsvt)
B = R[h.ravel(),s.ravel()]
B = np.minimum(B,1)
B = B.reshape(hsvt.shape[:2])
```

----------------------------------------

TITLE: Creating an ArUco Grid Board in C++
DESCRIPTION: Code snippet showing how to create an ArUco grid board with specified parameters. The grid board is defined by the number of markers in X and Y directions, marker size, separation between markers, and dictionary type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_board_detection/aruco_board_detection.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
cv::aruco::Dictionary dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);
cv::Ptr<cv::aruco::GridBoard> board = cv::aruco::GridBoard::create(5, 7, 0.04, 0.01, dictionary);
```

----------------------------------------

TITLE: Loading an Image using OpenCV in Java
DESCRIPTION: Loads an image from a file specified by a command-line argument using the `Imgcodecs.imread` function. It performs error checking to ensure the image was loaded correctly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
public void run(String[] args) {
        //![load]
        String filename = args.length > 0 ? args[0] : "../data/chicky_512.png";
        // Load the image
        Mat src = Imgcodecs.imread(filename);
        // Check if image is loaded fine
        if( src.empty() ) {
            System.out.println("Error opening image!");
            System.out.println("Program Arguments: [image_name -- default ../data/chicky_512.png]");
            System.exit(-1);
        }
        //![load]
```

----------------------------------------

TITLE: Using MatVector Container with OpenCV.js - JavaScript
DESCRIPTION: Demonstrates initialization and use of cv.MatVector, a dynamic container for multiple Mat objects. Includes adding (push_back) and retrieval (get) of Mats. Highlights the importance of manually deleting resources after use. Useful for collections of images or channels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_5

LANGUAGE: JavaScript
CODE:
```
let mat = new cv.Mat();
// Initialise a MatVector
let matVec = new cv.MatVector();
// Push a Mat back into MatVector
matVec.push_back(mat);
// Get a Mat fom MatVector
let cnt = matVec.get(0);
mat.delete(); matVec.delete(); cnt.delete();
```

----------------------------------------

TITLE: Drawing Detected ArUco Markers using OpenCV C++
DESCRIPTION: This code snippet demonstrates the use of OpenCV's `drawDetectedMarkers()` function to visualize detected markers on an image. It requires an input/output Mat image, and structures for detected marker corners and IDs obtained from `detectMarkers()`. This is typically used for verification and does not affect detection accuracy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
cv::Mat outputImage = inputImage.clone();
cv::aruco::drawDetectedMarkers(outputImage, markerCorners, markerIds);
```

----------------------------------------

TITLE: Applying the Probabilistic Hough Line Transform in OpenCV (C++)
DESCRIPTION: This C++ code applies HoughLinesP to detect line segments using the probabilistic version of Hough Transform. The function returns start and end points for each line. Inputs include the edge image, rho/theta resolutions, threshold, minLineLength, and maxLineGap. Suitable for line segments extraction.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_12

LANGUAGE: C++
CODE:
```
vector<Vec4i> linesP;\nHoughLinesP(edges, linesP, 1, CV_PI/180, 50, 50, 10);\n
```

----------------------------------------

TITLE: Computing Bounding Rotated Boxes and Ellipses in Contours - OpenCV C++
DESCRIPTION: This C++ snippet leverages OpenCV functions to find contours in an image and compute both the minimum area rotated rectangle and the best-fit ellipse for each contour where applicable. Dependencies include OpenCV (C++ bindings), and the code typically expects a binary or grayscale image as input. The key parameters are the input image and parameters for contour detection; the output is a visualization or coordinates of bounding rotated boxes and ellipses. This version uses cv::minAreaRect and cv::fitEllipse and is compatible with OpenCV 3.0 and above.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rotated_ellipses/bounding_rotated_ellipses.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>\nusing namespace cv;\nusing namespace std;\n\nint main(int argc, char** argv)\n{\n    // Load image\n    Mat src = imread("shapes.png", IMREAD_GRAYSCALE);\n    threshold(src, src, 100, 255, THRESH_BINARY);\n    vector<vector<Point>> contours;\n    findContours(src, contours, RETR_LIST, CHAIN_APPROX_SIMPLE);\n\n    Mat drawing = Mat::zeros(src.size(), CV_8UC3);\n    for (size_t i = 0; i < contours.size(); i++)\n    {\n        // Compute the bounding rotated rectangle for each contour\n        RotatedRect box = minAreaRect(contours[i]);\n        Point2f rect_points[4];\n        box.points(rect_points);\n        for (int j = 0; j < 4; j++)\n            line(drawing, rect_points[j], rect_points[(j+1)%4], Scalar(0,255,0), 2);\n        // Fit ellipse if contour has enough points\n        if (contours[i].size() > 5)\n        {\n            RotatedRect ellipse_box = fitEllipse(contours[i]);\n            ellipse(drawing, ellipse_box, Scalar(255,0,0), 2);\n        }\n    }\n    imshow("Contours", drawing);\n    waitKey(0);\n    return 0;\n}
```

----------------------------------------

TITLE: Creating Custom ArUco Dictionary in C++
DESCRIPTION: This code demonstrates how to manually create a custom ArUco dictionary with 100 markers, each 6x6 bits in size. It uses the Dictionary::getByteListFromBits() method to convert binary marker representations to the compressed format used in the dictionary.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
    cv::aruco::Dictionary dictionary;

    // Markers of 6x6 bits
    dictionary.markerSize = 6;

    // Maximum number of bit corrections
    dictionary.maxCorrectionBits = 3;

    // Let's create a dictionary of 100 markers
    for(int i = 0; i < 100; i++)
    {
        // Assume generateMarkerBits() generates a new marker in binary format, so that
        // markerBits is a 6x6 matrix of CV_8UC1 type, only containing 0s and 1s
        cv::Mat markerBits = generateMarkerBits();
        cv::Mat markerCompressed = cv::aruco::Dictionary::getByteListFromBits(markerBits);

        // Add the marker as a new row
        dictionary.bytesList.push_back(markerCompressed);
    }
```

----------------------------------------

TITLE: Setting OpenCV Directory Environment Variable using Windows Batch
DESCRIPTION: This series of batch commands uses the setx utility to set the OpenCV_DIR environment variable to appropriate paths based on Visual Studio version and system architecture. Users should adjust the path according to their installation or build directories. This approach makes it easier for both scripts and IDEs to locate OpenCV's files while building or running projects. The command takes effect for new processes and requires administrative rights for machine-level updates, and modifications might be needed depending on user privileges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_6

LANGUAGE: batch
CODE:
```
setx OpenCV_DIR D:\OpenCV\build\x64\vc14     (suggested for Visual Studio 2015 - 64 bit Windows)
setx OpenCV_DIR D:\OpenCV\build\x86\vc14     (suggested for Visual Studio 2015 - 32 bit Windows)

setx OpenCV_DIR D:\OpenCV\build\x64\vc15     (suggested for Visual Studio 2017 - 64 bit Windows)
setx OpenCV_DIR D:\OpenCV\build\x86\vc15     (suggested for Visual Studio 2017 - 32 bit Windows)

setx OpenCV_DIR D:\OpenCV\build\x64\vc16     (suggested for Visual Studio 2019 - 64 bit Windows)
setx OpenCV_DIR D:\OpenCV\build\x86\vc16     (suggested for Visual Studio 2019 - 32 bit Windows)

setx OpenCV_DIR D:\OpenCV\build\x64\vc17     (suggested for Visual Studio 2022 - 64 bit Windows)
setx OpenCV_DIR D:\OpenCV\build\x86\vc17     (suggested for Visual Studio 2022 - 32 bit Windows)
```

----------------------------------------

TITLE: Converting Integer FourCC to String using a Union (C++)
DESCRIPTION: Presents an alternative method using a C++ union to convert an integer FourCC codec identifier into its 4-character string representation. Assigning the integer (`ex`) to the union's integer member (`v`) allows accessing the underlying bytes as characters via the character array member (`c`). A null terminator is added manually to `c[4]`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
union { int v; char c[5];} uEx ;
uEx.v = ex;                              // From Int to char via union
uEx.c[4]='\0';
```

----------------------------------------

TITLE: Implementing Lucas-Kanade Optical Flow Tracking in Python
DESCRIPTION: Python implementation of tracking feature points in a video using the Lucas-Kanade optical flow method. The code detects Shi-Tomasi corner points in the first frame and then tracks them through subsequent frames using cv.calcOpticalFlowPyrLK().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/optical_flow.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
import argparse

parser = argparse.ArgumentParser(description='This sample demonstrates Lucas-Kanade Optical Flow calculation. \n'
                                     'The example file can be downloaded from: \n'
                                     'https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4')
parser.add_argument('image', type=str, help='path to image file')
args = parser.parse_args()

cap = cv.VideoCapture(args.image)

# params for ShiTomasi corner detection
feature_params = dict( maxCorners = 100,
                       qualityLevel = 0.3,
                       minDistance = 7,
                       blockSize = 7 )

# Parameters for lucas kanade optical flow
lk_params = dict( winSize  = (15, 15),
                  maxLevel = 2,
                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))

# Create some random colors
color = np.random.randint(0, 255, (100, 3))

# Take first frame and find corners in it
ret, old_frame = cap.read()
old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)
p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)

# Create a mask image for drawing purposes
mask = np.zeros_like(old_frame)

while(1):
    ret, frame = cap.read()
    if not ret:
        print('No frames grabbed!')
        break

    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)

    # calculate optical flow
    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Select good points
    if p1 is not None:
        good_new = p1[st==1]
        good_old = p0[st==1]

    # draw the tracks
    for i,(new,old) in enumerate(zip(good_new, good_old)):
        a,b = new.ravel()
        c,d = old.ravel()
        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)
        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)
    img = cv.add(frame, mask)

    cv.imshow('frame', img)
    k = cv.waitKey(30) & 0xff
    if k == 27:
        break

    # Now update the previous frame and previous points
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)

cv.destroyAllWindows()
```

----------------------------------------

TITLE: Converting Images to HSV Format for Histogram Comparison
DESCRIPTION: Converting RGB images to HSV color space, which is more suitable for histogram-based image analysis and comparison.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
Mat hsv_base;
Mat hsv_test1;
Mat hsv_test2;
cvtColor( src_base, hsv_base, COLOR_BGR2HSV );
cvtColor( src_test1, hsv_test1, COLOR_BGR2HSV );
cvtColor( src_test2, hsv_test2, COLOR_BGR2HSV );
```

LANGUAGE: java
CODE:
```
Mat hsv_base = new Mat();
Mat hsv_test1 = new Mat();
Mat hsv_test2 = new Mat();
Imgproc.cvtColor( src_base, hsv_base, Imgproc.COLOR_BGR2HSV );
Imgproc.cvtColor( src_test1, hsv_test1, Imgproc.COLOR_BGR2HSV );
Imgproc.cvtColor( src_test2, hsv_test2, Imgproc.COLOR_BGR2HSV );
```

LANGUAGE: python
CODE:
```
hsv_base = cv.cvtColor(src_base, cv.COLOR_BGR2HSV)
hsv_test1 = cv.cvtColor(src_test1, cv.COLOR_BGR2HSV)
hsv_test2 = cv.cvtColor(src_test2, cv.COLOR_BGR2HSV)
```

----------------------------------------

TITLE: Undistorting Images using Calculated Calibration Parameters with OpenCV C++
DESCRIPTION: This C++ snippet reference points to code demonstrating how to apply the calculated camera matrix and distortion coefficients to correct image distortion. It uses the `cv::undistort` function to remap the input image pixels, producing an undistorted output image based on the calibration results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp output_undistorted
```

----------------------------------------

TITLE: Loading an Image from File with OpenCV in Java
DESCRIPTION: Illustrates loading an image file using OpenCV in Java via Imgcodecs.imread. Requires OpenCV native libraries available to the JVM. The loaded Mat contains BGR data (3 channels) for standard color images. Accepts a file path as input and returns a Mat object. File format support depends on the OpenCV distribution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.Mat;\nimport org.opencv.imgcodecs.Imgcodecs;\nMat img = Imgcodecs.imread("my_image.jpg");
```

----------------------------------------

TITLE: Image Sharpening with Laplacian Filter
DESCRIPTION: Applies a laplacian filter to sharpen the image and accentuate edges of foreground objects
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/distance_transformation/distance_transform.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
Mat kernel = (Mat_<float>(3,3) <<
        1,  1, 1,
        1, -8, 1,
        1,  1, 1);
Mat imgLaplacian;
filter2D(src, imgLaplacian, CV_32F, kernel);
Mat sharp;
src.convertTo(sharp, CV_32F);
Mat imgResult = sharp - imgLaplacian;
```

LANGUAGE: Python
CODE:
```
kernel = np.array([[1, 1, 1],
                   [1, -8, 1],
                   [1, 1, 1]], dtype=np.float32)
img_laplacian = cv.filter2D(src, cv.CV_32F, kernel)
sharp = np.float32(src)
img_result = sharp - img_laplacian
```

----------------------------------------

TITLE: Building WebNN Module with OpenCV
DESCRIPTION: This code snippet demonstrates how to add the WebNN backend to the OpenCV build process by passing the -DWITH_WEBNN=ON option to the cmake command, as per the Linux installation tutorial. It is important to run this in the OpenCV directory root and have CMake available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/src/webnn/README.md#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
cmake -DWITH_WEBNN=ON ../opencv
```

----------------------------------------

TITLE: Creating and Copying OpenCV Mat Headers in C++
DESCRIPTION: Demonstrates basic Mat object creation, assignment using `imread`, and copy construction. Highlights that the copy constructor (`Mat B(A);`) and assignment operator (`C = A;`) only copy the header and share the underlying matrix data with the original (`A`) due to OpenCV's reference counting system. Requires an image path via `argv[1]`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
Mat A, C;                          // creates just the header parts
A = imread(argv[1], IMREAD_COLOR); // here we'll know the method used (allocate matrix)

Mat B(A);                                 // Use the copy constructor

C = A;                                    // Assignment operator
```

----------------------------------------

TITLE: Detecting Keypoints and Computing Descriptors with SURF in OpenCV C++
DESCRIPTION: Uses the SURF algorithm to detect keypoints and compute descriptors for an input image. This process is repeated for both input images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/detection_of_planar_objects/detection_of_planar_objects.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
// detecting keypoints
Ptr<Feature2D> surf = SURF::create();
vector<KeyPoint> keypoints1;
Mat descriptors1;
surf->detectAndCompute(img1, Mat(), keypoints1, descriptors1);

... // do the same for the second image
```

----------------------------------------

TITLE: Extracting Rotational Component Using OpenCV in Java
DESCRIPTION: This snippet demonstrates extracting the rotational component from two images captured by a rotating camera using the OpenCV library in Java. It requires the OpenCV library with Java bindings. Inputs involve image views, and the output is the rotational component.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_30

LANGUAGE: Java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.Mat;

public void extractRotation(Mat image1, Mat image2) {
    // Code to extract rotation component
    // ...
}
```

----------------------------------------

TITLE: Finding Contour Orientation and Axis Lengths in OpenCV Python
DESCRIPTION: This snippet determines the orientation (angle) of the object represented by the contour, along with the lengths of its major (MA) and minor (ma) axes. It achieves this by fitting an ellipse to the contour points using `cv.fitEllipse`. Requires an existing contour variable `cnt`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
(x,y),(MA,ma),angle = cv.fitEllipse(cnt)
```

----------------------------------------

TITLE: Exposure Fusion using Mertens Algorithm in OpenCV Python
DESCRIPTION: Demonstrates exposure fusion using Mertens algorithm which results in an image within [0..1] range without requiring exposure times.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_hdr/py_hdr.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
# Exposure fusion using Mertens
merge_mertens = cv.createMergeMertens()
res_mertens = merge_mertens.process(img_list)
```

----------------------------------------

TITLE: Classifying Multiple Data Points with kNN in OpenCV
DESCRIPTION: This code snippet shows how to classify multiple new data points (newcomers) at once using the trained kNN model. It creates 10 random test points and performs classification on all of them simultaneously, returning arrays of results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_knn/py_knn_understanding/py_knn_understanding.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
# 10 new-comers
newcomers = np.random.randint(0,100,(10,2)).astype(np.float32)
ret, results,neighbours,dist = knn.findNearest(newcomer, 3)
# The results also will contain 10 labels.
```

----------------------------------------

TITLE: Configuring OpenCV 2.4 Build for Ubuntu Linux using CMake (Shell)
DESCRIPTION: Runs CMake to configure the OpenCV 2.4 build for desktop Ubuntu Linux (14.04/16.04 LTS). It sets build type to Release, enables CUDA 8.0 support for multiple architectures (3.0, 3.5, 5.0, 6.0, 6.2), enables Python 2 bindings (`BUILD_opencv_python`), TBB, and FFMPEG, while disabling several other optional dependencies (PNG, TIFF, Jasper, ZLIB, Java, nonfree modules, OpenCL, OpenMP, GStreamer, VTK, 1394, OpenEXR) and specifying the test data path. Assumes execution from a build directory sibling to `opencv` and `opencv_extra`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_17

LANGUAGE: Shell
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_nonfree=OFF \
    -DBUILD_opencv_python=ON \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0 \
    -DCUDA_ARCH_BIN='3.0 3.5 5.0 6.0 6.2' \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=ON \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Referencing OpenCV Bayer Pattern Conversion Functions
DESCRIPTION: This snippet lists various OpenCV color conversion functions for different Bayer pattern types. These functions convert Bayer patterns to BGR or RGB color spaces.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/imgproc/doc/colors.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
cv::COLOR_BayerRGGB2BGR, cv::COLOR_BayerGRBG2BGR, cv::COLOR_BayerBGGR2BGR, cv::COLOR_BayerGBRG2BGR, cv::COLOR_BayerRGGB2RGB, cv::COLOR_BayerGRBG2RGB, cv::COLOR_BayerBGGR2RGB, cv::COLOR_BayerGBRG2RGB
cv::COLOR_BayerBG2BGR, cv::COLOR_BayerGB2BGR, cv::COLOR_BayerRG2BGR, cv::COLOR_BayerGR2BGR, cv::COLOR_BayerBG2RGB, cv::COLOR_BayerGB2RGB, cv::COLOR_BayerRG2RGB, cv::COLOR_BayerGR2RGB
```

----------------------------------------

TITLE: Zero Padding for Optimal DFT Performance - Python
DESCRIPTION: Demonstrates two methods for padding a 2D image array to optimal size for efficient FFT/DFT processing in Python. The first approach creates a new zeros array and copies the original image into it; the second approach uses OpenCV's cv.copyMakeBorder() to pad the image directly. Dependencies: Numpy (np) and OpenCV (cv). Key parameters: nrows/ncols (optimal sizes), rows/cols (original sizes), img (input array). Outputs a zero-padded array, suitable for DFT. Handles constant-value padding with border type specification.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
nimg = np.zeros((nrows,ncols))
nimg[:rows,:cols] = img
```

LANGUAGE: Python
CODE:
```
right = ncols - cols
bottom = nrows - rows
bordertype = cv.BORDER_CONSTANT #just to avoid line breakup in PDF file
nimg = cv.copyMakeBorder(img,0,bottom,0,right,bordertype, value = 0)
```

----------------------------------------

TITLE: Overlaying Non-Rectangular ROI Using Bitwise Operations in Python
DESCRIPTION: This code snippet shows how to overlay a non-rectangular image (OpenCV logo) onto another image using bitwise operations in OpenCV. It involves creating a mask and an inverse mask, masking the ROI, and then combining images to achieve the overlay. Dependencies include the images messi5.jpg and opencv-logo-white.png.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_image_arithmetics/py_image_arithmetics.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
# Load two images
img1 = cv.imread('messi5.jpg')
img2 = cv.imread('opencv-logo-white.png')
assert img1 is not None, "file could not be read, check with os.path.exists()"
assert img2 is not None, "file could not be read, check with os.path.exists()"

# I want to put logo on top-left corner, So I create a ROI
rows,cols,channels = img2.shape
roi = img1[0:rows, 0:cols]

# Now create a mask of logo and create its inverse mask also
img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)
ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY)
mask_inv = cv.bitwise_not(mask)

# Now black-out the area of logo in ROI
img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv)

# Take only region of logo from logo image.
img2_fg = cv.bitwise_and(img2,img2,mask = mask)

# Put logo in ROI and modify the main image
dst = cv.add(img1_bg,img2_fg)
img1[0:rows, 0:cols ] = dst

cv.imshow('res',img1)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Converting Mat Types with OpenCV.js - JavaScript
DESCRIPTION: Utilizes convertTo to change the data type (depth) of a cv.Mat. Supports optional scaling (alpha) and offset (beta); output is stored in another matrix. This is essential for dynamic range adjustments, normalization, and type compatibility. The function signature in code matches the C++ OpenCV convention.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_4

LANGUAGE: JavaScript
CODE:
```
src.convertTo(dst, rtype);
```

----------------------------------------

TITLE: Estimating Pose of ChArUco Diamond Markers Using solvePnP (C++)
DESCRIPTION: This two-part snippet covers 3D pose estimation of detected ChArUco diamond markers using cv::solvePnP() in OpenCV C++. With the four detected diamond corners, known square length, and camera calibration parameters, it calculates each diamond's rotation and translation vectors. Typically, the diamond corners are ordered consistently (clockwise starting from top-left), and the pose is visualized by drawing the frame axes using cv::aruco::drawAxis() or cv::drawFrameAxes(). Proper calibration (intrinsic/extrinsic parameters) is required for accurate results. Outputs include rvecs/tvecs for each diamond; limitations include dependency on corner detection quality and calibration accuracy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_diamond_detection/charuco_diamond_detection.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
// Pose estimation for diamond markers
std::vector<std::vector<cv::Point2f>> diamondCorners;
std::vector<cv::Vec4i> diamondIds;
double squareLength;
cv::Mat cameraMatrix, distCoeffs;
std::vector<cv::Vec3d> rvecs, tvecs;

for (size_t i=0; i<diamondCorners.size(); i++) {
    std::vector<cv::Point3f> objectPoints;
    // Define 3D corners for the square on the chessboard plane
    objectPoints.push_back(cv::Point3f(0, 0, 0));
    objectPoints.push_back(cv::Point3f(squareLength, 0, 0));
    objectPoints.push_back(cv::Point3f(squareLength, squareLength, 0));
    objectPoints.push_back(cv::Point3f(0, squareLength, 0));
    cv::Vec3d rvec, tvec;
    cv::solvePnP(objectPoints, diamondCorners[i], cameraMatrix, distCoeffs, rvec, tvec);
    rvecs.push_back(rvec);
    tvecs.push_back(tvec);
}

```

LANGUAGE: C++
CODE:
```
// Draw axes to show diamond pose
double axisLength = squareLength * 0.5; // Or another scale
for (size_t i=0; i<diamondCorners.size(); i++) {
    cv::aruco::drawAxis(image, cameraMatrix, distCoeffs, rvecs[i], tvecs[i], axisLength);
}
```

----------------------------------------

TITLE: Building the Project and Running the OpenCV Executable with Bash
DESCRIPTION: These Bash snippets provide the essential shell commands to build the project using CMake and Make, and to run the resulting OpenCV executable. The first block changes to the build directory, invokes cmake to generate build files, and compiles the code. The second block demonstrates running the program with an image file as input. Dependencies: Bash shell, GCC, Make, CMake, and OpenCV installed. Inputs: directory containing source and CMakeLists.txt, path to input image. Outputs: builds and runs the ./DisplayImage executable. Limitation: paths and filenames must be correct.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_gcc_cmake/linux_gcc_cmake.markdown#2025-04-22_snippet_2

LANGUAGE: Bash
CODE:
```
cd <DisplayImage_directory>\ncmake .\nmake
```

LANGUAGE: Bash
CODE:
```
./DisplayImage lena.jpg
```

----------------------------------------

TITLE: Cloning and Copying OpenCV Mat Objects in C++
DESCRIPTION: Demonstrates creating a new matrix by cloning or copying an existing one. Shows how to create a new header for an existing Mat object and then use clone() or copyTo() methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_8

LANGUAGE: C++
CODE:
```
// clone or copyTo to get a copy of the data.
Mat RowClone = C.row(1).clone();
cout << "RowClone = " << endl << " " << RowClone << endl << endl;
```

----------------------------------------

TITLE: Reading Input Images in OpenCV C++
DESCRIPTION: Reads two grayscale input images using OpenCV's imread function. The images are expected to be provided as command-line arguments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/detection_of_planar_objects/detection_of_planar_objects.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
Mat img1 = imread(argv[1], IMREAD_GRAYSCALE);
Mat img2 = imread(argv[2], IMREAD_GRAYSCALE);
```

----------------------------------------

TITLE: Generating Linearly Separable Training Data for SVM (Python)
DESCRIPTION: Python implementation for generating linearly separable training data using numpy and OpenCV. Creates points from two different classes that could be separated by a linear boundary.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
# Set up the linearly separable part of the training data
labels = [1, -1]
trainData = np.empty((2 * NTRAINING_SAMPLES, 2), dtype=np.float32)
trainLabels = np.empty((2 * NTRAINING_SAMPLES, 1), dtype=np.int32)
rng = np.random.RandomState(100)

# Generate training samples
for i in range(2):
    n = NTRAINING_SAMPLES
    trainData[i*n:(i+1)*n, 0:1] = rng.uniform(size=(n, 1))
    trainData[i*n:(i+1)*n, 0:1] = trainData[i*n:(i+1)*n, 0:1] * 0.2 + (0.2 if i == 0 else 0.6)
    trainData[i*n:(i+1)*n, 1:2] = rng.uniform(size=(n, 1))
    trainLabels[i*n:(i+1)*n, :] = labels[i]
```

----------------------------------------

TITLE: Tracking a Colored Object in Real-Time Video with OpenCV in Python
DESCRIPTION: This comprehensive code tracks a blue object using a webcam feed. It converts each frame from BGR to HSV, thresholds for a blue HSV range, and extracts that object with a bitwise AND. Requires OpenCV (cv2) and numpy, and access to a video capture device. Key parameters: lower_blue and upper_blue define the color boundaries. Displays three real-time windows for live video, mask, and result. Will run until the ESC key (27) is pressed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import cv2 as cv\nimport numpy as np\n\ncap = cv.VideoCapture(0)\n\nwhile(1):\n\n    # Take each frame\n    _, frame = cap.read()\n\n    # Convert BGR to HSV\n    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n\n    # define range of blue color in HSV\n    lower_blue = np.array([110,50,50])\n    upper_blue = np.array([130,255,255])\n\n    # Threshold the HSV image to get only blue colors\n    mask = cv.inRange(hsv, lower_blue, upper_blue)\n\n    # Bitwise-AND mask and original image\n    res = cv.bitwise_and(frame,frame, mask= mask)\n\n    cv.imshow('frame',frame)\n    cv.imshow('mask',mask)\n    cv.imshow('res',res)\n    k = cv.waitKey(5) & 0xFF\n    if k == 27:\n        break\n\ncv.destroyAllWindows()
```

----------------------------------------

TITLE: Basic OAK Depth Camera Integration with G-API Inference
DESCRIPTION: This code demonstrates how to use an OAK depth camera with OpenCV's G-API for inference. It shows initialization of camera parameters, setting up streams, performing neural network inference, and visualizing results. The example uses a face detection model and processes frames in a pipeline approach.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/oak_devices/oak_devices.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include <opencv2/core.hpp>
#include <opencv2/gapi.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/gapi/core.hpp>
#include <opencv2/gapi/cpu/gcpukernel.hpp>
#include <opencv2/gapi/infer.hpp>
#include <opencv2/gapi/render.hpp>
#include <opencv2/gapi/streaming/cap.hpp>
#include <opencv2/gapi/streaming/onevpl.hpp>
#include <opencv2/gapi/oak/oak.hpp>

#include <string>
#include <algorithm>

// Default parameters ////////////////////////////////////////////////////

// NB: default video source
const std::string default_oak_uri = "oak:color"; // Use device color camera
const std::string default_blob_path = "face-detection-adas-0001.blob";
const std::string default_detect_output_layer = "detection_output_1:DetectionOutput:1";

// Inference parameters
const cv::Scalar background_color{0.2, 115.0 / 255, 115.0 / 255};
const cv::Scalar rect_color{240.0 / 255, 171.0 / 255, 96.0 / 255};
const cv::Scalar tl_color{0.0, 0.0, 0.0};

// Font settings
const double tl_font_scale = 0.9;
const int tl_thickness = 1;

// NB: Used to control window size
const double scale_factor = 1.0;

int main(int argc, char *argv[]) {
    // Parse args
    cv::CommandLineParser cmd(argc, argv, cv::format(
        "{ h help     || } "
        "{ input i    | %s | OAK camera URI for reading frames } "
        "{ model m    | %s | Inference model (blob) } "
        "{ layer l    | %s | Inference model output layer }",
        default_oak_uri.c_str(), default_blob_path.c_str(),
        default_detect_output_layer.c_str()));

    if (cmd.get<bool>("help")) {
        std::cout << "G-API Oak with inference demo\n\n";
        cmd.printMessage();
        return 0;
    }

    const std::string oak_uri = cmd.get<std::string>("input");
    const std::string blob_path = cmd.get<std::string>("model");
    const std::string detect_out_layer = cmd.get<std::string>("layer");

    // Read NN configuration
    cv::size_sp output_size{0, 0};

    // Create NN object
    cv::gapi::mx::nn::forward::Params detect_params;
    detect_params.num_classes = 1;
    detect_params.is_background_transparent = false;
    detect_params.output_layer = detect_out_layer;
    detect_params.blob_path = blob_path;

    // Create pipeline
    cv::GArray<cv::Rect> faces;
    cv::GFrame in;
    cv::GMat in_y;
    cv::GMat bgr;
    cv::GMat render_mat; // For rendering
    std::tie(in_y, bgr) = cv::gapi::oak::ColorCamera::outputFrame(in);

    // NB: Take median value from all faces as a background intensity
    auto avg_face_prob = cv::gapi::streaming::encodeTimestamp
        (cv::gapi::mx::nn::forward::Detect::on(in_y, detect_params), faces);

    // Rendering
    render_mat = cv::gapi::copy(bgr);
    for (const auto& face : faces) {
        cv::gapi::wip::draw::Rectangle(render_mat, face, rect_color, 2);
    }

    // Assemble pipeline
    cv::GComputation pipeline([&](){ return cv::GComputation(cv::GIn(in), cv::GOut(render_mat, faces, avg_face_prob)); });

    // Set compiled params
    auto oak_params = cv::gapi::oak::ColorCamera::params(
        oak_uri, // device_id
        /* frame_size */ cv::Size{800, 600},
        /* master_fps */ 30
    );

    auto kernels = cv::gapi::combine
        (cv::gapi::oak::kernels(),
        cv::gapi::render::oe::kernels());

    auto networks = cv::gapi::networks(cv::gapi::mx::nn::forward::loads());

    auto pipeline_args = cv::compile_args
        (cv::gapi::mx::nn::forward::op::params(),
        cv::gapi::oak::ColorCamera::params(oak_uri),
        kernels, networks);

    // Compile pipeline
    // FIXME: make a callable object
    auto exec = pipeline().compileStreaming(std::move(pipeline_args));

    // Setup input
    const auto source = cv::gapi::wip::make_src<cv::gapi::oak::ColorCamera>();
    exec.setSource(source);

    // Start processing
    exec.start();

    cv::Mat render_mat_out;
    std::vector<cv::Rect> faces_out;
    double median_prob_out = 0.0;
    cv::TickMeter tm;

    // Video display loop
    std::cout << "Press ESC key to exit...\n";
    tm.start();
    while (exec.pull(cv::gout(render_mat_out, faces_out, median_prob_out))) {
        // Show processed frame
        cv::Mat output = render_mat_out.clone();

        // Draw FPS information
        tm.stop();
        const double fps = 1.0 / tm.getTimeSec();
        tm.reset();
        tm.start();

        cv::putText(output, cv::format("FPS: %.2f", fps),
                   cv::Point(output.cols - 200, 40), cv::FONT_HERSHEY_SIMPLEX, 1.0,
                   cv::Scalar(0, 0, 255), 2);

        // Show inference output
        cv::imshow("OAK Pipeline", output);
        const int key = cv::waitKey(1);
        if (key == 27) break; // ESC
    }

    return 0;
}
```

----------------------------------------

TITLE: Estimating Homography using OpenCV's findHomography - Python
DESCRIPTION: This Python snippet invokes cv2.findHomography to calculate the perspective homography matrix from matching corner points. Requires lists of detected correspondences in two images. Produces a 3x3 matrix for warping; may use RANSAC for robustness. Used prior to geometric transformation operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_12

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/features2D/Homography/perspective_correction.py estimate-homography
```

----------------------------------------

TITLE: Defining and Linking Targets for Each GPU Sample in CMake
DESCRIPTION: Iterates through each filename stored in the `all_samples` variable. Inside the loop, it defines an executable target (`tgt`) for the sample using `ocv_define_sample`, specifying its source file (`sample_filename`) and category ('gpu'). It then links the target against the core required libraries (`OPENCV_LINKER_LIBS`, `OPENCV_CUDA_SAMPLES_REQUIRED_DEPS`) and conditionally links against `opencv_xfeatures2d` and `opencv_cudacodec` if they are available, using `ocv_target_link_libraries`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: cmake
CODE:
```
foreach(sample_filename ${all_samples})
  ocv_define_sample(tgt ${sample_filename} gpu)
  ocv_target_link_libraries(${tgt} PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_CUDA_SAMPLES_REQUIRED_DEPS})
  if(HAVE_opencv_xfeatures2d)
    ocv_target_link_libraries(${tgt} PRIVATE opencv_xfeatures2d)
  endif()
  if(HAVE_opencv_cudacodec)
    ocv_target_link_libraries(${tgt} PRIVATE opencv_cudacodec)
  endif()
endforeach()
```

----------------------------------------

TITLE: Performing Template Matching Operation (Python)
DESCRIPTION: Calls the `cv2.matchTemplate` function to compare the template against the source image using the specified method. It handles methods that support masking by passing the mask image if available, otherwise performs matching without a mask. The result (correlation map) is stored.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_24

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py match_template
```

----------------------------------------

TITLE: Creating 2D Histogram using NumPy histogram2d function
DESCRIPTION: This snippet shows how to create a 2D histogram using NumPy's histogram2d function. It loads an image, converts it to HSV, and then calculates a histogram of Hue and Saturation values with 180 and 256 bins respectively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_2d_histogram/py_2d_histogram.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('home.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"
hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)

hist, xbins, ybins = np.histogram2d(h.ravel(),s.ravel(),[180,256],[[0,180],[0,256]])
```

----------------------------------------

TITLE: Creating Morphological Kernel in C++
DESCRIPTION: Creates a structuring element (kernel) for morphological operations with specified shape and size
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
Mat element = getStructuringElement(morph_type,
                                   Size(2 * erosion_size + 1, 2 * erosion_size + 1),
                                   Point(erosion_size, erosion_size));
```

----------------------------------------

TITLE: Executing Kalman Filter Prediction and Correction Steps in C++ (OpenCV)
DESCRIPTION: Defines the `updateKalmanFilter` C++ function using OpenCV's `cv::KalmanFilter`. It takes the Kalman Filter object (`KF`), the latest measurement vector (`measurement`), and output matrices for estimated translation (`translation_estimated`) and rotation (`rotation_estimated`). It performs the two core Kalman Filter steps: prediction (`KF.predict()`) to update the internal state prediction, and correction (`KF.correct(measurement)`) using the measurement to refine the state estimate. From the corrected state vector (`estimated`), it extracts the translation components (indices 0-2) and Euler angles (indices 9-11), converts the Euler angles back to a rotation matrix using `euler2rot`, and populates the output matrices.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_25

LANGUAGE: cpp
CODE:
```
void updateKalmanFilter( cv::KalmanFilter &KF, cv::Mat &measurement,
                     cv::Mat &translation_estimated, cv::Mat &rotation_estimated )
{

    // First predict, to update the internal statePre variable
    cv::Mat prediction = KF.predict();

    // The "correct" phase that is going to use the predicted value and our measurement
    cv::Mat estimated = KF.correct(measurement);

    // Estimated translation
    translation_estimated.at<double>(0) = estimated.at<double>(0);
    translation_estimated.at<double>(1) = estimated.at<double>(1);
    translation_estimated.at<double>(2) = estimated.at<double>(2);

    // Estimated euler angles
    cv::Mat eulers_estimated(3, 1, CV_64F);
    eulers_estimated.at<double>(0) = estimated.at<double>(9);
    eulers_estimated.at<double>(1) = estimated.at<double>(10);
    eulers_estimated.at<double>(2) = estimated.at<double>(11);

    // Convert estimated quaternion to rotation matrix
    rotation_estimated = euler2rot(eulers_estimated);

}
```

----------------------------------------

TITLE: Constructing a Mat from std::vector of Points with OpenCV in C++
DESCRIPTION: Demonstrates conversion of a std::vector<cv::Point2f> or std::vector<cv::Point3f> to a cv::Mat, useful for calib3d functions. The resulting matrix type matches either 32FC2 or 32FC3. Input is vector of points. Resulting Mat shares data with vector, so vector lifetime must exceed Mat's.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_19

LANGUAGE: C++
CODE:
```
std::vector<cv::Point2f> points; // assume filled\ncv::Mat pointsMat(points);
```

----------------------------------------

TITLE: Computing Plane Distance to Camera Frame in OpenCV - C++
DESCRIPTION: This snippet calculates the signed distance from the camera to the target plane, needed for proper homography scaling. It uses the dot product of the normal vector with a point on the plane or extracts from plane equation coefficients. Prereqs: plane normal, known 3D point in camera frame.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_23

LANGUAGE: cpp
CODE:
```
@snippet homography_from_camera_displacement.cpp compute-plane-distance-to-the-camera-frame-1
```

----------------------------------------

TITLE: Creating HDR Image from Multiple Exposures in OpenCV
DESCRIPTION: This code creates an HDR image by merging multiple exposures using Debevec's weighting scheme and the camera response function calculated in the previous step.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/hdr_imaging.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
Mat hdr;
Ptr<MergeDebevec> merge_debevec = createMergeDebevec();
merge_debevec->process(images, hdr, times, response);
```

LANGUAGE: java
CODE:
```
Mat hdr = new Mat();
MergeDebevec mergeDebevec = Photo.createMergeDebevec();
mergeDebevec.process(images, hdr, times, response);
```

LANGUAGE: python
CODE:
```
merge_debevec = cv.createMergeDebevec()
hdr = merge_debevec.process(images, times, response)
```

----------------------------------------

TITLE: Reducing Noise with Gaussian Blur in C++
DESCRIPTION: Applies a 3x3 Gaussian blur to the source image using cv::GaussianBlur to reduce noise before applying the Laplacian operator. Requires OpenCV imgproc module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
//! [reduce_noise]
// Reduce noise by blurring with a Gaussian filter ( kernel size = 3 )
gaussianBlur( src, src, Size(3, 3), 0, 0, BORDER_DEFAULT );
//! [reduce_noise]
```

----------------------------------------

TITLE: Using Simple Thresholding in OpenCV - JavaScript
DESCRIPTION: Implements simple thresholding where each pixel value is compared against a given threshold. If the pixel value is greater than the threshold, it is set to a specified max value; otherwise, it is set to zero. Key dependencies are the OpenCV library for JavaScript. Inputs include source and destination arrays, a threshold value, a maximum value, and the thresholding type. Outputs a binary image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_thresholding/js_thresholding.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
cv.threshold(src, dst, thresh, maxval, type);
```

----------------------------------------

TITLE: Detect Edges with Canny in OpenCV C++
DESCRIPTION: Uses OpenCV's Canny function in C++ to detect edges in an image. Requires input image and a corresponding output edge map.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
cv::Mat edges;
cv::Canny(gray, edges, lowThreshold, highThreshold);
```

----------------------------------------

TITLE: Writing and Reading Sequences (Vectors/Arrays) - OpenCV C++
DESCRIPTION: This C++ snippet demonstrates how to serialize and deserialize std::vector or similar sequence types into XML/YAML/JSON using OpenCV's FileStorage. Sequences are written using the << operator with special delimiters ([ ... ]). Reading uses FileNode and FileNodeIterator to iterate through the sequence. Requires knowledge of the vector's type; only handles types supported by OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
// Writing\nfs << "sequence" << "[" << 1 << 2 << 3 << "]";\n\n// Reading\nFileNode n = fs["sequence"];\nfor (FileNodeIterator it = n.begin(); it != n.end(); ++it) {\n    int value = (int)*it;\n    // process value\n}
```

----------------------------------------

TITLE: Create and Display Windows with OpenCV Python
DESCRIPTION: Creates a window to display an image using OpenCV in Python. Requires OpenCV module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_15

LANGUAGE: Python
CODE:
```
cv2.namedWindow("Source", cv2.WINDOW_AUTOSIZE)
cv2.imshow("Source", src)
```

----------------------------------------

TITLE: Projecting Object Bounding Box in C++
DESCRIPTION: This code applies the estimated homography transformation to project the object's bounding box from the first frame onto the current frame.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_tracking/akaze_tracking.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
perspectiveTransform(object_bb, new_bb, homography);
```

----------------------------------------

TITLE: Cloning Halide Git Repository
DESCRIPTION: This snippet shows how to clone the Halide repository from GitHub using git. It is used to obtain the Halide source code necessary for building the Halide library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown#2025-04-22_snippet_2

LANGUAGE: Git
CODE:
```
git clone https://github.com/halide/Halide.git
```

----------------------------------------

TITLE: Running OpenCV.js Build with Documentation Generation in Docker - Bash
DESCRIPTION: This command starts a Docker container using the previously built "opencv-js-doc" image, mounting the source directory and invoking the OpenCV.js build script with the '--build_doc' flag, which generates documentation alongside the build. Requires Docker, the custom image, and appropriate user permissions. Outputs documentation as well as the OpenCV.js build artifacts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_29

LANGUAGE: bash
CODE:
```
docker run --rm -v $(pwd):/src -u $(id -u):$(id -g) "opencv-js-doc" emcmake python3 ./platforms/js/build_js.py build_js --build_doc
```

----------------------------------------

TITLE: Applying the Standard Hough Line Transform in OpenCV (Java)
DESCRIPTION: This code applies the OpenCV HoughLines function in Java to detect lines in an image. It takes a binary edge map and stores detected lines in a Mat. Key parameters are rho resolution, theta resolution, and threshold. Requires prior edge detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
Mat lines = new Mat();\nImgproc.HoughLines(edges, lines, 1, Math.PI/180, 150, 0, 0);\n
```

----------------------------------------

TITLE: K-Means Distance Formula in LaTeX
DESCRIPTION: Mathematical formula showing the optimization objective of K-Means clustering, which minimizes the sum of distances between points and their corresponding centroids.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_understanding/py_kmeans_understanding.markdown#2025-04-22_snippet_0

LANGUAGE: latex
CODE:
```
minimize \;\bigg[J = \sum_{All\: Red\_Points}distance(C1,Red\_Point) + \sum_{All\: Blue\_Points}distance(C2,Blue\_Point)\bigg]
```

----------------------------------------

TITLE: Configuring OpenCV.js Loader Paths and Usage - JavaScript
DESCRIPTION: Configures path options for various OpenCV.js builds (wasm, threads, simd, threadsSimd) and calls the loadOpenCV function with these settings and a main callback. Dependency: loader.js must be included and WebAssembly Feature Detection (UMD version) provided. Parameters: pathsConfig object specifying file paths and a main function callback. No direct output; OpenCV.js loads asynchronously via the loader.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_7

LANGUAGE: javascript
CODE:
```
// Set paths configuration\nlet pathsConfig = {\n    wasm: "../../build_wasm/opencv.js",\n    threads: "../../build_mt/opencv.js",\n    simd: "../../build_simd/opencv.js",\n    threadsSimd: "../../build_mtSIMD/opencv.js",\n}\n\n// Load OpenCV.js and use the pathsConfiguration and main function as the params.\nloadOpenCV(pathsConfig, main);
```

----------------------------------------

TITLE: Warping Image with OpenCV warpPerspective - Python
DESCRIPTION: With OpenCV’s cv2.warpPerspective, this Python snippet applies a computed homography to warp the source image to a new perspective. Requires cv2, homography (numpy array), and image. Returns warped output; destination size must be defined. Useful for visual perspective correction tasks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_15

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/features2D/Homography/perspective_correction.py warp-chessboard
```

----------------------------------------

TITLE: Building OpenCV with contrib modules on Linux
DESCRIPTION: Quick start script for building OpenCV with contrib modules on Linux. It downloads both core and contrib sources, creates a build directory, configures CMake with contrib modules, and builds the project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.x.zip
unzip opencv.zip
unzip opencv_contrib.zip
mkdir -p build && cd build
cmake -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib-4.x/modules ../opencv-4.x
cmake --build .
```

----------------------------------------

TITLE: Edge Detection using Canny Detector in OpenCV (Java)
DESCRIPTION: This snippet demonstrates edge detection using OpenCV's Canny function in Java. The source image is converted to grayscale before applying the detector, with specific threshold parameters. Inputs are the image and thresholds; output is a Mat representing edges. Requires OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_4

LANGUAGE: Java
CODE:
```
Mat src_gray = new Mat();\nImgproc.cvtColor(src, src_gray, Imgproc.COLOR_BGR2GRAY);\nMat edges = new Mat();\nImgproc.Canny(src_gray, edges, 50, 200, 3, false);\n
```

----------------------------------------

TITLE: Performing Erosion with OpenCV in Python
DESCRIPTION: This Python snippet focuses on implementing the erosion operation using OpenCV's cv::erode function. It takes a source image and a kernel, whose shape and size can be specified via cv::getStructuringElement. Required dependencies: OpenCV-Python. Inputs: source image (src), kernel (element). Outputs: eroded image. The kernel shape may be one of MORPH_RECT, MORPH_CROSS, or MORPH_ELLIPSE. The anchor point defaults to the center if not provided. This function performs basic erosion without exposing additional advanced parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_6

LANGUAGE: Python
CODE:
```
@snippet python/tutorial_code/imgProc/erosion_dilatation/morphology_1.py erosion
```

LANGUAGE: Python
CODE:
```
@snippet python/tutorial_code/imgProc/erosion_dilatation/morphology_1.py kernel
```

----------------------------------------

TITLE: CSV Formatting for OpenCV Mat Output in C++
DESCRIPTION: Demonstrates formatting OpenCV Mat output as comma-separated values (CSV) using the format() method with FormatCSV flag.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_12

LANGUAGE: C++
CODE:
```
cout << "R (csv) = " << endl << format(R, Formatter::FMT_CSV) << endl << endl;
```

----------------------------------------

TITLE: Final Visualization Call in Java using OpenCV
DESCRIPTION: Illustrates drawing the detected contour and calling `getOrientation`, which internally draws the PCA axes and center point onto the source image `src`. This occurs within the loop iterating over filtered contours.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_13

LANGUAGE: java
CODE:
```
//! [visualization1]
    // Draw each contour only for visualisation purposes
    drawContours(src, contours, i, new Scalar(0, 0, 255), 2);
    // Find the orientation of each shape
    getOrientation(contours.get(i), src);
//! [visualization1]
```

----------------------------------------

TITLE: Applying Gaussian Blur with OpenCV in C++
DESCRIPTION: This C++ snippet showcases the use of OpenCV's GaussianBlur() function to apply a Gaussian filter for image smoothing. It requires OpenCV and kernel size, and standard deviation parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
@snippet cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp gaussianblur
```

----------------------------------------

TITLE: Implementing Dense Optical Flow in Java
DESCRIPTION: Java implementation of dense optical flow using Farneback's algorithm (calcOpticalFlowFarneback()). The code computes the optical flow for all points in the frame and visualizes the flow field using HSV color coding where hue represents direction and value represents magnitude.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/optical_flow.markdown#2025-04-22_snippet_5

LANGUAGE: java
CODE:
```
import java.util.ArrayList;
import java.util.List;

import org.opencv.core.Core;
import org.opencv.core.CvType;
import org.opencv.core.Mat;
import org.opencv.core.Scalar;
import org.opencv.highgui.HighGui;
import org.opencv.imgproc.Imgproc;
import org.opencv.video.Video;
import org.opencv.videoio.VideoCapture;

class OpticalFlowDense {
    public void run(String[] args) {
        String filename = args[0];
        VideoCapture capture = new VideoCapture(filename);
        if (!capture.isOpened()) {
            System.out.println("Could not open the input video: " + filename);
            System.exit(0);
        }

        Mat frame1 = new Mat();
        capture.read(frame1);
        Mat prvs = new Mat();
        Imgproc.cvtColor(frame1, prvs, Imgproc.COLOR_BGR2GRAY);

        while (true) {
            Mat frame2 = new Mat(), next = new Mat();
            capture.read(frame2);
            if (frame2.empty()) {
                break;
            }
            Imgproc.cvtColor(frame2, next, Imgproc.COLOR_BGR2GRAY);

            Mat flow = new Mat(prvs.size(), CvType.CV_32FC2);
            Video.calcOpticalFlowFarneback(prvs, next, flow, 0.5, 3, 15, 3, 5, 1.2, 0);

            // visualization
            List<Mat> flowParts = new ArrayList<>(2);
            Core.split(flow, flowParts);
            Mat magnitude = new Mat(), angle = new Mat(), magnNorm = new Mat();
            Core.cartToPolar(flowParts.get(0), flowParts.get(1), magnitude, angle, true);
            Core.normalize(magnitude, magnNorm, 0.0, 1.0, Core.NORM_MINMAX);
            // build hsv image
            angle.convertTo(angle, CvType.CV_32F, ((1.f / 360.f) * (180.f / 255.f)));
            Mat hsv_parts[] = { angle, Mat.ones(angle.size(), CvType.CV_32F), magnNorm };
            Mat hsv = new Mat();
            Core.merge(hsv_parts, hsv);
            Mat bgr = new Mat();
            Imgproc.cvtColor(hsv, bgr, Imgproc.COLOR_HSV2BGR);
            bgr.convertTo(bgr, CvType.CV_8UC3, 255.0);

            HighGui.imshow("frame2", bgr);

            int keyboard = HighGui.waitKey(30);
            if (keyboard == 'q' || keyboard == 27) {
                break;
            }
            prvs = next;
        }

        System.exit(0);
    }
}

public class OpticalFlowDenseDemo {
    public static void main(String[] args) {
        // Load the native OpenCV library
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);

        new OpticalFlowDense().run(args);
    }
}
```

----------------------------------------

TITLE: Initializing Animation Structure in OpenCV
DESCRIPTION: Demonstrates how to initialize a cv::Animation structure to hold frames from an animated image file. This structure is essential for handling animated image data in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/animations.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
cv::Animation animation;
```

LANGUAGE: Python
CODE:
```
animation = {}
```

----------------------------------------

TITLE: OpenCV XML Output Format Example
DESCRIPTION: Example of the XML output format produced by OpenCV's file writing operations, showing how various data types are serialized.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_22

LANGUAGE: xml
CODE:
```
<?xml version="1.0"?>
<opencv_storage>
<iterationNr>100</iterationNr>
<strings>
  image1.jpg Awesomeness baboon.jpg</strings>
<Mapping>
  <One>1</One>
  <Two>2</Two></Mapping>
<R type_id="opencv-matrix">
  <rows>3</rows>
  <cols>3</cols>
  <dt>u</dt>
  <data>
    1 0 0 0 1 0 0 0 1</data></R>
<T type_id="opencv-matrix">
  <rows>3</rows>
  <cols>1</cols>
  <dt>d</dt>
  <data>
    0. 0. 0.</data></T>
<MyData>
  <A>97</A>
  <X>3.1415926535897931e+000</X>
  <id>mydata1234</id></MyData>
</opencv_storage>
```

----------------------------------------

TITLE: Final Visualization Call in C++ using OpenCV
DESCRIPTION: This snippet shows the final step where the contours and PCA results (axes and center) are drawn onto the source image within the main loop after PCA calculation. It uses `drawContours` and relies on the `getOrientation` function having already modified the `src` image by calling `drawAxis`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
//! [visualization1]
    // Draw each contour only for visualisation purposes
    drawContours(src, contours, static_cast<int>(i), Scalar(0, 0, 255), 2);
    // Find the orientation of each shape
    getOrientation(contours[i], src);
//! [visualization1]
```

----------------------------------------

TITLE: Step Functor for GpuMat Iterator Traversal
DESCRIPTION: A functor that calculates memory offsets to correctly traverse a pitched matrix in GPU memory. It takes a linear index and converts it to the appropriate memory location.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
template<typename T>
struct step_functor : public thrust::unary_function<int, int>
{
    int columns;
    int rows;
    int step;

    __host__ __device__ step_functor(int columns_, int rows_, int step_) : 
        columns(columns_), rows(rows_), step(step_) {}

    __host__ __device__ int operator()(int linear_idx) const
    {
        int row = linear_idx / columns;
        int column = linear_idx % columns;

        return row * step + column;
    }
};
```

----------------------------------------

TITLE: Complete Histogram Backprojection Implementation with OpenCV in Python
DESCRIPTION: A full implementation of histogram backprojection using OpenCV's built-in calcBackProject function. This code loads target and reference images, calculates and normalizes histograms, applies backprojection, filters the result with a disc kernel, and segments the object using thresholding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_backprojection/py_histogram_backprojection.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

roi = cv.imread('rose_red.png')
assert roi is not None, "file could not be read, check with os.path.exists()"
hsv = cv.cvtColor(roi,cv.COLOR_BGR2HSV)

target = cv.imread('rose.png')
assert target is not None, "file could not be read, check with os.path.exists()"
hsvt = cv.cvtColor(target,cv.COLOR_BGR2HSV)

# calculating object histogram
roihist = cv.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )

# normalize histogram and apply backprojection
cv.normalize(roihist,roihist,0,255,cv.NORM_MINMAX)
dst = cv.calcBackProject([hsvt],[0,1],roihist,[0,180,0,256],1)

# Now convolute with circular disc
disc = cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))
cv.filter2D(dst,-1,disc,dst)

# threshold and binary AND
ret,thresh = cv.threshold(dst,50,255,0)
thresh = cv.merge((thresh,thresh,thresh))
res = cv.bitwise_and(target,thresh)

res = np.vstack((target,thresh,res))
cv.imwrite('res.jpg',res)
```

----------------------------------------

TITLE: Implementing Unsharp Mask Operation with G-API
DESCRIPTION: Function that creates an unsharp mask using G-API operations including Gaussian blur, subtraction and addition to enhance image details.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
// Unsharp mask implementation
inline cv::GMat unsharpMask(const cv::GMat& src) {
    // Gaussian blur with kernel size 3x3 and sigma=0.8
    cv::GMat blurred = cv::gapi::gaussianBlur(src, cv::Size(3,3), 0.8, 0.8);
    // Unsharp mask formula: src + WEIGHT * (src - blurred)
    return src + 0.7 * (src - blurred);
}
```

----------------------------------------

TITLE: Including Full Template Matching Demo Code (Python)
DESCRIPTION: Reference to include the complete Python source code file for the OpenCV template matching demonstration. This script loads images, performs matching with `cv2.matchTemplate`, normalizes the result using `cv2.normalize`, finds the best match location with `cv2.minMaxLoc`, and displays the result using `cv2.imshow`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_9

LANGUAGE: python
CODE:
```
@include samples/python/tutorial_code/imgProc/match_template/match_template.py
```

----------------------------------------

TITLE: Selecting Region of Interest (ROI) with OpenCV in C++
DESCRIPTION: Extracts a rectangular subregion from a cv::Mat using cv::Rect in C++. The syntax returns a Mat header referencing the ROI. Input is a cv::Mat and cv::Rect(x, y, w, h). Changes to ROI affect parent Mat.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_31

LANGUAGE: C++
CODE:
```
cv::Mat roi = img(cv::Rect(x, y, w, h));
```

----------------------------------------

TITLE: Updating Kalman Filter with Pose Measurements in C++ (OpenCV)
DESCRIPTION: This C++ snippet demonstrates the logic for updating an OpenCV Kalman Filter (Step 5 of the algorithm) based on pose estimation results from RANSAC/PnP. It checks if the number of inliers found (`inliers_idx.rows`) meets a minimum threshold (`minInliersKalman`). If the measurement is considered good, it retrieves the translation (`translation_measured`) and rotation (`rotation_measured`) matrices from a `pnp_detection` object. It then calls `fillMeasurements` to format these into the `measurements` vector and finally calls `updateKalmanFilter` to incorporate this measurement and refine the estimated state (translation and rotation).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_23

LANGUAGE: cpp
CODE:
```
// -- Step 5: Kalman Filter

// GOOD MEASUREMENT
if( inliers_idx.rows >= minInliersKalman )
{

    // Get the measured translation
    cv::Mat translation_measured(3, 1, CV_64F);
    translation_measured = pnp_detection.get_t_matrix();

    // Get the measured rotation
    cv::Mat rotation_measured(3, 3, CV_64F);
    rotation_measured = pnp_detection.get_R_matrix();

    // fill the measurements vector
    fillMeasurements(measurements, translation_measured, rotation_measured);

}

// Instantiate estimated translation and rotation
cv::Mat translation_estimated(3, 1, CV_64F);
cv::Mat rotation_estimated(3, 3, CV_64F);

// update the Kalman filter with good measurements
updateKalmanFilter( KF, measurements,
              translation_estimated, rotation_estimated);
```

----------------------------------------

TITLE: Approximating Contours in Python with OpenCV
DESCRIPTION: This snippet demonstrates contour approximation using the Douglas-Peucker algorithm via cv.approxPolyDP(). It reduces the number of vertices in a contour shape based on the specified epsilon value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
epsilon = 0.1*cv.arcLength(cnt,True)
approx = cv.approxPolyDP(cnt,epsilon,True)
```

----------------------------------------

TITLE: Implementing Shi-Tomasi Corner Detection in Python
DESCRIPTION: Python implementation of the Shi-Tomasi corner detection algorithm using OpenCV's goodFeaturesToTrack function. This sample code shows how to detect corners in an image using Python with OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/good_features_to_track/good_features_to_track.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
This tutorial code's is shown lines below. You can also download it from
[here](https://github.com/opencv/opencv/tree/4.x/samples/python/tutorial_code/TrackingMotion/good_features_to_track/goodFeaturesToTrack_Demo.py)
```

----------------------------------------

TITLE: Applying Frequency Domain Filter to Image using OpenCV C++
DESCRIPTION: Filters an input image `inputImg` using a provided frequency domain filter `H` (e.g., a Wiener filter). The function computes the DFT of the input image, performs element-wise multiplication with the complex conjugate of the filter `H` in the frequency domain, computes the inverse DFT of the result, and stores the real part of the inverse transform in the `outputImg`. Requires OpenCV `dft`, `idft`, `mulSpectrums`, `Mat` operations and complex number handling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/out_of_focus_deblur_filter/out_of_focus_deblur_filter.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
void filter2DFreq(const Mat& inputImg, Mat& outputImg, const Mat& H)
{
    Mat planes[2] = { Mat_<float>(inputImg.clone()), Mat::zeros(inputImg.size(), CV_32F) };
    Mat complexI;
    merge(planes, 2, complexI);
    dft(complexI, complexI, DFT_SCALE);

    Mat planesH[2] = { Mat_<float>(H.clone()), Mat::zeros(H.size(), CV_32F) };
    Mat complexH;
    merge(planesH, 2, complexH);
    Mat complexIH;
    mulSpectrums(complexI, complexH, complexIH, 0);

    idft(complexIH, complexIH);
    split(complexIH, planes);
    outputImg = planes[0];
}
```

----------------------------------------

TITLE: Implementing Custom Corner Detectors in Java
DESCRIPTION: Java implementation of custom Harris and Shi-Tomasi corner detectors using OpenCV functions. Includes image processing, corner detection, and result visualization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/generic_corner_detector/generic_corner_detector.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;\nimport org.opencv.highgui.HighGui;\nimport org.opencv.imgcodecs.Imgcodecs;\nimport org.opencv.imgproc.Imgproc;\n\nclass CornerDetectorDemo {\n    private Mat src = new Mat();\n    private Mat srcGray = new Mat();\n    private Mat myHarris_dst = new Mat();\n    private Mat myHarris_copy = new Mat();\n    private Mat Mc = new Mat();\n    private Mat myShiTomasi_dst = new Mat();\n    private Mat myShiTomasi_copy = new Mat();\n\n    private int myShiTomasi_qualityLevel = 50;\n    private int myHarris_qualityLevel = 50;\n    private int max_qualityLevel = 100;\n\n    private double myHarris_minVal;\n    private double myHarris_maxVal;\n    private double myShiTomasi_minVal;\n    private double myShiTomasi_maxVal;\n\n    private Random rng = new Random(12345);\n\n    private String myHarris_window = "My Harris corner detector";\n    private String myShiTomasi_window = "My Shi Tomasi corner detector";\n\n    public void run(String[] args) {\n        String filename = args.length > 0 ? args[0] : "../data/pic3.png";\n        src = Imgcodecs.imread(filename);\n        if (src.empty()) {\n            System.err.println("Cannot read image: " + filename);\n            System.exit(0);\n        }\n\n        Imgproc.cvtColor(src, srcGray, Imgproc.COLOR_BGR2GRAY);\n\n        int blockSize = 3;\n        int apertureSize = 3;\n\n        Imgproc.cornerEigenValsAndVecs(srcGray, myHarris_dst, blockSize, apertureSize, Imgproc.BORDER_DEFAULT);\n\n        /* calculate Mc */\n        Mc = Mat.zeros(srcGray.size(), CvType.CV_32F);\n\n        for (int j = 0; j < srcGray.rows(); j++) {\n            for (int i = 0; i < srcGray.cols(); i++) {\n                float[] vecData = new float[(int) (myHarris_dst.total() * myHarris_dst.channels())];\n                myHarris_dst.get(j, i, vecData);\n                float lambda_1 = vecData[0];\n                float lambda_2 = vecData[1];\n                Mc.put(j, i, lambda_1 * lambda_2 - 0.04f * ((lambda_1 + lambda_2) * (lambda_1 + lambda_2)));\n            }\n        }\n\n        Core.MinMaxLocResult res = Core.minMaxLoc(Mc);\n        myHarris_minVal = res.minVal;\n        myHarris_maxVal = res.maxVal;\n\n        /* Create Window and Trackbar */\n        HighGui.namedWindow(myHarris_window);\n        HighGui.createTrackbar("Quality Level:", myHarris_window, new int[] { myHarris_qualityLevel }, max_qualityLevel,\n                new HighGui.TrackbarCallback() {\n                    @Override\n                    public void onChange(int pos, Object userData) {\n                        myHarris_function(pos, userData);\n                    }\n                });\n        myHarris_function(0, null);\n\n        Imgproc.cornerMinEigenVal(srcGray, myShiTomasi_dst, blockSize, apertureSize, Imgproc.BORDER_DEFAULT);\n\n        res = Core.minMaxLoc(myShiTomasi_dst);\n        myShiTomasi_minVal = res.minVal;\n        myShiTomasi_maxVal = res.maxVal;\n\n        /* Create Window and Trackbar */\n        HighGui.namedWindow(myShiTomasi_window);\n        HighGui.createTrackbar("Quality Level:", myShiTomasi_window, new int[] { myShiTomasi_qualityLevel },\n                max_qualityLevel, new HighGui.TrackbarCallback() {\n                    @Override\n                    public void onChange(int pos, Object userData) {\n                        myShiTomasi_function(pos, userData);\n                    }\n                });\n        myShiTomasi_function(0, null);\n\n        HighGui.waitKey();\n        System.exit(0);\n    }\n\n    private void myShiTomasi_function(int qualityLevel, Object userData) {\n        myShiTomasi_copy = src.clone();\n        myShiTomasi_qualityLevel = Math.max(qualityLevel, 1);\n\n        for (int j = 0; j < srcGray.rows(); j++) {\n            for (int i = 0; i < srcGray.cols(); i++) {\n                float[] pixelData = new float[1];\n                myShiTomasi_dst.get(j, i, pixelData);\n                if (pixelData[0] > myShiTomasi_minVal + (myShiTomasi_maxVal - myShiTomasi_minVal) * myShiTomasi_qualityLevel\n                        / max_qualityLevel) {\n                    Imgproc.circle(myShiTomasi_copy, new Point(i, j), 4,\n                            new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Imgproc.FILLED);\n                }\n            }\n        }\n        HighGui.imshow(myShiTomasi_window, myShiTomasi_copy);\n    }\n\n    private void myHarris_function(int qualityLevel, Object userData) {\n        myHarris_copy = src.clone();\n        myHarris_qualityLevel = Math.max(qualityLevel, 1);\n\n        for (int j = 0; j < srcGray.rows(); j++) {\n            for (int i = 0; i < srcGray.cols(); i++) {\n                float[] pixelData = new float[1];\n                Mc.get(j, i, pixelData);\n                if (pixelData[0] > myHarris_minVal\n                        + (myHarris_maxVal - myHarris_minVal) * myHarris_qualityLevel / max_qualityLevel) {\n                    Imgproc.circle(myHarris_copy, new Point(i, j), 4,\n                            new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Imgproc.FILLED);\n                }\n            }\n        }\n        HighGui.imshow(myHarris_window, myHarris_copy);\n    }\n}\n\npublic class CornerDetectorDemoRun {\n    public static void main(String[] args) {\n        // Load the native OpenCV library\n        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);\n        new CornerDetectorDemo().run(args);\n    }\n}
```

----------------------------------------

TITLE: Configuring Class Labels in labelmap.prototxt (Protobuf)
DESCRIPTION: Defines the content for the `labelmap.prototxt` file used by Caffe. This file maps human-readable class names ('background', 'face') to numerical labels (0, 1) used internally during model training and inference. It's a required component for SSD training data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/face_detector/how_to_train_face_detector.txt#2025-04-22_snippet_1

LANGUAGE: protobuf
CODE:
```
item {
  name: "none_of_the_above"
  label: 0
  display_name: "background"
}
item {
  name: "face"
  label: 1
  display_name: "face"
}
```

----------------------------------------

TITLE: Draw Contours on Mat in OpenCV Python
DESCRIPTION: Initializes a Mat canvas to draw contour shapes, using OpenCV in Python to randomize colors for contours, bounding boxes, and circles. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_20

LANGUAGE: Python
CODE:
```
import numpy as np
import random
drawing = np.zeros((edges.shape[0], edges.shape[1], 3), dtype=np.uint8)
for i in range(len(contours)):
    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
    cv2.drawContours(drawing, contours, i, color)
    cv2.rectangle(drawing, bound_rect[:2], (bound_rect[0]+bound_rect[2], bound_rect[1]+bound_rect[3]), color, 2)
    cv2.circle(drawing, (int(center[0]), int(center[1])), int(radius), color, 2)
```

----------------------------------------

TITLE: Matching Keypoints Using 2-nn Matcher in C++
DESCRIPTION: This code performs keypoint matching between the first frame and the current frame using a 2-nearest neighbor matcher. It filters matches based on a distance ratio test.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_tracking/akaze_tracking.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
matcher->knnMatch(first_desc, desc, matches, 2);
for(unsigned i = 0; i < matches.size(); i++) {
    if(matches[i][0].distance < nn_match_ratio * matches[i][1].distance) {
        matched1.push_back(first_kp[matches[i][0].queryIdx]);
        matched2.push_back(      kp[matches[i][0].trainIdx]);
    }
}
```

----------------------------------------

TITLE: Implementing Shi-Tomasi Corner Detection in C++
DESCRIPTION: C++ implementation of the Shi-Tomasi corner detection algorithm using OpenCV's goodFeaturesToTrack function. This sample code demonstrates how to detect corners in an image and visualize the results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/good_features_to_track/good_features_to_track.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
This tutorial code's is shown lines below. You can also download it from
[here](https://github.com/opencv/opencv/tree/4.x/samples/cpp/tutorial_code/TrackingMotion/goodFeaturesToTrack_Demo.cpp)
```

----------------------------------------

TITLE: Loading an Image from File in Grayscale with OpenCV in C++
DESCRIPTION: Demonstrates reading an image file as a single-channel grayscale using OpenCV in C++. The imread function is passed cv::IMREAD_GRAYSCALE to convert the loaded image. Requires OpenCV libraries. Input is file path, output is a grayscale cv::Mat. Useful for algorithms expecting single channel intensities.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
cv::Mat img_gray = cv::imread("my_image.jpg", cv::IMREAD_GRAYSCALE);
```

----------------------------------------

TITLE: Rotating Images in OpenCV Python
DESCRIPTION: Demonstrates image rotation using cv.getRotationMatrix2D() and cv.warpAffine(). This example rotates the image by 90 degrees with respect to its center without scaling, using a custom transformation matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
rows,cols = img.shape

# cols-1 and rows-1 are the coordinate limits.
M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)
dst = cv.warpAffine(img,M,(cols,rows))
```

----------------------------------------

TITLE: Running Segmentation Test Mode
DESCRIPTION: Command to run the model in test mode, which performs inference on a single image. The command allows specifying whether to use default preprocessing parameters or custom values for scale, mean, and standard deviation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_11

LANGUAGE: bash
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.segmentation.py_to_py_segm --test True --default_img_preprocess <True/False> --evaluate False
```

----------------------------------------

TITLE: Image Subtraction with OpenCV.js
DESCRIPTION: Shows how to subtract two images using cv.subtract() function. Both input images must have the same depth and type. When used with RGBA images, the alpha channel is also subtracted.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_image_arithmetics/js_image_arithmetics.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
let src1 = cv.imread("canvasInput1");
let src2 = cv.imread("canvasInput2");
let dst = new cv.Mat();
let mask = new cv.Mat();
let dtype = -1;
cv.subtract(src1, src2, dst, mask, dtype);
src1.delete(); src2.delete(); dst.delete(); mask.delete();
```

----------------------------------------

TITLE: Loading Video Input for Detection - OpenCV C++
DESCRIPTION: Illustrates opening and reading video input using OpenCV's VideoCapture in C++. It is essential for capturing the scene required for real-time detection of the object. Assumes presence of a video file at the specified path.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
cv::VideoCapture cap;                // instantiate VideoCapture
cap.open(video_read_path);           // open a recorded video

if(!cap.isOpened())                  // check if we succeeded
{
   std::cout << "Could not open the camera device" << std::endl;

```

----------------------------------------

TITLE: Cropping and Saving Calibrated Image in OpenCV with Python
DESCRIPTION: This code snippet demonstrates how to crop a calibrated image using a region of interest (ROI) and save the result. It extracts a portion of the destination image based on x, y, width, and height coordinates and writes it to a file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
# crop the image
x, y, w, h = roi
dst = dst[y:y+h, x:x+w]
cv.imwrite('calibresult.png', dst)
```

----------------------------------------

TITLE: Implementing Perspective Transformation in OpenCV Python
DESCRIPTION: Demonstrates perspective transformation using cv.getPerspectiveTransform() and cv.warpPerspective(). This transformation allows rectifying an image by mapping it from one plane to another, requiring four source and destination point pairs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
img = cv.imread('sudoku.png')
assert img is not None, "file could not be read, check with os.path.exists()"
rows,cols,ch = img.shape

pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])

M = cv.getPerspectiveTransform(pts1,pts2)

dst = cv.warpPerspective(img,M,(300,300))

plt.subplot(121),plt.imshow(img),plt.title('Input')
plt.subplot(122),plt.imshow(dst),plt.title('Output')
plt.show()
```

----------------------------------------

TITLE: Constructing RotatedRect Structures in OpenCV.js (JavaScript)
DESCRIPTION: Demonstrates the construction of a RotatedRect structure using cv.RotatedRect and an object literal with center, size, and angle properties. RotatedRect represents rectangles with arbitrary orientation. Requires OpenCV.js and valid input values for center, dimensions, and angle.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_5

LANGUAGE: JavaScript
CODE:
```
// The first way
let rotatedRect = new cv.RotatedRect(center, size, angle);
// The second way
let rotatedRect = {center : center, size : size, angle : angle};
```

----------------------------------------

TITLE: Generating ChArUco Board Pattern with Predefined Dictionary using Python Script (Shell)
DESCRIPTION: Runs 'gen_pattern.py' to create a ChArUco board pattern ('charuco_board') saved as 'charuco_board.svg'. Specifies 7 rows, 5 columns, a square size of 30mm, and an ArUco marker size of 15mm. It uses a predefined ArUco dictionary ('DICT_5X5_100') provided in a compressed JSON file. Requires Python, the 'gen_pattern.py' script, and the specified dictionary file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_pattern/camera_calibration_pattern.markdown#2025-04-22_snippet_4

LANGUAGE: shell
CODE:
```
python gen_pattern.py -o charuco_board.svg --rows 7 --columns 5 -T charuco_board --square_size 30 --marker_size 15 -f DICT_5X5_100.json.gz
```

----------------------------------------

TITLE: Loading and Predicting with TensorFlow and OpenCV Models
DESCRIPTION: This Python code block demonstrates reading TensorFlow and optimized OpenCV model graphs, preparing input data, and performing inference. Dependencies include the TensorFlow and OpenCV libraries. The outputs are segmentation masks and visualization using OpenCV's imshow function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
# get TF model graph from the obtained frozen graph
deeplab_graph = read_deeplab_frozen_graph(deeplab_frozen_graph_path)

# read DeepLab frozen graph with OpenCV API
opencv_net = cv2.dnn.readNetFromTensorflow(opt_deeplab_frozen_graph_path)
print("OpenCV model was successfully read. Model layers: \n", opencv_net.getLayerNames())

# get processed image
original_img_shape, tf_input_blob, opencv_input_img = get_processed_imgs("test_data/sem_segm/2007_000033.jpg")

# obtain OpenCV DNN predictions
opencv_prediction = get_opencv_dnn_prediction(opencv_net, opencv_input_img)

# obtain TF model predictions
tf_prediction = get_tf_dnn_prediction(deeplab_graph, tf_input_blob)

# get PASCAL VOC classes and colors
pascal_voc_classes, pascal_voc_colors = read_colors_info("test_data/sem_segm/pascal-classes.txt")

# obtain colored segmentation masks
opencv_colored_mask = get_colored_mask(original_img_shape, opencv_prediction, pascal_voc_colors)
tf_colored_mask = get_tf_colored_mask(original_img_shape, tf_prediction, pascal_voc_colors)

# obtain palette of PASCAL VOC colors
color_legend = get_legend(pascal_voc_classes, pascal_voc_colors)

cv2.imshow('TensorFlow Colored Mask', tf_colored_mask)
cv2.imshow('OpenCV DNN Colored Mask', opencv_colored_mask)

cv2.imshow('Color Legend', color_legend)
```

----------------------------------------

TITLE: Extracting Face Features for Recognition - OpenCV DNN Python
DESCRIPTION: This snippet shows how to use FaceRecognizerSF in Python to extract deep features from a detected and aligned face. The feature function takes the input image and detected face bounding box. The output is a floating-point feature array suitable for face comparison or matching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
# Extract features for recognition
face_feature = recognizer.feature(image, face_box)
# 'face_feature' is a numpy array describing the face embedding
```

----------------------------------------

TITLE: Initializing OpenCV Logistic Regression Parameters in C++
DESCRIPTION: This C++ snippet demonstrates how to create an instance of the `cv::ml::LogisticRegression` classifier and configure its training parameters. It sets the learning rate, number of iterations, regularization type (L2), training method (Mini-Batch), and mini-batch size using the respective setter methods provided by the class. This setup prepares the classifier for training.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ml/doc/ml_intro.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
// A sample set of training parameters for the Logistic Regression classifier can be initialized as follows:
//! [init]
Ptr<LogisticRegression> lr = LogisticRegression::create();
lr->setLearningRate(0.001);
lr->setIterations(10);
lr->setRegularization(LogisticRegression::REG_L2);
lr->setTrainMethod(LogisticRegression::MINI_BATCH);
lr->setMiniBatchSize(1);
//! [init]
```

----------------------------------------

TITLE: Retrieving Contours With RETR_LIST in OpenCV Python
DESCRIPTION: This snippet demonstrates how to use OpenCV's RETR_LIST retrieval mode for extracting contours without creating a hierarchy. It treats all contours as being on the same level, indicated by -1 in the hierarchy structure for parent and child fields.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_hierarchy/py_contours_hierarchy.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
>>> hierarchy
array([[[ 1, -1, -1, -1],
        [ 2,  0, -1, -1],
        [ 3,  1, -1, -1],
        [ 4,  2, -1, -1],
        [ 5,  3, -1, -1],
        [ 6,  4, -1, -1],
        [ 7,  5, -1, -1],
        [-1,  6, -1, -1]]])
```

----------------------------------------

TITLE: Verifying Pkg-config for AArch64 (Bash)
DESCRIPTION: Tests the `pkg-config` setup for the `aarch64` architecture. It sets environment variables (`PKG_CONFIG_PATH`, `PKG_CONFIG_LIBDIR`, `PKG_CONFIG_SYSROOT_DIR`) to point `pkg-config` to the correct directories for `aarch64` libraries and then lists all discoverable packages for that architecture.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_11

LANGUAGE: bash
CODE:
```
PKG_CONFIG_PATH=/usr/lib/aarch64-linux-gnu/pkgconfig:/usr/share/pkgconfig \
    PKG_CONFIG_LIBDIR=/usr/lib/aarch64-linux-gnu \
    PKG_CONFIG_SYSROOT_DIR=/ \
      pkg-config --list-all
```

----------------------------------------

TITLE: Brute-Force Matching with OpenCV in C++
DESCRIPTION: The code uses a brute-force matcher with Hamming distance in C++ to find matches between the computed descriptors of the images using OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
samples/cpp/tutorial_code/features2D/AKAZE_match.cpp 2-nn matching
```

----------------------------------------

TITLE: Converting PaddleSeg Model to ONNX Format (Shell)
DESCRIPTION: Uses the `paddle2onnx` command-line tool to convert the downloaded PaddleSeg inference model files (`model.pdmodel`, `model.pdiparams`) located in the `humanseg_hrnet18_small_v1` directory into an ONNX file (`humanseg_hrnet18_tiny.onnx`). It specifies ONNX opset version 11 for compatibility. Note that the model must have a fixed input shape.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/dnn_model_runner/dnn_conversion/paddlepaddle/README.md#2025-04-22_snippet_3

LANGUAGE: shell
CODE:
```
paddle2onnx --model_dir humanseg_hrnet18_small_v1 \
            --model_filename model.pdmodel \
            --params_filename model.pdiparams \
            --opset_version 11 \
            --save_file humanseg_hrnet18_tiny.onnx
```

----------------------------------------

TITLE: Executing PyTorch-OpenCV Segmentation Pipeline in Python
DESCRIPTION: This Python script demonstrates the end-to-end process of using a PyTorch FCN ResNet-50 segmentation model. It initializes the PyTorch model, converts it to ONNX format (via `get_pytorch_onnx_model`), reads the ONNX model using OpenCV DNN (`cv2.dnn.readNetFromONNX`), preprocesses an input image (`get_processed_imgs`), performs inference using both the original PyTorch model (`get_pytorch_dnn_prediction`) and the converted OpenCV model (`get_opencv_dnn_prediction`), generates colored segmentation masks based on PASCAL VOC classes (`read_colors_info`, `get_colored_mask`), creates a color legend (`get_legend`), and finally displays the original image, the masks, and the legend using OpenCV's `imshow`. Dependencies include `torch`, `torchvision.models`, `cv2`, and potentially custom helper functions (`get_pytorch_onnx_model`, `get_processed_imgs`, `get_opencv_dnn_prediction`, `get_pytorch_dnn_prediction`, `read_colors_info`, `get_colored_mask`, `get_legend`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
# initialize PyTorch FCN ResNet-50 model
original_model = models.segmentation.fcn_resnet50(pretrained=True)

# get the path to the converted into ONNX PyTorch model
full_model_path = get_pytorch_onnx_model(original_model)

# read converted .onnx model with OpenCV API
opencv_net = cv2.dnn.readNetFromONNX(full_model_path)
print("OpenCV model was successfully read. Layer IDs: \n", opencv_net.getLayerNames())

# get preprocessed image
img, input_img = get_processed_imgs("test_data/sem_segm/2007_000033.jpg")

# obtain OpenCV DNN predictions
opencv_prediction = get_opencv_dnn_prediction(opencv_net, input_img)

# obtain original PyTorch ResNet50 predictions
pytorch_prediction = get_pytorch_dnn_prediction(original_model, input_img)

pascal_voc_classes, pascal_voc_colors = read_colors_info("test_data/sem_segm/pascal-classes.txt")

# obtain colored segmentation masks
opencv_colored_mask = get_colored_mask(img.shape, opencv_prediction, pascal_voc_colors)
pytorch_colored_mask = get_colored_mask(img.shape, pytorch_prediction, pascal_voc_colors)

# obtain palette of PASCAL VOC colors
color_legend = get_legend(pascal_voc_classes, pascal_voc_colors)

cv2.imshow('PyTorch Colored Mask', pytorch_colored_mask)
cv2.imshow('OpenCV DNN Colored Mask', opencv_colored_mask)
cv2.imshow('Color Legend', color_legend)

cv2.waitKey(0)
```

----------------------------------------

TITLE: Loading Image in OpenCV (C++/Java/Python)
DESCRIPTION: Loads the source image from the specified file path. The C++ and Python versions use `imread`, while the Java version uses `Imgcodecs.imread`. An error check is included in C++ and Python to ensure the image was loaded successfully.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
//![load_image]
const char* keys =
{"{ help h | | Print help message. }"
 "{ input | ../data/notes.png | Path to input image. }"
};
CommandLineParser parser(argc, argv, keys);
Mat src = imread(samples::findFile(parser.get<String>("input")), IMREAD_COLOR);
if (src.empty())
{
    cout << "Could not open or find the image!" << endl;
    cout << "Usage: " << argv[0] << " <Input image>" << endl;
    return -1;
}

// Show source image
imshow("src", src);
//![load_image]
```

LANGUAGE: java
CODE:
```
//![load_image]
// Load the image
String filename = args.length > 0 ? args[0] : "../data/notes.png";
Mat src = Imgcodecs.imread(filename, Imgcodecs.IMREAD_COLOR);

// Check if image is loaded fine
if( src.empty() ) {
    System.out.println("Error opening image: " + filename);
    System.exit(-1);
}

// Show source image
HighGui.imshow("src", src);
//![load_image]
```

LANGUAGE: python
CODE:
```
#![load_image]
# Read the image
parser = argparse.ArgumentParser(description='Code for Morphological Line Detection tutorial.')
parser.add_argument('--input', help='Path to input image.', default='notes.png')
args = parser.parse_args()

src = cv.imread(cv.samples.findFile(args.input), cv.IMREAD_COLOR)

# Check if image is loaded fine
if src is None:
    print ('Error opening image!')
    print ('Usage: morphology_lines_detection.py [image_name -- default notes.png]')
    sys.exit()


# Show source image
cv.imshow("src", src)
#![load_image]
```

----------------------------------------

TITLE: Thresholding Backprojection Results in Python OpenCV
DESCRIPTION: This snippet applies a binary threshold to the backprojection probability map to segment the object from the background. The threshold value of 50 is used to distinguish between probable object areas and non-object areas.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_backprojection/py_histogram_backprojection.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
ret,thresh = cv.threshold(B,50,255,0)
```

----------------------------------------

TITLE: Shape Matching using Hu-Moments in OpenCV Python
DESCRIPTION: Demonstrates how to compare two shapes using cv.matchShapes() which uses Hu-moments for comparison. Lower return values indicate better matches, and the comparison is invariant to rotation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_more_functions/py_contours_more_functions.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np

img1 = cv.imread('star.jpg', cv.IMREAD_GRAYSCALE)
img2 = cv.imread('star2.jpg', cv.IMREAD_GRAYSCALE)
assert img1 is not None, "file could not be read, check with os.path.exists()"
assert img2 is not None, "file could not be read, check with os.path.exists()"

ret, thresh = cv.threshold(img1, 127, 255,0)
ret, thresh2 = cv.threshold(img2, 127, 255,0)
contours,hierarchy = cv.findContours(thresh,2,1)
cnt1 = contours[0]
contours,hierarchy = cv.findContours(thresh2,2,1)
cnt2 = contours[0]

ret = cv.matchShapes(cnt1,cnt2,1,0.0)
print( ret )
```

----------------------------------------

TITLE: Creating ChArUco Board
DESCRIPTION: Demonstrates creation of a ChArUco board with specified dimensions and marker properties
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
cv::aruco::CharucoBoard board(cv::Size(5, 7), 0.04f, 0.02f, dictionary);
```

----------------------------------------

TITLE: Timing Median Filtering with OpenCV and Python Assertions
DESCRIPTION: Demonstrates loading an image, applying repeated median filtering with increasing kernel sizes, and timing the process using OpenCV timing functions. Ensures the image exists with an assertion and prints the measured time. Dependencies include cv2 and a suitable image file. Inputs are the image file path and kernel size range (5 to 49). Outputs the elapsed time for the entire median blur operation loop. An assertion guards against missing files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_optimization/py_optimization.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
img1 = cv.imread('messi5.jpg')
assert img1 is not None, "file could not be read, check with os.path.exists()"

e1 = cv.getTickCount()
for i in range(5,49,2):
    img1 = cv.medianBlur(img1,i)
e2 = cv.getTickCount()
t = (e2 - e1)/cv.getTickFrequency()
print( t )

# Result I got is 0.521107655 seconds
```

----------------------------------------

TITLE: Drawing SURF Keypoints on an Image in OpenCV Python
DESCRIPTION: This snippet demonstrates how to visualize SURF keypoints by drawing them on the original image using OpenCV's drawKeypoints function and displaying the result with matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
>>> img2 = cv.drawKeypoints(img,kp,None,(255,0,0),4)

>>> plt.imshow(img2),plt.show()
```

----------------------------------------

TITLE: Generating Random Point Coordinates with OpenCV RNG in C++
DESCRIPTION: Demonstrates using the `rng.uniform(a, b)` method of the cv::RNG object to generate random coordinates for a point (pt1). `rng.uniform` produces numbers from a uniform distribution between 'a' (inclusive) and 'b' (exclusive). Here, it generates x and y coordinates within the bounds defined by (x_1, x_2) and (y_1, y_2) respectively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
@code{.cpp}
pt1.x = rng.uniform( x_1, x_2 );
pt1.y = rng.uniform( y_1, y_2 );
@endcode
```

----------------------------------------

TITLE: Applying Erosion - OpenCV.js - JavaScript
DESCRIPTION: This snippet demonstrates usage of the cv.erode() function from OpenCV.js to perform erosion on an input image using a specified structuring element. Dependencies include the OpenCV.js library, and key parameters are: src (input image), dst (output image), kernel (structuring element), anchor (anchor position, default center), iterations (number of times erosion is applied), borderType (how pixels at the edge are handled), and borderValue. The function accepts images of various types (uchar, ushort, float, etc.) and returns the eroded image. The thickness of the foreground object will decrease based on kernel size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_morphological_ops/js_morphological_ops.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
cv.erode(src, dst, kernel, anchor = new cv.Point(-1, -1), iterations = 1, borderType = cv.BORDER_CONSTANT, borderValue = cv.morphologyDefaultBorderValue())
```

----------------------------------------

TITLE: Calculating PSNR for Image Similarity in OpenCV
DESCRIPTION: This function calculates the Peak Signal-to-Noise Ratio (PSNR) between two images. It computes the mean squared error and converts it to a logarithmic scale. The function handles the case where images are identical (MSE=0) by returning 100, which represents perfect similarity.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
double getPSNR(const Mat& I1, const Mat& I2)
{
    Mat s1;
    absdiff(I1, I2, s1);       // |I1 - I2|
    s1.convertTo(s1, CV_32F);  // cannot make a square on 8 bits
    s1 = s1.mul(s1);           // |I1 - I2|^2

    Scalar s = sum(s1);        // sum elements per channel

    double sse = s.val[0] + s.val[1] + s.val[2]; // sum channels

    if( sse <= 1e-10) // for small values return zero
        return 0;
    else
    {
        double mse = sse / (double)(I1.channels() * I1.total());
        double psnr = 10.0 * log10((255 * 255) / mse);
        return psnr;
    }
}
```

----------------------------------------

TITLE: Displaying Results in Python
DESCRIPTION: Python snippet displaying the original source image and the generated histogram image in separate windows using `cv.imshow`. It waits indefinitely for a key press using `cv.waitKey(0)` before proceeding (implicitly closing windows upon script termination).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_34

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Display
```

----------------------------------------

TITLE: Defining the cv.drawContours Function Signature in OpenCV.js
DESCRIPTION: Defines the signature for the `cv.drawContours` function in OpenCV.js, used to draw detected contours onto a destination image. Parameters allow specifying which contours to draw (contourIdx), their color, thickness (negative value fills interiors), line type, hierarchy level (for nested contours), and an optional offset.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contours_begin/js_contours_begin.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
cv.drawContours (image, contours, contourIdx, color, thickness = 1, lineType = cv.LINE_8, hierarchy = new cv.Mat(), maxLevel = INT_MAX, offset = new cv.Point(0, 0))
@param image         destination image.
@param contours      all the input contours.
@param contourIdx    parameter indicating a contour to draw. If it is negative, all the contours are drawn.
@param color         color of the contours.
@param thickness     thickness of lines the contours are drawn with. If it is negative, the contour interiors are drawn.
@param lineType      line connectivity(see cv.LineTypes).
@param hierarchy     optional information about hierarchy. It is only needed if you want to draw only some of the contours(see maxLevel).
@param maxLevel      maximal level for drawn contours. If it is 0, only the specified contour is drawn. If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This parameter is only taken into account when there is hierarchy available.
@param offset        optional contour shift parameter.
```

----------------------------------------

TITLE: Initializing OpenCV Java Bindings in Eclipse - Java
DESCRIPTION: This Java snippet demonstrates a minimal setup for loading the OpenCV native library and creating a 3x3 identity matrix using OpenCV's Mat API. Required dependencies include the OpenCV Java SDK and correct native library paths set up via Eclipse's user library mechanism. It expects no arguments and prints the contents of a 3x3 matrix to standard output for verification. Ensure that 'opencv-xxx.jar' is included in the build path and that the associated native libraries are properly configured.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/java_eclipse/java_eclipse.markdown#2025-04-22_snippet_0

LANGUAGE: java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.CvType;
import org.opencv.core.Mat;

public class Hello
{
   public static void main( String[] args )
   {
      System.loadLibrary( Core.NATIVE_LIBRARY_NAME );
      Mat mat = Mat.eye( 3, 3, CvType.CV_8UC1 );
      System.out.println( "mat = " + mat.dump() );
   }
}
```

----------------------------------------

TITLE: Copying Source Image in Callback (Python)
DESCRIPTION: Inside the `MatchingMethod` callback function, this code creates a copy of the global source image using `img.copy()`. This copy (`img_display`) is used for drawing the result rectangle, preserving the original image for future template matching calls with different methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_21

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py copy_source
```

----------------------------------------

TITLE: Applying Morphological Transformations with Interactive Trackbars in OpenCV (Java)
DESCRIPTION: This Java code provides an interactive demo of morphological operations (Opening, Closing, Gradient, Top Hat, Black Hat) using OpenCV's Java API. It loads an image, sets up a JFrame with trackbars (JSliders) for operator, element, and kernel size, and redraws the processed image using Imgproc.morphologyEx whenever sliders change. Dependencies include OpenCV for Java, a suitable image file, and Java Swing/AWT for window controls. Key parameters are chosen via sliders; outputs appear in the GUI frame. Users can experiment with different transformations and kernel properties in real time. Platform must support Java Swing and OpenCV native binaries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;\nimport org.opencv.imgcodecs.Imgcodecs;\nimport org.opencv.imgproc.Imgproc;\nimport javax.swing.*;\nimport java.awt.*;\nimport java.awt.image.BufferedImage;\n\npublic class MorphologyDemo2 {\n    static { System.loadLibrary(Core.NATIVE_LIBRARY_NAME); }\n    private Mat src, dst;\n    private JFrame frame;\n    private JLabel imgLabel;\n    private int morph_operator = 0;\n    private int morph_elem = 0;\n    private int morph_size = 0;\n    private final int max_operator = 4;\n    private final int max_elem = 2;\n    private final int max_kernel_size = 21;\n\n    public MorphologyDemo2(String imgPath) {\n        src = Imgcodecs.imread(imgPath);\n        dst = new Mat();\n        setupGUI();\n        applyMorphology();\n    }\n\n    private void setupGUI() {\n        frame = new JFrame("Morphology Transformations");\n        frame.setLayout(new BorderLayout());\n\n        imgLabel = new JLabel();\n        frame.add(imgLabel, BorderLayout.CENTER);\n\n        JPanel sliders = new JPanel(new GridLayout(3, 1));\n        JSlider operatorSlider = new JSlider(0, max_operator, morph_operator);\n        JSlider elemSlider = new JSlider(0, max_elem, morph_elem);\n        JSlider sizeSlider = new JSlider(0, max_kernel_size, morph_size);\n        operatorSlider.setBorder(BorderFactory.createTitledBorder("Operator"));\n        elemSlider.setBorder(BorderFactory.createTitledBorder("Element"));\n        sizeSlider.setBorder(BorderFactory.createTitledBorder("Kernel Size"));\n\n        operatorSlider.addChangeListener(e -> { morph_operator = operatorSlider.getValue(); applyMorphology(); });\n        elemSlider.addChangeListener(e -> { morph_elem = elemSlider.getValue(); applyMorphology(); });\n        sizeSlider.addChangeListener(e -> { morph_size = sizeSlider.getValue(); applyMorphology(); });\n\n        sliders.add(operatorSlider);\n        sliders.add(elemSlider);\n        sliders.add(sizeSlider);\n        frame.add(sliders, BorderLayout.SOUTH);\n\n        frame.setSize(900, 600);\n        frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n        frame.setVisible(true);\n    }\n\n    private void applyMorphology() {\n        int operation = morph_operator + 2;\n        Mat element = Imgproc.getStructuringElement(morph_elem,\n                new Size(2 * morph_size + 1, 2 * morph_size + 1),\n                new Point(morph_size, morph_size));\n        Imgproc.morphologyEx(src, dst, operation, element);\n        Image img = toBufferedImage(dst);\n        imgLabel.setIcon(new ImageIcon(img));\n    }\n\n    private Image toBufferedImage(Mat mat) {\n        int type = BufferedImage.TYPE_3BYTE_BGR;\n        if(mat.channels() == 1) type = BufferedImage.TYPE_BYTE_GRAY;\n        int bufferSize = mat.channels() * mat.cols() * mat.rows();\n        byte[] b = new byte[bufferSize];\n        mat.get(0,0,b);\n        BufferedImage image = new BufferedImage(mat.cols(), mat.rows(), type);\n        final byte[] targetPixels = ((DataBufferByte) image.getRaster().getDataBuffer()).getData();\n        System.arraycopy(b, 0, targetPixels, 0, b.length);\n        return image;\n    }\n\n    public static void main(String[] args) {\n        String imgPath = (args.length > 0) ? args[0] : "baboon.png";\n        new MorphologyDemo2(imgPath);\n    }\n}\n
```

----------------------------------------

TITLE: Loading Images and Homography with OpenCV in Java
DESCRIPTION: Java code for loading grayscale images and a homography matrix using OpenCV, preparing them for subsequent AKAZE feature detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java load
```

----------------------------------------

TITLE: Configuring OpenCV CMake Build for Ubuntu Desktop Linux
DESCRIPTION: CMake configuration options for building OpenCV with CUDA support on Ubuntu Desktop Linux 14.04/16.04 LTS. Supports multiple CUDA architectures and enables Python 2 bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_python2=ON \
    -DBUILD_opencv_python3=OFF \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0 \
    -DCUDA_ARCH_BIN='3.0 3.5 5.0 6.0 6.2' \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=OFF \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Creating a BackgroundSubtractor in OpenCV
DESCRIPTION: Creates a BackgroundSubtractor object using either MOG2 or KNN algorithm based on user selection. This object will generate foreground masks by separating moving objects from the background.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/background_subtraction.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
//create Background Subtractor objects
Ptr<BackgroundSubtractor> pBackSub;
if (parser.get<String>("algorithm") == "MOG2")
    pBackSub = createBackgroundSubtractorMOG2();
else
    pBackSub = createBackgroundSubtractorKNN();
```

LANGUAGE: Java
CODE:
```
// create Background Subtractor objects
BackgroundSubtractor backSub;
if (algorithm.equals("MOG2"))
    backSub = Video.createBackgroundSubtractorMOG2();
else
    backSub = Video.createBackgroundSubtractorKNN();
```

LANGUAGE: Python
CODE:
```
#create Background Subtractor objects
if args.algo == 'MOG2':
    backSub = cv.createBackgroundSubtractorMOG2()
else:
    backSub = cv.createBackgroundSubtractorKNN()
```

----------------------------------------

TITLE: Finding Fourier Transform using Numpy FFT
DESCRIPTION: This snippet demonstrates how to apply the Fourier Transform to an image using Numpy's FFT function. It requires Numpy and Matplotlib libraries. The snippet reads an image, applies FFT, then uses a magnitude spectrum to visualize frequency content. Input is a grayscale image; output is a plotted frequency spectrum.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
f = np.fft.fft2(img)
fshift = np.fft.fftshift(f)
magnitude_spectrum = 20*np.log(np.abs(fshift))

plt.subplot(121),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')
plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])
plt.show()
```

----------------------------------------

TITLE: Applying Laplacian Operator in Java
DESCRIPTION: Applies the Laplacian operator to the grayscale image (`srcGray`) using Imgproc.Laplacian. The destination Mat (`dst`) is initialized, and the output depth is set to CvType.CV_16S to avoid overflow. Default values are used for kernel size, scale, delta, and border type. Requires OpenCV Java bindings (Imgproc).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_16

LANGUAGE: java
CODE:
```
//! [laplacian]
/// Apply Laplace function
dst = new Mat();
int kernelSize = 3;
int scale = 1;
int delta = 0;
int ddepth = CvType.CV_16S;
Imgproc.Laplacian( srcGray, dst, ddepth, kernelSize, scale, delta, Core.BORDER_DEFAULT );
//! [laplacian]
```

----------------------------------------

TITLE: Building the Face Beautification Processing Pipeline with G-API
DESCRIPTION: Construction of the main G-API graph for face beautification that combines DNN inference with custom operations to process and enhance facial features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
// Let's build a G-API graph for this:    
auto kernels = cv::gapi::combine(cv::gapi::core::cpu::kernels(),
                                    cv::gapi::imgproc::cpu::kernels());
        
cv::GMat in;
    
// Part 1. G-API offers various operations and patterns out-of-the-box,
// so unsharp mask is easily expressed as:
cv::GMat blurred = unsharpMask(in);
    
// Part 2. G-API doesn't have bilateral filter yet so need to wrap it up
// as a custom operation.
cv::GMat bilateral = custom::bilateralFilter(in, 15, 80, 80);
    
// Part 3. Face & Landmarks detection
// 3.1. Face detection using G-API Network inference
cv::GMat face_detection = cv::gapi::infer<FaceDetector>(in);
    
// 3.2. Parse SSD object detection result
cv::GArray<cv::Rect> faces = custom::ParseSSD::on(face_detection, in.dims(), 0.5f, true);
    
// 3.3. Detect landmarks on every face (generating per-face outputs)
cv::GArray<cv::GMat> landmarks = cv::gapi::infer<LandmarksDetector>(in, faces);
    
// 3.4. Process landmarks to get contours of face parts
cv::GArray<std::vector<custom::Contour>> elem_contours;
cv::GArray<custom::Contour> face_contours;
std::tie(elem_contours, face_contours) = custom::landmarksToContours::on(landmarks, faces);
    
// 3.5. Generate background mask (the areas where the original image stays as-is)
cv::GMat bg_mask = custom::contourMask::on(cv::gapi::copy(in), face_contours, false);
    
// 3.6. Prepare face features masks
cv::GMat sharpen_mask = custom::elemMask::on(in, elem_contours, face_contours, false, true, true, true, true);
cv::GMat blur_mask = custom::elemMask::on(in, elem_contours, face_contours, true, false, false, false, false);
    
// 4. Combine the results using standard operations
cv::GMat result = in * bg_mask + blurred * sharpen_mask + bilateral * blur_mask;
    
// 5. Finally construct the computation object
auto computation = cv::GComputation(cv::GIn(in), cv::GOut(result));
```

----------------------------------------

TITLE: Running OpenCV DNN Inference
DESCRIPTION: Executes inference using an OpenCV Deep Neural Network model after setting the input blob. This example assumes that the OpenCV model has been loaded and input data prepared. The output is segmentation class predictions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
# set OpenCV DNN input
opencv_net.setInput(preproc_img)

# OpenCV DNN inference
out = opencv_net.forward()
print("OpenCV DNN segmentation prediction: \n")
print("* shape: ", out.shape)

# get IDs of predicted classes
out_predictions = np.argmax(out[0], axis=0)
```

----------------------------------------

TITLE: Drawing a Specific Contour Using a Different Approach in OpenCV Python
DESCRIPTION: This code shows an alternative method for drawing a specific contour (the 5th contour) by first extracting it into a variable and then passing it as a single-element list to cv.drawContours().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
cnt = contours[4]
cv.drawContours(img, [cnt], 0, (0,255,0), 3)
```

----------------------------------------

TITLE: Loading Image in OpenCV
DESCRIPTION: Loads an input image from file using OpenCV's imread function. Returns error if image loading fails.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
Mat src = imread(samples::findFile("lena.jpg"));
if (src.empty())
{
    printf(" Error opening image\n");
    printf(" Program Arguments: [image_name -- default ../data/lena.jpg] \n");
    return EXIT_FAILURE;
}
```

----------------------------------------

TITLE: Calculating Dense Optical Flow with Farneback in JavaScript
DESCRIPTION: This snippet shows the application of Farneback's algorithm for dense optical flow using the cv.calcOpticalFlowFarneback function in OpenCV.js. The method computes flow for every point in the frame, making it suitable for more comprehensive motion analysis. It requires parameters such as pyramid scale and levels, window size, iterations, and polynomial expansion settings. Outputs are detailed flow fields for the given frames. This approach is computationally intensive and facilitates detailed motion analysis across the entire frame.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_video/js_lucas_kanade/js_lucas_kanade.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
cv.calcOpticalFlowFarneback(prev, next, flow, pyrScale, levels, winsize, iterations, polyN, polySigma, flags);
```

----------------------------------------

TITLE: Enabling TBB and Eigen Support in OpenCV CMake Configuration (Shell)
DESCRIPTION: Configures the OpenCV build to include support for Intel TBB (Threading Building Blocks) and the Eigen library by setting `WITH_TBB` and `WITH_EIGEN` flags to 'ON'. These libraries provide performance benefits for certain OpenCV operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_10

LANGUAGE: sh
CODE:
```
cmake -D WITH_TBB=ON -D WITH_EIGEN=ON ..
```

----------------------------------------

TITLE: Arithmetic Operations with Vector Registers in C++
DESCRIPTION: Demonstrates element-wise addition and multiplication of two vector registers containing float values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
v_float32 a, b;                          // {a1, ..., an}, {b1, ..., bn}
v_float32 c;
c = a + b                                // {a1 + b1, ..., an + bn}
c = a * b;                               // {a1 * b1, ..., an * bn}
```

----------------------------------------

TITLE: Classifying and Visualizing SVM Regions with OpenCV - Python
DESCRIPTION: This Python snippet applies OpenCV to train an SVM classifier and visually differentiate regions by class on a Cartesian plane (green for label 1, blue for label -1). Dependencies are the OpenCV Python package (cv2) and numpy. The code builds the training set, configures and trains the SVM, then applies the classifier to each pixel for visualization. Accepted inputs are arrays of labeled data points; the result is an image with different colors per class and a clear decision boundary.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_6

LANGUAGE: python
CODE:
```
# SVM region classification and visualization in Python using OpenCV
# ... (full code from samples/python/tutorial_code/ml/introduction_to_svm/introduction_to_svm.py, show)
```

----------------------------------------

TITLE: Refining Edges and Extracting Objects in OpenCV (C++/Java/Python)
DESCRIPTION: Refines the result by first subtracting the detected vertical lines from the original binary image. Then, it applies dilation followed by erosion (morphological closing, although not explicitly named) with a small 2x2 square kernel to smooth the edges of the remaining objects (presumably the music notes).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
//![smooth]
// Inverse vertical image
bitwise_not(vertical, vertical);
show_wait_destroy("vertical_bit", vertical);

// Extract edges and smooth image according to the logic
// 1. extract edges
// 2. dilate(edges)
// 3. src.copyTo(smooth)
// 4. blur smooth img
// 5. smooth.copyTo(src, edges)

// Step 1
Mat edges;
adaptiveThreshold(vertical, edges, 255, ADAPTIVE_THRESH_MEAN_C, THRESH_BINARY, 3, -2);
show_wait_destroy("edges", edges);

// Step 2
Mat kernel = Mat::ones(2, 2, CV_8UC1);
dilate(edges, edges, kernel);
show_wait_destroy("dilate", edges);

// Step 3
Mat smooth;
vertical.copyTo(smooth);

// Step 4
blur(smooth, smooth, Size(2, 2));

// Step 5
smooth.copyTo(vertical, edges);

// Show final result
show_wait_destroy("smooth - final", vertical);
//![smooth]
```

LANGUAGE: java
CODE:
```
//![smooth]
// Inverse vertical image
Core.bitwise_not(vertical, vertical);
showWaitDestroy("vertical_bit", vertical);

// Extract edges and smooth image according to the logic
// 1. extract edges
// 2. dilate(edges)
// 3. src.copyTo(smooth)
// 4. blur smooth img
// 5. smooth.copyTo(src, edges)

// Step 1
Mat edges = new Mat();
Imgproc.adaptiveThreshold(vertical, edges, 255, Imgproc.ADAPTIVE_THRESH_MEAN_C, Imgproc.THRESH_BINARY, 3, -2);
showWaitDestroy("edges", edges);

// Step 2
Mat kernel = Mat.ones(2, 2, CvType.CV_8UC1);
Imgproc.dilate(edges, edges, kernel);
showWaitDestroy("dilate", edges);

// Step 3
Mat smooth = new Mat();
vertical.copyTo(smooth);

// Step 4
Imgproc.blur(smooth, smooth, new Size(2, 2));

// Step 5
smooth.copyTo(vertical, edges);

// Show final result
showWaitDestroy("smooth - final", vertical);
//![smooth]
```

LANGUAGE: python
CODE:
```
#![smooth]
# Inverse vertical image
vertical = cv.bitwise_not(vertical)
show_wait_destroy("vertical_bit", vertical)

# Step 1: Extract edges
edges = cv.adaptiveThreshold(vertical, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 3, -2)
show_wait_destroy("edges", edges)

# Step 2: Dilate(edges)
kernel = np.ones((2,2), np.uint8)
edges = cv.dilate(edges, kernel)
show_wait_destroy("dilate", edges)

# Step 3: src.copyTo(smooth)
smooth = np.copy(vertical)

# Step 4: blur smooth img
smooth = cv.blur(smooth, (2,2))

# Step 5: smooth.copyTo(src, edges)
(rows, cols) = np.where(edges != 0)
vertical[rows, cols] = smooth[rows, cols]

# Show final result
show_wait_destroy("smooth - final", vertical)
#![smooth]
```

----------------------------------------

TITLE: Using Watershed Algorithm for Image Segmentation in OpenCV
DESCRIPTION: This snippet demonstrates the implementation of the watershed algorithm using OpenCV to segment mutually touching objects. It covers the usage of the cv.watershed(), cv.distanceTransform(), and cv.connectedComponents() functions along with morphological operations to preprocess the image. The script requires OpenCV to be installed and includes dependencies such as cv.watershed() and cv.distanceTransform(). It processes grayscale images, requiring initial binarization, and uses markers for segmentation based on user-defined regions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_watershed/js_watershed.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
Below we will see an example on how to use the Distance Transform along with watershed to segment mutually touching objects.
```

----------------------------------------

TITLE: Opening and Closing XML/YAML/JSON Files with OpenCV FileStorage - C++
DESCRIPTION: This C++ snippet demonstrates how to open and close XML/YAML/JSON files with the OpenCV FileStorage class. It uses the constructor or the open() function for opening files with modes such as WRITE, READ, or APPEND, and shows calling release() to explicitly close the file. Requires OpenCV installed and the <opencv2/core.hpp> header. The file extension determines the format; compressed files (e.g., .xml.gz) are supported.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/core.hpp>\nusing namespace cv;\n\n// Opening a file for writing\nFileStorage fs("output.yml", FileStorage::WRITE);\n\n// ... perform write operations ...\n\n// Explicitly closing the file\nfs.release();
```

----------------------------------------

TITLE: Image Undistortion using Remapping in Python
DESCRIPTION: This snippet performs image undistortion by establishing a remapping function using cv.initUndistortRectifyMap() and cv.remap(). The function takes an input image with camera parameters and outputs a corrected image. The approach is more involved compared to cv.undistort() but provides flexibility in processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
# undistort
mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)
dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)
```

----------------------------------------

TITLE: Configuring Sample Android Project - CMake
DESCRIPTION: Defines a sample project for example image manipulations and sets up the build environment using CMake. The snippet sets project-specific variables, invokes a macro to configure Android project settings such as library dependencies and SDK target, and establishes dependency relationships to guarantee correct build sequencing. Requires OpenCV Android libraries, CMake, and the Android SDK; assumes environment variables and paths for OpenCV and the Android SDK are set. Inputs include sample project names and paths. Outputs are the updated CMake build targets and dependency graph for Android examples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/image-manipulations/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(sample example-image-manipulations)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Creating an Interactive Morphology Demo in OpenCV with Python
DESCRIPTION: This Python snippet provides the general structure for an interactive script using OpenCV to perform and visualize image erosion and dilation. It loads an image, creates GUI windows with trackbars to select morphological type and kernel size, and provides callback functions to update the output as sliders are moved. Dependencies: OpenCV-Python. Key parameters: input image path, kernel type, kernel size. Output is shown in separate windows for each operation. The script expects at least one image file as input or uses a default if none provided.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
@snippet python/tutorial_code/imgProc/erosion_dilatation/morphology_1.py main
```

----------------------------------------

TITLE: Reading Images from Canvas Elements using OpenCV.js - JavaScript
DESCRIPTION: This snippet demonstrates how to read images from two HTML canvas elements into OpenCV.js Mat objects using cv.imread. It is a preparatory step required before performing any image operations or blending. Dependencies include OpenCV.js and two canvas elements with IDs 'canvasInput1' and 'canvasInput2'.
Parameters: canvas IDs for source images. Inputs: Canvas DOM elements. Outputs: src1 and src2 Mat objects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_trackbar/js_trackbar.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
let src1 = cv.imread('canvasInput1');
let src2 = cv.imread('canvasInput2');
```

----------------------------------------

TITLE: Simplified Image Reading and Displaying with OpenCV.js
DESCRIPTION: This example utilizes OpenCV.js methods for simplified reading and output of images from an HTML source directly to a canvas. Dependencies include OpenCV.js and an HTML structure with an image or canvas element.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_image_display/js_image_display.markdown#2025-04-22_snippet_3

LANGUAGE: JavaScript
CODE:
```
let img = cv.imread(imageSource);
cv.imshow(canvasOutput, img);
img.delete();
```

----------------------------------------

TITLE: Disabling GPU Modules in OpenCV CMake Configuration (Shell)
DESCRIPTION: Configures CMake to exclude GPU-related modules during the OpenCV build. This includes disabling OpenCL (`WITH_OPENCL=OFF`) and various specific `opencv_gpu*` modules, potentially speeding up the build and reducing dependencies if GPU acceleration isn't required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_12

LANGUAGE: sh
CODE:
```
cmake -D WITH_OPENCL=OFF -D BUILD_opencv_gpu=OFF -D BUILD_opencv_gpuarithm=OFF -D BUILD_opencv_gpubgsegm=OFF -D BUILD_opencv_gpucodec=OFF -D BUILD_opencv_gpufeatures2d=OFF -D BUILD_opencv_gpufilters=OFF -D BUILD_opencv_gpuimgproc=OFF -D BUILD_opencv_gpulegacy=OFF -D BUILD_opencv_gpuoptflow=OFF -D BUILD_opencv_gpustereo=OFF -D BUILD_opencv_gpuwarping=OFF ..
```

----------------------------------------

TITLE: Applying Laplacian Operator Full Example in C++
DESCRIPTION: Complete C++ code demonstrating loading an image, applying Gaussian blur, converting to grayscale, using the Laplacian operator for edge detection, converting the result to CV_8U, and displaying it. This code relies on the OpenCV library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
// The tutorial code's is shown lines below. You can also download it from
// [here](https://raw.githubusercontent.com/opencv/opencv/4.x/samples/cpp/tutorial_code/ImgTrans/Laplace_Demo.cpp)
@include samples/cpp/tutorial_code/ImgTrans/Laplace_Demo.cpp
```

----------------------------------------

TITLE: Blending Images Using cv.addWeighted in Python
DESCRIPTION: This snippet demonstrates image blending using the OpenCV function cv.addWeighted(), which combines two images with specified weights to create a blend. Dependencies include the images ml.png and opencv-logo.png. The main parameters include weights for each image and an optional scalar added to the output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_image_arithmetics/py_image_arithmetics.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
img1 = cv.imread('ml.png')
img2 = cv.imread('opencv-logo.png')
assert img1 is not None, "file could not be read, check with os.path.exists()"
assert img2 is not None, "file could not be read, check with os.path.exists()"

dst = cv.addWeighted(img1,0.7,img2,0.3,0)

cv.imshow('dst',dst)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Implementing Face Detection Post-Processing Kernel
DESCRIPTION: Kernel implementation for parsing SSD (Single Shot MultiBox Detector) output to produce an array of face rectangles with optional scaling to the original frame size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
// Implementation of the SSD post-processing kernel
STRUCT_KERNEL(GAPI_OCV_KERNEL, ParseSSD, CustomParseSSDBatchImpl) {
    static void run(const cv::Mat& in_ssd_result,
                    const cv::Size& in_size,
                    float confidence_threshold,
                    bool alignment_to_square,
                    std::vector<cv::Rect>& out_objects) {
        const auto& ssd_dims = in_ssd_result.size;
        GAPI_Assert(ssd_dims.dims() == 4u);            // Fixed dims count
        GAPI_Assert(ssd_dims[0] == 1);                 // Fixed batch size
        GAPI_Assert(ssd_dims[1] == 1);                 // Fixed batch size
        GAPI_Assert(ssd_dims[2] > 0);                  // Should have at least 1 proposal
        GAPI_Assert(ssd_dims[3] == 7);                 // Fixed proposal size

        const int MAX_PROPOSALS = ssd_dims[2];
        const int OBJECT_SIZE = ssd_dims[3];
        const cv::Rect surface({0,0}, in_size);

        const float* data = in_ssd_result.ptr<float>();
        out_objects.clear();

        for (int i = 0; i < MAX_PROPOSALS; i++) {
            const float *it = data + i * OBJECT_SIZE;
            float image_id   = it[0];                  // batch id
            float confidence  = it[2];                  // confidence
            float rc_left    = it[3];                  // left
            float rc_top     = it[4];                  // top
            float rc_right   = it[5];                  // right
            float rc_bottom  = it[6];                  // bottom

            if (image_id < 0.f) {                      // indicates end of detections
                break;
            }
            if (confidence < confidence_threshold) {     // skip objects with low confidence
                continue;
            }

            // map relative coordinates to the original image scale
            // taking available surface into account
            cv::Rect rc;  // map to the original scale
            rc.x      = static_cast<int>(rc_left   * in_size.width);
            rc.y      = static_cast<int>(rc_top    * in_size.height);
            rc.width  = static_cast<int>(rc_right  * in_size.width)  - rc.x;
            rc.height = static_cast<int>(rc_bottom * in_size.height) - rc.y;

            // now warp the produced rectangle if needed
            if (alignment_to_square) {
                // make square
                int max_side = std::max(rc.width, rc.height);
                int d_x = (max_side - rc.width)/2;
                int d_y = (max_side - rc.height)/2;

                rc.x -= d_x;
                rc.y -= d_y;
                rc.width  = max_side;
                rc.height = max_side;
            }

            // finally, clip to the source image boundaries
            rc = rc & surface;

            // and add to the result
            out_objects.emplace_back(std::move(rc));
        }
    }
};
```

----------------------------------------

TITLE: Drawing an Ellipse in Java
DESCRIPTION: Implementation of the MyEllipse function that draws a rotated ellipse in OpenCV Java. The function takes the image and angle, and uses the ellipse() function to draw the shape with specified color and thickness.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_19

LANGUAGE: java
CODE:
```
private static void MyEllipse(Mat img, double angle) {
    int thickness = 2;
    int lineType = Core.LINE_8;

    Imgproc.ellipse(img,
            new Point(w/2, w/2),
            new Size(w/4, w/16),
            angle,
            0,
            360,
            new Scalar(255, 0, 0),
            thickness,
            lineType);
}
```

----------------------------------------

TITLE: Configuring Dependencies and Samples with CMake
DESCRIPTION: This CMake script sets up dependencies and defines build targets for OpenGL samples in the OpenCV project. It checks for specific libraries like X11 and EPOXY and sets up samples accordingly. The script uses CMake macros to filter and define targets based on the presence of these libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/opengl/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(APPLE)
  return()
endif()

if(UNIX)
  find_package(X11 QUIET)
endif()

find_package(PkgConfig QUIET)
pkg_search_module(EPOXY QUIET epoxy)

SET(OPENCV_OPENGL_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui)
ocv_check_dependencies(${OPENCV_OPENGL_SAMPLES_REQUIRED_DEPS})

if(BUILD_EXAMPLES AND OCV_DEPENDENCIES_FOUND)
  project(opengl_samples)
  ocv_include_modules_recurse(${OPENCV_OPENGL_SAMPLES_REQUIRED_DEPS})
  file(GLOB all_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
  if(NOT X11_FOUND)
    ocv_list_filterout(all_samples "opengl_interop")
  endif()
  if(NOT EPOXY_FOUND)
    ocv_list_filterout(all_samples "opengl3_2")
  endif()
  foreach(sample_filename ${all_samples})
    ocv_define_sample(tgt ${sample_filename} opengl)
    ocv_target_link_libraries(${tgt} PRIVATE "${OPENGL_LIBRARIES}" "${OPENCV_OPENGL_SAMPLES_REQUIRED_DEPS}")
    if(sample_filename STREQUAL "opengl_interop.cpp")
      ocv_target_link_libraries(${tgt} PRIVATE ${X11_LIBRARIES})
      ocv_target_include_directories(${tgt} ${X11_INCLUDE_DIR})
    endif()
    if(sample_filename STREQUAL "opengl3_2.cpp")
      ocv_target_link_libraries(${tgt} PRIVATE ${EPOXY_LIBRARIES})
      ocv_target_include_directories(${tgt} PRIVATE ${EPOXY_INCLUDE_DIRS})
    endif()
  endforeach()
endif()

ocv_install_example_src(opengl *.cpp *.hpp CMakeLists.txt)
```

----------------------------------------

TITLE: Creating a Look-up Table for Histogram Equalization
DESCRIPTION: This code creates a look-up table for histogram equalization using NumPy masked arrays. It transforms the CDF into a mapping function that will redistribute pixel values across the full intensity range (0-255), which is the core operation of histogram equalization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_equalization/py_histogram_equalization.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
cdf_m = np.ma.masked_equal(cdf,0)
cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())
cdf = np.ma.filled(cdf_m,0).astype('uint8')
```

----------------------------------------

TITLE: Displaying Calibration Results and Removing Distortion in C++
DESCRIPTION: This code shows how to display calibration results and remove distortion from images using OpenCV functions like initUndistortRectifyMap and remap.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
show_results
```

----------------------------------------

TITLE: Upsampling Image using pyrUp in Java
DESCRIPTION: Performs image upsampling on the `tmp` Mat object using `Imgproc.pyrUp`. The output `dst` Mat object is specified to have dimensions twice those of the input.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_10

LANGUAGE: java
CODE:
```
            } else if( c == 'i' ) {
                Imgproc.pyrUp( tmp, dst, new Size( tmp.cols()*2, tmp.rows()*2 ) );
                System.out.println("** Zoom In: Image x 2");
            }
```

----------------------------------------

TITLE: Initializing OpenCV Random Number Generator (RNG) in C++
DESCRIPTION: Initializes an instance of the OpenCV Random Number Generator class (cv::RNG). The generator is seeded with the value 0xFFFFFFFF. This 'rng' object will be used later to generate random numbers for coordinates, colors, and other parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
@code{.cpp}
RNG rng( 0xFFFFFFFF );
@endcode
```

----------------------------------------

TITLE: Implementing AGAST_7_12d Corner Detection in C++
DESCRIPTION: This code snippet implements the AGAST_7_12d variant of the AGAST corner detection algorithm. It uses a 12-pixel mask in diamond format to score potential corner pixels based on intensity differences.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_10

LANGUAGE: C++
CODE:
```
template<>
int agast_cornerScore<AgastFeatureDetector::AGAST_7_12d>(const uchar* ptr, const int pixel[], int threshold)
{
    int bmin = threshold;
    int bmax = 255;
    int b_test = (bmax + bmin)/2;

    short offset0 = (short) pixel[0];
    short offset1 = (short) pixel[1];
    short offset2 = (short) pixel[2];
    short offset3 = (short) pixel[3];
    short offset4 = (short) pixel[4];
    short offset5 = (short) pixel[5];
    short offset6 = (short) pixel[6];
    short offset7 = (short) pixel[7];
    short offset8 = (short) pixel[8];
    short offset9 = (short) pixel[9];
    short offset10 = (short) pixel[10];
    short offset11 = (short) pixel[11];

    while(true)
    {
        const int cb = *ptr + b_test;
        const int c_b = *ptr - b_test;
        if(ptr[offset0] > cb)
          if(ptr[offset5] > cb)
            if(ptr[offset2] > cb)
              if(ptr[offset9] > cb)
                if(ptr[offset1] > cb)
                  if(ptr[offset6] > cb)
                    if(ptr[offset3] > cb)
                      if(ptr[offset4] > cb)
                        goto is_a_corner;
                      else
                        if(ptr[offset10] > cb)
                          if(ptr[offset11] > cb)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset8] > cb)
                        if(ptr[offset10] > cb)
                          if(ptr[offset11] > cb)
                            goto is_a_corner;
                          else
                            if(ptr[offset4] > cb)
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset11] > cb)
                      if(ptr[offset3] > cb)
                        if(ptr[offset4] > cb)
                          goto is_a_corner;
                        else
                          if(ptr[offset10] > cb)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset8] > cb)
                          if(ptr[offset10] > cb)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      if(ptr[offset8] > cb)
                        if(ptr[offset4] > cb)
                          if(ptr[offset3] > cb)
                            goto is_a_corner;
                          else
                            if(ptr[offset10] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset10] > cb)
                            if(ptr[offset11] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset3] > cb)
                  if(ptr[offset4] > cb)
                    if(ptr[offset1] > cb)
                      if(ptr[offset6] > cb)
                        goto is_a_corner;
                      else
                        if(ptr[offset11] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset6] > cb)
                        if(ptr[offset7] > cb)
                          if(ptr[offset8] > cb)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset9] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset1] > cb)
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto is_a_corner;
                        else
                          if(ptr[offset6] > cb)
                            if(ptr[offset4] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset6] > cb)
                          if(ptr[offset3] > cb)
                            if(ptr[offset4] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset6] > cb)
                        if(ptr[offset4] > cb)
                          if(ptr[offset3] > cb)
                            goto is_a_corner;
                          else
                            if(ptr[offset10] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset10] > cb)
                            if(ptr[offset11] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset5] < c_b)
              if(ptr[offset9] > cb)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset11] > cb)
                      if(ptr[offset1] > cb)
                        if(ptr[offset8] > cb)
                          if(ptr[offset10] > cb)
                            if(ptr[offset2] > cb)
                              goto is_a_corner;
                            else
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
```

----------------------------------------

TITLE: Applying Histogram Equalization with OpenCV
DESCRIPTION: Using the equalizeHist function to enhance image contrast by redistributing intensity values across the available range.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
Mat dst;
equalizeHist( src_gray, dst );
```

LANGUAGE: Java
CODE:
```
Mat dst = new Mat();
equalizeHist(srcGray, dst);
```

LANGUAGE: Python
CODE:
```
dst = cv.equalizeHist(src_gray)
```

----------------------------------------

TITLE: Computing Histograms for BGR Channels in Python
DESCRIPTION: Python snippet calculating histograms for each B, G, and R plane using `cv.calcHist`. It calls `calcHist` for each plane (`bgr_planes[0]`, `bgr_planes[1]`, `bgr_planes[2]`), specifying the channel ([0]), no mask (None), bin count (`histSize`), and range (`histRange`). The results are stored in `b_hist`, `g_hist`, and `r_hist`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_20

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Compute the histograms
```

----------------------------------------

TITLE: Specifying Source for JPEG Data in Decompression in C
DESCRIPTION: This snippet demonstrates opening a file and specifying it as a source of compressed JPEG data for decompression using 'jpeg_stdio_src'. It includes file opening and error checking. Using a binary mode ('rb') is important to prevent data corruption on non-Unix systems.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_12

LANGUAGE: C
CODE:
```
FILE *infile;
if ((infile = fopen(filename, "rb")) == NULL) {
    fprintf(stderr, "can't open %s\n", filename);
    exit(1);
}
jpeg_stdio_src(&cinfo, infile);
```

----------------------------------------

TITLE: Loading and Converting Input Image (Java)
DESCRIPTION: This Java snippet loads the input image with Highgui.imread and converts it to grayscale using Imgproc.cvtColor. The code includes a check for read failures, printing an error if the file can't be loaded. Input: filename via args[]. Output: grayscale Mat in src_gray, required for further thresholding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_4

LANGUAGE: Java
CODE:
```
// [load]\nsrc = Highgui.imread(args.length > 0 ? args[0] : "chicky_512.png");\nif (src.empty()) {\n    System.out.println("Error opening image");\n    return;\n}\nImgproc.cvtColor(src, src_gray = new Mat(), Imgproc.COLOR_BGR2GRAY);\n// [load]
```

----------------------------------------

TITLE: Displaying Image using imshow and waitKey in OpenCV in Java
DESCRIPTION: Java bindings do not support GUI display directly. External libraries or wrappers are necessary. Sample code displayed here assumes such an interface, otherwise displaying via imwrite and opening via OS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_41

LANGUAGE: Java
CODE:
```
// Java OpenCV does not natively support imshow; use JavaFX or third-party windowing.
```

----------------------------------------

TITLE: Model Download Implementation in Python
DESCRIPTION: Python code example showing how to download model files programmatically using the download_models utility with optional SHA hash verification.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/README.md#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
from download_models import downloadFile

filepath1 = downloadFile("https://drive.google.com/uc?export=download&id=0B3gersZ2cHIxRm5PMWRoTkdHdHc", None, filename="MobileNetSSD_deploy.caffemodel", save_dir="save_dir_1")
filepath2 = downloadFile("https://drive.google.com/uc?export=download&id=0B3gersZ2cHIxRm5PMWRoTkdHdHc", "994d30a8afaa9e754d17d2373b2d62a7dfbaaf7a", filename="MobileNetSSD_deploy.caffemodel")
print(filepath1)
print(filepath2)
# Your code
```

----------------------------------------

TITLE: Converting Laplacian Output to CV_8U in C++
DESCRIPTION: Converts the Laplacian output image (`dst`), which has a depth of CV_16S, to an 8-bit unsigned integer image (`abs_dst`) using cv::convertScaleAbs. This computes the absolute value and scales the result to the 0-255 range, making it suitable for display. Requires OpenCV core module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_18

LANGUAGE: cpp
CODE:
```
//! [convert]
// converting back to CV_8U
convertScaleAbs( dst, abs_dst );
//! [convert]
```

----------------------------------------

TITLE: Configuring Android ABI for OpenCL-enabled OpenCV SDK Build - Python
DESCRIPTION: This Python-style configuration line defines the ABI build parameters for OpenCV, enabling OpenCL and specifying the path to the custom Android OpenCL SDK. It is used within build scripts or configuration files for OpenCV's build_sdk.py system. Correct path substitution and alignment of OpenCL SDK location are required for successful builds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
ABI("3", "arm64-v8a", None, 21, cmake_vars=dict('WITH_OPENCL': 'ON', 'ANDROID_OPENCL_SDK': 'path_to_your_Android_OpenCL_SDK'))
```

----------------------------------------

TITLE: Finding Homography Transformation in OpenCV C++
DESCRIPTION: Computes the homography transformation between two sets of points using the RANSAC algorithm. The ransacReprojThreshold parameter determines the maximum allowed reprojection error.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/detection_of_planar_objects/detection_of_planar_objects.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
vector<Point2f> points1, points2;
// fill the arrays with the points
....
Mat H = findHomography(Mat(points1), Mat(points2), RANSAC, ransacReprojThreshold);
```

----------------------------------------

TITLE: Capturing and Displaying Video from Camera in Python with OpenCV
DESCRIPTION: This snippet demonstrates how to capture video from a camera, convert it to grayscale, and display it using OpenCV. It uses cv.VideoCapture() to access the camera and processes frames in a loop until 'q' is pressed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_video_display/py_video_display.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)
if not cap.isOpened():
    print("Cannot open camera")
    exit()
while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    # Our operations on the frame come here
    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    # Display the resulting frame
    cv.imshow('frame', gray)
    if cv.waitKey(1) == ord('q'):
        break

# When everything done, release the capture
cap.release()
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Converting Images to Grayscale in OpenCV
DESCRIPTION: Converting color images to grayscale prior to histogram equalization, as the technique is applied to intensity values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cvtColor( src, src_gray, COLOR_BGR2GRAY );
```

LANGUAGE: Java
CODE:
```
Mat srcGray = new Mat();
CvtColor(src, srcGray, COLOR_BGR2GRAY);
```

LANGUAGE: Python
CODE:
```
src_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
```

----------------------------------------

TITLE: Loading Images and Text Recognition Model in C++
DESCRIPTION: This C++ snippet demonstrates how to load a text image and initialize the TextRecognitionModel with ONNX weights for recognition. It requires the OpenCV DNN module, and a text recognition model file, and a vocabulary file. It sets up the image and model, configures the decoding method, and prepares the vocabulary for recognition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include <opencv2/opencv.hpp>
#include <opencv2/dnn.hpp>
#include <fstream>
#include <vector>

// Load a cropped text line image
// you can find cropped images for testing in "Images for Testing"
int rgb = IMREAD_COLOR; // This should be changed according to the model input requirement.
Mat image = imread("path/to/text_rec_test.png", rgb);

// Load models weights
TextRecognitionModel model("path/to/crnn_cs.onnx");

// The decoding method
// more methods will be supported in future
model.setDecodeType("CTC-greedy");

// Load vocabulary
// vocabulary should be changed according to the text recognition model
std::ifstream vocFile;
vocFile.open("path/to/alphabet_94.txt");
CV_Assert(vocFile.is_open());
String vocLine;
std::vector<String> vocabulary;
while (std::getline(vocFile, vocLine)) {
    vocabulary.push_back(vocLine);
}
model.setVocabulary(vocabulary);
```

----------------------------------------

TITLE: Generating ChArUco Board Image
DESCRIPTION: Shows how to generate an image of the ChArUco board for printing
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
cv::Mat boardImage;
board.generateImage(cv::Size(600, 500), boardImage, 10, 1);
```

----------------------------------------

TITLE: Matching Extracted Face Features - OpenCV DNN Python
DESCRIPTION: This snippet shows how to compare two extracted face features (numpy arrays) in Python using FaceRecognizerSF. The match function returns the similarity (cosine) or distance (normL2) between the two feature vectors, used to determine if they refer to the same person according to set thresholds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_9

LANGUAGE: Python
CODE:
```
# Compare two extracted face features
cosine_score = recognizer.match(feature1, feature2, cv2.FaceRecognizerSF_FR_COSINE)
l2_score     = recognizer.match(feature1, feature2, cv2.FaceRecognizerSF_FR_NORM_L2)
# Compare scores to thresholds for matching
```

----------------------------------------

TITLE: Detecting and Decoding Barcodes in One Step
DESCRIPTION: Combines detection and decoding into a single function call using cv::barcode::BarcodeDetector::detectAndDecode. This method simplifies the process of obtaining decoded information from barcodes with one function call.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/barcode_detect_and_decode.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
@snippet cpp/barcode.cpp detectAndDecode
```

----------------------------------------

TITLE: Constructor for Custom Layer OpenCV C++
DESCRIPTION: This constructor retrieves hyper-parameters from cv::dnn::LayerParams with the option for trainable weight storage.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp MyLayer::MyLayer
```

----------------------------------------

TITLE: Handling User Input for Camera Calibration in C++
DESCRIPTION: This snippet demonstrates how to handle user input to toggle distortion removal, restart detection, or quit the application during camera calibration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
await_input
```

----------------------------------------

TITLE: Downsampling Image using pyrDown in C++
DESCRIPTION: Downsamples the image `tmp` using the `pyrDown` function. The destination image `dst` will have dimensions half that of `tmp`. The size is explicitly provided.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
        else if( c == 'o' )
        { pyrDown( tmp, dst, Size( tmp.cols/2, tmp.rows/2 ) ); printf("** Zoom Out: Image / 2 \n"); }
```

----------------------------------------

TITLE: Main Program: Loading a 3D Model - OpenCV C++
DESCRIPTION: Shows how to instantiate a Model object and load a 3D textured object model using the load function in the main program. Requires defining a valid path to the YAML file containing the model data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
Model model;               // instantiate Model object
model.load(yml_read_path); // load a 3D textured object model

```

----------------------------------------

TITLE: Loading DEM Data with Native Value Preservation in OpenCV (C++)
DESCRIPTION: The code illustrates loading a Digital Elevation Model (DEM) with OpenCV while preserving the intrinsic elevation data using the IMREAD_ANYDEPTH and IMREAD_LOAD_GDAL flags. This ensures raw numeric data (e.g., signed shorts for SRTM/DTED formats) are maintained. Requires OpenCV with GDAL enabled and Dem files in a compatible format.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/raster_io_gdal.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
// Load a DEM raster with depth preservation
cv::Mat dem = cv::imread("/path/to/file.hgt", cv::IMREAD_ANYDEPTH | cv::IMREAD_LOAD_GDAL);
```

----------------------------------------

TITLE: Console Output from OpenCV File Operations
DESCRIPTION: Sample console output showing the results of writing and reading operations, including successful reads and handling of non-existent files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_21

LANGUAGE: bash
CODE:
```
Write Done.

Reading:
100image1.jpg
Awesomeness
baboon.jpg
Two  2; One  1


R = [1, 0, 0;
  0, 1, 0;
  0, 0, 1]
T = [0; 0; 0]

MyData =
{ id = mydata1234, X = 3.14159, A = 97}

Attempt to read NonExisting (should initialize the data structure with its default).
NonExisting =
{ id = , X = 0, A = 0}

Tip: Open up output.xml with a text editor to see the serialized data.
```

----------------------------------------

TITLE: Calibrating Camera with ArUco Board in OpenCV
DESCRIPTION: This code shows the camera calibration process using an ArUco board. It detects markers from multiple viewpoints, collects coordinates, and computes the camera calibration parameters. This approach is less accurate than ChArUco but useful in scenarios where ChArUco boards cannot be used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_calibration/aruco_calibration.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
cv::Ptr<cv::aruco::DetectorParameters> detectorParams = cv::aruco::DetectorParameters::create();
cv::Ptr<cv::aruco::Dictionary> dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::PREDEFINED_DICTIONARY_NAME(dictionaryId));

// Create a board
cv::Ptr<cv::aruco::GridBoard> gridboard = cv::aruco::GridBoard::create(markersX, markersY, markerLength, markerSeparation, dictionary);
cv::Ptr<cv::aruco::Board> board = gridboard.staticCast<cv::aruco::Board>();

// Collect data from each frame:
std::vector<std::vector<cv::Point2f>> allCornersConcatenated;
std::vector<int> allIdsConcatenated;
std::vector<int> markerCounterPerFrame;

// For each frame:
std::vector<int> ids;
std::vector<std::vector<cv::Point2f>> corners, rejected;

// Detect markers
aruco::detectMarkers(image, dictionary, corners, ids, detectorParams, rejected);

// If at least one marker detected
if(ids.size() > 0) {
    markerCounterPerFrame.push_back((int)ids.size());
    for(unsigned int i = 0; i < ids.size(); i++) {
        allCornersConcatenated.push_back(corners[i]);
        allIdsConcatenated.push_back(ids[i]);
    }
}
```

LANGUAGE: cpp
CODE:
```
// After processing all frames
if(allIdsConcatenated.size() > 0) {
    
    // Setup calibration
    cv::Mat cameraMatrix, distCoeffs;
    std::vector<cv::Mat> rvecs, tvecs;
    
    // prepare data for calibration
    std::vector<std::vector<cv::Point2f>> allCorners;
    std::vector<std::vector<cv::Point3f>> allObjectPoints;
    std::vector<int> allIds;
    std::vector<cv::Mat> allImgs;
    
    // Fill with data from detected markers
    int counter = 0;
    for(unsigned int i = 0; i < markerCounterPerFrame.size(); i++) {
        int markerNum = markerCounterPerFrame[i];
        std::vector<cv::Point2f> currentImgPoints;
        std::vector<int> currentIds;
        for(int j = 0; j < markerNum; j++) {
            currentImgPoints.push_back(allCornersConcatenated[counter][0]);
            currentImgPoints.push_back(allCornersConcatenated[counter][1]);
            currentImgPoints.push_back(allCornersConcatenated[counter][2]);
            currentImgPoints.push_back(allCornersConcatenated[counter][3]);
            currentIds.push_back(allIdsConcatenated[counter]);
            counter++;
        }
        allCorners.push_back(currentImgPoints);
        allIds.push_back(currentIds);
        allImgs.push_back(images[i]);
    }
```

LANGUAGE: cpp
CODE:
```
// Create objPoints for board using objPoints from gridboard
std::vector<cv::Point3f> objPoints;
for(unsigned int i = 0; i < allIds.size(); i++) {
    std::vector<cv::Point3f> boardObjPoints;
    gridboard->matchImagePoints(allCorners[i], allIds[i], boardObjPoints);
    objPoints.insert(objPoints.end(), boardObjPoints.begin(), boardObjPoints.end());
}

// Calibrate camera now using object and image points
double calibrationReprojErr = cv::calibrateCamera(objPoints, imgPoints, imgSize, cameraMatrix, distCoeffs, rvecs, tvecs, calibrationFlags);

// Print results
std::cout << "Rep Error: " << calibrationReprojErr << std::endl;
std::cout << "Calibration matrix: " << cameraMatrix << std::endl;
std::cout << "Distortion coefficients: " << distCoeffs << std::endl;
```

----------------------------------------

TITLE: Loading an Image using OpenCV in C++
DESCRIPTION: This snippet demonstrates how to load an image using OpenCV in C++. The image is read in grayscale mode using the imread function. This operation requires OpenCV installed and linked with your C++ project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_square_chess/camera_calibration_square_chess.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
Mat img = imread(argv[1], IMREAD_GRAYSCALE);
```

----------------------------------------

TITLE: Setting Up FFmpeg Plugin for OpenCV Videoio
DESCRIPTION: This CMake script configures the FFmpeg plugin for OpenCV's videoio module. It sets up the source directory, includes necessary dependencies, and creates the plugin with the required parameters. The script also displays the versions of FFmpeg components being used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/misc/plugin_ffmpeg/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.5)

get_filename_component(OpenCV_SOURCE_DIR "${CMAKE_CURRENT_LIST_DIR}/../../../.." ABSOLUTE)
include("${OpenCV_SOURCE_DIR}/cmake/OpenCVPluginStandalone.cmake")

# scan dependencies
set(WITH_FFMPEG ON)
set(OPENCV_FFMPEG_SKIP_BUILD_CHECK ON)
include("${OpenCV_SOURCE_DIR}/modules/videoio/cmake/init.cmake")

set(OPENCV_PLUGIN_DEPS core imgproc imgcodecs)
ocv_create_plugin(videoio "opencv_videoio_ffmpeg" "ocv.3rdparty.ffmpeg" "FFmpeg" "src/cap_ffmpeg.cpp")

message(STATUS "FFMPEG_libavcodec_VERSION=${FFMPEG_libavcodec_VERSION}")
message(STATUS "FFMPEG_libavformat_VERSION=${FFMPEG_libavformat_VERSION}")
message(STATUS "FFMPEG_libavutil_VERSION=${FFMPEG_libavutil_VERSION}")
message(STATUS "FFMPEG_libswscale_VERSION=${FFMPEG_libswscale_VERSION}")
message(STATUS "FFMPEG_libavresample_VERSION=${FFMPEG_libavresample_VERSION}")
if(OPENCV_FFMPEG_ENABLE_LIBAVDEVICE)
  message(STATUS "FFMPEG_libavdevice_VERSION=${FFMPEG_libavdevice_VERSION}")
endif()
```

----------------------------------------

TITLE: Detecting Subpixel Corners using OpenCV in C++
DESCRIPTION: C++ implementation of corner detection with subpixel accuracy using OpenCV's cornerSubPix function. The code demonstrates image loading, corner detection, and refinement of corner positions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/corner_subpixels/corner_subpixels.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <iostream>
#include <opencv2/core.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>

using namespace cv;
using namespace std;

Mat src, src_gray;

int maxCorners = 10;
int maxTrackbar = 100;

RNG rng(12345);
char* source_window = "Image";

void goodFeaturesToTrack_Demo( int, void* );

int main( int argc, char** argv )
{
    CommandLineParser parser( argc, argv, "{@input | pic3.png | input image}" );
    src = imread( samples::findFile( parser.get<String>( "@input" ) ) );
    if( src.empty() )
    {
        cout << "Could not open or find the image!\n" << endl;
        cout << "Usage: " << argv[0] << " <Input image>" << endl;
        return -1;
    }
    cvtColor( src, src_gray, COLOR_BGR2GRAY );

    namedWindow( source_window );
    createTrackbar( "Max corners:", source_window, &maxCorners, maxTrackbar, goodFeaturesToTrack_Demo );

    imshow( source_window, src );
    goodFeaturesToTrack_Demo( 0, 0 );

    waitKey();
    return 0;
}

void goodFeaturesToTrack_Demo( int, void* )
{
    maxCorners = MAX(maxCorners, 1);
    vector<Point2f> corners;
    double qualityLevel = 0.01;
    double minDistance = 10;
    int blockSize = 3, gradientSize = 3;
    bool useHarrisDetector = false;
    double k = 0.04;

    Mat copy = src.clone();

    goodFeaturesToTrack( src_gray,
                         corners,
                         maxCorners,
                         qualityLevel,
                         minDistance,
                         Mat(),
                         blockSize,
                         gradientSize,
                         useHarrisDetector,
                         k );

    cout << "** Number of corners detected: " << corners.size() << endl;
    int radius = 4;
    for( size_t i = 0; i < corners.size(); i++ )
    {
        circle( copy, corners[i], radius, Scalar(rng.uniform(0,255), rng.uniform(0, 256), rng.uniform(0, 256)), FILLED );
    }

    namedWindow( "Sharp corners" );
    imshow( "Sharp corners", copy );

    Size winSize = Size( 5, 5 );
    Size zeroZone = Size( -1, -1 );
    TermCriteria criteria = TermCriteria( TermCriteria::EPS + TermCriteria::COUNT, 40, 0.001 );

    cornerSubPix( src_gray, corners, winSize, zeroZone, criteria );

    for( size_t i = 0; i < corners.size(); i++ )
    {
        cout << " -- Refined Corner [" << i << "]  (" << corners[i].x << "," << corners[i].y << ")" << endl;
    }
}
```

----------------------------------------

TITLE: Implementing Camshift Object Tracking in Python
DESCRIPTION: Python implementation of the Camshift algorithm for adaptive object tracking. This code extends the Meanshift approach by using CamShift to track objects with changing size and orientation across video frames. It includes histogram calculation and backprojection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/meanshift.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
import numpy as np\nimport cv2 as cv\nimport argparse\n\nparser = argparse.ArgumentParser(description='This sample demonstrates the camshift algorithm. \\\n                                              The example file can be downloaded from: \\\n                                              https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4')\nparser.add_argument('image', type=str, help='path to image file')\nargs = parser.parse_args()\n\ncap = cv.VideoCapture(args.image)\n# take first frame of the video\nret,frame = cap.read()\n# setup initial location of window\nx, y, w, h = 300, 200, 100, 50 # simply hardcoded the values\ntrack_window = (x, y, w, h)\n# set up the ROI for tracking\nroi = frame[y:y+h, x:x+w]\nhsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\nmask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\nroi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\ncv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\nterm_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\nwhile(1):\n    ret, frame = cap.read()\n    if ret == True:\n        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n        # apply camshift to get the new location\n        ret, track_window = cv.CamShift(dst, track_window, term_crit)\n        # Draw it on image\n        pts = cv.boxPoints(ret)\n        pts = np.int0(pts)\n        img2 = cv.polylines(frame,[pts],True, 255,2)\n        cv.imshow('img2',img2)\n        k = cv.waitKey(30) & 0xff\n        if k == 27:\n            break\n    else:\n        break\ncv.destroyAllWindows()\ncap.release()
```

----------------------------------------

TITLE: Exporting Classes and Methods Using OpenCV Macros in C++
DESCRIPTION: This example illustrates how to export a full C++ class and its methods to Python using CV_EXPORTS_W for the class, CV_WRAP for methods, and CV_PROP for properties. The CLAHE class outlines methods to apply and configure the algorithm, each annotated to direct the binding generator. The expected inputs and outputs are as per the specified arguments; required dependency is OpenCV's Algorithm base class.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
class CV_EXPORTS_W CLAHE : public Algorithm
{
public:
    CV_WRAP virtual void apply(InputArray src, OutputArray dst) = 0;

    CV_WRAP virtual void setClipLimit(double clipLimit) = 0;
    CV_WRAP virtual double getClipLimit() const = 0;
}
```

----------------------------------------

TITLE: Applying Histogram Comparison Methods in OpenCV
DESCRIPTION: Comparing histograms using four different methods: Correlation, Chi-Square, Intersection, and Bhattacharyya distance, displaying each comparison result.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
for( int compare_method = 0; compare_method < 4; compare_method++ )
{
    double base_base = compareHist( hist_base, hist_base, compare_method );
    double base_half = compareHist( hist_base, hist_half_down, compare_method );
    double base_test1 = compareHist( hist_base, hist_test1, compare_method );
    double base_test2 = compareHist( hist_base, hist_test2, compare_method );
    cout << "Method [" << compare_method << "] Perfect, Base-Half, Base-Test(1), Base-Test(2) : "
         << base_base << " / " << base_half << " / " << base_test1 << " / " << base_test2 << endl;
}
```

LANGUAGE: java
CODE:
```
for( int compare_method = 0; compare_method < 4; compare_method++ ) {
    double base_base = Imgproc.compareHist( hist_base, hist_base, compare_method );
    double base_half = Imgproc.compareHist( hist_base, hist_half_down, compare_method );
    double base_test1 = Imgproc.compareHist( hist_base, hist_test1, compare_method );
    double base_test2 = Imgproc.compareHist( hist_base, hist_test2, compare_method );
    System.out.println("Method [" + compare_method + "] Perfect, Base-Half, Base-Test(1), Base-Test(2) : "
                      + base_base + " / " + base_half + " / " + base_test1 + " / " + base_test2);
}
```

LANGUAGE: python
CODE:
```
for compare_method in range(4):
    base_base = cv.compareHist(hist_base, hist_base, compare_method)
    base_half = cv.compareHist(hist_base, hist_half_down, compare_method)
    base_test1 = cv.compareHist(hist_base, hist_test1, compare_method)
    base_test2 = cv.compareHist(hist_base, hist_test2, compare_method)
    print('Method:', compare_method, 'Perfect, Base-Half, Base-Test(1), Base-Test(2) :',\
          base_base, '/', base_half, '/', base_test1, '/', base_test2)
```

----------------------------------------

TITLE: Finding Minimum and Maximum Match Values/Locations (Java)
DESCRIPTION: Utilizes `Core.minMaxLoc` to identify the minimum and maximum correlation values in the normalized result matrix (`result`) and their respective coordinates. The results (min/max values and points) are returned in a `MinMaxLocResult` object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_29

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java best_match
```

----------------------------------------

TITLE: Calculating Contour Aspect Ratio in OpenCV Python
DESCRIPTION: This snippet calculates the aspect ratio of a contour. It first finds the upright bounding rectangle of the contour using `cv.boundingRect` to get its width (w) and height (h). The aspect ratio is then computed as the ratio of width to height. Requires an existing contour variable `cnt`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
x,y,w,h = cv.boundingRect(cnt)
aspect_ratio = float(w)/h
```

----------------------------------------

TITLE: Downsampling Image using pyrDown in Python
DESCRIPTION: Downsamples the input image `tmp` using `cv.pyrDown`. The output image `dst` will be half the dimensions of the input. The destination size is inferred by the function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_14

LANGUAGE: python
CODE:
```
        elif c == ord('o'):
            dst = cv.pyrDown(tmp)
            print ('** Zoom Out: Image / 2')
```

----------------------------------------

TITLE: Detecting Circles using Hough Transform
DESCRIPTION: Applying HoughCircles transform to detect circles in the preprocessed image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
vector<Vec3f> circles;
HoughCircles(gray, circles, HOUGH_GRADIENT, 1,
            gray.rows/16,  // change this value to detect circles with different distances to each other
            100, 30, 1, 30 // change the last two parameters
            // (min_radius & max_radius) to detect larger circles
);
```

LANGUAGE: Java
CODE:
```
Mat circles = new Mat();
Imgproc.HoughCircles(gray, circles, Imgproc.HOUGH_GRADIENT, 1.0,
        (double)gray.rows()/16, // change this value to detect circles with different distances to each other
        100.0, 30.0, 1, 30); // change the last two parameters
        // (min_radius & max_radius) to detect larger circles
```

LANGUAGE: Python
CODE:
```
circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, 1, gray.shape[0]/16,
                            param1=100, param2=30,
                            minRadius=1, maxRadius=30)
```

----------------------------------------

TITLE: Extracting and Matching SIFT Features with FLANN in OpenCV (Python)
DESCRIPTION: This snippet detects SIFT keypoints and descriptors in two images, then matches them using FLANN-based matcher. It applies Lowe's ratio test to retain only robust matches. Dependencies: OpenCV (with SIFT module), NumPy, Matplotlib. Key parameters include image file paths, matcher index and parameters, and Lowe's ratio threshold. Input images must be grayscale. Outputs: lists of keypoints and filtered good matches. This code is foundational for subsequent geometric analysis.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_feature_homography/py_feature_homography.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np\nimport cv2 as cv\nfrom matplotlib import pyplot as plt\n\nMIN_MATCH_COUNT = 10\n\nimg1 = cv.imread('box.png', cv.IMREAD_GRAYSCALE)          # queryImage\nimg2 = cv.imread('box_in_scene.png', cv.IMREAD_GRAYSCALE) # trainImage\n\n# Initiate SIFT detector\nsift = cv.SIFT_create()\n\n# find the keypoints and descriptors with SIFT\nkp1, des1 = sift.detectAndCompute(img1,None)\nkp2, des2 = sift.detectAndCompute(img2,None)\n\nFLANN_INDEX_KDTREE = 1\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks = 50)\n\nflann = cv.FlannBasedMatcher(index_params, search_params)\n\nmatches = flann.knnMatch(des1,des2,k=2)\n\n# store all the good matches as per Lowe's ratio test.\ngood = []\nfor m,n in matches:\n    if m.distance < 0.7*n.distance:\n        good.append(m)
```

----------------------------------------

TITLE: Installing to System Location with Elevated Privileges - Shell
DESCRIPTION: Executes the CMake install step using 'sudo' to achieve the required permissions for writing to system directories (such as /usr/local). This is necessary when the installation prefix is set to a system-wide location. Prerequisites include existing build artifacts and correctly configured CMake project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_23

LANGUAGE: shell
CODE:
```
sudo cmake --build . --target install
```

----------------------------------------

TITLE: Basic Hough Line Transform Implementation in Python OpenCV
DESCRIPTION: Demonstrates the implementation of standard Hough Transform for line detection using cv.HoughLines(). The function detects lines in a binary image by converting them to rho-theta parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
@include hough_line_transform.py
```

----------------------------------------

TITLE: Generating an ArUco Board Image for Printing in C++
DESCRIPTION: Code snippet demonstrating how to generate an image of an ArUco board for printing. The function takes the board dimensions, output image, margin, and border size parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_board_detection/aruco_board_detection.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
cv::Size imageSize;
imageSize.width = 600;
imageSize.height = 500;

// create a synthetic image for a board
cv::Mat boardImage;
board->generateImage(imageSize, boardImage, 10, 1);
```

----------------------------------------

TITLE: Establishing Histogram Bin Count in C++
DESCRIPTION: C++ snippet defining the number of bins to be used for the histogram calculation. A variable `histSize` is declared and initialized, typically to 256 for an 8-bit grayscale or single-channel image, representing one bin for each possible intensity value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Establish the number of bins
```

----------------------------------------

TITLE: Implementing Meanshift Object Tracking in C++
DESCRIPTION: Implementation of the Meanshift algorithm for object tracking in videos using OpenCV C++. The code sets up target histogram calculation, performs histogram backprojection, and applies the meanshift algorithm to track objects across video frames.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/meanshift.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include "opencv2/imgproc.hpp"\n#include "opencv2/videoio.hpp"\n#include "opencv2/highgui.hpp"\n#include <iostream>\n\nusing namespace cv;\nusing namespace std;\n\nMat frame, hsv, hue, mask, hist, histimg = Mat::zeros(200, 320, CV_8UC3), backproj;\nint main( int argc, char** argv )\n{\n    VideoCapture cap;\n    Rect trackWindow;\n    int hsize = 16;\n    float hranges[] = {0,180};\n    const float* phranges = hranges;\n\n    cap.open( samples::findFile(argc > 1 ? argv[1] : \"video.avi\") );\n\n    if( !cap.isOpened() )\n    {\n        cout << \"Could not initialize capturing...\" << endl;\n        return 0;\n    }\n\n    namedWindow( \"Histogram\", 0 );\n    namedWindow( \"CamShift Demo\", 0 );\n    setMouseCallback( \"CamShift Demo\", onMouse, 0 );\n    createTrackbar( \"Vmin\", \"CamShift Demo\", &vmin, 256, 0 );\n    createTrackbar( \"Vmax\", \"CamShift Demo\", &vmax, 256, 0 );\n    createTrackbar( \"Smin\", \"CamShift Demo\", &smin, 256, 0 );\n\n    for(;;)\n    {\n        cap >> frame;\n        if( frame.empty() )\n            break;\n\n        frame.copyTo(image);\n        cvtColor(image, hsv, COLOR_BGR2HSV);\n\n        if( trackObject )\n        {\n            int _vmin = vmin, _vmax = vmax;\n\n            inRange(hsv, Scalar(0, smin, MIN(_vmin,_vmax)),\n                    Scalar(180, 256, MAX(_vmin, _vmax)), mask);\n            int ch[] = {0, 0};\n            hue.create(hsv.size(), hsv.depth());\n            mixChannels(&hsv, 1, &hue, 1, ch, 1);\n\n            if( trackObject < 0 )\n            {\n                Mat roi(hue, selection), maskroi(mask, selection);\n                calcHist(&roi, 1, 0, maskroi, hist, 1, &hsize, &phranges);\n                normalize(hist, hist, 0, 255, NORM_MINMAX);\n\n                trackWindow = selection;\n                trackObject = 1;\n\n                histimg = Scalar::all(0);\n                int binW = histimg.cols / hsize;\n                Mat buf(1, hsize, CV_8UC3);\n                for( int i = 0; i < hsize; i++ )\n                    buf.at<Vec3b>(i) = Vec3b(saturate_cast<uchar>(i*180./hsize), 255, 255);\n                cvtColor(buf, buf, COLOR_HSV2BGR);\n\n                for( int i = 0; i < hsize; i++ )\n                {\n                    int val = saturate_cast<int>(hist.at<float>(i)*histimg.rows/255);\n                    rectangle( histimg, Point(i*binW,histimg.rows),\n                            Point((i+1)*binW,histimg.rows - val),\n                            Scalar(buf.at<Vec3b>(i)), -1, 8 );\n                }\n            }\n\n            calcBackProject(&hue, 1, 0, hist, backproj, &phranges);\n            backproj &= mask;\n            meanShift(backproj, trackWindow,\n                        TermCriteria( TermCriteria::EPS | TermCriteria::COUNT, 10, 1 ));\n            rectangle(image, trackWindow, Scalar(0,0,255), 3, LINE_AA);\n        }\n\n        if( selectObject && selection.width > 0 && selection.height > 0 )\n        {\n            Mat roi(image, selection);\n            bitwise_not(roi, roi);\n        }\n\n        imshow( \"CamShift Demo\", image );\n        imshow( \"Histogram\", histimg );\n\n        char c = (char)waitKey(30);\n        if( c == 27 )\n            break;\n        switch(c)\n        {\n        case 'b':\n            backprojMode = !backprojMode;\n            break;\n        case 'c':\n            trackObject = 0;\n            histimg = Scalar::all(0);\n            break;\n        case 'h':\n            showHist = !showHist;\n            if( !showHist )\n                destroyWindow( \"Histogram\" );\n            else\n                namedWindow( \"Histogram\", 1 );\n            break;\n        case 'p':\n            paused = !paused;\n            break;\n        default:\n            ;\n        }\n    }\n\n    return 0;\n}
```

----------------------------------------

TITLE: Color Quantization Using K-Means Clustering in OpenCV
DESCRIPTION: This code performs color quantization on an image using K-means clustering. It reduces the number of colors in the image to K=8 by treating each pixel's RGB values as a 3D point, clustering these points, and then replacing each pixel's color with its cluster centroid.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('home.jpg')
Z = img.reshape((-1,3))

# convert to np.float32
Z = np.float32(Z)

# define criteria, number of clusters(K) and apply kmeans()
criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)
K = 8
ret,label,center=cv.kmeans(Z,K,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)

# Now convert back into uint8, and make original image
center = np.uint8(center)
res = center[label.flatten()]
res2 = res.reshape((img.shape))

cv.imshow('res2',res2)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Applying the Probabilistic Hough Line Transform in OpenCV (Java)
DESCRIPTION: This Java snippet uses Imgproc.HoughLinesP to find line segments with OpenCV's probabilistic Hough Transform. It requires the binary edge image and parameters for thresholds and line criteria. Outputs a matrix of line segments as (x1, y1, x2, y2).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_13

LANGUAGE: Java
CODE:
```
Mat linesP = new Mat();\nImgproc.HoughLinesP(edges, linesP, 1, Math.PI/180, 50, 50, 10);\n
```

----------------------------------------

TITLE: Performing Inverse Fourier Transform using Numpy IFFT
DESCRIPTION: This code performs inverse Fourier Transform on an image using Numpy's IFFT function after high-pass filtering in the frequency domain. It assumes prior use of FFT and shifting. The snippet removes low frequencies from the transformed data, then uses inverse shifting and IFFT to reconstruct the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
rows, cols = img.shape
crow, ccol = rows//2, cols//2
fshift[crow-30:crow+31, ccol-30:ccol+31] = 0
f_ishift = np.fft.ifftshift(fshift)
img_back = np.fft.ifft2(f_ishift)
img_back = np.real(img_back)

plt.subplot(131),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'), plt.xticks([]), plt.yticks([])
plt.subplot(132),plt.imshow(img_back, cmap = 'gray')
plt.title('Image after HPF'), plt.xticks([]), plt.yticks([])
plt.subplot(133),plt.imshow(img_back)
plt.title('Result in JET'), plt.xticks([]), plt.yticks([])

plt.show()
```

----------------------------------------

TITLE: SURF Feature Description and Matching in C++
DESCRIPTION: Demonstrates using SURF for feature description, BruteForce matcher for matching, and drawMatches for visualization in C++. Requires OpenCV contrib modules for SURF features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_description/feature_description.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <iostream>
#include <opencv2/core.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/features2d.hpp>
#include <opencv2/xfeatures2d.hpp>

using namespace cv;
using namespace cv::xfeatures2d;
using std::cout;
using std::endl;

int main( int argc, char* argv[] )
{
    CommandLineParser parser( argc, argv, "{@input1 | box.png | input image 1 }"
                                        "{@input2 | box_in_scene.png | input image 2 }"
                                        "{@output |matches.jpg | output image }"
                                        "{help h |  | show help message}" );
    if (parser.has("help"))
    {
        parser.printMessage();
        return 0;
    }

    Mat img1 = imread( samples::findFile( parser.get<String>("@input1") ), IMREAD_GRAYSCALE );
    Mat img2 = imread( samples::findFile( parser.get<String>("@input2") ), IMREAD_GRAYSCALE );
    if ( img1.empty() || img2.empty() )
    {
        cout << "Could not open or find the image!\n" << endl;
        parser.printMessage();
        return -1;
    }

    //-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors
    int minHessian = 400;
    Ptr<SURF> detector = SURF::create( minHessian );
    std::vector<KeyPoint> keypoints1, keypoints2;
    Mat descriptors1, descriptors2;
    detector->detectAndCompute( img1, noArray(), keypoints1, descriptors1 );
    detector->detectAndCompute( img2, noArray(), keypoints2, descriptors2 );

    //-- Step 2: Matching descriptor vectors with a brute force matcher
    // Since SURF is a floating-point descriptor NORM_L2 is used
    Ptr<DescriptorMatcher> matcher = DescriptorMatcher::create(DescriptorMatcher::BRUTEFORCE);
    std::vector< DMatch > matches;
    matcher->match( descriptors1, descriptors2, matches );

    //-- Draw matches
    Mat img_matches;
    drawMatches( img1, keypoints1, img2, keypoints2, matches, img_matches );

    //-- Show detected matches
    imshow("Matches", img_matches );

    imwrite(parser.get<String>("@output"), img_matches);

    waitKey();
    return 0;
}
```

----------------------------------------

TITLE: Trackbar for Upper HSV Range in C++
DESCRIPTION: Controls the upper HSV range for image thresholding in an OpenCV C++ application. Enables real-time adjustment of threshold parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
int high_h = 179;\ncv::createTrackbar("High H", "Control", &high_h, 179);
```

----------------------------------------

TITLE: Applying Histogram Equalization with cv.equalizeHist in JavaScript
DESCRIPTION: Demonstrates the usage of the `cv.equalizeHist` function in OpenCV.js to perform histogram equalization. This function takes an 8-bit single-channel source image (`src`) and produces a destination image (`dst`) of the same size and type with equalized histogram, typically improving image contrast. It stretches the pixel intensity distribution across the full range.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_histograms/js_histogram_equalization/js_histogram_equalization.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.equalizeHist (src, dst)
```

----------------------------------------

TITLE: List of OpenCV Debug Libraries
DESCRIPTION: Provides a full list of OpenCV debug libraries to be added as additional dependencies in Visual Studio.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
opencv_calib3d300d.lib
opencv_core300d.lib
opencv_features2d300d.lib
opencv_flann300d.lib
opencv_highgui300d.lib
opencv_imgcodecs300d.lib
opencv_imgproc300d.lib
opencv_ml300d.lib
opencv_objdetect300d.lib
opencv_photo300d.lib
opencv_shape300d.lib
opencv_stitching300d.lib
opencv_superres300d.lib
opencv_ts300d.lib
opencv_video300d.lib
opencv_videoio300d.lib
opencv_videostab300d.lib
```

----------------------------------------

TITLE: Drawing Minimum Enclosing Circle for Contours in Python with OpenCV
DESCRIPTION: This code snippet shows how to find and draw the minimum enclosing circle for a contour using cv.minEnclosingCircle() and cv.circle() functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_9

LANGUAGE: Python
CODE:
```
(x,y),radius = cv.minEnclosingCircle(cnt)
center = (int(x),int(y))
radius = int(radius)
cv.circle(img,center,radius,(0,255,0),2)
```

----------------------------------------

TITLE: Loading and Converting Input Image (C++)
DESCRIPTION: This snippet demonstrates loading an image in OpenCV C++ and converting it from BGR to grayscale using cv::imread and cv::cvtColor. If loading fails, the program prints an error and exits. This code must be used before thresholding and requires OpenCV's core and imgproc modules. Input: image file path. Output: grayscale Mat in src_gray.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
// [load]\nsrc = imread( argc >=2 ? argv[1] : "chicky_512.png", IMREAD_COLOR );\nif( src.empty() )\n{\n    printf("Error opening image\n");\n    return -1;\n}\ncvtColor( src, src_gray, COLOR_BGR2GRAY );\n// [load]
```

----------------------------------------

TITLE: Loading and Converting Input Image (Python)
DESCRIPTION: This Python snippet uses cv.imread to load an image and cv.cvtColor to convert it to grayscale, handling missing files by printing an error and exiting. This is preparatory for thresholding and depends on OpenCV-Python. Input: filename from command line or default. Output: src_gray as a grayscale np.ndarray.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
# [load]\nsrc = cv.imread(sys.argv[1] if len(sys.argv) > 1 else 'chicky_512.png')\nif src is None:\n    print('Error opening image')\n    sys.exit(-1)\nsrc_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n# [load]
```

----------------------------------------

TITLE: Implementing Camshift Object Tracking in Java
DESCRIPTION: Java implementation of the Camshift algorithm for adaptive object tracking. This implementation extends the Meanshift approach to include adaptive window sizing and rotation, providing better tracking for objects that change in size and orientation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/meanshift.markdown#2025-04-22_snippet_5

LANGUAGE: Java
CODE:
```
import java.util.List;\nimport javax.swing.*;\n\nimport org.opencv.core.*;\nimport org.opencv.highgui.*;\nimport org.opencv.imgproc.Imgproc;\nimport org.opencv.video.Video;\nimport org.opencv.videoio.VideoCapture;\nimport org.opencv.videoio.Videoio;\n\nclass CamshiftDemo {\n    public void run(String[] args) {\n        String filename = args.length > 0 ? args[0] : \"../data/slow_traffic_small.mp4\";\n\n        VideoCapture capture = new VideoCapture(filename);\n        if (!capture.isOpened()) {\n            System.out.println(\"Could not initialize capturing...\\n\");\n            System.exit(0);\n        }\n\n        Mat frame = new Mat();\n        capture.read(frame);\n\n        if (frame.empty()) {\n            System.out.println(\"No captured frame -- Break!\");\n            System.exit(0);\n        }\n\n        // setup initial location of window\n        Rect trackWindow = new Rect(300, 200, 100, 50);\n\n        // set up the ROI for tracking\n        Mat roi = frame.submat(trackWindow);\n        Mat hsvRoi = new Mat();\n        Imgproc.cvtColor(roi, hsvRoi, Imgproc.COLOR_BGR2HSV);\n\n        Mat mask = new Mat();\n        Core.inRange(hsvRoi, new Scalar(0, 60, 32), new Scalar(180, 255, 255), mask);\n\n        Mat roiHist = new Mat();\n        int[] channels = {0};\n        int[] histSize = {180};\n        float[] ranges = {0, 180};\n        float[][] histRanges = {ranges};\n\n        Imgproc.calcHist(List.of(hsvRoi), new MatOfInt(channels), mask, roiHist, new MatOfInt(histSize), new MatOfFloat(ranges));\n        Core.normalize(roiHist, roiHist, 0, 255, Core.NORM_MINMAX);\n\n        // Setup the termination criteria, either 10 iteration or move by at least 1 pt\n        TermCriteria termCrit = new TermCriteria(TermCriteria.EPS | TermCriteria.COUNT, 10, 1);\n\n        JFrame jframe = new JFrame(\"Camshift Demo\");\n        jframe.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n        JLabel vidPanel = new JLabel();\n        jframe.setContentPane(vidPanel);\n        jframe.setSize(frame.cols(), frame.rows());\n        jframe.setVisible(true);\n\n        Mat hsv = new Mat();\n        Mat backProject = new Mat();\n        while (true) {\n            capture.read(frame);\n            if (frame.empty()) {\n                break;\n            }\n\n            Imgproc.cvtColor(frame, hsv, Imgproc.COLOR_BGR2HSV);\n            Imgproc.calcBackProject(List.of(hsv), new MatOfInt(channels), roiHist, backProject, new MatOfFloat(histRanges), 1);\n\n            // apply CamShift to get the new location\n            RotatedRect rotatedRect = Video.CamShift(backProject, trackWindow, termCrit);\n\n            // Draw it on image\n            Point[] points = new Point[4];\n            rotatedRect.points(points);\n            MatOfPoint matPts = new MatOfPoint();\n            matPts.fromArray(points);\n            Imgproc.polylines(frame, List.of(matPts), true, new Scalar(0, 0, 255), 2);\n\n            ImageIcon image = new ImageIcon(Mat2BufferedImage.getImage(frame));\n            vidPanel.setIcon(image);\n            vidPanel.repaint();\n        }\n        System.out.println(\"Video processing done!\\n\");\n    }\n\n    public static void main(String[] args) {\n        // Load the native OpenCV library\n        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);\n        new CamshiftDemo().run(args);\n    }\n}
```

----------------------------------------

TITLE: SURF Feature Description and Matching in Python
DESCRIPTION: Demonstrates using SURF for feature description, BruteForce matcher for matching, and drawMatches for visualization in Python. Requires OpenCV contrib modules for SURF features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_description/feature_description.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np
import sys

if len(sys.argv) != 3:
    print('Please specify two images: SURF_matching_Demo.py <image1> <image2>')
    sys.exit()

img1 = cv.imread(cv.samples.findFile(sys.argv[1]), cv.IMREAD_GRAYSCALE)
img2 = cv.imread(cv.samples.findFile(sys.argv[2]), cv.IMREAD_GRAYSCALE)
if img1 is None or img2 is None:
    print('Could not open or find the images!')
    sys.exit()

#-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors
minHessian = 400
detector = cv.xfeatures2d_SURF.create(hessianThreshold=minHessian)
keypoints1, descriptors1 = detector.detectAndCompute(img1, None)
keypoints2, descriptors2 = detector.detectAndCompute(img2, None)

#-- Step 2: Matching descriptor vectors with a FLANN based matcher
# Since SURF is a floating-point descriptor NORM_L2 is used
matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)
knn_matches = matcher.knnMatch(descriptors1, descriptors2, 2)

#-- Filter matches using the Lowe's ratio test
ratio_thresh = 0.7
good_matches = []
for m,n in knn_matches:
    if m.distance < ratio_thresh * n.distance:
        good_matches.append(m)

#-- Draw matches
img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)
cv.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, img_matches, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

#-- Show detected matches
cv.imshow('Good Matches', img_matches)

cv.waitKey()
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Implementing Pixel Comparison Decision Tree for Corner Detection in C++
DESCRIPTION: This code snippet implements a decision tree for corner detection based on pixel intensity comparisons. It uses pointer arithmetic to access pixel offsets and branches between 'is_a_corner' and 'is_not_a_corner' labels based on comparing values against threshold variables c_b and cb.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_29

LANGUAGE: C++
CODE:
```
if(ptr[offset10] < c_b)
  if(ptr[offset4] < c_b)
    goto is_a_corner;
  else
    if(ptr[offset11] < c_b)
      goto is_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset11] < c_b)
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        goto is_a_corner;
      else
        if(ptr[offset10] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset8] < c_b)
        if(ptr[offset10] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset6] > cb)
    goto is_not_a_corner;
  else
    if(ptr[offset6] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset3] < c_b)
            goto is_a_corner;
          else
            if(ptr[offset10] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset1] > cb)
    if(ptr[offset6] > cb)
      goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        if(ptr[offset8] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset3] < c_b)
              goto is_a_corner;
            else
              if(ptr[offset10] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset1] < c_b)
      if(ptr[offset6] > cb)
        if(ptr[offset8] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset8] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset3] < c_b)
                goto is_a_corner;
              else
                if(ptr[offset10] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          if(ptr[offset8] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
    else
      if(ptr[offset6] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset8] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset3] < c_b)
                goto is_a_corner;
              else
                if(ptr[offset10] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
else
  if(ptr[offset2] > cb)
    goto is_not_a_corner;
  else
    if(ptr[offset2] < c_b)
      if(ptr[offset1] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset6] > cb)
            if(ptr[offset11] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
```

----------------------------------------

TITLE: Configuring Halide Layer Scheduling via YAML in OpenCV DNN
DESCRIPTION: This YAML snippet demonstrates how to provide scheduling directives for specific Halide functions (layers like `relu1` and `conv1_constant_exterior`) within an OpenCV DNN network. It shows the use of directives like `reorder`, `split`, `parallel`, `unroll`, `vectorize`, and `compute_at` to optimize performance. This configuration file is intended to be passed to `cv::dnn::Net::setHalideScheduler`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide_scheduling/dnn_halide_scheduling.markdown#2025-04-22_snippet_0

LANGUAGE: yaml
CODE:
```
relu1:
  reorder: [x, c, y]
  split: { y: 2, c: 8 }
  parallel: [yo, co]
  unroll: yi
  vectorize: { x: 4 }
conv1_constant_exterior:
  compute_at: { relu1: yi }
```

----------------------------------------

TITLE: Running SSD MobileNetV1 Inference via Model Alias - Console
DESCRIPTION: This command runs 'object_detection.py' using a model alias from models.yml, specifying the input test image. Expects that configuration files and model weights are specified under the alias. Produces detection output on the sample image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_7

LANGUAGE: console
CODE:
```
python object_detection.py ssd_tf --input ../data/pexels_double_decker_bus.jpg
```

----------------------------------------

TITLE: SURF Feature Description and Matching in Java
DESCRIPTION: Demonstrates using SURF for feature description, BruteForce matcher for matching, and drawMatches for visualization in Java. Requires OpenCV contrib modules for SURF features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_description/feature_description.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.MatOfDMatch;
import org.opencv.core.MatOfKeyPoint;
import org.opencv.features2d.DescriptorMatcher;
import org.opencv.features2d.Features2d;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.xfeatures2d.SURF;

class SURFMatchingDemo {
    public void run() {
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
        String filename1 = "../data/box.png";
        String filename2 = "../data/box_in_scene.png";
        Mat img1 = Imgcodecs.imread(filename1, Imgcodecs.IMREAD_GRAYSCALE);
        Mat img2 = Imgcodecs.imread(filename2, Imgcodecs.IMREAD_GRAYSCALE);
        if (img1.empty() || img2.empty()) {
            System.err.println("Cannot read images!");
            System.exit(0);
        }

        //-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors
        int minHessian = 400;
        SURF detector = SURF.create(minHessian);
        MatOfKeyPoint keypoints1 = new MatOfKeyPoint(), keypoints2 = new MatOfKeyPoint();
        Mat descriptors1 = new Mat(), descriptors2 = new Mat();
        detector.detectAndCompute(img1, new Mat(), keypoints1, descriptors1);
        detector.detectAndCompute(img2, new Mat(), keypoints2, descriptors2);

        //-- Step 2: Matching descriptor vectors with a brute force matcher
        // Since SURF is a floating-point descriptor NORM_L2 is used
        DescriptorMatcher matcher = DescriptorMatcher.create(DescriptorMatcher.BRUTEFORCE);
        MatOfDMatch matches = new MatOfDMatch();
        matcher.match(descriptors1, descriptors2, matches);

        //-- Draw matches
        Mat imgMatches = new Mat();
        Features2d.drawMatches(img1, keypoints1, img2, keypoints2, matches, imgMatches);

        //-- Show detected matches
        Imgcodecs.imwrite("SURFmatchesDemo.jpg", imgMatches);
    }

    public static void main(String[] args) {
        new SURFMatchingDemo().run();
    }
}
```

----------------------------------------

TITLE: Multi-Stream Data Capture with RealSense
DESCRIPTION: Shows how to capture multiple data streams (depth map, RGB image, and IR image) simultaneously using VideoCapture's grab and retrieve methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/intelperc.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
    VideoCapture capture(CAP_REALSENSE);
    for(;;)
    {
        Mat depthMap;
        Mat image;
        Mat irImage;

        capture.grab();

        capture.retrieve( depthMap, CAP_INTELPERC_DEPTH_MAP );
        capture.retrieve(    image, CAP_INTELPERC_IMAGE );
        capture.retrieve(  irImage, CAP_INTELPERC_IR_MAP);

        if( waitKey( 30 ) >= 0 )
            break;
    }
```

----------------------------------------

TITLE: Loading and Transforming Image in Java with OpenCV
DESCRIPTION: This snippet shows Java code leveraging OpenCV to load an image, calculate an affine transformation matrix from three points, apply this transformation, and subsequently rotate the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown#2025-04-22_snippet_2

LANGUAGE: Java
CODE:
```
@snippet samples/java/tutorial_code/ImgTrans/warp_affine/GeometricTransformsDemo.java Load the image
```

----------------------------------------

TITLE: Defining Segmentation Module Test Configuration in Python
DESCRIPTION: This Python data class specifies configuration parameters for testing segmentation models, allowing customization of image paths, scaling, and color preprocessing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_13

LANGUAGE: python
CODE:
```
@dataclass
class TestSegmModuleConfig:
    segm_test_data_dir: str = "test_data/sem_segm"
    test_module_name: str = "segmentation"
    test_module_path: str = "segmentation.py"
    input_img: str = os.path.join(segm_test_data_dir, "2007_000033.jpg")
    model: str = ""

    frame_height: str = str(TestSegmConfig.frame_size)
    frame_width: str = str(TestSegmConfig.frame_size)
    scale: float = 1.0
    mean: List[float] = field(default_factory=lambda: [0.0, 0.0, 0.0])
    std: List[float] = field(default_factory=list)
    crop: bool = False
    rgb: bool = True
    classes: str = os.path.join(segm_test_data_dir, "pascal-classes.txt")
```

----------------------------------------

TITLE: Defining a Header and Identifier Section - Markdown/plaintext
DESCRIPTION: Shows how to add a Level1 header and documentation identifier at the top of an OpenCV documentation page. This establishes the markdown title and a unique doxygen page identifier required for cross-referencing and documentation generation. No dependencies beyond markdown and doxygen are needed. Inputs are the title and identifier, with no outputs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_5

LANGUAGE: plaintext
CODE:
```
Writing documentation for OpenCV {#tutorial_documentation}
================================
```

----------------------------------------

TITLE: Full Contour Hierarchical Representation With RETR_TREE in OpenCV Python
DESCRIPTION: This snippet demonstrates the use of the RETR_TREE mode in OpenCV, which generates a full representation of contour hierarchies, capturing detailed parent-child-grandparent relationships among contours.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_hierarchy/py_contours_hierarchy.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
>>> hierarchy
array([[[ 7, -1,  1, -1],
        [-1, -1,  2,  0],
        [-1, -1,  3,  1],
        [-1, -1,  4,  2],
        [-1, -1,  5,  3],
        [ 6, -1, -1,  4],
        [-1,  5, -1,  4],
        [ 8,  0, -1, -1],
        [-1,  7, -1, -1]]])
```

----------------------------------------

TITLE: Using cv::putText with Random Parameters in OpenCV C++
DESCRIPTION: Demonstrates calling the `cv::putText` function to draw text on an image. It uses the `rng` object to randomize several parameters: the bottom-left origin point (`org`), the font type (`rng.uniform(0,8)`), the font scale (`rng.uniform(0,100)*0.05+0.1`), the text color (`randomColor(rng)`), and the text thickness (`rng.uniform(1, 10)`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
@code{.cpp}
putText( image, "Testing text rendering", org, rng.uniform(0,8),
         rng.uniform(0,100)*0.05+0.1, randomColor(rng), rng.uniform(1, 10), lineType);
@endcode
```

----------------------------------------

TITLE: Iterator-Based Image Scanning in OpenCV
DESCRIPTION: This snippet demonstrates using iterators to safely traverse an image matrix in OpenCV. It simplifies skipping non-contiguous memory gaps and provides safe access to image elements, especially color channels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
@snippet how_to_scan_images.cpp scan-iterator
```

----------------------------------------

TITLE: Visualizing Barcode Detection Results
DESCRIPTION: Provides a way to visualize the results of barcode detection, showing how detected barcodes appear on the processed image. Relies on visualization libraries and functions within OpenCV for display purposes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/barcode_detect_and_decode.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
@snippet cpp/barcode.cpp visualize
```

----------------------------------------

TITLE: Finding Calibration Patterns (Chessboard/Circles/ChArUco) in Image using OpenCV C++
DESCRIPTION: This C++ code snippet reference indicates code that finds calibration patterns (chessboard, circles grid, or ChArUco) within an input image using OpenCV. It utilizes functions like `cv::findChessboardCorners`, `cv::findCirclesGrid`, or `cv::aruco::CharucoDetector::detectBoard` based on the configured pattern type, outputting the detected pattern points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp find_pattern
```

----------------------------------------

TITLE: Converting Laplacian Output to CV_8U in Java
DESCRIPTION: Converts the CV_16S Laplacian output (`dst`) to a CV_8U image (`absDst`) using Core.convertScaleAbs. This takes the absolute value and scales the result appropriately for display. Requires OpenCV Java bindings (Core).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_19

LANGUAGE: java
CODE:
```
//! [convert]
// converting back to CV_8U
absDst = new Mat();
Core.convertScaleAbs( dst, absDst );
//! [convert]
```

----------------------------------------

TITLE: Applying the Standard Hough Line Transform in OpenCV (Python)
DESCRIPTION: This Python snippet uses OpenCV's cv2.HoughLines to detect lines from an edge-detected image. Inputs are the binary edge map, rho and theta resolutions, and a threshold; output is a list of (rho, theta) line parameters. Requires cv2 and edge detection result.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
lines = cv2.HoughLines(edges, 1, np.pi/180, 150, None, 0, 0)\n
```

----------------------------------------

TITLE: Compiling OpenCV with Custom HAL Replacement
DESCRIPTION: This snippet provides steps to compile the OpenCV library using a custom HAL replacement. By setting the OpenCV_HAL_DIR variable, users can specify the directory of the compiled HAL library. The subsequent make command will use this HAL during the build process, with an example command to run a specific performance test for logical 'bitwise_and' operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/hal/README.md#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
cmake \
    -DOpenCV_HAL_DIR="<home-dir>/my-hal-build/" \
    <opencv-src>
```

LANGUAGE: shell
CODE:
```
make
```

LANGUAGE: shell
CODE:
```
./bin/opencv_perf_core --gtest_filter=*bitwise_and*
```

----------------------------------------

TITLE: Sample Log Output for Model Evaluation Run (Console)
DESCRIPTION: Provides an example of log output upon running the evaluation script, detailing input data and log file destinations. While not executable, this output illustrates what information is surfaced by the evaluation process. Inputs reflect paths and settings, while outputs are saved logs containing further evaluation results. No additional dependencies are required to generate this output beyond a successful script run.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_3

LANGUAGE: console
CODE:
```
===== Running evaluation of the model with the following params:
    * val data location: ./ILSVRC2012_img_val
    * log file location: dnn_model_runner/dnn_conversion/logs/TF_mobilenet_log.txt
```

----------------------------------------

TITLE: Configuring OpenNI Sensor Properties
DESCRIPTION: Example showing how to set and get sensor properties using VideoCapture methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/kinect_openni.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
VideoCapture capture( CAP_OPENNI );
capture.set( CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE, CAP_OPENNI_VGA_30HZ );
cout << "FPS    " << capture.get( CAP_OPENNI_IMAGE_GENERATOR+CAP_PROP_FPS ) << endl;
```

----------------------------------------

TITLE: Computing Transformed Corner Coordinates with OpenCV - Python
DESCRIPTION: Using OpenCV’s cv2.perspectiveTransform, this Python snippet maps detected chessboard corners to their new positions from homography. Expects numpy arrays and a computed 3x3 homography. Returns transformed points for overlaying or match verification. Useful for evaluating transformation accuracy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_18

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/features2D/Homography/perspective_correction.py compute-transformed-corners
```

----------------------------------------

TITLE: Detecting ChArUco Diamond Markers in an Image with OpenCV ArUco (C++)
DESCRIPTION: This snippet illustrates how to detect ChArUco diamond markers in an image using the cv::aruco::CharucoDetector::detectDiamonds() function in OpenCV C++. It requires a source image, previously detected ArUco marker corners and IDs, and a specified square-to-marker size ratio. The function outputs detected diamond corners and their corresponding IDs arrays. Dependencies include OpenCV's aruco module and prior marker detection. It expects the input chessboard image and marker data; square length and marker length parameters affect detection accuracy and must match the generated diamonds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_diamond_detection/charuco_diamond_detection.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
// Assuming markerCorners and markerIds have been obtained from prior detection
cv::Mat image;
std::vector<std::vector<cv::Point2f>> markerCorners;
std::vector<int> markerIds;
float squareMarkerLengthRate = 1.67f; // Example value: squareLength / markerLength
std::vector<std::vector<cv::Point2f>> diamondCorners;
std::vector<cv::Vec4i> diamondIds;
cv::aruco::CharucoDetector charucoDetector(dictionary);
charucoDetector.detectDiamonds(image, markerCorners, markerIds,
    diamondCorners, diamondIds, squareMarkerLengthRate);
```

----------------------------------------

TITLE: Basic Image Pyramid Operations with OpenCV
DESCRIPTION: Demonstrates how to create lower and higher resolution versions of an image using pyramid operations. Uses cv.pyrDown() to reduce resolution and cv.pyrUp() to increase resolution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_pyramids/py_pyramids.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
img = cv.imread('messi5.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"
lower_reso = cv.pyrDown(higher_reso)
```

LANGUAGE: python
CODE:
```
higher_reso2 = cv.pyrUp(lower_reso)
```

----------------------------------------

TITLE: Threshold Operation Callback Function (Java)
DESCRIPTION: This Java method re-applies the Imgproc.threshold function each time a trackbar value changes, updating the GUI window with the result. Invoked by onChange listeners. Inputs: current src_gray Mat, threshold_value, threshold_type; output: updated visualization in window.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_13

LANGUAGE: Java
CODE:
```
// [Threshold_Demo]\nstatic void update() {\n    Imgproc.threshold(src_gray, dst = new Mat(), threshold_value, max_BINARY_value, threshold_type);\n    HighGui.imshow(window_name, dst);\n}\n// [Threshold_Demo]
```

----------------------------------------

TITLE: Downsampling Image using pyrDown in Java
DESCRIPTION: Performs image downsampling on the `tmp` Mat object using `Imgproc.pyrDown`. The output `dst` Mat object is specified to have dimensions half those of the input.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_13

LANGUAGE: java
CODE:
```
            } else if( c == 'o' ) {
                Imgproc.pyrDown( tmp, dst, new Size( tmp.cols()/2, tmp.rows()/2 ) );
                System.out.println("** Zoom Out: Image / 2");
            }
```

----------------------------------------

TITLE: Applying SURF Feature Detection in Python
DESCRIPTION: This Python script demonstrates the use of OpenCV's SURF detector for keypoint detection. It includes image loading, SURF detector initialization, keypoint detection, and visualization of the results using matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_detection/feature_detection.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2 as cv\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv.imread('box.png', cv.IMREAD_GRAYSCALE)\nif img is None:\n    print('Could not open or find the image:', 'box.png')\n    exit(0)\n\n# Create SURF object. You can specify params here or later.\n# Here I set Hessian Threshold to 400\nsurf = cv.xfeatures2d.SURF_create(400)\n\n# Find keypoints and descriptors directly\nkp = surf.detect(img,None)\n\nimg2 = cv.drawKeypoints(img, kp, None, (255,0,0), 4)\n\nplt.imshow(img2)\nplt.show()
```

----------------------------------------

TITLE: Demonstrating Sobel and Laplacian Operators in OpenCV Python
DESCRIPTION: This snippet demonstrates the use of Laplacian and Sobel operators to find gradients in an image. It applies different gradient operators (Laplacian, Sobel X, and Sobel Y) to a grayscale image and visualizes the results using matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_gradients/py_gradients.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('dave.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"

laplacian = cv.Laplacian(img,cv.CV_64F)
sobelx = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)
sobely = cv.Sobel(img,cv.CV_64F,0,1,ksize=5)

plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')
plt.title('Original'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')
plt.title('Laplacian'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')
plt.title('Sobel X'), plt.xticks([]), plt.yticks([])
plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')
plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])

plt.show()
```

----------------------------------------

TITLE: Initializing Face Recognizer (FaceRecognizerSF) - OpenCV DNN Python
DESCRIPTION: This snippet demonstrates how to create a FaceRecognizerSF instance in Python using OpenCV. It takes an ONNX model, input image size, and other parameters as arguments. The output is an object ready to process face patches and extract feature vectors representing faces for recognition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_6

LANGUAGE: Python
CODE:
```
# Initialize FaceRecognizerSF
recognizer = cv2.FaceRecognizerSF_create(
    modelPath,        # Path to face recognition .onnx model
    "",               # No config file
    (112, 112)        # Input size expected by recognition model
)
```

----------------------------------------

TITLE: Defining a Function to Draw Random Lines with OpenCV in C++
DESCRIPTION: Defines the function `Drawing_Random_Lines` which draws a specified number (NUMBER) of lines on the input `image`. Inside a loop, it generates random start (pt1) and end (pt2) points using `rng.uniform`, selects a random color using `randomColor`, and chooses a random thickness. It uses `cv::line` to draw each line and updates the display using `cv::imshow`. `cv::waitKey` introduces a delay and checks for user interruption.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
@code{.cpp}
int Drawing_Random_Lines( Mat image, char* window_name, RNG rng )
{
  int lineType = 8;
  Point pt1, pt2;

  for( int i = 0; i < NUMBER; i++ )
  {
   pt1.x = rng.uniform( x_1, x_2 );
   pt1.y = rng.uniform( y_1, y_2 );
   pt2.x = rng.uniform( x_1, x_2 );
   pt2.y = rng.uniform( y_1, y_2 );

   line( image, pt1, pt2, randomColor(rng), rng.uniform(1, 10), 8 );
   imshow( window_name, image );
   if( waitKey( DELAY ) >= 0 )
   { return -1; }
  }
  return 0;
}
@endcode
```

----------------------------------------

TITLE: Padding Images with Borders in OpenCV JavaScript
DESCRIPTION: This snippet describes cv.copyMakeBorder, a function in OpenCV.js that pads an image with additional borders. Parameters specify the source and destination arrays, border thickness on each side (top, bottom, left, right), border type, and an optional constant border value. Often used to prepare images for DFT or convolution operations. Dependencies: OpenCV.js; requires source and output Mat objects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_transforms/js_fourier_transform/js_fourier_transform.markdown#2025-04-22_snippet_2

LANGUAGE: JavaScript
CODE:
```
cv.copyMakeBorder (src, dst, top, bottom, left, right, borderType, value = new cv.Scalar())
```

----------------------------------------

TITLE: Adding OpenMP Support to OpenCV Video Module
DESCRIPTION: Conditionally links OpenMP libraries to the video module if OpenMP support is available and its libraries are defined.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/video/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(HAVE_OPENMP AND DEFINED OpenMP_CXX_LIBRARIES AND OpenMP_CXX_LIBRARIES)
  ocv_target_link_libraries(${the_module} LINK_PRIVATE "${OpenMP_CXX_LIBRARIES}")
endif()
```

----------------------------------------

TITLE: Computing HOG Descriptors for Digit Recognition in Python OpenCV
DESCRIPTION: Function that calculates HOG (Histogram of Oriented Gradients) features for a digit image. Computes Sobel derivatives, gradient magnitudes and directions, and generates a 64-value feature vector.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_svm/py_svm_opencv/py_svm_opencv.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
def hog(img):
    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)
    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)
    mag, ang = cv2.cartToPolar(gx, gy)
    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)
    bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]
    mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]
    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]
    hist = np.hstack(hists)     # hist is a 64 bit vector
    return hist
```

----------------------------------------

TITLE: Extracting 2D and 3D Correspondences in C++
DESCRIPTION: Extracts 2D image points and corresponding 3D model points by sorting through the good matches from feature matching. Essential for applications requiring 3D spatial data alignment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
// -- Step 2: Find out the 2D/3D correspondences

std::vector<cv::Point3f> list_points3d_model_match;    // container for the model 3D coordinates found in the scene
std::vector<cv::Point2f> list_points2d_scene_match;    // container for the model 2D coordinates found in the scene

for(unsigned int match_index = 0; match_index < good_matches.size(); ++match_index)
{
    cv::Point3f point3d_model = list_points3d_model[ good_matches[match_index].trainIdx ];   // 3D point from model
    cv::Point2f point2d_scene = keypoints_scene[ good_matches[match_index].queryIdx ].pt;    // 2D point from the scene
    list_points3d_model_match.push_back(point3d_model);                                      // add 3D point
    list_points2d_scene_match.push_back(point2d_scene);                                      // add 2D point
}
```

----------------------------------------

TITLE: Building libspng Static Library
DESCRIPTION: Defines and configures the static library target for libspng. Sets compiler definitions for MSVC, links with ZLIB, and configures output properties including debug postfix and output paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libspng/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(MSVC)
    add_definitions(-D_CRT_SECURE_NO_DEPRECATE)
endif(MSVC)

add_library(${SPNG_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${spng_headers} ${spng_sources})
target_link_libraries(${SPNG_LIBRARY} ${ZLIB_LIBRARIES})

set_target_properties(${SPNG_LIBRARY}
        PROPERTIES OUTPUT_NAME ${SPNG_LIBRARY}
        DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
        COMPILE_PDB_NAME ${SPNG_LIBRARY}
        COMPILE_PDB_NAME_DEBUG "${SPNG_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
        ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
        )

target_compile_definitions(${SPNG_LIBRARY} PUBLIC SPNG_STATIC)
```

----------------------------------------

TITLE: Performing Brightness and Contrast Adjustment in OpenCV (Python)
DESCRIPTION: This Python snippet demonstrates how to adjust contrast and brightness of an image using OpenCV. The code involves reading an image, creating a new matrix with the same size and type, and applying user-specified gain (alpha) and bias (beta) using `cv.convertScaleAbs` to ensure pixel values are within valid limits.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np

image = cv.imread('path/to/image')
new_image = np.zeros(image.shape, image.dtype)

alpha = 2.2  # Contrast control
beta = 50    # Brightness control


cv.convertScaleAbs(image, new_image, alpha=alpha, beta=beta)

cv.imshow('Original Image', image)
cv.imshow('New Image', new_image)

cv.waitKey(0)
cv.destroyAllWindows()

```

----------------------------------------

TITLE: Detecting Faces and Eyes with Haar Cascades in C++ using OpenCV
DESCRIPTION: This C++ code snippet demonstrates how to use OpenCV's CascadeClassifier to detect faces and eyes. It involves loading pre-trained Haar cascade XML files for frontal faces and eyes using `CascadeClassifier::load`. It then captures video frames, converts them to grayscale, and applies `detectMultiScale` to find face regions. Within each detected face, it further applies `detectMultiScale` to locate eyes. Finally, it draws rectangles around the detected objects and displays the processed frame. Requires OpenCV library and the specified Haar cascade XML files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/cascade_classifier.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
// This tutorial code's is shown lines below. You can also download it from
// [here](https://github.com/opencv/opencv/tree/4.x/samples/cpp/tutorial_code/objectDetection/objectDetection.cpp)
@include samples/cpp/tutorial_code/objectDetection/objectDetection.cpp
```

----------------------------------------

TITLE: Calibrating Camera with ChArUco Board in OpenCV
DESCRIPTION: This code demonstrates how to perform camera calibration using a ChArUco board. The process involves detecting ChArUco corners across multiple viewpoints, collecting the data, and then using calibrateCamera() to compute the camera matrix and distortion coefficients.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_calibration/aruco_calibration.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
std::vector<std::vector<cv::Point2f>> allCharucoCorners;
std::vector<std::vector<int>> allCharucoIds;
std::vector<cv::Mat> rvecs, tvecs;
cv::Size imgSize;
```

LANGUAGE: cpp
CODE:
```
// Collect data from each frame
bool found = cv::findChessboardCorners(frame, chessboardSize, corners, flags);
// if the charuco board was found
if(found) {
    // Get charuco corners and ids from detected aruco markers
    aruco::interpolateCornersCharuco(corners, ids, frame, board, charucoCorners, charucoIds);
    // if at least one charuco corner detected
    if(charucoIds.size() > 0) {
        aruco::drawDetectedCornersCharuco(frameCopy, charucoCorners, charucoIds);
        allCharucoCorners.push_back(charucoCorners);
        allCharucoIds.push_back(charucoIds);
    }
}
```

LANGUAGE: cpp
CODE:
```
// After all frames processed
cv::Mat cameraMatrix, distCoeffs;
// prepare data for calibration
std::vector<cv::Mat> allCharucoCornersConcatenated;
std::vector<int> allCharucoIdsConcatenated;
std::vector<int> markerCounterPerFrame;

markerCounterPerFrame.reserve(allCharucoCorners.size());
for(unsigned int i = 0; i < allCharucoCorners.size(); i++) {
    markerCounterPerFrame.push_back((int)allCharucoCorners[i].size());
    for(unsigned int j = 0; j < allCharucoCorners[i].size(); j++) {
        allCharucoCornersConcatenated.push_back(allCharucoCorners[i][j]);
        allCharucoIdsConcatenated.push_back(allCharucoIds[i][j]);
    }
}

// calibrate camera using charuco
double repError = cv::aruco::calibrateCameraCharuco(allCharucoCorners, allCharucoIds,
                                                  board, imgSize, cameraMatrix, distCoeffs,
                                                  rvecs, tvecs, calibrationFlags);

// print calibration results
std::cout << "Rep Error: " << repError << std::endl;
std::cout << "Calibration matrix: " << cameraMatrix << std::endl;
std::cout << "Distortion coefficients: " << distCoeffs << std::endl;
```

----------------------------------------

TITLE: Converting Image to Grayscale in Java
DESCRIPTION: Converts the blurred source image to grayscale using Imgproc.cvtColor with the COLOR_BGR2GRAY conversion code. The output is stored in the `srcGray` Mat object. Requires OpenCV Java bindings (Imgproc).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_13

LANGUAGE: java
CODE:
```
//! [convert_to_gray]
// Convert the image to grayscale
srcGray = new Mat();
Imgproc.cvtColor( src, srcGray, Imgproc.COLOR_BGR2GRAY );
//! [convert_to_gray]
```

----------------------------------------

TITLE: Template Matching Formula: TM_CCORR (LaTeX)
DESCRIPTION: Mathematical formula for the Cross Correlation (TM_CCORR) template matching method used in OpenCV's `matchTemplate` function. R(x,y) is the result, T is the template, and I is the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_3

LANGUAGE: latex
CODE:
```
\f[R(x,y)= \sum _{x',y'} (T(x',y')  \cdot I(x+x',y+y'))\f]
```

----------------------------------------

TITLE: Normalizing Template Matching Results (C++)
DESCRIPTION: Normalizes the raw result matrix obtained from `matchTemplate` to the range [0, 1] using `cv::normalize`. This makes the result easier to visualize and interpret, regardless of the matching method used. Normalization type `NORM_MINMAX` is employed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_25

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp normalize
```

----------------------------------------

TITLE: Accessing Single Pixel Intensity Value in Grayscale Image with OpenCV in Python
DESCRIPTION: Demonstrates pixel value access for a single-channel image as a NumPy array in Python with OpenCV. Direct 2D array indexing is used: img[y, x]. Input indices must be valid for the image. Result is an integer intensity between 0-255 in most cases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
intensity = img[y, x]
```

----------------------------------------

TITLE: Initializing Camera in viewDidLoad (Objective-C)
DESCRIPTION: This snippet shows how to initialize the CvVideoCamera in the viewDidLoad method, setting various properties like device position, session preset, and orientation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/video_processing/video_processing.markdown#2025-04-22_snippet_2

LANGUAGE: Objective-C
CODE:
```
- (void)viewDidLoad
{
    [super viewDidLoad];
    // Do any additional setup after loading the view, typically from a nib.

    self.videoCamera = [[CvVideoCamera alloc] initWithParentView:imageView];
    self.videoCamera.defaultAVCaptureDevicePosition = AVCaptureDevicePositionFront;
    self.videoCamera.defaultAVCaptureSessionPreset = AVCaptureSessionPreset352x288;
    self.videoCamera.defaultAVCaptureVideoOrientation = AVCaptureVideoOrientationPortrait;
    self.videoCamera.defaultFPS = 30;
    self.videoCamera.grayscale = NO;
}
```

----------------------------------------

TITLE: Generating Single WinRT Configuration using setup_winrt.bat
DESCRIPTION: Executes the `setup_winrt.bat` script to generate Visual Studio project files specifically for Windows Phone 8.1 targeting the x86 architecture. The `-b` flag is omitted, so the generated solution will need to be built manually.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_1

LANGUAGE: batch
CODE:
```
setup_winrt.bat "WP" "8.1" "x86"
```

----------------------------------------

TITLE: Calculating Contour Perimeter in Python with OpenCV
DESCRIPTION: This code shows how to calculate the perimeter (arc length) of a contour using the cv.arcLength() function. The second argument specifies whether the contour is closed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
perimeter = cv.arcLength(cnt,True)
```

----------------------------------------

TITLE: Accessing Point in Matrix of Points with OpenCV in C++
DESCRIPTION: Shows how to access an individual point in a matrix of CV_32FC2 or CV_32FC3 points using Mat::at. Input is Mat constructed from vector; result is cv::Point2f or cv::Point3f. Useful for geometric operations. Out-of-bounds access may crash.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_20

LANGUAGE: C++
CODE:
```
cv::Point2f pt = pointsMat.at<cv::Point2f>(i, 0);
```

----------------------------------------

TITLE: Applying Morphological Transformations with Interactive Trackbars in OpenCV (Python)
DESCRIPTION: This Python code implements an interactive GUI for exploring different morphological operations using OpenCV, such as Opening, Closing, Morphological Gradient, Top Hat, and Black Hat. It loads an input image, creates trackbars for selecting the operation, structuring element, and kernel size, and applies the selected operation in real time whenever any trackbar value changes. It depends on OpenCV (cv2), requires an image path, and produces the result in a named window. Users control parameters via the GUI; outputs are shown dynamically. The solution is cross-platform but depends on OpenCV's GUI capability and Python 3.x.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2\nimport numpy as np\n\n# Load the image\nfilename = 'baboon.png'\nimg = cv2.imread(filename)\n\ndef nothing(x):\n    pass\n\ncv2.namedWindow('Morphology Transformations', cv2.WINDOW_AUTOSIZE)\ncv2.createTrackbar('Operator:\n0:Open\n1:Close\n2:Gradient\n3:Top Hat\n4:Black Hat','Morphology Transformations',0,4,nothing)\ncv2.createTrackbar('Element:\n0:Rect\n1:Cross\n2:Ellipse','Morphology Transformations',0,2,nothing)\ncv2.createTrackbar('Kernel size:\n2n+1','Morphology Transformations',0,21,nothing)\n\nwhile True:\n    morph_operator = cv2.getTrackbarPos('Operator:\n0:Open\n1:Close\n2:Gradient\n3:Top Hat\n4:Black Hat','Morphology Transformations')\n    morph_elem = cv2.getTrackbarPos('Element:\n0:Rect\n1:Cross\n2:Ellipse','Morphology Transformations')\n    morph_size = cv2.getTrackbarPos('Kernel size:\n2n+1','Morphology Transformations')\n\n    operation = morph_operator + 2\n    element = cv2.getStructuringElement(morph_elem,(2*morph_size+1,2*morph_size+1),(morph_size,morph_size))\n    dst = cv2.morphologyEx(img, operation, element)\n    cv2.imshow('Morphology Transformations', dst)\n    key = cv2.waitKey(1)&0xFF\n    if key == 27:\n        break\ncv2.destroyAllWindows()\n
```

----------------------------------------

TITLE: Reading Images using OpenCV in C++
DESCRIPTION: This snippet demonstrates how to read an image file in C++ using OpenCV's cv::imread function. The first argument specifies the file path while the second argument determines the color format (e.g., IMREAD_COLOR). The image data is stored in a cv::Mat object for further processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
Mat image = imread("starry_night.jpg", IMREAD_COLOR);
```

----------------------------------------

TITLE: Training SVM Model with Non-Linearly Separable Data (Java)
DESCRIPTION: Trains the SVM model in Java using the prepared training data containing both linearly and non-linearly separable examples. The training process requires patience due to high iteration count needed for convergence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
// Train the SVM
System.out.print("\nTraining the SVM...");
svm.train(completeTrainData, Ml.ROW_SAMPLE, completeTrainLabels);
System.out.println("Finished training");
```

----------------------------------------

TITLE: Calculating Vector Magnitude Using OpenCV in JavaScript
DESCRIPTION: This snippet illustrates the use of cv.magnitude to compute the magnitude of complex vectors given their x and y components. Used in processing the DFT result to extract amplitude information. Inputs are two floating-point arrays (x, y), with the result stored in the output array (magnitude) of matching size and type. Dependencies: OpenCV.js; input arrays must match in size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_transforms/js_fourier_transform/js_fourier_transform.markdown#2025-04-22_snippet_3

LANGUAGE: JavaScript
CODE:
```
cv.magnitude (x, y, magnitude)
```

----------------------------------------

TITLE: Plot RGB Histogram
DESCRIPTION: Creates separate histograms for each color channel (BGR) in a color image and plots them together using Matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('home.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"
color = ('b','g','r')
for i,col in enumerate(color):
    histr = cv.calcHist([img],[i],None,[256],[0,256])
    plt.plot(histr,color = col)
    plt.xlim([0,256])
plt.show()
```

----------------------------------------

TITLE: Classifying and Visualizing SVM Regions with OpenCV - C++
DESCRIPTION: This C++ snippet demonstrates how to train an SVM using OpenCV, classify data over a Cartesian plane, and visualize predicted classes by coloring points based on SVM output (green for label 1, blue for label -1). Dependencies include OpenCV C++ libraries and appropriate headers. Key steps involve setting up training data, configuring the SVM, and iterating over the image to assign colors based on classification. The expected input is an image or pixel grid with labeled data points, and the output is a visual representation of the SVM decision boundary.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
#include <opencv2/opencv.hpp>
#include <opencv2/ml.hpp>

// Training and visualizing SVM classification regions
// ... (full code from samples/cpp/tutorial_code/ml/introduction_to_svm/introduction_to_svm.cpp, show)
```

----------------------------------------

TITLE: Running SSD MobileNetV1 Inference with Explicit File Parameters - Console
DESCRIPTION: Runs the 'object_detection.py' script with explicit individual parameters for the model, config, input image, input dimensions, and class file. Offers more flexibility to override defaults and hardcoded options from YAML. Input/output files must exist and be accessible.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_8

LANGUAGE: console
CODE:
```
python object_detection.py --model ssd_mobilenet_v1_coco_2017_11_17.pb --config  ssd_mobilenet_v1_coco_2017_11_17.pbtxt  --input ../data/pexels_double_decker_bus.jpg --width 300 --height 300 --classes ../data/dnn/object_detection_classes_coco.txt
```

----------------------------------------

TITLE: Resizing Images with OpenCV
DESCRIPTION: This snippet demonstrates image resizing using OpenCV's cv.resize function. It allows you to specify the size of the output image directly or use scaling factors. The function requires interpolation methods, with cv.INTER_AREA best for shrinking and cv.INTER_CUBIC or cv.INTER_LINEAR for zooming.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_geometric_transformations/js_geometric_transformations.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
cv.resize(src, dst, dsize, fx = 0, fy = 0, interpolation = cv.INTER_LINEAR)
```

----------------------------------------

TITLE: Drawing a 3D Cube on an Image with OpenCV (Python)
DESCRIPTION: A modified function to render a 3D cube on the image by projecting eight 3D corner points. Uses OpenCV for drawing contours and lines, first outlining the cube base, then verticals, and finally the top. Accepts an image, chessboard corners, and projected cube points, and returns the image with the cube rendered for visualization of object pose.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_pose/py_pose.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
def draw(img, corners, imgpts):\n    imgpts = np.int32(imgpts).reshape(-1,2)\n\n    # draw ground floor in green\n    img = cv.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n\n    # draw pillars in blue color\n    for i,j in zip(range(4),range(4,8)):\n        img = cv.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n\n    # draw top layer in red color\n    img = cv.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)\n\n    return img
```

----------------------------------------

TITLE: Applying a Lookup Table (LUT) to an Image using cv::LUT() in C++
DESCRIPTION: This C++ snippet shows how to apply a pre-defined lookup table (`lookUpTable`) to an input image (`I`) using the `cv::LUT()` function from OpenCV. The result of the transformation is stored in the output image (`J`). This is presented as a potentially faster alternative to manual pixel iteration. Requires the OpenCV library and initialized `cv::Mat` objects for input (I), output (J), and the LUT.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
@snippet how_to_scan_images.cpp table-use
```

----------------------------------------

TITLE: Converting BGR Image to Grayscale with OpenCV in C++
DESCRIPTION: Converts a color image (BGR) to grayscale using cvtColor in OpenCV C++. Uses COLOR_BGR2GRAY code. Input is 3-channel Mat, output is 1-channel Mat. Output must be preallocated or function will allocate it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_34

LANGUAGE: C++
CODE:
```
cv::Mat gray;\ncv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);
```

----------------------------------------

TITLE: Loading Raster Data with GDAL in OpenCV (C++)
DESCRIPTION: This snippet shows how to use OpenCV's cv::imread function with specific flags to force loading using GDAL. It is essential for ensuring the correct import of georeferenced raster data, preserving its native format. Dependencies include OpenCV compiled with GDAL support, and input files must be in a GDAL-supported format.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/raster_io_gdal.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
// Load a raster image with GDAL support
cv::Mat image = cv::imread("/path/to/file.tif", cv::IMREAD_UNCHANGED | cv::IMREAD_LOAD_GDAL);
```

----------------------------------------

TITLE: Shifting Quadrants of Fourier Transform Output in OpenCV C++
DESCRIPTION: Rearranges the quadrants of a 2D matrix, typically the output of a Discrete Fourier Transform (DFT), to move the zero-frequency component (origin) from the top-left corner to the center of the matrix. This is a standard operation required for visualization and filtering in the frequency domain. It swaps the top-left quadrant with the bottom-right and the top-right with the bottom-left. Requires OpenCV `Mat` operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/out_of_focus_deblur_filter/out_of_focus_deblur_filter.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
void fftshift(const Mat& inputImg, Mat& outputImg)
{
    outputImg = inputImg.clone();
    int cx = outputImg.cols / 2;
    int cy = outputImg.rows / 2;
    Mat q0(outputImg, Rect(0, 0, cx, cy));
    Mat q1(outputImg, Rect(cx, 0, cx, cy));
    Mat q2(outputImg, Rect(0, cy, cx, cy));
    Mat q3(outputImg, Rect(cx, cy, cx, cy));
    Mat tmp;
    q0.copyTo(tmp);
    q3.copyTo(q0);
    tmp.copyTo(q3);
    q1.copyTo(tmp);
    q2.copyTo(q1);
    tmp.copyTo(q2);
}
```

----------------------------------------

TITLE: Accessing OpenCV Documentation in Clojure
DESCRIPTION: This code snippet provides a way to search for javadoc documentation of OpenCV classes, leveraging the REPL to find external Java documentation quickly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_12

LANGUAGE: clojure
CODE:
```
user=> (javadoc Rect)
"http://www.google.com/search?btnI=I%27m%20Feeling%20Lucky&q=allinurl:org/opencv/core/Rect.html"
```

----------------------------------------

TITLE: Converting Image for OpenCV DNN
DESCRIPTION: Prepares an image for input to an OpenCV-based DNN by resizing, reordering channels and normalizing pixel values. It employs OpenCV's blobFromImage function and requires numpy for array manipulations. Inputs involve image path and mean normalization value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
# read the image
input_img = cv2.imread(img_path, cv2.IMREAD_COLOR)
input_img = input_img.astype(np.float32)

# preprocess image for TF model input
tf_preproc_img = cv2.resize(input_img, (513, 513))
tf_preproc_img = cv2.cvtColor(tf_preproc_img, cv2.COLOR_BGR2RGB)

# define preprocess parameters for OpenCV DNN
mean = np.array([1.0, 1.0, 1.0]) * 127.5
scale = 1 / 127.5

# prepare input blob to fit the model input:
# 1. subtract mean
# 2. scale to set pixel values from 0 to 1
input_blob = cv2.dnn.blobFromImage(
    image=input_img,
    scalefactor=scale,
    size=(513, 513),  # img target size
    mean=mean,
    swapRB=True,  # BGR -> RGB
    crop=False  # center crop
)
```

----------------------------------------

TITLE: Configuring Standalone Sample Build Environment in CMake
DESCRIPTION: Sets up the CMake environment for building samples standalone (not part of the main OpenCV build). It requires CMake version 3.5+, defines the project as 'samples' (C/CXX), adds a `BUILD_EXAMPLES` option (default ON), and uses `find_package(OpenCV REQUIRED PATHS "..")` to locate a pre-installed OpenCV library, assuming the samples directory is located relative to the OpenCV installation share directory as described in the comments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.5)

project(samples C CXX)
option(BUILD_EXAMPLES "Build samples" ON)

# Assuming following installation folder structure (default for UNIX):
# <install_root>/share/
# └── OpenCV/  <-- OPENCV_CONFIG_INSTALL_PATH
#     ├── OpenCVConfig.cmake  <-- file to be found by find_package
#     ├── ...
#     ├── samples/  <-- OPENCV_SAMPLES_SRC_INSTALL_PATH
#     │   ├── CMakeLists.txt  <-- this file
#     │   ├── cpp/
find_package(OpenCV REQUIRED PATHS "..")
```

----------------------------------------

TITLE: Retrieving Camera Properties from Astra Depth Sensor
DESCRIPTION: Demonstrates retrieving camera properties from the depth sensor using the VideoCapture get method. This example retrieves the maximum depth value supported by the camera, which is important for properly scaling depth data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
// Get device properties
double maxDepth = depthStream.get(CAP_PROP_OPENNI_FRAME_MAX_DEPTH);
printf("Max depth: %f\n", maxDepth);
```

----------------------------------------

TITLE: Implementing AGAST 5-8 Corner Score Detection in OpenCV
DESCRIPTION: This code implements the AGAST_5_8 corner score calculation which is a specialized variant of the AGAST corner detection algorithm. It tests neighboring pixels in an 8-point pattern around a center pixel to determine if the pixel is a corner based on intensity thresholds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_42

LANGUAGE: C++
CODE:
```
// 8 pixel mask
template<>
int agast_cornerScore<AgastFeatureDetector::AGAST_5_8>(const uchar* ptr, const int pixel[], int threshold)
{
    int bmin = threshold;
    int bmax = 255;
    int b_test = (bmax + bmin)/2;

    short offset0 = (short) pixel[0];
    short offset1 = (short) pixel[1];
    short offset2 = (short) pixel[2];
    short offset3 = (short) pixel[3];
    short offset4 = (short) pixel[4];
    short offset5 = (short) pixel[5];
    short offset6 = (short) pixel[6];
    short offset7 = (short) pixel[7];

    while(true)
    {
        const int cb = *ptr + b_test;
        const int c_b = *ptr - b_test;
        if(ptr[offset0] > cb)
          if(ptr[offset2] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset5] > cb)
                if(ptr[offset1] > cb)
                  if(ptr[offset4] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset7] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset4] > cb)
                    if(ptr[offset6] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset1] > cb)
                  if(ptr[offset4] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset7] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset7] > cb)
                if(ptr[offset6] > cb)
                  if(ptr[offset5] > cb)
                    if(ptr[offset1] > cb)
                      goto is_a_corner;
                    else
                      if(ptr[offset4] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset1] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset5] < c_b)
                  if(ptr[offset3] < c_b)
                    if(ptr[offset7] < c_b)
                      if(ptr[offset4] < c_b)
                        if(ptr[offset6] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
          else
            if(ptr[offset5] > cb)
              if(ptr[offset7] > cb)
                if(ptr[offset6] > cb)
                  if(ptr[offset1] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset4] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset5] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset2] < c_b)
                    if(ptr[offset1] < c_b)
                      if(ptr[offset4] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      if(ptr[offset4] < c_b)
                        if(ptr[offset6] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset7] < c_b)
                      if(ptr[offset4] < c_b)
                        if(ptr[offset6] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
        else
        if(ptr[offset0] < c_b)
          if(ptr[offset2] < c_b)
            if(ptr[offset7] > cb)
```

----------------------------------------

TITLE: Configuring G-API OpenVINO Support Option in CMake
DESCRIPTION: Checks if the OpenVINO 3rd party target (`ocv.3rdparty.openvino`) exists. If it does, it defines a CMake option `OPENCV_GAPI_WITH_OPENVINO` to enable/disable OpenVINO support within G-API. It handles backward compatibility with a deprecated option `OPENCV_GAPI_INF_ENGINE`, issuing a warning if the old option is used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
if(TARGET ocv.3rdparty.openvino)
  # TODO: remove OPENCV_GAPI_INF_ENGINE option
  set(initial_value ON)
  if(DEFINED OPENCV_GAPI_INF_ENGINE)
    set(initial_value ${OPENCV_GAPI_INF_ENGINE})
    message(WARNING "OPENCV_GAPI_INF_ENGINE option is deprecated. Use OPENCV_GAPI_WITH_OPENVINO option instead.")
  endif()
  ocv_option(OPENCV_GAPI_WITH_OPENVINO "G-API: Enable OpenVINO Toolkit support" ${initial_value})
endif()
```

----------------------------------------

TITLE: Checking for Empty Frames After Reading in C++
DESCRIPTION: Shows how to check if the `cv::Mat` objects are empty after a read operation using the `empty()` method. This condition typically signifies that the end of the video file has been reached or the video stream was closed, indicating that no more frames could be acquired. Requires `<opencv2/core.hpp>` header.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
if( frameReference.empty()  || frameUnderTest.empty())
{
 // exit the program
}
```

----------------------------------------

TITLE: Calculating Contour Centroid from Moments in JavaScript
DESCRIPTION: This snippet demonstrates how to compute the centroid coordinates (cx, cy) of a contour using the moments object (M) returned by `cv.moments`. It utilizes the formulas Cx = M10 / M00 and Cy = M01 / M00, where M00 is the area of the contour, and M10 and M01 are the first-order moments. Assumes `M` is a valid moments object obtained from `cv.moments`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_features/js_contour_features.markdown#2025-04-22_snippet_0

LANGUAGE: js
CODE:
```
let cx = M.m10/M.m00
let cy = M.m01/M.m00
```

----------------------------------------

TITLE: Finding Required OpenCV Package in CMake
DESCRIPTION: Prints the value of the `ANDROID_ABI` variable to the status output. Uses `find_package` to locate the OpenCV library, making the components specified in `ANDROID_OPENCV_COMPONENTS` mandatory (`REQUIRED`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-2-mixedprocessing/jni/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
message(STATUS "ANDROID_ABI=${ANDROID_ABI}")
find_package(OpenCV REQUIRED COMPONENTS ${ANDROID_OPENCV_COMPONENTS})
```

----------------------------------------

TITLE: Applying the Standard Hough Line Transform in OpenCV (C++)
DESCRIPTION: This snippet demonstrates how to use the HoughLines function in OpenCV C++ to detect straight lines. It takes an edge image and outputs a vector of lines in (rho, theta) form. Inputs include the edge image, rho and theta resolutions, and threshold parameters. Requires OpenCV and successful edge detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
vector<Vec2f> lines;\nHoughLines(edges, lines, 1, CV_PI / 180, 150, 0, 0);\n
```

----------------------------------------

TITLE: Conditionally Setting OpenCV Dependency Name in CMake
DESCRIPTION: Checks the `OPENCV_FROM_SDK` variable. If true, sets `ANDROID_OPENCV_COMPONENTS` to `"opencv_java"` for local SDK usage. Otherwise, sets it to `"OpenCV::opencv_java${OPENCV_VERSION_MAJOR}"` for AAR usage, incorporating the major OpenCV version. Status messages indicate the chosen source.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-2-mixedprocessing/jni/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if (OPENCV_FROM_SDK)
  message(STATUS "Using OpenCV from local SDK")
  set(ANDROID_OPENCV_COMPONENTS "opencv_java" CACHE STRING "")
else()
  message(STATUS "Using OpenCV from AAR (Maven repo)")
  set(ANDROID_OPENCV_COMPONENTS "OpenCV::opencv_java${OPENCV_VERSION_MAJOR}" CACHE STRING "")
endif()
```

----------------------------------------

TITLE: Displaying Result Image in C++
DESCRIPTION: Displays the final absolute Laplacian image (`abs_dst`) in a window titled "Laplace Demo" using cv::imshow. Requires OpenCV highgui module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_21

LANGUAGE: cpp
CODE:
```
//! [display]
/// Showacilimage
imshow( window_name, abs_dst );
//! [display]
```

----------------------------------------

TITLE: Implementing Harris Corner Detector in Python
DESCRIPTION: This Python code demonstrates how to use the cv2.cornerHarris function to detect corners in an image using the Harris-Stephens method. It processes the input image, applies the corner detection algorithm, and visualizes the results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

filename = 'chessboard.png'
img = cv.imread(filename)
cv.imshow('src', img)
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

gray = np.float32(gray)
dst = cv.cornerHarris(gray, 2, 3, 0.04)

dst = cv.dilate(dst, None)

img[dst > 0.01 * dst.max()] = [0, 0, 255]

cv.imshow('dst', img)
if cv.waitKey(0) & 0xff == 27:
    cv.destroyAllWindows()
```

----------------------------------------

TITLE: Calculating Plane Normal at Camera Pose using OpenCV - C++
DESCRIPTION: This C++ snippet computes the normal vector to a plane expressed in the first camera frame. It may use the cross product of vectors or transform from object frame normals. Requires pose matrices or known normal in object frame. Output is a normalized 3-element vector for further homography calculations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_22

LANGUAGE: cpp
CODE:
```
@snippet homography_from_camera_displacement.cpp compute-plane-normal-at-camera-pose-1
```

----------------------------------------

TITLE: Applying Dilation - OpenCV.js - JavaScript
DESCRIPTION: This snippet shows how to use cv.dilate() from OpenCV.js to expand the foreground objects in an image. Required parameters include src (input image), dst (output image), kernel (structuring element), anchor (anchor's position; defaults to center), iterations (number of times the operation is applied), borderType, and borderValue. The function is typically used after erosion to restore object size while removing noise, and requires OpenCV.js as a dependency. Input and output images must match in size and type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_morphological_ops/js_morphological_ops.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
cv.dilate(src, dst, kernel, anchor = new cv.Point(-1, -1), iterations = 1, borderType = cv.BORDER_CONSTANT, borderValue = cv.morphologyDefaultBorderValue())
```

----------------------------------------

TITLE: Populating Kalman Filter Measurement Vector from Pose in C++ (OpenCV)
DESCRIPTION: Implements the `fillMeasurements` C++ function using OpenCV. This function takes measured translation (`translation_measured`) and rotation (`rotation_measured`) matrices as input. It converts the 3x3 rotation matrix to a 3x1 vector of Euler angles (`measured_eulers`) using a helper function `rot2euler`. It then populates the output `measurements` `cv::Mat` (presumably 6x1) with the translation vector components (x, y, z) followed by the calculated Euler angles (roll, pitch, yaw).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_24

LANGUAGE: cpp
CODE:
```
void fillMeasurements( cv::Mat &measurements,
                   const cv::Mat &translation_measured, const cv::Mat &rotation_measured)
{
    // Convert rotation matrix to euler angles
    cv::Mat measured_eulers(3, 1, CV_64F);
    measured_eulers = rot2euler(rotation_measured);

    // Set measurement to predict
    measurements.at<double>(0) = translation_measured.at<double>(0); // x
    measurements.at<double>(1) = translation_measured.at<double>(1); // y
    measurements.at<double>(2) = translation_measured.at<double>(2); // z
    measurements.at<double>(3) = measured_eulers.at<double>(0);      // roll
    measurements.at<double>(4) = measured_eulers.at<double>(1);      // pitch
    measurements.at<double>(5) = measured_eulers.at<double>(2);      // yaw
}
```

----------------------------------------

TITLE: Including Full Template Matching Demo Code (Java)
DESCRIPTION: Reference to include the complete Java source code file for the OpenCV template matching demonstration. This code loads images, performs matching using `Imgproc.matchTemplate`, normalizes results with `Core.normalize`, finds the best match using `Core.minMaxLoc`, and displays the output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_8

LANGUAGE: java
CODE:
```
@include samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java
```

----------------------------------------

TITLE: Creating Morphological Kernel in Java
DESCRIPTION: Java implementation for creating a morphological kernel with specified parameters
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_2

LANGUAGE: java
CODE:
```
Mat element = Imgproc.getStructuringElement(elementType,
                new Size(2 * kernelSize + 1, 2 * kernelSize + 1),
                new Point(kernelSize, kernelSize));
```

----------------------------------------

TITLE: Simplified Video Frame Processing with OpenCV.js
DESCRIPTION: This snippet simplifies video processing by using the OpenCV.js VideoCapture class to read video frames, convert them to grayscale, and display them. It illustrates a compact approach for handling video streams efficiently.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_video_display/js_video_display.markdown#2025-04-22_snippet_2

LANGUAGE: JavaScript
CODE:
```
let src = new cv.Mat(height, width, cv.CV_8UC4);
let dst = new cv.Mat(height, width, cv.CV_8UC1);
let cap = new cv.VideoCapture(videoSource);

const FPS = 30;
function processVideo() {
    let begin = Date.now();
    cap.read(src);
    cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
    cv.imshow("canvasOutput", dst);
    // schedule next one.
    let delay = 1000/FPS - (Date.now() - begin);
    setTimeout(processVideo, delay);
}

// schedule first one.
setTimeout(processVideo, 0);
```

----------------------------------------

TITLE: Draw Contours on Mat in OpenCV C++
DESCRIPTION: Initializes an empty matrix for drawing and iterates over contours to draw them, along with bounding rectangles and circles. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
cv::RNG rng(12345);
for (size_t i = 0; i < contours.size(); i++) {
    cv::Scalar color = cv::Scalar(rng.uniform(0, 256), rng.uniform(0, 256), rng.uniform(0, 256));
    cv::drawContours(drawing, contours, (int)i, color);
    cv::rectangle(drawing, boundRect[i].tl(), boundRect[i].br(), color, 2);
    cv::circle(drawing, center[i], (int)radius[i], color, 2);
}
```

----------------------------------------

TITLE: Applying the Probabilistic Hough Line Transform in OpenCV (Python)
DESCRIPTION: This Python snippet applies cv2.HoughLinesP to detect line segments in a binary edge map. Parameters include the edge image, rho/theta resolutions, threshold, minLineLength, and maxLineGap. Returns an array of line segment endpoints. Requires cv2 and numpy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_14

LANGUAGE: Python
CODE:
```
linesP = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=50, maxLineGap=10)\n
```

----------------------------------------

TITLE: Ratio Test Filtering in OpenCV using C++
DESCRIPTION: This C++ snippet filters matches using the ratio test to ensure correctness by comparing distances of multiple matches.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
samples/cpp/tutorial_code/features2D/AKAZE_match.cpp ratio test filtering
```

----------------------------------------

TITLE: Main AGAST Detection Implementation with Multiple Corner Patterns
DESCRIPTION: Complete implementation of the AGAST feature detection algorithm with support for multiple corner patterns. This function selects the appropriate detection algorithm based on the pattern type and performs feature scoring and optional non-maximum suppression.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_45

LANGUAGE: C++
CODE:
```
void AGAST(InputArray _img, std::vector<KeyPoint>& keypoints, int threshold, bool nonmax_suppression, int type)
{

    std::vector<KeyPoint> kpts;

    // detect
    switch(type) {
      case AgastFeatureDetector::AGAST_5_8:
        AGAST_5_8(_img, kpts, threshold);
        break;
      case AgastFeatureDetector::AGAST_7_12d:
        AGAST_7_12d(_img, kpts, threshold);
        break;
      case AgastFeatureDetector::AGAST_7_12s:
        AGAST_7_12s(_img, kpts, threshold);
        break;
      case AgastFeatureDetector::OAST_9_16:
        OAST_9_16(_img, kpts, threshold);
        break;
    }

    cv::Mat img = _img.getMat();

    // score
    int pixel_[16];
    makeAgastOffsets(pixel_, (int)img.step, type);

    std::vector<KeyPoint>::iterator kpt;
    for(kpt = kpts.begin(); kpt != kpts.end(); kpt++)
    {
        switch(type) {
          case AgastFeatureDetector::AGAST_5_8:
            kpt->response = (float)agast_cornerScore<AgastFeatureDetector::AGAST_5_8>
                (&img.at<uchar>((int)kpt->pt.y, (int)kpt->pt.x), pixel_, threshold);
            break;
          case AgastFeatureDetector::AGAST_7_12d:
            kpt->response = (float)agast_cornerScore<AgastFeatureDetector::AGAST_7_12d>
                (&img.at<uchar>((int)kpt->pt.y, (int)kpt->pt.x), pixel_, threshold);
            break;
          case AgastFeatureDetector::AGAST_7_12s:
            kpt->response = (float)agast_cornerScore<AgastFeatureDetector::AGAST_7_12s>
                (&img.at<uchar>((int)kpt->pt.y, (int)kpt->pt.x), pixel_, threshold);
            break;
          case AgastFeatureDetector::OAST_9_16:
            kpt->response = (float)agast_cornerScore<AgastFeatureDetector::OAST_9_16>
                (&img.at<uchar>((int)kpt->pt.y, (int)kpt->pt.x), pixel_, threshold);
            break;
        }
    }

    // suppression
    if(nonmax_suppression)
    {
        size_t j;
        size_t curr_idx;
        size_t lastRow = 0, next_lastRow = 0;
        size_t num_Corners = kpts.size();
        size_t lastRowCorner_ind = 0, next_lastRowCorner_ind = 0;

        std::vector<int> nmsFlags;
        std::vector<KeyPoint>::iterator currCorner_nms;
        std::vector<KeyPoint>::const_iterator currCorner;
    }
```

----------------------------------------

TITLE: Configuring WinRT Backend for HighGUI in CMake
DESCRIPTION: Sets up the WinRT backend for OpenCV HighGUI when WINRT is enabled. Handles different WinRT versions, adds WinRT-specific headers and source files, and manages platform-specific library dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: CMake
CODE:
```
elseif(WINRT)
  set(OPENCV_HIGHGUI_BUILTIN_BACKEND "WINRT")
  if(NOT WINRT_8_0)
    # Dependencies used by the implementation referenced
    # below are not available on WinRT 8.0.
    # Enabling it for WiRT 8.1+ only.

    # WinRT 8.1+ detected. Adding WinRT API header.
    message(STATUS "  ${name}: WinRT detected. Adding WinRT API header")
    list(APPEND highgui_ext_hdrs "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/highgui_winrt.hpp")


    list(APPEND highgui_srcs
      ${CMAKE_CURRENT_LIST_DIR}/src/window_winrt.cpp
      ${CMAKE_CURRENT_LIST_DIR}/src/window_winrt_bridge.cpp)
    list(APPEND highgui_hdrs
      ${CMAKE_CURRENT_LIST_DIR}/src/window_winrt_bridge.hpp)
  endif()

  # libraries below are neither available nor required
  # on ARM devices and/or Windows Phone
  if(WINRT_PHONE OR (OpenCV_ARCH STREQUAL "ARM"))
    list(REMOVE_ITEM HIGHGUI_LIBRARIES "comctl32" "gdi32" "ole32" "setupapi")
    if(WINRT_PHONE)
      message(STATUS "  ${name}: Windows Phone detected")
    elseif(OpenCV_ARCH STREQUAL "ARM")
      message(STATUS "  ${name}: ARM detected")
      if(WINRT_STORE)
        list(REMOVE_ITEM HIGHGUI_LIBRARIES "ws2_32")
        message(STATUS "  ${name}:   Removing 'ws2_32.lib'")
      endif()
    endif()
    message(STATUS "  ${name}:   Removing 'comctl32.lib, gdi32.lib, ole32.lib, setupapi.lib'")
    message(STATUS "  ${name}:   Leaving '${HIGHGUI_LIBRARIES}'")
  endif()

```

----------------------------------------

TITLE: Classifying New Data Points with Trained kNN Model in OpenCV
DESCRIPTION: This code demonstrates how to classify a new data point using the trained kNN model. It visualizes the new point (marked in green) and outputs the classification result, the labels of k nearest neighbors, and their distances from the new point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_knn/py_knn_understanding/py_knn_understanding.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
newcomer = np.random.randint(0,100,(1,2)).astype(np.float32)
plt.scatter(newcomer[:,0],newcomer[:,1],80,'g','o')

knn = cv.ml.KNearest_create()
knn.train(trainData, cv.ml.ROW_SAMPLE, responses)
ret, results, neighbours ,dist = knn.findNearest(newcomer, 3)

print( "result:  {}\n".format(results) )
print( "neighbours:  {}\n".format(neighbours) )
print( "distance:  {}\n".format(dist) )

plt.show()
```

----------------------------------------

TITLE: Copying Mat Data Using copy() in OpenCV in Python
DESCRIPTION: Displays deep copying NumPy arrays for OpenCV images in Python. The ndarray.copy() method returns a new array. Altering the copy does not affect the original. Useful before destructive operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_24

LANGUAGE: Python
CODE:
```
copy = img.copy()
```

----------------------------------------

TITLE: Configuring Python Tests Module in CMake for OpenCV
DESCRIPTION: Sets up the Python tests module as an internal module in OpenCV. It defines the module name and configures it not to be part of the world build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/test/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(MODULE_NAME "python_tests")
set(OPENCV_MODULE_IS_PART_OF_WORLD FALSE)
ocv_add_module(${MODULE_NAME} INTERNAL)
```

----------------------------------------

TITLE: Applying Bilateral Filter in OpenCV Python
DESCRIPTION: This code demonstrates the bilateral filter using cv.bilateralFilter(). This advanced filtering technique preserves edges while removing noise by considering both spatial proximity and intensity similarity between pixels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_filtering/py_filtering.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
blur = cv.bilateralFilter(img,9,75,75)
```

----------------------------------------

TITLE: Setting Cache Variables for Doxygen Template Files in CMake
DESCRIPTION: Defines CMake cache variables `OPENCV_DOCS_DOXYFILE_IN` and `OPENCV_DOCS_DOXYGEN_LAYOUT` to specify the paths to the Doxygen configuration template file (Doxyfile.in) and the Doxygen layout XML file, respectively. This allows users to potentially provide custom versions of these files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_14

LANGUAGE: cmake
CODE:
```
set(OPENCV_DOCS_DOXYFILE_IN "Doxyfile.in" CACHE PATH "Doxygen configuration template file (Doxyfile.in)")
set(OPENCV_DOCS_DOXYGEN_LAYOUT "DoxygenLayout.xml" CACHE PATH "Doxygen layout file (.xml)")
```

----------------------------------------

TITLE: Drawing 1-D Hue Histogram in Python with OpenCV
DESCRIPTION: This code illustrates how to draw a 1-D Hue histogram of an image using OpenCV in Python. It creates a histogram image and uses the line function to draw the histogram bars.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_10

LANGUAGE: Python
CODE:
```
w, h = 400, 400
bin_w = int(round(w / histSize))
hist_img = np.zeros((h, w, 3), dtype=np.uint8)
for i in range(histSize):
    cv.line(hist_img, (i * bin_w, h),
            (i * bin_w, h - int(round(hist[i] * h / 255.0))),
            (0, 0, 255), thickness=2)
cv.imshow('Histogram', hist_img)
```

----------------------------------------

TITLE: Warping Image with OpenCV warpPerspective - Java
DESCRIPTION: This Java example demonstrates how to use OpenCV’s Imgproc.warpPerspective to perform perspective transformation using a 3x3 homography matrix. Requires input Mat, transformation matrix, and output Mat destination. Produces a new Mat with transformed content.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_16

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/features2D/Homography/PerspectiveCorrection.java warp-chessboard
```

----------------------------------------

TITLE: Applying Gaussian Blur with OpenCV in Java
DESCRIPTION: This Java snippet demonstrates the use of OpenCV's GaussianBlur() function for smoothing images with a Gaussian filter. Requires OpenCV and parameters for source, destination images, kernel size, and standard deviations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_4

LANGUAGE: Java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java gaussianblur
```

----------------------------------------

TITLE: Drawing 1-D Hue Histogram in C++ with OpenCV
DESCRIPTION: This code shows how to draw a 1-D Hue histogram of an image using OpenCV in C++. It creates a histogram image and uses the line function to draw the histogram bars.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_8

LANGUAGE: C++
CODE:
```
int w = 400, h = 400;
int bin_w = cvRound( (double) w / histSize );
Mat histImg = Mat::zeros( h, w, CV_8UC3 );
for( int i = 0; i < histSize; i++ )
{
    rectangle( histImg, Point( i*bin_w, h ), Point( (i+1)*bin_w, h - cvRound( hist.at<float>(i)*h/255.0 ) ),
               Scalar( 0, 0, 255 ), FILLED );
}
imshow("Histogram", histImg);
```

----------------------------------------

TITLE: Writing Frames to OpenCV VideoWriter (C++)
DESCRIPTION: Illustrates two equivalent ways to write a video frame (represented by a `cv::Mat` object named `res`) to an opened `cv::VideoWriter` (`outputVideo`). One uses the `write` method, and the other uses the overloaded stream insertion `<<` operator. Requires an opened `VideoWriter` and a `Mat` containing the frame data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
outputVideo.write(res);  //or
outputVideo << res;
```

----------------------------------------

TITLE: Getting Back Projection in Python with OpenCV
DESCRIPTION: This code calculates the back projection of an image using OpenCV in Python. It utilizes the calcBackProject function with the previously computed histogram and image data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
backproj = cv.calcBackProject([hue], [0], hist, [0, 180], 1)
```

----------------------------------------

TITLE: Cloning and Deep Copying OpenCV Mat Objects in C++
DESCRIPTION: Shows how to create completely independent (deep) copies of an OpenCV Mat object (`A`). The `cv::Mat::clone()` method returns a new Mat (`F`) with its own copy of the data. The `cv::Mat::copyTo()` method copies the data from the source Mat (`A`) to a pre-existing or newly created Mat (`G`). Modifications to `F` or `G` will not affect `A`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
Mat F = A.clone();
Mat G;
A.copyTo(G);
```

----------------------------------------

TITLE: Machine Learning Model Training in OpenCV 2.4 vs 3.0
DESCRIPTION: Compares the process of training a machine learning model (Boost) between OpenCV 2.4 and 3.0, demonstrating the new API with separate setter methods instead of parameter structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
using namespace cv;
// ======== version 2.4 ========
Mat trainSamples, trainClasses;
prepare_train_data( trainSamples, trainClasses );
CvBoost  boost;
Mat var_types( 1, trainSamples.cols + 1, CV_8UC1, Scalar(CV_VAR_ORDERED) );
var_types.at<uchar>( trainSamples.cols ) = CV_VAR_CATEGORICAL;
CvBoostParams  params( CvBoost::DISCRETE, // boost_type
                       100, // weak_count
                       0.95, // weight_trim_rate
                       2, // max_depth
                       false, //use_surrogates
                       0 // priors
                     );
boost.train( trainSamples, CV_ROW_SAMPLE, trainClasses, Mat(), Mat(), var_types, Mat(), params );

// ======== version 3.0 ========
Ptr<Boost> boost = Boost::create();
boost->setBoostType(Boost::DISCRETE);
boost->setWeakCount(100);
boost->setWeightTrimRate(0.95);
boost->setMaxDepth(2);
boost->setUseSurrogates(false);
boost->setPriors(Mat());
boost->train(prepare_train_data()); // 'prepare_train_data' returns an instance of ml::TrainData class
```

----------------------------------------

TITLE: Using cv.Canny() for Edge Detection in OpenCV.js
DESCRIPTION: Demonstrates the function signature for applying the Canny edge detection algorithm using OpenCV.js. It takes an 8-bit input image and outputs an edge map. Key parameters include two thresholds for hysteresis (`threshold1`, `threshold2`), the aperture size for the Sobel operator (`apertureSize`), and a flag (`L2gradient`) to choose the gradient magnitude calculation method.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_canny/js_canny.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.Canny(image, edges, threshold1, threshold2, apertureSize = 3, L2gradient = false)
@param image         8-bit input image.
@param edges         output edge map; single channels 8-bit image, which has the same size as image.
@param threshold1    first threshold for the hysteresis procedure.
@param threshold2    second threshold for the hysteresis procedure..
@param apertureSize  aperture size for the Sobel operator.
@param L2gradient    specifies the equation for finding gradient
magnitude. If it is True, it uses the equation mentioned above which is more accurate, otherwise it uses this function: \f$Edge\_Gradient \; (G) = |G_x| + |G_y|\f$.
```

----------------------------------------

TITLE: Conditional Execution for OpenCV TAPI Sample Building - CMake
DESCRIPTION: Checks if the BUILD_EXAMPLES option and all required dependencies are satisfied; if not, terminates processing with return(). This ensures that TAPI sample compilation is only attempted when intended and possible. Relies on the variables BUILD_EXAMPLES and OCV_DEPENDENCIES_FOUND being properly set earlier in the build configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/tapi/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()
```

----------------------------------------

TITLE: Detecting Chessboard Corners using OpenCV in C++
DESCRIPTION: This snippet uses the findChessboardCorners function for detecting chessboard corners in an image. It's essential to have the OpenCV library loaded. The boardSize parameter specifies the number of inner corners per chessboard row and column.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_square_chess/camera_calibration_square_chess.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
bool found = findChessboardCorners(img, boardSize, ptvec, CALIB_CB_ADAPTIVE_THRESH);
```

----------------------------------------

TITLE: Loading an Image using OpenCV in Python
DESCRIPTION: Loads an image using `cv.imread` based on a command-line argument or a default path. Includes a check to ensure the image loaded successfully, exiting if it didn't.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
def main(argv):
    #![load]
    # General instructions
    print ('\n Zoom In-Out demo \n ')
    print ('------------------')
    print (' * [i] -> Zoom in')
    print (' * [o] -> Zoom out')
    print (' * [ESC] -> Close program \n')

    filename = argv[0] if len(argv) > 0 else '../data/chicky_512.png'

    # Load image
    src = cv.imread(cv.samples.findFile(filename))

    # Check if image is loaded fine
    if src is None:
        print ('Error opening image!')
        print ('Usage: pyramids.py [image_name -- default ../data/chicky_512.png] \n')
        return -1
    #![load]
```

----------------------------------------

TITLE: Drawing Rich SIFT Keypoints with Orientation in OpenCV Python
DESCRIPTION: This code snippet shows how to draw SIFT keypoints with rich information including their size and orientation using the DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS flag in the drawKeypoints function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
cv.imwrite('sift_keypoints.jpg',img)
```

----------------------------------------

TITLE: Running ResNet-50 Test Mode Example
DESCRIPTION: Complete example command for testing ResNet-50 model with default image preprocessing settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_14

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_cls --model_name resnet50 --test True --default_img_preprocess True --evaluate False
```

----------------------------------------

TITLE: Detecting Faces using Haar Cascade in OpenCV - JavaScript
DESCRIPTION: This JavaScript snippet uses OpenCV's detectMultiScale function to perform face detection. It requires OpenCV.js and pre-trained Haar cascade XML files. The function takes parameters for the image matrix, vector of rectangles for detected objects, scaling factor, minimum neighbors for detection, and size constraints for objects. Outputs are rectangles containing detected faces. This code must be run in a web environment with access to OpenCV.js and appropriate HTML elements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_objdetect/js_face_detection/js_face_detection.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
detectMultiScale(image, objects, scaleFactor = 1.1, minNeighbors = 3, flags = 0, minSize = new cv.Size(0, 0), maxSize = new cv.Size(0, 0));
```

----------------------------------------

TITLE: Background and Foreground Segmentation in OpenCV
DESCRIPTION: Performs noise removal using morphological operations and identifies sure background/foreground areas using distance transform and thresholding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_watershed/py_watershed.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
# noise removal
kernel = np.ones((3,3),np.uint8)
opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)

# sure background area
sure_bg = cv.dilate(opening,kernel,iterations=3)

# Finding sure foreground area
dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)
ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)

# Finding unknown region
sure_fg = np.uint8(sure_fg)
unknown = cv.subtract(sure_bg,sure_fg)
```

----------------------------------------

TITLE: Visualizing Keypoint Matches in OpenCV C++
DESCRIPTION: Creates a visualization of the matched keypoints between two images using OpenCV's drawMatches function and displays the result.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/detection_of_planar_objects/detection_of_planar_objects.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
// drawing the results
namedWindow("matches", 1);
Mat img_matches;
drawMatches(img1, keypoints1, img2, keypoints2, matches, img_matches);
imshow("matches", img_matches);
waitKey(0);
```

----------------------------------------

TITLE: Performing Template Matching Operation (Java)
DESCRIPTION: Executes the template matching using `Imgproc.matchTemplate`. It takes the source image (`img`), template (`template`), result matrix (`result`), the chosen match method integer (`match_method`), and the optional mask (`mask`) as input. The dimensions of the result matrix are determined based on image and template sizes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_23

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java match_template
```

----------------------------------------

TITLE: Performing Brightness and Contrast Adjustment in OpenCV (Java)
DESCRIPTION: The Java code snippet illustrates how to apply a linear transformation to adjust image contrast and brightness using OpenCV. It involves loading an image, creating a new image matrix with the same size and type, and modifying each pixel based on user-defined gain and bias values. The code ensures pixel values remain valid within the image's data type limits.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.CvType;
import org.opencv.core.Scalar;
import org.opencv.imgcodecs.Imgcodecs;
import java.util.Scanner;

class BasicLinearTransformsDemo {
    public static void main(String[] args) {
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
        Mat image = Imgcodecs.imread(args[0]);
        Mat newImage = Mat.zeros(image.size(), image.type());
        Scanner scanner = new Scanner(System.in);
        
        System.out.println("Basic Linear Transforms");
        System.out.println("------------------------");
        System.out.println("* Enter the alpha value [1.0-3.0]: ");
        double alpha = scanner.nextDouble();
        System.out.println("* Enter the beta value [0-100]: ");
        int beta = scanner.nextInt();

        image.convertTo(newImage, -1, alpha, beta);

        Imgcodecs.imwrite("new_image.jpg", newImage);
    }
}

```

----------------------------------------

TITLE: Homography Check for Matches with OpenCV in Python
DESCRIPTION: This Python code performs a homography test to evaluate matches' adherence to the homography model, utilizing OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_14

LANGUAGE: Python
CODE:
```
samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py homography check
```

----------------------------------------

TITLE: Measuring Elapsed Time with OpenCV
DESCRIPTION: This code shows how to measure the elapsed time between operations using OpenCV's cv::getTickCount() and cv::getTickFrequency(). The snippet calculates the time taken for a set of operations and prints it in seconds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
@code{.cpp}
double t = (double)getTickCount();
// do something ...
t = ((double)getTickCount() - t)/getTickFrequency();
cout << "Times passed in seconds: " << t << endl;
@endcode
```

----------------------------------------

TITLE: Capturing Video Frame by Frame in C++
DESCRIPTION: Captures frames from a video source until the ESC key is pressed and clones each frame for visualization. It is used as part of a real-time image processing pipeline.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
cv::Mat frame, frame_vis;

while(cap.read(frame) && cv::waitKey(30) != 27)    // capture frame until ESC is pressed
{

    frame_vis = frame.clone();                     // refresh visualisation frame

    // MAIN ALGORITHM

}
```

----------------------------------------

TITLE: Drawing an Individual Contour by Index with OpenCV Python
DESCRIPTION: This code demonstrates how to draw a single specific contour (the 4th contour) from the list of detected contours using cv.drawContours().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
cv.drawContours(img, contours, 3, (0,255,0), 3)
```

----------------------------------------

TITLE: Loading Source Image in C++
DESCRIPTION: Loads the source image from the path provided as a command-line argument using cv::imread. Includes error handling to check if the image was loaded successfully. Requires OpenCV imgcodecs module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
//! [load]
const char* imageName = argc >= 2 ? argv[1] : "lena.jpg";

src = imread( samples::findFile( imageName ), IMREAD_COLOR ); // Load an image

// Check if image is loaded fine
if(src.empty())
{
    printf(" Error opening image\n");
    printf(" Program Arguments: [image_name -- default lena.jpg] \n");
    return -1;
}
//! [load]
```

----------------------------------------

TITLE: Converting Image to Grayscale in C++
DESCRIPTION: Converts the noise-reduced source image (presumably BGR) to grayscale using cv::cvtColor with the COLOR_BGR2GRAY code. The result is stored in the `src_gray` Mat object. Requires OpenCV imgproc module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
//! [convert_to_gray]
// Convert the image to grayscale
cvtColor( src, src_gray, COLOR_BGR2GRAY );
//! [convert_to_gray]
```

----------------------------------------

TITLE: Extracting and Displaying SVM Support Vectors - Python
DESCRIPTION: This Python snippet obtains support vectors from a trained OpenCV SVM (using cv2.ml.SVM.getSupportVectors) and visually highlights them on the output image. The implementation depends on training an SVM with cv2 and requires Python's OpenCV library and numpy. Inputs are the trained SVM model and data/image for display. Outputs are images with special rings indicating support vectors. The code demonstrates analyzing the SVM's influence points for interpretation and debugging.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_9

LANGUAGE: python
CODE:
```
# Python: Highlight SVM support vectors using OpenCV
# ... (full code from samples/python/tutorial_code/ml/introduction_to_svm/introduction_to_svm.py, show_vectors)
```

----------------------------------------

TITLE: Parallel Mandelbrot Computation with C++11 Lambda and cv::parallel_for_ - C++
DESCRIPTION: This advanced snippet demonstrates using a C++11 lambda function directly in cv::parallel_for_ to replace the functor class, streamlining parallel Mandelbrot image generation. Requires OpenCV 3.x+ and C++11 support. The lambda captures image and maxIter by reference, splitting the processing across available threads; result is a parallelized grayscale image output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
// C++11 lambda-based parallel_for_ example
cv::parallel_for_(cv::Range(0, image.rows * image.cols),
    [&](const cv::Range& range) {
        for (int r = range.start; r < range.end; ++r)
        {
            int row = r / image.cols;
            int col = r % image.cols;
            double x0 = (col / (double)image.cols) * 3.0 - 2.0;
            double y0 = (row / (double)image.rows) * 2.0 - 1.0;
            int iter = mandelbrot(cv::Point2d(x0, y0), maxIter);
            image.at<uchar>(row, col) = grayscaleValue(iter, maxIter);
        }
    });

```

----------------------------------------

TITLE: Verifying OpenCV Installation
DESCRIPTION: Python code to verify successful installation of OpenCV by importing the library and checking its version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import cv2 as cv
print(cv.__version__)
```

----------------------------------------

TITLE: Applying Median Blur
DESCRIPTION: Reducing image noise using median blur to improve circle detection accuracy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
medianBlur(gray, gray, 5);
```

LANGUAGE: Java
CODE:
```
Imgproc.medianBlur(gray, gray, 5);
```

LANGUAGE: Python
CODE:
```
gray = cv.medianBlur(gray, 5)
```

----------------------------------------

TITLE: Computing Homography from Camera Displacement - C++
DESCRIPTION: This code computes the homography matrix from the camera poses, plane normal, and distance according to the physical displacement, as per the formal plane-induced homography formula. Prereqs: camera rotation/translation, plane normal, camera intrinsics, and distance. Yields a homography matrix that can be directly compared with one estimated from image correspondences.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_25

LANGUAGE: cpp
CODE:
```
@snippet homography_from_camera_displacement.cpp compute-homography-from-camera-displacement
```

----------------------------------------

TITLE: DFT Performance Comparison Using Numpy and OpenCV - Python
DESCRIPTION: Performs timing benchmarks comparing Numpy's fft2 and OpenCV's dft functions on both original- and optimal-size (zero-padded) images. Utilizes IPython %timeit magic for measurement. Inputs: 'img' (original image), 'nimg' (zero-padded array), optimal sizes (nrows, ncols). Dependencies: Numpy (np), OpenCV (cv), IPython environment. Outputs: execution times for default and optimized DFT. Shows that both libraries benefit from optimal sizing, with OpenCV being faster.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_6

LANGUAGE: Python
CODE:
```
In [22]: %timeit fft1 = np.fft.fft2(img)
10 loops, best of 3: 40.9 ms per loop
In [23]: %timeit fft2 = np.fft.fft2(img,[nrows,ncols])
100 loops, best of 3: 10.4 ms per loop
```

LANGUAGE: Python
CODE:
```
In [24]: %timeit dft1= cv.dft(np.float32(img),flags=cv.DFT_COMPLEX_OUTPUT)
100 loops, best of 3: 13.5 ms per loop
In [27]: %timeit dft2= cv.dft(np.float32(nimg),flags=cv.DFT_COMPLEX_OUTPUT)
100 loops, best of 3: 3.11 ms per loop
```

----------------------------------------

TITLE: PSF Calculation Function in C++
DESCRIPTION: Generates the PSF based on input parameters \f$LEN\f$ and \f$THETA\f$ which define the length and angle of the motion blur. Essential for constructing the motion blur model before applying the restoration filter.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/motion_deblur_filter/motion_deblur_filter.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
@snippet samples/cpp/tutorial_code/ImgProc/motion_deblur_filter/motion_deblur_filter.cpp calcPSF
```

----------------------------------------

TITLE: Configuring Qt Backend for HighGUI in CMake
DESCRIPTION: Sets up the Qt backend for OpenCV HighGUI when HAVE_QT is enabled. Handles different Qt versions (4, 5, 6), processes Qt resources and moc files, adds OpenGL support if available, and links necessary Qt libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: CMake
CODE:
```
elseif(HAVE_QT)
  set(OPENCV_HIGHGUI_BUILTIN_BACKEND "QT${QT_VERSION_MAJOR}")
  add_definitions(-DHAVE_QT)

  if(QT_VERSION_MAJOR GREATER 4)
    # "Automoc" doesn't work properly with opencv_world build, use QT<ver>_WRAP_CPP() directly
    #set(CMAKE_AUTOMOC ON)

    set(CMAKE_INCLUDE_CURRENT_DIR ON)

    if(QT_VERSION_MAJOR EQUAL 6)
      add_definitions(-DHAVE_QT6) # QGLWidget deprecated for QT6, use this preprocessor to adjust window_QT.[h,cpp]
      QT6_ADD_RESOURCES(_RCC_OUTFILES ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.qrc)
      QT6_WRAP_CPP(_MOC_OUTFILES ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.h)
    elseif(QT_VERSION_MAJOR EQUAL 5)
      QT5_ADD_RESOURCES(_RCC_OUTFILES ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.qrc)
      QT5_WRAP_CPP(_MOC_OUTFILES ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.h)
    else()
      message(FATAL_ERROR "Unsupported QT version: ${QT_VERSION_MAJOR}")
    endif()

    list(APPEND highgui_srcs
         ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.cpp
         ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.h
         ${_MOC_OUTFILES}
         ${_RCC_OUTFILES})

    set(qt_deps Core Gui Widgets Test Concurrent)
    if(HAVE_QT_OPENGL)
      add_definitions(-DHAVE_QT_OPENGL)
      # QOpenGLWidget requires Qt6 package component OpenGLWidgets
      if(QT_VERSION_MAJOR GREATER 5)
        list(APPEND qt_deps OpenGLWidgets)
      endif()
      list(APPEND qt_deps OpenGL)
      if(OPENGL_LIBRARIES)
        list(APPEND HIGHGUI_LIBRARIES "${OPENGL_LIBRARIES}")
      endif()
    endif()

    foreach(dt_dep ${qt_deps})
      add_definitions(${Qt${QT_VERSION_MAJOR}${dt_dep}_DEFINITIONS})
      include_directories(${Qt${QT_VERSION_MAJOR}${dt_dep}_INCLUDE_DIRS})
      list(APPEND HIGHGUI_LIBRARIES ${Qt${QT_VERSION_MAJOR}${dt_dep}_LIBRARIES})
    endforeach()
  else()
    ocv_assert(QT_VERSION_MAJOR EQUAL 4)
    if(HAVE_QT_OPENGL)
      set(QT_USE_QTOPENGL TRUE)
      if(OPENGL_LIBRARIES)
        list(APPEND HIGHGUI_LIBRARIES "${OPENGL_LIBRARIES}")
      endif()
    endif()
    include(${QT_USE_FILE})

    QT4_ADD_RESOURCES(_RCC_OUTFILES ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.qrc)
    QT4_WRAP_CPP(_MOC_OUTFILES ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.h)

    list(APPEND HIGHGUI_LIBRARIES ${QT_LIBRARIES})
    list(APPEND highgui_srcs ${CMAKE_CURRENT_LIST_DIR}/src/window_QT.cpp ${_MOC_OUTFILES} ${_RCC_OUTFILES})
    ocv_check_flag_support(CXX -Wno-missing-declarations _have_flag "")
    if(${_have_flag})
      set_source_files_properties(${_RCC_OUTFILES} PROPERTIES COMPILE_FLAGS -Wno-missing-declarations)
    endif()
  endif()

```

----------------------------------------

TITLE: Disabling Specific C++ Compiler Warning in CMake
DESCRIPTION: Uses the custom CMake function `ocv_warnings_disable` (presumably defined within the OpenCV build system) to modify the C++ compiler flags (`CMAKE_CXX_FLAGS`). Specifically, it removes the `-Wmissing-declarations` flag, suppressing warnings about functions or variables used without a preceding declaration. This requires the `ocv_warnings_disable` function to be defined elsewhere.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
ocv_warnings_disable(CMAKE_CXX_FLAGS -Wmissing-declarations)
```

----------------------------------------

TITLE: Converting Image Color Spaces with OpenCV.js
DESCRIPTION: Defines the usage of the `cv.cvtColor` function in OpenCV.js to convert an input image (`src`) to a different color space. The conversion type is specified by the `code` parameter (e.g., `cv.COLOR_RGBA2GRAY`), and the result is stored in `dst`. The optional `dstCn` parameter specifies the number of channels in the destination image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_colorspaces/js_colorspaces.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.cvtColor (src, dst, code, dstCn = 0)
```

----------------------------------------

TITLE: Installing OpenCV C++ Header with CMake - CMake DSL
DESCRIPTION: This snippet uses CMake's install() function to place the 'opencv2/opencv.hpp' header file into the library's include directory at installation time, defined by the ${OPENCV_INCLUDE_INSTALL_PATH} variable. Intended for developers packaging or distributing OpenCV, this setup ensures that the essential header is available under the correct directory for downstream users. The 'COMPONENT dev' parameter denotes that this action is part of the development files component, which is typically used to allow optional installation subsets (such as runtime vs developer files) during project configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/include/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
install(FILES "opencv2/opencv.hpp"
    DESTINATION ${OPENCV_INCLUDE_INSTALL_PATH}/opencv2
    COMPONENT dev)
```

----------------------------------------

TITLE: Running Face Detection Model in the Browser
DESCRIPTION: This JavaScript code snippet demonstrates how to run a face detection network using OpenCV.js. The network takes a BGR image as input and produces bounding boxes for detected faces. It allows adjustments to input blob sizes to optimize detection quality and efficiency. The snippet requires the OpenCV.js library and expects an input image for detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_javascript/dnn_javascript.markdown#2025-04-22_snippet_0

LANGUAGE: HTML
CODE:
```
"Run face detection model"
```

----------------------------------------

TITLE: Exporting YOLO Model to ONNX Using Minimal Python Script
DESCRIPTION: Shows how to export a YOLO model from PyTorch to an ONNX graph using Python. This minimal export script loads a PyTorch model checkpoint, prepares a dummy input with the shape required for the model, exports the model to ONNX with dynamic axes for batching compatibility, and then uses onnx-simplifier for graph simplification. Required dependencies: torch, onnx, onnxsim. The input consists of the model state dict, checkpoint path, and export arguments; output is a simplified ONNX file validated for correctness.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
    import onnx\n    import torch\n    from onnxsim import simplify\n\n    # load the model state dict\n    ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n    model.load_state_dict(ckpt)\n\n    # prepare dummy input\n    dummy_input = torch.randn(args.batch_size, 3, exp.test_size[0], exp.test_size[1])\n\n    #export the model\n    torch.onnx._export(\n        model,\n        dummy_input,\n        \"yolox.onnx\",\n        input_names=[\"input\"],\n        output_names=[\"output\"],\n        dynamic_axes={\"input\": {0: 'batch'},\n                      \"output\": {0: 'batch'}})\n\n    # use onnx-simplifier to reduce reduent model.\n    onnx_model = onnx.load(args.output_name)\n    model_simp, check = simplify(onnx_model)\n    assert check, \"Simplified ONNX model could not be validated\"\n    onnx.save(model_simp, args.output_name)
```

----------------------------------------

TITLE: Configuring Zlib Build Options and Feature Summaries - CMake
DESCRIPTION: This CMake snippet manages zlib build configuration within the OpenCV project. It conditionally enables or disables test targets and benchmarks based on whether shared libraries are enabled and sets up feature information for a wide variety of build and architecture-specific parameters, using CMake commands like add_feature_info and conditional if()-elseif() logic. The script also configures installation rules for binary libraries and licenses and observes solution folder organization. Required dependencies include functional CMake, defined zlib build variables, and (optionally) CPU detection modules. Inputs are various CMake cache/build options, and outputs are feature summaries, build targets, and installed binaries; upstream dependencies must define relevant variables. Limitations include reliance on external CMake settings and platform-specific conditions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_38

LANGUAGE: CMake
CODE:
```
# Example binaries\n#============================================================================\n\nif(ZLIB_ENABLE_TESTS)\n    enable_testing()\n\n    if(ZLIB_BUILD_SHARED_LIBS)\n        if(ZLIBNG_ENABLE_TESTS)\n            message(STATUS "Disabling zlib-ng tests because shared libraries are enabled")\n            set(ZLIBNG_ENABLE_TESTS OFF)\n        endif()\n\n        if(WITH_BENCHMARKS OR WITH_BENCHMARK_APPS)\n            message(STATUS "Disabling benchmarks because shared libraries are enabled")\n            set(WITH_BENCHMARKS OFF)\n            set(WITH_BENCHMARK_APPS OFF)\n        endif()\n    endif()\n\n    add_subdirectory(test)\nendif()\n\nadd_feature_info(WITH_GZFILEOP WITH_GZFILEOP "Compile with support for gzFile related functions")\nadd_feature_info(ZLIB_COMPAT ZLIB_COMPAT "Compile with zlib compatible API")\nadd_feature_info(ZLIB_ENABLE_TESTS ZLIB_ENABLE_TESTS "Build test binaries")\nadd_feature_info(ZLIBNG_ENABLE_TESTS ZLIBNG_ENABLE_TESTS "Test zlib-ng specific API")\nadd_feature_info(WITH_SANITIZER WITH_SANITIZER "Enable sanitizer support")\nadd_feature_info(WITH_GTEST WITH_GTEST "Build gtest_zlib")\nadd_feature_info(WITH_FUZZERS WITH_FUZZERS "Build test/fuzz")\nadd_feature_info(WITH_BENCHMARKS WITH_BENCHMARKS "Build test/benchmarks")\nadd_feature_info(WITH_BENCHMARK_APPS WITH_BENCHMARK_APPS "Build application benchmarks")\nadd_feature_info(WITH_OPTIM WITH_OPTIM "Build with optimisation")\nadd_feature_info(WITH_NEW_STRATEGIES WITH_NEW_STRATEGIES "Use new strategies")\nadd_feature_info(WITH_NATIVE_INSTRUCTIONS WITH_NATIVE_INSTRUCTIONS\n    "Instruct the compiler to use the full instruction set on this host (gcc/clang -march=native)")\nadd_feature_info(WITH_RUNTIME_CPU_DETECTION WITH_RUNTIME_CPU_DETECTION "Build with runtime CPU detection")\nadd_feature_info(WITH_MAINTAINER_WARNINGS WITH_MAINTAINER_WARNINGS "Build with project maintainer warnings")\nadd_feature_info(WITH_CODE_COVERAGE WITH_CODE_COVERAGE "Enable code coverage reporting")\nadd_feature_info(WITH_INFLATE_STRICT WITH_INFLATE_STRICT "Build with strict inflate distance checking")\nadd_feature_info(WITH_INFLATE_ALLOW_INVALID_DIST WITH_INFLATE_ALLOW_INVALID_DIST "Build with zero fill for inflate invalid distances")\n\nif(BASEARCH_ARM_FOUND)\n    add_feature_info(WITH_ACLE WITH_ACLE "Build with ACLE")\n    add_feature_info(WITH_NEON WITH_NEON "Build with NEON intrinsics")\n    add_feature_info(WITH_ARMV6 WITH_ARMV6 "Build with ARMv6 SIMD")\nelseif(BASEARCH_PPC_FOUND)\n    add_feature_info(WITH_ALTIVEC WITH_ALTIVEC "Build with AltiVec optimisations")\n    add_feature_info(WITH_POWER8 WITH_POWER8 "Build with optimisations for POWER8")\n    add_feature_info(WITH_POWER9 WITH_POWER9 "Build with optimisations for POWER9")\nelseif(BASEARCH_RISCV_FOUND)\n    add_feature_info(WITH_RVV WITH_RVV "Build with RVV intrinsics")\nelseif(BASEARCH_S360_FOUND)\n    add_feature_info(WITH_DFLTCC_DEFLATE WITH_DFLTCC_DEFLATE "Build with DFLTCC intrinsics for compression on IBM Z")\n    add_feature_info(WITH_DFLTCC_INFLATE WITH_DFLTCC_INFLATE "Build with DFLTCC intrinsics for decompression on IBM Z")\n    add_feature_info(WITH_CRC32_VX WITH_CRC32_VX "Build with vectorized CRC32 on IBM Z")\nelseif(BASEARCH_X86_FOUND)\n    add_feature_info(WITH_AVX2 WITH_AVX2 "Build with AVX2")\n    add_feature_info(WITH_AVX512 WITH_AVX512 "Build with AVX512")\n    add_feature_info(WITH_AVX512VNNI WITH_AVX512VNNI "Build with AVX512 VNNI")\n    add_feature_info(WITH_SSE2 WITH_SSE2 "Build with SSE2")\n    add_feature_info(WITH_SSSE3 WITH_SSSE3 "Build with SSSE3")\n    add_feature_info(WITH_SSE42 WITH_SSE42 "Build with SSE42")\n    add_feature_info(WITH_PCLMULQDQ WITH_PCLMULQDQ "Build with PCLMULQDQ")\n    add_feature_info(WITH_VPCLMULQDQ WITH_VPCLMULQDQ "Build with VPCLMULQDQ")\nendif()\n\nadd_feature_info(INSTALL_UTILS INSTALL_UTILS "Copy minigzip and minideflate during install")\n\nFEATURE_SUMMARY(WHAT ALL INCLUDE_QUIET_PACKAGES)\n\nif(ENABLE_SOLUTION_FOLDERS)\n  set_target_properties(${ZLIB_INSTALL_LIBRARIES} PROPERTIES FOLDER "3rdparty")\nendif()\n\nif(NOT BUILD_SHARED_LIBS)\n  ocv_install_target(${ZLIB_INSTALL_LIBRARIES} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev)\nendif()\n\nocv_install_3rdparty_licenses(${ZLIB_INSTALL_LIBRARIES} LICENSE.md)\n
```

----------------------------------------

TITLE: Building Excluding OpenCV Components Using --without Flag - Python/Bash
DESCRIPTION: This snippet demonstrates how to build an OpenCV xcframework while excluding specific functionalities such as 'video' and 'objc'. The --without flag (used once per excluded module) modifies the build process to omit the listed components, reducing build size or dependencies. This command must be run in an environment where build_xcframework.py and all dependencies are available. Input modules are passed via repeated --without flags; output is an xcframework excluding the chosen modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/apple/readme.md#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
python build_xcframework.py --out somedir --without video --without objc
```

----------------------------------------

TITLE: Configuring OpenCV Build with CMake on macOS
DESCRIPTION: This command configures the OpenCV build using CMake, setting the build type to Release and enabling the building of examples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_EXAMPLES=ON ../opencv
```

----------------------------------------

TITLE: Automatic Dictionary Generation for ArUco using OpenCV C++
DESCRIPTION: This code snippet shows how to generate a custom dictionary using OpenCV's ArUco module, optimizing the inter-marker distance by specifying the number of markers and bits. Useful for creating dictionaries when predefined sets do not meet specific application needs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
cv::aruco::Dictionary dictionary = cv::aruco::extendDictionary(36, 5);
```

----------------------------------------

TITLE: Thresholding Image Colors within a Range using OpenCV.js
DESCRIPTION: Defines the usage of the `cv.inRange` function in OpenCV.js. This function checks if elements of the source image (`src`) lie between the corresponding elements of the lower boundary (`lowerb`) and upper boundary (`upperb`) Mats. It outputs a binary mask (`dst`) of type `cv.CV_8U`, where pixels within the specified range are set.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_colorspaces/js_colorspaces.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
cv.inRange (src, lowerb, upperb, dst)
```

----------------------------------------

TITLE: Compiling G-API Streaming Pipeline
DESCRIPTION: Shows how to compile a G-API computation for streaming execution. Uses compileStreaming() to optimize for throughput and returns a GStreamingCompiled object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
auto pipeline = comp.compileStreaming(cv::compile_args(
    cv::gapi::kernels<custom::PostProc>(),
    networks));
```

----------------------------------------

TITLE: Performing Exposure Fusion in OpenCV as Alternative to HDR
DESCRIPTION: This code demonstrates exposure fusion, an alternative technique to HDR that directly merges multiple exposures into a single LDR image without requiring gamma correction or exposure values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/hdr_imaging.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
Mat fusion;
Ptr<MergeMertens> merge_mertens = createMergeMertens();
merge_mertens->process(images, fusion);
Mat fusion_8bit;
fusion = 255 * fusion;
fusion.convertTo(fusion_8bit, CV_8UC3);
```

LANGUAGE: java
CODE:
```
Mat fusion = new Mat();
MergeMertens mergeMertens = Photo.createMergeMertens();
mergeMertens.process(images, fusion);
fusion.convertTo(fusion, fusion.type(), 255, 0);
Mat fusion8bit = new Mat();
fusion.convertTo(fusion8bit, CvType.CV_8UC3);
```

LANGUAGE: python
CODE:
```
merge_mertens = cv.createMergeMertens()
fusion = merge_mertens.process(images)
fusion_8bit = np.clip(fusion*255, 0, 255).astype('uint8')
```

----------------------------------------

TITLE: Creating Different Structuring Elements with OpenCV Python
DESCRIPTION: Shows how to create different types of structuring elements (rectangular, elliptical, and cross-shaped) using cv.getStructuringElement().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
# Rectangular Kernel
>>> cv.getStructuringElement(cv.MORPH_RECT,(5,5))
array([[1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1]], dtype=uint8)

# Elliptical Kernel
>>> cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))
array([[0, 0, 1, 0, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1],
       [0, 0, 1, 0, 0]], dtype=uint8)

# Cross-shaped Kernel
>>> cv.getStructuringElement(cv.MORPH_CROSS,(5,5))
array([[0, 0, 1, 0, 0],
       [0, 0, 1, 0, 0],
       [1, 1, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [0, 0, 1, 0, 0]], dtype=uint8)
```

----------------------------------------

TITLE: Installing OpenCV via pip on macOS
DESCRIPTION: This command uses pip to install the Python bindings for OpenCV on macOS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_10

LANGUAGE: bash
CODE:
```
pip install opencv-python
```

----------------------------------------

TITLE: Parameter Setup for Generalized Hough Transform in C++
DESCRIPTION: This snippet involves configuring parameters for the Generalized Hough Transform detection. Achieving optimal values often requires experimentation, influenced by factors like image resolution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/generalized_hough_ballard_guil/generalized_hough_ballard_guil.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
# Setup parameters
@snippet samples/cpp/tutorial_code/ImgTrans/generalizedHoughTransform.cpp generalized-hough-transform-setup-parameters
```

----------------------------------------

TITLE: Exposing Standalone Functions Using OpenCV Macros in C++
DESCRIPTION: This snippet demonstrates how to export a standalone function to Python using the CV_EXPORTS_W macro in a C++ header. The function equalizeHist is declared with special macros and argument wrappers (InputArray, OutputArray) to enable automatic generation of Python bindings by OpenCV scripts. No additional dependencies are required beyond OpenCV headers. Inputs are OpenCV's image wrapper types, and the output is created by modifying the dst parameter.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
CV_EXPORTS_W void equalizeHist( InputArray src, OutputArray dst );
```

----------------------------------------

TITLE: Performing Opening Operation with OpenCV Python
DESCRIPTION: Demonstrates the opening operation which is erosion followed by dilation. Used for noise removal while preserving object shape.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)
```

----------------------------------------

TITLE: Initializing VideoCapture with MSMF Backend for File Input in C++
DESCRIPTION: This snippet shows how to create a VideoCapture object to read video from a file using the Microsoft Media Foundation (MSMF) backend. It demonstrates two approaches: using the constructor and using the open() method.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/doc/videoio_overview.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
//declare a capture object
cv::VideoCapture cap(filename, cv::CAP_MSMF);

//or specify the apiPreference with open
cap.open(filename, cv::CAP_MSMF);
```

----------------------------------------

TITLE: Initializing Small OpenCV Matrices with Comma Separators in C++
DESCRIPTION: Creates small matrices using comma-separated initializers. This method is convenient for small matrices with known values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
// for small matrices, comma-separated initializer is available
Mat C = (Mat_<double>(3,3) << 0, -1, 0, -1, 5, -1, 0, -1, 0);
cout << "C = " << endl << " " << C << endl << endl;
```

----------------------------------------

TITLE: Running YOLO Detector Command Line Usage
DESCRIPTION: Command line parameters for running the OpenCV YOLO detector example, including input configuration, model parameters, and processing options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
./bin/example_dnn_yolo_detector --input=<path_to_your_input_file> \
                                --classes=<path_to_class_names_file> \
                                --thr=<confidence_threshold> \
                                --nms=<non_maximum_suppression_threshold> \
                                --mean=<mean_normalization_value> \
                                --scale=<scale_factor> \
                                --yolo=<yolo_model_version> \
                                --padvalue=<padding_value> \
                                --paddingmode=<padding_mode> \
                                --backend=<computation_backend> \
                                --target=<target_computation_device> \
                                --width=<model_input_width> \
                                --height=<model_input_height>
```

----------------------------------------

TITLE: Setting up Dependencies for Android Build in CMake
DESCRIPTION: This CMake code initializes the `depends` list for the subsequent Android build command. It includes the previously defined `${the_module}_android_source_copy` target and its corresponding dependency helper file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
set(depends ${the_module}_android_source_copy "${OPENCV_DEPHELPER}/${the_module}_android_source_copy")
```

----------------------------------------

TITLE: Saving Inliers from Matched Keypoints in C++
DESCRIPTION: This code snippet saves the inlier matches based on the mask computed by the RANSAC algorithm during homography estimation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_tracking/akaze_tracking.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
for(unsigned i = 0; i < matched1.size(); i++) {
    if(inlier_mask.at<uchar>(i)) {
        int new_i = static_cast<int>(inliers1.size());
        inliers1.push_back(matched1[i]);
        inliers2.push_back(matched2[i]);
        inlier_matches.push_back(DMatch(new_i, new_i, 0));
    }
}
```

----------------------------------------

TITLE: Allocating/Resizing Output Mat using numpy.zeros_like in OpenCV in Python
DESCRIPTION: For Python OpenCV, np.zeros_like creates an array of same shape and type as an input image. Ensures output buffer is appropriately sized, useful before assignments or in-place operations. Requires numpy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_27

LANGUAGE: Python
CODE:
```
output = np.zeros_like(input)
```

----------------------------------------

TITLE: Conditionally Adding Example Subdirectories (OpenCV Build) in CMake
DESCRIPTION: Includes subdirectories containing various example categories (C++, Java, DNN, GPU, etc.) when building as part of OpenCV. Inclusion is conditional based on CMake variables like `WIN32`, `HAVE_DIRECTX`, `ANDROID`, `HAVE_OPENGL`, `HAVE_OPENVX`, `UNIX`, `HAVE_VA`, `BUILD_ANDROID_EXAMPLES`, `INSTALL_ANDROID_EXAMPLES`, `INSTALL_PYTHON_EXAMPLES`, and `OPENCV_SEMIHOSTING`, ensuring only relevant examples are processed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
add_subdirectory(cpp)
add_subdirectory(java/tutorial_code)
add_subdirectory(dnn)
add_subdirectory(gpu)
add_subdirectory(tapi)
add_subdirectory(opencl)
add_subdirectory(sycl)
if(WIN32 AND HAVE_DIRECTX)
  add_subdirectory(directx)
endif()
if((NOT ANDROID) AND HAVE_OPENGL)
  add_subdirectory(opengl)
endif()
if(HAVE_OPENVX)
  add_subdirectory(openvx)
endif()
if(UNIX AND NOT ANDROID AND HAVE_VA)
  add_subdirectory(va_intel)
endif()
if(ANDROID AND (BUILD_ANDROID_EXAMPLES OR INSTALL_ANDROID_EXAMPLES))
  add_subdirectory(android)
endif()
if(INSTALL_PYTHON_EXAMPLES)
  add_subdirectory(python)
endif()
# The examples in this folder will work with a semihosting version of
# OpenCV. For more information about semihosting, see
# https://developer.arm.com/documentation/100863/latest
if(OPENCV_SEMIHOSTING)
  add_subdirectory(semihosting)
endif()
```

----------------------------------------

TITLE: Implementing Color Image Denoising with OpenCV Python
DESCRIPTION: Demonstrates how to use cv.fastNlMeansDenoisingColored() to remove Gaussian noise from color images. The function processes the image in CIELAB colorspace and applies denoising separately to luminance and color components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_non_local_means/py_non_local_means.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('die.png')

dst = cv.fastNlMeansDenoisingColored(img,None,10,10,7,21)

plt.subplot(121),plt.imshow(img)
plt.subplot(122),plt.imshow(dst)
plt.show()
```

----------------------------------------

TITLE: Loading Input Image and Converting to Blob Format in C++
DESCRIPTION: This snippet shows how to read an input image (or video) and convert it into a format suitable for GoogLeNet using OpenCV. It utilizes the cv::VideoCapture and cv::dnn::blobFromImage functions to read images and prepare them by resizing, mean subtraction, and reshaping to `1x3x224x224` dimensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
@snippet dnn/classification.cpp Open a video file or an image file or a camera stream
```

LANGUAGE: C++
CODE:
```
@snippet dnn/classification.cpp Create a 4D blob from a frame
```

----------------------------------------

TITLE: Building For Custom Architectures Using build_xcframework.py - Python/Bash
DESCRIPTION: This snippet demonstrates specifying the target architectures for each Apple platform when invoking build_xcframework.py. By using the *_archs flags for each platform, you can control which architectures are included in the build process. Requires the same Python and platform dependencies as a standard build. Inputs are architecture flags and output directory; output is the built xcframework tailored to the architectures provided.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/apple/readme.md#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
python build_xcframework.py --out somedir --iphoneos_archs arm64 --iphonesimulator_archs arm64 --macos_archs arm64 --catalyst_archs arm64
```

----------------------------------------

TITLE: Creating Trackbar for Method Selection (Java)
DESCRIPTION: Creates a trackbar using `HighGui.createTrackbar` within a Swing `JFrame`. This UI element enables the user to choose the template matching method. An event listener updates the `match_method` variable and triggers the matching process when the slider value changes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_17

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java create_trackbar
```

----------------------------------------

TITLE: Calculating SSIM on GPU (Optimized) in C++
DESCRIPTION: Defines an optimized C++ function `getMSSIM_GPU_optimized` for GPU-based MSSIM calculation. It utilizes a pre-allocated buffer structure (`BufferMSSIM`, not shown but implied) to hold intermediate `gpu::GpuMat` results, minimizing GPU memory allocation overhead. The function uploads input matrices (`I1`, `I2`) and calls the optimized GPU `ssim` function, passing the buffer.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
//![getssimopt]
Scalar getMSSIM_GPU_optimized(const Mat& i1, const Mat& i2, BufferMSSIM& b)
{
    // Upload data to GPU
    b.gI1.upload(i1);
    b.gI2.upload(i2);

    return ssim(b.gI1, b.gI2);
}
//![getssimopt]
```

----------------------------------------

TITLE: NumPy-Style Formatting for OpenCV Mat Output in C++
DESCRIPTION: Shows how to format OpenCV Mat output to resemble NumPy syntax using the format() method with FormatNumPy flag.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_13

LANGUAGE: C++
CODE:
```
cout << "R (numpy) = " << endl << format(R, Formatter::FMT_NUMPY) << endl << endl;
```

----------------------------------------

TITLE: Computing Histograms for BGR Channels in C++
DESCRIPTION: C++ snippet calculating histograms for each B, G, and R plane using `cv::calcHist`. It iterates through the separated planes (`bgr_planes`), calling `calcHist` for each with the previously defined parameters (`histSize`, `histRange`, `uniform`, `accumulate`). The results are stored in `b_hist`, `g_hist`, and `r_hist` Mats.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_18

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Compute the histograms
```

----------------------------------------

TITLE: Loading and Initial Image Processing
DESCRIPTION: Loads the source image and converts white background to black for better foreground object discrimination
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/distance_transformation/distance_transform.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
Mat src = imread(samples::findFile("cards.png"));
if (src.empty())
{
    cout << "Could not open or find the image!\n";
    return -1;
}
imshow("Source", src);
```

LANGUAGE: Python
CODE:
```
src = cv.imread(cv.samples.findFile("cards.png"))
if src is None:
    print('Could not open or find the image!')
    exit(0)
cv.imshow('Source', src)
```

----------------------------------------

TITLE: Displaying Results and Drawing Rectangle (Java)
DESCRIPTION: Draws a rectangle on the copied source image (`img_display`) using `Imgproc.rectangle` to highlight the best match area. The rectangle's corners are defined by `matchLoc` and the template dimensions. Both the result matrix and the image with the drawn rectangle are then displayed in separate windows using custom display logic (likely involving `HighGui.imshow` or Swing components).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_35

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java imshow
```

----------------------------------------

TITLE: Running RANSAC Pose Estimation in C++
DESCRIPTION: Demonstrates steps 3 and 4 of the main pose estimation algorithm using RANSAC. It first estimates the pose via RANSAC and then collects inliers for drawing, ensuring RANSAC runs only when matches exist.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_18

LANGUAGE: cpp
CODE:
```
if(good_matches.size() > 0) // None matches, then RANSAC crashes
{

    // -- Step 3: Estimate the pose using RANSAC approach
    pnp_detection.estimatePoseRANSAC( list_points3d_model_match, list_points2d_scene_match,
                                      pnpMethod, inliers_idx, iterationsCount, reprojectionError, confidence );


    // -- Step 4: Catch the inliers keypoints to draw
    for(int inliers_index = 0; inliers_index < inliers_idx.rows; ++inliers_index)
    {
    int n = inliers_idx.at<int>(inliers_index);         // i-inlier
    cv::Point2f point2d = list_points2d_scene_match[n]; // i-inlier point 2D
    list_points2d_inliers.push_back(point2d);           // add i-inlier to list
}
```

----------------------------------------

TITLE: Core PSNR Calculation Function in C++
DESCRIPTION: Provides overloaded C++ functions named `psnr` for calculating Peak Signal-to-Noise Ratio. One version takes standard CPU `Mat` objects, calculates the sum of squared differences, and computes PSNR. The other version takes `gpu::GpuMat` objects, performs calculations on the GPU using functions like `gpu::absdiff`, `gpu::multiply`, and `gpu::sum`, downloads the result, and computes PSNR. Handles potential zero difference cases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
//![psnr]
double psnr(const Mat& I1, const Mat& I2)
{
    Mat s1;
    absdiff(I1, I2, s1);       // |I1 - I2|
    s1.convertTo(s1, CV_32F);  // cannot make a square on 8 bits
    s1 = s1.mul(s1);           // |I1 - I2|^2

    Scalar s = sum(s1);        // sum elements per channel

    double sse = s.val[0] + s.val[1] + s.val[2]; // sum channels

    if( sse <= 1e-10) // for small values return zero
        return 0;
    else
    {
        double mse = sse / (double)(I1.channels() * I1.total());
        double psnr = 10.0 * log10((255*255) / mse);
        return psnr;
    }
}

double psnr(const gpu::GpuMat& d_I1, const gpu::GpuMat& d_I2)
{
    gpu::GpuMat d_s1;
    gpu::absdiff(d_I1, d_I2, d_s1);
    d_s1.convertTo(d_s1, CV_32F);
    gpu::multiply(d_s1, d_s1, d_s1);

    Scalar s = gpu::sum(d_s1);
    double sse = s.val[0] + s.val[1] + s.val[2];

    if( sse <= 1e-10)
        return 0;
    else
    {
        double mse = sse / (double)(d_I1.channels() * d_I1.total());
        double psnr = 10.0 * log10((255*255) / mse);
        return psnr;
    }
}
//![psnr]
```

----------------------------------------

TITLE: Image Stitching Using OpenCV in C++
DESCRIPTION: This C++ function performs image stitching using the computed homography matrix with OpenCV. It requires the OpenCV library setup and previously calculated matrices. The function takes pre-processed images and results in a stitched panorama.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_37

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>

void stitchImages(cv::Mat image1, cv::Mat image2, cv::Mat homography) {
    // Code to stitch images
    // ...
}
```

----------------------------------------

TITLE: Refining Corners with SubPixel Accuracy in OpenCV (Python)
DESCRIPTION: This code snippet shows how to refine detected corners using OpenCV's cv.cornerSubPix() function to achieve sub-pixel accuracy. After finding Harris corners, the centroid of these corners is calculated and refined for accuracy using specified criteria. The function requires defining termination criteria and neighborhood size. Output displays refined corners in green, while initially detected corners remain in red. This snippet uses the OpenCV and NumPy libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

filename = 'chessboard2.jpg'
img = cv.imread(filename)
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)

# find Harris corners
gray = np.float32(gray)
dst = cv.cornerHarris(gray,2,3,0.04)
dst = cv.dilate(dst,None)
ret, dst = cv.threshold(dst,0.01*dst.max(),255,0)
dst = np.uint8(dst)

# find centroids
ret, labels, stats, centroids = cv.connectedComponentsWithStats(dst)

# define the criteria to stop and refine the corners
criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.001)
corners = cv.cornerSubPix(gray,np.float32(centroids),(5,5),(-1,-1),criteria)

# Now draw them
res = np.hstack((centroids,corners))
res = np.int0(res)
img[res[:,1],res[:,0]]=[0,0,255]
img[res[:,3],res[:,2]] = [0,255,0]

cv.imwrite('subpixel5.png',img)
```

----------------------------------------

TITLE: Detecting FAST Corners using OpenCV in Python
DESCRIPTION: This Python script demonstrates using OpenCV's FAST feature detector. It loads a grayscale image, creates a `FastFeatureDetector` object, detects keypoints with default settings (including non-maximal suppression), prints detector parameters, and visualizes the results by drawing keypoints. It then disables non-maximal suppression, detects keypoints again, prints the count, and saves both resulting images for comparison. Requires `numpy`, `cv2` (OpenCV), and an input image file ('blox.jpg'). `matplotlib.pyplot` is imported but not used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_fast/py_fast.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
@code{.py}
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('blox.jpg', cv.IMREAD_GRAYSCALE) # `<opencv_root>/samples/data/blox.jpg`

# Initiate FAST object with default values
fast = cv.FastFeatureDetector_create()

# find and draw the keypoints
kp = fast.detect(img,None)
img2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))

# Print all default params
print( "Threshold: {}".format(fast.getThreshold()) )
print( "nonmaxSuppression:{}".format(fast.getNonmaxSuppression()) )
print( "neighborhood: {}".format(fast.getType()) )
print( "Total Keypoints with nonmaxSuppression: {}".format(len(kp)) )

cv.imwrite('fast_true.png', img2)

# Disable nonmaxSuppression
fast.setNonmaxSuppression(0)
kp = fast.detect(img, None)

print( "Total Keypoints without nonmaxSuppression: {}".format(len(kp)) )

img3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))

cv.imwrite('fast_false.png', img3)
@endcode
```

----------------------------------------

TITLE: Implementing Meanshift Object Tracking in Python
DESCRIPTION: Python implementation of the Meanshift algorithm using OpenCV. The code sets up video capture, calculates the target histogram in HSV color space, and tracks objects across frames using the meanshift algorithm.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/meanshift.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import numpy as np\nimport cv2 as cv\nimport argparse\n\nparser = argparse.ArgumentParser(description='This sample demonstrates the meanshift algorithm. \\\n                                              The example file can be downloaded from: \\\n                                              https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4')\nparser.add_argument('image', type=str, help='path to image file')\nargs = parser.parse_args()\n\ncap = cv.VideoCapture(args.image)\n# take first frame of the video\nret,frame = cap.read()\n# setup initial location of window\nx, y, w, h = 300, 200, 100, 50 # simply hardcoded the values\ntrack_window = (x, y, w, h)\n# set up the ROI for tracking\nroi = frame[y:y+h, x:x+w]\nhsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\nmask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\nroi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\ncv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n# Setup the termination criteria, either 10 iteration or move by at least 1 pt\nterm_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\nwhile(1):\n    ret, frame = cap.read()\n    if ret == True:\n        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n        # apply meanshift to get the new location\n        ret, track_window = cv.meanShift(dst, track_window, term_crit)\n        # Draw it on image\n        x,y,w,h = track_window\n        img2 = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n        cv.imshow('img2',img2)\n        k = cv.waitKey(30) & 0xff\n        if k == 27:\n            break\n    else:\n        break\ncv.destroyAllWindows()\ncap.release()
```

----------------------------------------

TITLE: Draw Contours on Mat in OpenCV Java
DESCRIPTION: Creates and processes a drawing canvas by iterating over contours, drawing them and associated shapes in Java. Utilizes OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_13

LANGUAGE: Java
CODE:
```
Mat drawing = Mat.zeros(edges.size(), CvType.CV_8UC3);
Random rng = new Random(12345);
for (int i = 0; i < contours.size(); i++) {
    Scalar color = new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256));
    Imgproc.drawContours(drawing, contours, i, color);
    Imgproc.rectangle(drawing, rect.tl(), rect.br(), color, 2);
    Imgproc.circle(drawing, center, (int) radius[0], color, 2);
}
```

----------------------------------------

TITLE: Detecting Subpixel Corners using OpenCV in Java
DESCRIPTION: Java implementation of corner detection with subpixel accuracy using OpenCV's cornerSubPix function. The code demonstrates image loading, corner detection, and refinement of corner positions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/corner_subpixels/corner_subpixels.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;
import org.opencv.highgui.HighGui;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;

class CornerSubPixDemo {
    private Mat src = new Mat();
    private Mat srcGray = new Mat();
    private int maxCorners = 10;
    private int maxTrackbar = 25;
    private RNG rng = new RNG(12345);
    private String sourceWindow = "Image";

    public void run(String[] args) {
        String filename = args.length > 0 ? args[0] : "../data/pic3.png";
        src = Imgcodecs.imread(filename);
        if (src.empty()) {
            System.err.println("Cannot read image: " + filename);
            System.exit(0);
        }

        Imgproc.cvtColor(src, srcGray, Imgproc.COLOR_BGR2GRAY);

        HighGui.namedWindow(sourceWindow);
        HighGui.createTrackbar("Max corners:", sourceWindow, null, maxTrackbar, (val) -> {
            maxCorners = Math.max(val, 1);
            goodFeaturesToTrack_Demo();
        });

        goodFeaturesToTrack_Demo();

        HighGui.waitKey();
        System.exit(0);
    }

    private void goodFeaturesToTrack_Demo() {
        MatOfPoint corners = new MatOfPoint();
        double qualityLevel = 0.01;
        double minDistance = 10;
        int blockSize = 3, gradientSize = 3;
        boolean useHarrisDetector = false;
        double k = 0.04;

        Mat copy = src.clone();

        Imgproc.goodFeaturesToTrack(srcGray, corners, maxCorners, qualityLevel, minDistance, new Mat(),
                blockSize, gradientSize, useHarrisDetector, k);

        System.out.println("** Number of corners detected: " + corners.rows());

        Point[] cornersArr = corners.toArray();
        for (int i = 0; i < cornersArr.length; i++) {
            Imgproc.circle(copy, cornersArr[i], 4,
                    new Scalar(rng.nextInt(256), rng.nextInt(256), rng.nextInt(256)), Imgproc.FILLED);
        }

        HighGui.imshow("Sharp corners", copy);

        Size winSize = new Size(5, 5);
        Size zeroZone = new Size(-1, -1);
        TermCriteria criteria = new TermCriteria(TermCriteria.EPS + TermCriteria.COUNT, 40, 0.001);

        MatOfPoint2f corners2f = new MatOfPoint2f(corners.toArray());
        Imgproc.cornerSubPix(srcGray, corners2f, winSize, zeroZone, criteria);

        Point[] refinedCorners = corners2f.toArray();
        for (int i = 0; i < refinedCorners.length; i++) {
            System.out.println(String.format(" -- Refined Corner [%d] (%.2f,%.2f)", i, refinedCorners[i].x, refinedCorners[i].y));
        }
    }
}

public class CornerSubPixDemoRun {
    public static void main(String[] args) {
        // Load the native OpenCV library
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);

        new CornerSubPixDemo().run(args);
    }
}
```

----------------------------------------

TITLE: Implementing Face and Eye Detection with OpenCV.js in Node.js
DESCRIPTION: A complete Node.js application that uses OpenCV.js to detect faces and eyes in an image. It loads pre-trained Haar cascade classifiers, processes the image, draws rectangles around detected features, and saves the output as a JPEG file. The code demonstrates how to use OpenCV's computer vision capabilities in a JavaScript environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_nodejs/js_nodejs.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
const { Canvas, createCanvas, Image, ImageData, loadImage } = require('canvas');
const { JSDOM } = require('jsdom');
const { writeFileSync, existsSync, mkdirSync } = require('fs');

(async () => {
  await loadOpenCV();

  const image = await loadImage('lena.jpg');
  const src = cv.imread(image);
  let gray = new cv.Mat();
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
  let faces = new cv.RectVector();
  let eyes = new cv.RectVector();
  let faceCascade = new cv.CascadeClassifier();
  let eyeCascade = new cv.CascadeClassifier();

  // Load pre-trained classifier files. Notice how we reference local files using relative paths just
  // like we normally would do
  faceCascade.load('./haarcascade_frontalface_default.xml');
  eyeCascade.load('./haarcascade_eye.xml');

  let mSize = new cv.Size(0, 0);
  faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, mSize, mSize);
  for (let i = 0; i < faces.size(); ++i) {
    let roiGray = gray.roi(faces.get(i));
    let roiSrc = src.roi(faces.get(i));
    let point1 = new cv.Point(faces.get(i).x, faces.get(i).y);
    let point2 = new cv.Point(faces.get(i).x + faces.get(i).width, faces.get(i).y + faces.get(i).height);
    cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
    eyeCascade.detectMultiScale(roiGray, eyes);
    for (let j = 0; j < eyes.size(); ++j) {
      let point1 = new cv.Point(eyes.get(j).x, eyes.get(j).y);
      let point2 = new cv.Point(eyes.get(j).x + eyes.get(j).width, eyes.get(j).y + eyes.get(j).height);
      cv.rectangle(roiSrc, point1, point2, [0, 0, 255, 255]);
    }
    roiGray.delete();
    roiSrc.delete();
  }

  const canvas = createCanvas(image.width, image.height);
  cv.imshow(canvas, src);
  writeFileSync('output3.jpg', canvas.toBuffer('image/jpeg'));
  src.delete(); gray.delete(); faceCascade.delete(); eyeCascade.delete(); faces.delete(); eyes.delete()
})();

/**
 * Loads opencv.js.
 *
 * Installs HTML Canvas emulation to support `cv.imread()` and `cv.imshow`
 *
 * Mounts given local folder `localRootDir` in emscripten filesystem folder `rootDir`. By default it will mount the local current directory in emscripten `/work` directory. This means that `/work/foo.txt` will be resolved to the local file `./foo.txt`
 * @param {string} rootDir The directory in emscripten filesystem in which the local filesystem will be mount.
 * @param {string} localRootDir The local directory to mount in emscripten filesystem.
 * @returns {Promise} resolved when the library is ready to use.
 */
function loadOpenCV(rootDir = '/work', localRootDir = process.cwd()) {
  if(global.Module && global.Module.onRuntimeInitialized && global.cv && global.cv.imread) {
    return Promise.resolve()
  }
  return new Promise(resolve => {
    installDOM()
    global.Module = {
      onRuntimeInitialized() {
        // We change emscripten current work directory to 'rootDir' so relative paths are resolved
        // relative to the current local folder, as expected
        cv.FS.chdir(rootDir)
        resolve()
      },
      preRun() {
        // preRun() is another callback like onRuntimeInitialized() but is called just before the
        // library code runs. Here we mount a local folder in emscripten filesystem and we want to
        // do this before the library is executed so the filesystem is accessible from the start
        const FS = global.Module.FS
        // create rootDir if it doesn't exists
        if(!FS.analyzePath(rootDir).exists) {
          FS.mkdir(rootDir);
        }
        // create localRootFolder if it doesn't exists
        if(!existsSync(localRootDir)) {
          mkdirSync(localRootDir, { recursive: true});
        }
        // FS.mount() is similar to Linux/POSIX mount operation. It basically mounts an external
        // filesystem with given format, in given current filesystem directory.
        FS.mount(FS.filesystems.NODEFS, { root: localRootDir}, rootDir);
      }
    };
    global.cv = require('./opencv.js')
  });
}

function installDOM(){
  const dom = new JSDOM();
  global.document = dom.window.document;
  global.Image = Image;
  global.HTMLCanvasElement = Canvas;
  global.ImageData = ImageData;
  global.HTMLImageElement = Image;
}
```

----------------------------------------

TITLE: Calculating Convex Hull in C++ using OpenCV
DESCRIPTION: This C++ code snippet demonstrates loading an image, finding its contours after thresholding, and then computing and drawing the convex hull for each contour using the `cv::convexHull` and `cv::drawContours` functions from the OpenCV library. It requires the OpenCV core, imgproc, imgcodecs, and highgui modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/hull/hull.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
@add_toggle_cpp
This tutorial code's is shown lines below. You can also download it from
[here](https://github.com/opencv/opencv/tree/4.x/samples/cpp/tutorial_code/ShapeDescriptors/hull_demo.cpp)
@include samples/cpp/tutorial_code/ShapeDescriptors/hull_demo.cpp
@end_toggle
```

----------------------------------------

TITLE: Implementing Custom Post-Processing Kernel in G-API
DESCRIPTION: Demonstrates implementation of a custom kernel for post-processing SSD detection results. Shows kernel definition and implementation for processing inference outputs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
G_API_OP(PostProc,
         <std::tuple<cv::GMat, std::vector<cv::Rect>, std::vector<cv::Str>, std::vector<cv::Str>>
         (cv::GMat, cv::GMat, cv::GMat, cv::GMat, float, cv::Size)>,
         "custom.post_proc") {
    static std::tuple<cv::GArrayDesc, cv::GArrayDesc, cv::GArrayDesc>
        outMeta(const cv::GMatDesc&, const cv::GMatDesc&,
                const cv::GMatDesc&, const cv::GMatDesc&,
                float, const cv::Size&) {
        return std::make_tuple(cv::empty_array_desc(),
                              cv::empty_array_desc(),
                              cv::empty_array_desc());
    }
};
```

----------------------------------------

TITLE: Installing OpenCV Example Source Files using CMake
DESCRIPTION: This CMake command uses the OpenCV-specific function `ocv_install_example_src` to designate C++ source files (*.cpp), header files (*.hpp), and the CMakeLists.txt file itself for installation as part of the project's examples. The 'cpp' argument likely specifies the subdirectory within the installation path.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/openvx/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
ocv_install_example_src(cpp *.cpp *.hpp CMakeLists.txt)
```

----------------------------------------

TITLE: Capturing and Visualizing Orbbec UVC Depth and Color Images - OpenCV C++
DESCRIPTION: This code snippet showcases how to use OpenCV in C++ to access an Orbbec UVC depth camera, retrieve intrinsic parameters, grab color (BGR) and depth frames, normalize and colorize depth maps, overlay depth data onto the color image, display all outputs, and handle keyboard interrupts. Key dependencies are OpenCV built with Orbbec support and an appropriate build environment. Intrinsic camera parameters are retrieved for further use, and depth overlays are produced by resizing and blending images. The loop runs until a key is pressed, then resources are released upon completion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_uvc.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
// Open Orbbec Depth Sensor\ncv::VideoCapture obsensorCapture(0, cv::CAP_OBSENSOR);\nif (!obsensorCapture.isOpened()) {\n    std::cerr << "Failed to open Orbbec device!" << std::endl;\n    return -1;\n}\n\n// Retrieve Camera Intrinsic Parameters\ndouble fx = obsensorCapture.get(cv::CAP_PROP_OBSENSOR_INTRINSIC_FX);\ndouble fy = obsensorCapture.get(cv::CAP_PROP_OBSENSOR_INTRINSIC_FY);\ndouble cx = obsensorCapture.get(cv::CAP_PROP_OBSENSOR_INTRINSIC_CX);\ndouble cy = obsensorCapture.get(cv::CAP_PROP_OBSENSOR_INTRINSIC_CY);\n\nwhile (true) {\n    if (!obsensorCapture.grab())\n        continue;\n\n    cv::Mat image;\n    if (obsensorCapture.retrieve(image, cv::CAP_OBSENSOR_BGR_IMAGE)) {\n        cv::imshow("BGR", image);\n    }\n\n    cv::Mat depthMap;\n    if (obsensorCapture.retrieve(depthMap, cv::CAP_OBSENSOR_DEPTH_MAP)) {\n        int minDepth = 300, maxDepth = 5000;\n        depthMap.setTo(0, depthMap < minDepth);\n        depthMap.setTo(0, depthMap > maxDepth);\n        cv::Mat adjDepthMap;\n        double scale = 255.0 / (maxDepth - minDepth);\n        depthMap.convertTo(adjDepthMap, CV_8U, scale, -minDepth * scale);\n        cv::applyColorMap(adjDepthMap, adjDepthMap, cv::COLORMAP_JET);\n        cv::imshow("DEPTH", adjDepthMap);\n\n        // Overlay Depth Map on BGR Image\n        if (!image.empty()) {\n            cv::Mat resizedAdjDepthMap;\n            cv::resize(adjDepthMap, resizedAdjDepthMap, image.size());\n            double alpha = 0.35;\n            cv::addWeighted(resizedAdjDepthMap, alpha, image, 1 - alpha, 0.0, image);\n            cv::imshow("DepthToColor", image);\n        }\n    }\n\n    if (cv::pollKey() >= 0)\n        break;\n}\n\nobsensorCapture.release();
```

----------------------------------------

TITLE: Defining a Scalar Color in Java
DESCRIPTION: Creating a Scalar object to represent a BGR color in OpenCV Java. The Scalar represents a 3-element vector with Blue, Green, and Red values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_4

LANGUAGE: java
CODE:
```
Scalar( a, b, c )
```

----------------------------------------

TITLE: Illustrating Fused Layer Computation (Pseudocode)
DESCRIPTION: This pseudocode shows the resulting fused Halide function after combining the Convolution, Scale, and ReLU operations from the previous example. The entire computation is expressed within the `relu` function, meaning only this single fused function needs scheduling directives, simplifying optimization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide_scheduling/dnn_halide_scheduling.markdown#2025-04-22_snippet_2

LANGUAGE: pseudocode
CODE:
```
relu(x, y, c, n) = max((sum(...) + bias(c)) * weights(c), 0);
```

----------------------------------------

TITLE: Creating Custom Target for Copying Java Source Files in CMake
DESCRIPTION: This CMake code appends the `gen_opencv_java_source` script to the `depends` list. It then defines a custom target `${the_module}_android_source_copy` using the `ocv_copyfiles_add_target` macro (likely defined elsewhere in the OpenCV CMake setup) to handle the copying of Java source files for the Android SDK build. Finally, it removes a dependency helper file to ensure this copy target is rebuilt if CMake is re-run.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
list(APPEND depends gen_opencv_java_source "${OPENCV_DEPHELPER}/gen_opencv_java_source")
ocv_copyfiles_add_target(${the_module}_android_source_copy JAVA_SRC_COPY "Copy Java(Android SDK) source files" ${depends})
file(REMOVE "${OPENCV_DEPHELPER}/${the_module}_android_source_copy")  # force rebuild after CMake run
```

----------------------------------------

TITLE: Brute-Force Matching with OpenCV in Python
DESCRIPTION: Python code utilizing a brute-force matcher and Hamming distance to locate matches between image descriptors with OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py 2-nn matching
```

----------------------------------------

TITLE: Installing OpenCV-Python Package
DESCRIPTION: Command to install the pre-built OpenCV-Python package from Ubuntu repositories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
sudo apt-get install python3-opencv
```

----------------------------------------

TITLE: Defining a Point in C++
DESCRIPTION: Two different ways to define a 2D point using the cv::Point structure in C++. A Point represents a 2D coordinate with x and y values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
Point pt;
pt.x = 10;
pt.y = 8;
```

LANGUAGE: cpp
CODE:
```
Point pt =  Point(10, 8);
```

----------------------------------------

TITLE: Displaying Image using imshow and waitKey in OpenCV in Python
DESCRIPTION: Demonstrates displaying an image array in Python using cv2.imshow and waiting for keyboard input. Requires cv2 (opencv-python) and a GUI backend. Window opens with given name; user keys close the window.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_42

LANGUAGE: Python
CODE:
```
cv2.imshow('Window', img)\ncv2.waitKey(0)
```

----------------------------------------

TITLE: Defining OpenCV Photo Module Dependencies
DESCRIPTION: Defines the photo module with required and optional dependencies, including CUDA modules and language bindings for Java, Objective-C, Python, and JavaScript.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/photo/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
ocv_define_module(photo opencv_imgproc OPTIONAL opencv_cudaarithm opencv_cudaimgproc WRAP java objc python js)
```

----------------------------------------

TITLE: Configuring and Installing Data Files with CMake - CMake
DESCRIPTION: This snippet uses CMake commands to collect Haar and LBP cascade XML files from specified directories and configures rules for their installation into the appropriate paths within the OpenCV installation hierarchy. It employs the file(GLOB ...) pattern to aggregate matching files and the install(FILES ...) and install(DIRECTORY ...) commands to deploy these files and directories, respectively. Conditional logic ensures that test data is only installed if certain variables are set. Required dependencies include a standard CMake environment, the presence of haarcascades and lbpcascades directories containing XML files, and proper variable configuration; variables like OPENCV_OTHER_INSTALL_PATH and OPENCV_TEST_DATA_INSTALL_PATH must be defined. The primary input is the set of XML files, and the expected output is their presence in the installation tree. Limitations include the need for proper path variable setup and sufficient permissions during installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/data/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
file(GLOB HAAR_CASCADES haarcascades/*.xml)
file(GLOB LBP_CASCADES lbpcascades/*.xml)

install(FILES ${HAAR_CASCADES} DESTINATION ${OPENCV_OTHER_INSTALL_PATH}/haarcascades COMPONENT libs)
install(FILES ${LBP_CASCADES}  DESTINATION ${OPENCV_OTHER_INSTALL_PATH}/lbpcascades  COMPONENT libs)

if(INSTALL_TESTS AND OPENCV_TEST_DATA_PATH)
  install(DIRECTORY "${OPENCV_TEST_DATA_PATH}/" DESTINATION "${OPENCV_TEST_DATA_INSTALL_PATH}" COMPONENT "tests")
endif()
```

----------------------------------------

TITLE: Applying Blur Filter with OpenCV in Java
DESCRIPTION: This Java snippet shows how to utilize OpenCV's blur() function for image smoothing using a normalized box filter. Prerequisites include OpenCV. The function requires parameters for source, destination image, kernel size, and anchor point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java blur
```

----------------------------------------

TITLE: ResNet-50 ONNX Conversion Command - Console
DESCRIPTION: This command invokes the conversion pipeline specifically for the ResNet-50 model. It mirrors the batch conversion example but hardcodes the model name for clarity and reproducibility. Results will be placed in the directory controlled by project configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_7

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_cls --model_name resnet50 --evaluate False
```

----------------------------------------

TITLE: Plot Histogram with Matplotlib
DESCRIPTION: Uses Matplotlib's hist() function to directly plot a histogram from image data without pre-calculation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('home.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
plt.hist(img.ravel(),256,[0,256]); plt.show()
```

----------------------------------------

TITLE: Defining 3D Cube Corner Points with OpenCV (Python)
DESCRIPTION: Defines the coordinates of the eight 3D vertices of a cube for use in projecting and drawing on the image. Points are specified in the same size units as the chessboard squares for scale consistency. This array is to be used with the pose estimation and projection routines to correctly render a cube's outline according to real-world orientation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_pose/py_pose.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
axis = np.float32([[0,0,0], [0,3,0], [3,3,0], [3,0,0],\n                   [0,0,-3],[0,3,-3],[3,3,-3],[3,0,-3] ])
```

----------------------------------------

TITLE: Retrieving FourCC Codec from Input Video using OpenCV (C++)
DESCRIPTION: Shows how to obtain the FourCC (Four Character Code) identifier of the codec used in an input video file. It opens the input video using `cv::VideoCapture`, retrieves the `CAP_PROP_FOURCC` property using the `get` method, and casts the returned double value to an integer. Requires an initialized `VideoCapture` object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
VideoCapture inputVideo(source);                                // Open input
int ex = static_cast<int>(inputVideo.get(CAP_PROP_FOURCC));     // Get Codec Type- Int form
```

----------------------------------------

TITLE: Outputting 3D Points in OpenCV C++
DESCRIPTION: Demonstrates outputting 3D point objects using the << operator, showing OpenCV's support for streaming complex data structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_16

LANGUAGE: C++
CODE:
```
Point3f P3f(2, 6, 7);
cout << "Point (3D) = " << P3f << endl << endl;
```

----------------------------------------

TITLE: Writing and Reading OpenCV Mat Objects to XML/YAML/JSON - OpenCV Python
DESCRIPTION: These Python snippets illustrate writing and reading OpenCV Mat (NumPy array) objects with FileStorage. Use write() for writing and getNode().mat() for reading. Handles various array types and shapes supported by OpenCV and NumPy. Requires opencv-python and numpy installed. The variable must be a NumPy array for writing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_6

LANGUAGE: Python
CODE:
```
import numpy as np\nm = np.eye(3)\nfs.write('matrix', m)\n\nmat = fs.getNode('matrix').mat()
```

----------------------------------------

TITLE: Implementing Hit-or-Miss Transform in Python using OpenCV
DESCRIPTION: This Python code shows how to implement the Hit-or-Miss transform using OpenCV's morphologyEx() function to detect specific patterns in binary images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/hitOrMiss/hitOrMiss.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

# Create an image
input_image = np.array(([
    [0, 0, 0, 0, 0, 0, 0, 0],
    [0, 255, 255, 255, 0, 0, 0, 255],
    [0, 255, 255, 255, 0, 0, 0, 0],
    [0, 255, 255, 255, 0, 255, 0, 0],
    [0, 0, 255, 0, 0, 0, 0, 0],
    [0, 0, 255, 0, 0, 255, 255, 0],
    [0, 255, 0, 255, 0, 0, 255, 0],
    [0, 255, 255, 255, 0, 0, 0, 0]]), dtype="uint8")

# Set kernel
kernel = np.array(([
    [0, 1, 0],
    [1, -1, 1],
    [0, 1, 0]]), dtype="int")

output_image = cv.morphologyEx(input_image, cv.MORPH_HITMISS, kernel)

rate = 50
kernel_display = (kernel + 1) * 127
kernel_display = np.uint8(kernel_display)

kernel_display = cv.resize(kernel_display, None, fx=rate, fy=rate, interpolation=cv.INTER_NEAREST)
input_disp = cv.resize(input_image, None, fx=rate, fy=rate, interpolation=cv.INTER_NEAREST)
output_disp = cv.resize(output_image, None, fx=rate, fy=rate, interpolation=cv.INTER_NEAREST)

cv.imshow("kernel", kernel_display)
cv.imshow("Original", input_disp)
cv.imshow("Hit or Miss", output_disp)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Initializing VideoCapture with MSMF Backend for Camera Input in C++
DESCRIPTION: This snippet demonstrates how to create a VideoCapture object to capture video from the default camera using the Microsoft Media Foundation (MSMF) backend. It shows two methods: using the constructor and using the open() method.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/doc/videoio_overview.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
//declare a capture object
cv::VideoCapture cap(0, cv::CAP_MSMF);

//or specify the apiPreference with open
cap.open(0, cv::CAP_MSMF);
```

----------------------------------------

TITLE: Computing Chessboard Object Points in OpenCV C++
DESCRIPTION: Code to compute 3D object points for a chessboard pattern. It calculates the real-world coordinates of each corner based on a known square size and assigns Z=0 since the board is planar.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
std::vector<cv::Point3f> objectPoints;
for (int i = 0; i < patternSize.height; ++i) {
    for (int j = 0; j < patternSize.width; ++j) {
        objectPoints.push_back(cv::Point3f(j * squareSize, i * squareSize, 0.0f));
    }
}
```

----------------------------------------

TITLE: Identifying Python-Wrapped Modules in CMake for OpenCV
DESCRIPTION: Iterates through all OpenCV modules to identify those with Python wrappers. It builds a list of modules that should be included in Python tests.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/test/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
set(OPENCV_PYTHON_MODULES)
foreach(m ${OPENCV_MODULES_BUILD})
  if(";${OPENCV_MODULE_${m}_WRAPPERS};" MATCHES ";python.*;" AND HAVE_${m})
    list(APPEND OPENCV_PYTHON_MODULES ${m})
    #message(STATUS "\t${m}")
  endif()
endforeach()
```

----------------------------------------

TITLE: Persisting and Reloading kNN Data with NumPy
DESCRIPTION: The Python code segment shows how to save and load OCR model data using NumPy functions like np.savez and np.load. This method decreases startup time by reusing previously computed training data. It also suggests converting data to np.uint8 for storage efficiency. Dependencies include NumPy. Files related to model data are inputs and outputs of this code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_knn/py_knn_opencv/py_knn_opencv.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
# Save the data
np.savez('knn_data.npz',train=train, train_labels=train_labels)

# Now load the data
with np.load('knn_data.npz') as data:
    print( data.files )
    train = data['train']
    train_labels = data['train_labels']
```

----------------------------------------

TITLE: Implementing Gamma Correction with Look-Up Table in Java using OpenCV
DESCRIPTION: This Java code snippet performs gamma correction on an image (`src`) using OpenCV bindings. It computes a look-up table (`lut`) containing the gamma-transformed values (O = ((I/255)^gamma) * 255) for each possible pixel intensity (0-255), storing them as bytes. The `Core.LUT` function is then used to efficiently apply this transformation to the source image, storing the result in the destination matrix (`dst`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown#2025-04-22_snippet_4

LANGUAGE: java
CODE:
```
//![changing-contrast-brightness-gamma-correction]
        // Calculate gamma correction lookup table
        Mat lut = new Mat(1, 256, CvType.CV_8UC1);
        lut.setTo(new Scalar(0));
        double gammaValue = sliderGamma.getValue() / 100.0;
        byte[] lutData = new byte[(int) (lut.total() * lut.channels())];
        for (int i = 0; i < 256; i++) {
            double v = Math.pow(i / 255.0, gammaValue) * 255.0;
            if( v < 0 ) {
                v=0;
            }
            if( v > 255 ) {
                v=255;
            }
            lutData[i] = (byte) v;
        }
        lut.put(0, 0, lutData);

        Core.LUT(src, lut, dst);
        //![changing-contrast-brightness-gamma-correction]
```

----------------------------------------

TITLE: Configuring OpenCV Applications with CMake
DESCRIPTION: This CMake snippet adds the definition for compiling the \'opencv_version\' application with OpenCV core modules. It sets specific options and defines required for building on Windows platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/version/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
ocv_add_application(opencv_version MODULES opencv_core SRCS opencv_version.cpp)
if(WIN32)
  ocv_add_application(opencv_version_win32 MODULES opencv_core SRCS opencv_version.cpp)
  target_compile_definitions(opencv_version_win32 PRIVATE "OPENCV_WIN32_API=1")
endif()
```

----------------------------------------

TITLE: Uploading/Downloading Data to/from GPU Memory in C++
DESCRIPTION: Demonstrates how to transfer image data between CPU memory (`cv::Mat`) and GPU memory (`cv::cuda::GpuMat`) in C++. It shows creating a `GpuMat` object (`gI`), uploading data from a `Mat` object (`I1`) using the `upload()` method, and downloading data back to a `Mat` object using simple assignment (which implicitly calls `download()`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
Mat I1;         // Main memory item - read image into with imread for example
gpu::GpuMat gI; // GPU matrix - for now empty
gI1.upload(I1); // Upload a data from the system memory to the GPU memory

I1 = gI1;       // Download, gI1.download(I1) will work too
```

----------------------------------------

TITLE: Verifying CMake Installation on macOS
DESCRIPTION: This command checks the installed version of CMake to ensure it's correctly installed on the system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
cmake --version
```

----------------------------------------

TITLE: Creating Mask and Extracting Pixel Points for Contour in OpenCV Python
DESCRIPTION: This snippet demonstrates how to create a binary mask for a specific contour and extract the coordinates of all pixels belonging to that contour. It initializes a zero mask using `np.zeros` with the shape of the input image (`imgray`), draws the filled contour onto the mask using `cv.drawContours`, and then finds the coordinates of the white pixels (the contour points) using NumPy's `np.nonzero` and `np.transpose`. An alternative using `cv.findNonZero` is commented out. Requires an existing contour `cnt`, the source image `imgray` (for shape), and NumPy (`np`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
mask = np.zeros(imgray.shape,np.uint8)
cv.drawContours(mask,[cnt],0,255,-1)
pixelpoints = np.transpose(np.nonzero(mask))
#pixelpoints = cv.findNonZero(mask)
```

----------------------------------------

TITLE: Including OpenCV.js Asynchronously with Callback (HTML)
DESCRIPTION: Shows how to include the OpenCV.js library asynchronously using the `async` attribute in the `<script>` tag. The `onload` attribute specifies a JavaScript function (`onOpenCvReady()`) that will be called once the `opencv.js` script has finished loading and executing. This prevents the script from blocking page rendering.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_usage/js_usage.markdown#2025-04-22_snippet_2

LANGUAGE: html
CODE:
```
<script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
```

----------------------------------------

TITLE: Feature Matching with FLANN in C++
DESCRIPTION: This C++ implementation demonstrates how to use the FlannBasedMatcher for efficient feature matching with SURF descriptors. It loads two images, detects and describes features, matches them using FLANN, and filters the matches using Lowe's distance ratio test.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_flann_matcher/feature_flann_matcher.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include <stdio.h>
#include <iostream>
#include <opencv2/core.hpp>
#include <opencv2/features2d.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/xfeatures2d.hpp>
#include <opencv2/imgcodecs.hpp>

using namespace std;
using namespace cv;
using namespace cv::xfeatures2d;

const char* keys =
    "{ help h |                  | Print help message. }"
    "{ input1 | box.png          | Path to input image 1. }"
    "{ input2 | box_in_scene.png  | Path to input image 2. }";

int main( int argc, char* argv[] )
{
    CommandLineParser parser( argc, argv, keys );
    Mat img_object = imread( samples::findFile( parser.get<String>("input1") ), IMREAD_GRAYSCALE );
    Mat img_scene = imread( samples::findFile( parser.get<String>("input2") ), IMREAD_GRAYSCALE );
    if ( img_object.empty() || img_scene.empty() )
    {
        cout << "Could not open or find the image!\n" << endl;
        parser.printMessage();
        return -1;
    }

    //-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors
    int minHessian = 400;
    Ptr<SURF> detector = SURF::create( minHessian );
    std::vector<KeyPoint> keypoints_object, keypoints_scene;
    Mat descriptors_object, descriptors_scene;
    detector->detectAndCompute( img_object, noArray(), keypoints_object, descriptors_object );
    detector->detectAndCompute( img_scene, noArray(), keypoints_scene, descriptors_scene );

    //-- Step 2: Matching descriptor vectors using FLANN matcher
    FlannBasedMatcher matcher;
    std::vector< DMatch > matches;
    matcher.match( descriptors_object, descriptors_scene, matches );

    double max_dist = 0; double min_dist = 100;
    //-- Quick calculation of max and min distances between keypoints
    for( int i = 0; i < descriptors_object.rows; i++ )
    {
        double dist = matches[i].distance;
        if( dist < min_dist ) min_dist = dist;
        if( dist > max_dist ) max_dist = dist;
    }
    printf("-- Max dist : %f \n", max_dist );
    printf("-- Min dist : %f \n", min_dist );

    //-- Draw only "good" matches (i.e. whose distance is less than 2*min_dist,
    //-- or a small arbitary value ( 0.02 ) in the event that min_dist is very
    //-- small)
    //-- PS.- radiusMatch can also be used here.
    std::vector< DMatch > good_matches;
    for( int i = 0; i < descriptors_object.rows; i++ )
    {
        if( matches[i].distance <= max(2*min_dist, 0.02) )
        {
            good_matches.push_back( matches[i]);
        }
    }

    //-- Draw only "good" matches
    Mat img_matches;
    drawMatches( img_object, keypoints_object, img_scene, keypoints_scene,
                good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),
                std::vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS );

    //-- Show detected matches
    imshow( "Good Matches", img_matches );
    waitKey();
    return 0;
}
```

----------------------------------------

TITLE: Creating Custom Target for JavaScript Bindings Generation in CMake
DESCRIPTION: Defines a custom target 'gen_opencv_js_source' that depends on the generated bindings and specifies source files for the generation process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/generator/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
add_custom_target(gen_opencv_js_source
  # excluded from all: ALL
  DEPENDS ${bindings_cpp} "${OPENCV_DEPHELPER}/gen_opencv_js_source"
  SOURCES
      ${JS_SOURCE_DIR}/src/core_bindings.cpp
      ${CMAKE_CURRENT_SOURCE_DIR}/embindgen.py
      ${CMAKE_CURRENT_SOURCE_DIR}/templates.py
)
```

----------------------------------------

TITLE: Accessing and Modifying Pixel Values (data property) with OpenCV.js - JavaScript
DESCRIPTION: Accesses RGBA pixel values directly through the Mat.data array for continuous Mats, requiring calculation of the linear index. Useful for low-level manipulation or inspection of pixels, assuming the matrix is stored in a continuous memory block. Must check Mat continuity with isContinuous().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_6

LANGUAGE: JavaScript
CODE:
```
let row = 3, col = 4;
let src = cv.imread("canvasInput");
if (src.isContinuous()) {
    let R = src.data[row * src.cols * src.channels() + col * src.channels()];
    let G = src.data[row * src.cols * src.channels() + col * src.channels() + 1];
    let B = src.data[row * src.cols * src.channels() + col * src.channels() + 2];
    let A = src.data[row * src.cols * src.channels() + col * src.channels() + 3];
}
```

----------------------------------------

TITLE: Writing and Reading Maps (Associative Containers) - OpenCV C++
DESCRIPTION: This C++ snippet illustrates writing and reading associative maps (e.g., std::map) to XML/YAML/JSON files. The << operator is used for insertion with curly brace delimiters ({ ... }). Reading is done through the [] operator or FileNode. Only types supported by OpenCV and the serialization format are allowed. All keys must be unique.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
fs << "mymap" << "{" << "one" << 1 << "two" << 2 << "}";\n\nFileNode n = fs["mymap"];\nint one = (int)n["one"];
```

----------------------------------------

TITLE: Transforming OpenCV Segmentation Mask to Colored Visualization
DESCRIPTION: Converts a segmentation mask from OpenCV's DNN model into a colored visualization by mapping class indices to PASCAL VOC colors. The mask is resized to match the original image dimensions and converted from BGR to RGB color space.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_7

LANGUAGE: python
CODE:
```
mask_height = segm_mask.shape[0]
mask_width = segm_mask.shape[1]

img_height = original_img_shape[0]
img_width = original_img_shape[1]

# convert mask values into PASCAL VOC colors
processed_mask = np.stack([colors[color_id] for color_id in segm_mask.flatten()])

# reshape mask into 3-channel image
processed_mask = processed_mask.reshape(mask_height, mask_width, 3)
processed_mask = cv2.resize(processed_mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST).astype(
    np.uint8)

# convert colored mask from BGR to RGB
processed_mask = cv2.cvtColor(processed_mask, cv2.COLOR_BGR2RGB)
```

----------------------------------------

TITLE: Implementing Hit-or-Miss Transform in Java using OpenCV
DESCRIPTION: This Java implementation shows how to use OpenCV's morphologyEx() to perform the Hit-or-Miss transform on a binary image to detect specific patterns.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/hitOrMiss/hitOrMiss.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
import org.opencv.core.*;
import org.opencv.highgui.HighGui;
import org.opencv.imgproc.Imgproc;

class HitMiss {
    public void run() {
        // Create an image
        byte[] data = new byte[] {
                0, 0, 0, 0, 0, 0, 0, 0,
                0, 1, 1, 1, 0, 0, 0, 1,
                0, 1, 1, 1, 0, 0, 0, 0,
                0, 1, 1, 1, 0, 1, 0, 0,
                0, 0, 1, 0, 0, 0, 0, 0,
                0, 0, 1, 0, 0, 1, 1, 0,
                0, 1, 0, 1, 0, 0, 1, 0,
                0, 1, 1, 1, 0, 0, 0, 0
                };
        Mat inputImage = new Mat(8, 8, CvType.CV_8U);
        inputImage.put(0, 0, data);
        for (int i = 0; i < inputImage.rows(); i++) {
            for (int j = 0; j < inputImage.cols(); j++) {
                if (inputImage.get(i, j)[0] == 1) {
                    inputImage.put(i, j, 255);
                }
            }
        }

        Mat kernel = new Mat(3, 3, CvType.CV_16S);
        kernel.put(0, 0,
                   0, 1, 0,
                   1, -1, 1,
                   0, 1, 0);

        Mat outputImage = new Mat();
        Imgproc.morphologyEx(inputImage, outputImage, Imgproc.MORPH_HITMISS, kernel);

        final int rate = 50;
        Mat ones = Mat.ones(3, 3, CvType.CV_16S);
        Mat kernelDisp = new Mat();
        Core.add(kernel, ones, kernelDisp);
        Core.multiply(kernelDisp, new Scalar(127), kernelDisp);
        kernelDisp.convertTo(kernelDisp, CvType.CV_8U);

        Imgproc.resize(kernelDisp, kernelDisp, new Size(), rate, rate, Imgproc.INTER_NEAREST);
        Imgproc.resize(inputImage, inputImage, new Size(), rate, rate, Imgproc.INTER_NEAREST);
        Imgproc.resize(outputImage, outputImage, new Size(), rate, rate, Imgproc.INTER_NEAREST);

        HighGui.imshow("kernel", kernelDisp);
        HighGui.imshow("Original", inputImage);
        HighGui.imshow("Hit or Miss", outputImage);
        HighGui.waitKey(0);
        System.exit(0);
    }
}

public class HitMissDemo {
    public static void main(String[] args) {
        // Load the native OpenCV library
        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);

        new HitMiss().run();
    }
}
```

----------------------------------------

TITLE: Loading Source Images in C++
DESCRIPTION: This C++ snippet demonstrates loading two source images (`src1`, `src2`) using `imread`. It includes basic error handling to check if the images were loaded successfully. These images will be used for alpha blending.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
//![load]
/// Read image ( same size, same type )
src1 = imread( samples::findFile("LinuxLogo.jpg") );
src2 = imread( samples::findFile("WindowsLogo.jpg") );

if( src1.empty() ) { cout << "Error loading src1" << endl; return EXIT_FAILURE; }
if( src2.empty() ) { cout << "Error loading src2" << endl; return EXIT_FAILURE; }
//![load]
```

----------------------------------------

TITLE: Creating and Displaying Image Window in C++
DESCRIPTION: Creates a named window titled "Pyramids Demo" and displays the initial source image within it using `namedWindow` and `imshow`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
    //![show_image]
    /// Create window
    namedWindow( window_name, WINDOW_AUTOSIZE );
    imshow( window_name, src );
    //![show_image]
```

----------------------------------------

TITLE: Find Contours in OpenCV C++
DESCRIPTION: This snippet finds image contours using OpenCV in C++. It outputs them to vectors for further processing. Dependencies include OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
std::vector<std::vector<cv::Point>> contours;
std::vector<cv::Vec4i> hierarchy;
cv::findContours(edges, contours, hierarchy, cv::RETR_TREE, cv::CHAIN_APPROX_SIMPLE);
```

----------------------------------------

TITLE: Highlighting Support Vectors in Non-Linear SVM Classification
DESCRIPTION: This snippet demonstrates how to obtain and highlight the support vectors in non-linear SVM classification using OpenCV. It uses the getSupportVectors method to identify support vectors and draws circles around them.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_14

LANGUAGE: C++
CODE:
```
Mat sv = svm->getSupportVectors();
for (int i = 0; i < sv.rows; ++i)
{
    const float* v = sv.ptr<float>(i);
    int x = (int)(v[0] * WIDTH);
    int y = (int)(v[1] * HEIGHT);
    circle(res, Point(x,y), 6, Scalar(128, 128, 128), 2);
}
```

LANGUAGE: Java
CODE:
```
Mat sv = svm.getSupportVectors();
for (int i = 0; i < sv.rows(); i++) {
    double[] v = sv.get(i, 0);
    int x = (int) (v[0] * WIDTH);
    int y = (int) (v[1] * HEIGHT);
    Imgproc.circle(res, new Point(x, y), 6, new Scalar(128, 128, 128), 2);
}
```

LANGUAGE: Python
CODE:
```
sv = svm.getSupportVectors()
for i in range(sv.shape[0]):
    x = int(sv[i,0]*WIDTH)
    y = int(sv[i,1]*HEIGHT)
    cv.circle(res, (x,y), 6, (128, 128, 128), 2)
```

----------------------------------------

TITLE: Example: Generating Windows Phone 8.1 x86 Project Files
DESCRIPTION: A sequence of shell commands demonstrating how to create a build directory (`bin`), navigate into it, and then run CMake to generate Visual Studio 2013 project files for Windows Phone 8.1 x86, assuming the source code is in the parent directory (`../`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_13

LANGUAGE: shell
CODE:
```
mkdir bin
```

LANGUAGE: shell
CODE:
```
cd bin
```

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013" -DCMAKE_SYSTEM_NAME=WindowsPhone -DCMAKE_SYSTEM_VERSION=8.1 ../
```

----------------------------------------

TITLE: Instantiating Pretrained PyTorch FCN ResNet-50 Model
DESCRIPTION: This Python code snippet initializes a pre-trained Fully Convolutional Network (FCN) model with a ResNet-50 backbone using the `torchvision.models.segmentation` module. Setting `pretrained=True` loads weights trained on a standard dataset (likely COCO or PASCAL VOC). The `original_model` variable will hold the PyTorch model object. Requires `torch` and `torchvision` libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
# initialize PyTorch FCN ResNet-50 model
original_model = models.segmentation.fcn_resnet50(pretrained=True)
```

----------------------------------------

TITLE: Configuring Android Manifest for DNN App - Android/XML
DESCRIPTION: This XML code snippet demonstrates how to configure the application's manifest to support the DNN object detection app. It sets up the necessary attributes in the <application> tag, such as the app label. Developers should extend this configuration by adding permissions (such as CAMERA) and activity declarations. This configuration is required to enable full screen, proper screen orientation, and camera usage for the application.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_dnn_intro.markdown#2025-04-22_snippet_0

LANGUAGE: xml
CODE:
```
<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\">\n\n    <application\n        android:label=\"@string/app_name\">
```

----------------------------------------

TITLE: Loading Images with OpenCV in Python
DESCRIPTION: This snippet demonstrates how to load an image using OpenCV in Python with cv2.imread. It checks if the image is None to handle errors. The primary parameter is the image path; the output is a NumPy ndarray. Requires OpenCV installed (cv2 module).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2\n\nsrc = cv2.imread('path_to_image', cv2.IMREAD_COLOR)\nif src is None:\n    print('Could not open or find the image!')\n    exit()\n
```

----------------------------------------

TITLE: Facial Landmarks Post-Processing to Generate Contours
DESCRIPTION: Custom operation that processes facial landmarks into contours for different face elements (eyes, mouth) and skin areas for selective image processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
// Landmark post-processing to extract facial feature contours
G_API_OP(landmarksToContours,
         <std::tuple<cv::GArray<std::vector<Contour>>,
                    cv::GArray<Contour>>
         (cv::GArray<cv::GMat>, cv::GArray<cv::Rect>)>,
         "custom.ld_postproc") {
    static std::tuple<cv::GArrayDesc, cv::GArrayDesc> outMeta(const cv::GArrayDesc&,
                                                              const cv::GArrayDesc&) {
        return std::make_tuple(cv::empty_array_desc(), cv::empty_array_desc());
    }
};

// Implementation of the landmarks post-processing kernel
STRUCT_KERNEL(GAPI_OCV_KERNEL, landmarksToContours, landmarksToContoursImpl) {
    static void run(const std::vector<cv::Mat>& in_landmarks,
                   const std::vector<cv::Rect>& in_ROIs,
                   std::vector<std::vector<Contour>>& out_element_contours,
                   std::vector<Contour>& out_face_contours) {
        // Process landmarks for every face in the frame
        out_element_contours.clear();
        out_face_contours.clear();

        GAPI_Assert(in_landmarks.size() == in_ROIs.size());

        for (std::size_t i = 0; i < in_landmarks.size(); i++) {
            auto& landmarks = in_landmarks[i];
            const auto& ROI = in_ROIs[i];

            // Basic landmarks validity check
            GAPI_Assert(landmarks.depth() == CV_32F);
            GAPI_Assert(landmarks.size[0] == 1);
            GAPI_Assert(landmarks.size[1] == 70);

            const float *ld_data = landmarks.ptr<float>();

            // Scale landmarks from normalized coordinates to the original ROI
            std::vector<cv::Point> cv_landmarks;
            for (int j = 0; j < 35; ++j) {
                int xy_index = j * 2;
                int x = static_cast<int>(ld_data[xy_index]   * ROI.width)  + ROI.x;
                int y = static_cast<int>(ld_data[xy_index+1] * ROI.height) + ROI.y;
                cv_landmarks.emplace_back(x, y);
            }

            // Now get contours out of the keypoints
            // --------------------------------------

            // The full list of landmarks is available at
            // https://github.com/opencv/open_model_zoo/blob/master/models/intel/facial-landmarks-35-adas-0002/description/facial-landmarks-35-adas-0002.md

            std::vector<Contour> all_elements;

            // Left eye
            // Left eye landmark indices: 0 = far left corner, 1 = far right corner
            Contour leye = getEyeContour({cv_landmarks[0], cv_landmarks[1]});
            all_elements.emplace_back(std::move(leye));

            // Right eye
            // Right eye landmark indices: 2 = far left corner, 3 = far right corner
            Contour reye = getEyeContour({cv_landmarks[2], cv_landmarks[3]});
            all_elements.emplace_back(std::move(reye));

            // Mouth (lips)
            // Outer lip landmark indices: 6, 7, 8, 9 (clockwise from bottom)
            Contour mouth;
            mouth.reserve(4);
            mouth.push_back(cv_landmarks[6]);
            mouth.push_back(cv_landmarks[9]);
            mouth.push_back(cv_landmarks[8]);
            mouth.push_back(cv_landmarks[7]);
            all_elements.emplace_back(std::move(mouth));

            // Create face contour
            // 10,11, ...., 19 are face contour landmarks (clockwise from left bottom corner)
            Contour face;
            for (int j = 19; j >= 10; --j) {
                face.push_back(cv_landmarks[j]);
            }

            // Join contour with line (forehead) - simply connect first and last points with a line
            face.push_back(cv_landmarks[10]);

            // Add to the lists
            out_element_contours.emplace_back(std::move(all_elements));
            out_face_contours.emplace_back(std::move(face));
        }
    }
};
```

----------------------------------------

TITLE: Process Contours and Draw Shapes in OpenCV C++
DESCRIPTION: Applies contour approximation and draws bounding rectangles and enclosing circles for each contour. Needs OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
for (size_t i = 0; i < contours.size(); i++) {
    cv::approxPolyDP(cv::Mat(contours[i]), contours_poly[i], 3, true);
    boundRect[i] = cv::boundingRect(cv::Mat(contours_poly[i]));
    cv::minEnclosingCircle(contours_poly[i], center[i], radius[i]);
}
```

----------------------------------------

TITLE: Finding and Drawing Epilines with OpenCV - Python
DESCRIPTION: Calculates epilines for points in one image and draws them on another image using OpenCV. This requires matched points, the fundamental matrix, and images to draw on, outputting images with epilines overlaid. Depends on previous computations of matched points and the fundamental matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
# Find epilines corresponding to points in right image (second image) and
# drawing its lines on left image
lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)
lines1 = lines1.reshape(-1,3)
img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)

# Find epilines corresponding to points in left image (first image) and
# drawing its lines on right image
lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)
lines2 = lines2.reshape(-1,3)
img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)

plt.subplot(121),plt.imshow(img5)
plt.subplot(122),plt.imshow(img3)
plt.show()
```

----------------------------------------

TITLE: Capturing Video Stream in C++
DESCRIPTION: Captures video stream from the default or a specified capturing device using OpenCV in C++. This is essential for processing live video data for thresholding operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>\nint main() {\n    cv::VideoCapture cap(0);\n    if(!cap.isOpened()) {\n        return -1;\n    }\n    // Further code\n}
```

----------------------------------------

TITLE: Initial Image Thresholding in OpenCV Python
DESCRIPTION: Reads an image and applies Otsu's binarization to create an initial threshold. Converts image to grayscale and uses binary inverse thresholding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_watershed/py_watershed.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('coins.png')
assert img is not None, "file could not be read, check with os.path.exists()"
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)
ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)
```

----------------------------------------

TITLE: Calculating Morphological Gradient with OpenCV Python
DESCRIPTION: Demonstrates how to calculate morphological gradient which shows the outline of objects by finding the difference between dilation and erosion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)
```

----------------------------------------

TITLE: Detecting Subpixel Corners using OpenCV in Python
DESCRIPTION: Python implementation of corner detection with subpixel accuracy using OpenCV's cornerSubPix function. The code demonstrates image loading, corner detection, and refinement of corner positions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/corner_subpixels/corner_subpixels.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

from math import sqrt

source_window = 'Image'
max_trackbar = 100
corner_count = 0

rng = np.random.default_rng()

def goodFeaturesToTrack_Demo(val):
    maxCorners = max(val, 1)

    # Parameters for Shi-Tomasi algorithm
    qualityLevel = 0.01
    minDistance = 10
    blockSize = 3
    gradientSize = 3
    useHarrisDetector = False
    k = 0.04

    # Copy the source image
    copy = np.copy(src)

    # Apply corner detection
    corners = cv.goodFeaturesToTrack(src_gray, maxCorners, qualityLevel, minDistance, None,
                                     blockSize=blockSize, gradientSize=gradientSize,
                                     useHarrisDetector=useHarrisDetector, k=k)

    print('Number of corners detected:', len(corners))
    # Draw corners detected
    radius = 4
    for i in range(corners.shape[0]):
        cv.circle(copy, (int(corners[i,0,0]), int(corners[i,0,1])), radius,
                  (rng.integers(0,256), rng.integers(0,256), rng.integers(0,256)), cv.FILLED)

    # Show what you got
    cv.namedWindow('Sharp corners')
    cv.imshow('Sharp corners', copy)

    # Set the needed parameters to find the refined corners
    winSize = (5, 5)
    zeroZone = (-1, -1)
    criteria = (cv.TERM_CRITERIA_EPS + cv.TermCriteria_COUNT, 40, 0.001)

    # Calculate the refined corner locations
    corners = cv.cornerSubPix(src_gray, corners, winSize, zeroZone, criteria)

    # Write them down
    for i in range(corners.shape[0]):
        print(" -- Refined Corner [", i, "]  (", corners[i,0,0], ",", corners[i,0,1], ")")

# Load source image and convert it to gray
src = cv.imread(cv.samples.findFile('pic3.png'))
if src is None:
    print('Could not open or find the image: ', args.input)
    exit(0)

src_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)

# Create a window and a trackbar
cv.namedWindow(source_window)
max_trackbar = 25
cv.createTrackbar('Max corners:', source_window, max_trackbar, max_trackbar, goodFeaturesToTrack_Demo)

cv.imshow(source_window, src)
goodFeaturesToTrack_Demo(max_trackbar)

cv.waitKey()

```

----------------------------------------

TITLE: Displaying Results with OpenCV imshow in C++
DESCRIPTION: This snippet shows how to display images (original and with detected lines) in separate windows using OpenCV in C++. It uses cv::imshow for display and cv::waitKey for event handling. Requires OpenCV GUI support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_18

LANGUAGE: C++
CODE:
```
imshow("Source", src);\nimshow("Detected Lines (in red) - Standard Hough Line Transform", cdst);\nimshow("Detected Lines (in green) - Probabilistic Line Transform", cdstP);\nwaitKey();\n
```

----------------------------------------

TITLE: K-Means Clustering with Two-Dimensional Data in OpenCV
DESCRIPTION: This code demonstrates K-means clustering on two-dimensional data (height and weight). It generates random 2D data points in two distinct groups, applies the clustering algorithm with 2 clusters, and visualizes the results with a scatter plot.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

X = np.random.randint(25,50,(25,2))
Y = np.random.randint(60,85,(25,2))
Z = np.vstack((X,Y))

# convert to np.float32
Z = np.float32(Z)

# define criteria and apply kmeans()
criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)
ret,label,center=cv.kmeans(Z,2,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)

# Now separate the data, Note the flatten()
A = Z[label.ravel()==0]
B = Z[label.ravel()==1]

# Plot the data
plt.scatter(A[:,0],A[:,1])
plt.scatter(B[:,0],B[:,1],c = 'r')
plt.scatter(center[:,0],center[:,1],s = 80,c = 'y', marker = 's')
plt.xlabel('Height'),plt.ylabel('Weight')
plt.show()
```

----------------------------------------

TITLE: Detecting Keypoints and Computing Descriptors in C++
DESCRIPTION: This code snippet detects keypoints and computes descriptors for each frame in the video sequence using the specified detector.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_tracking/akaze_tracking.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
(*detector)(frame, noArray(), kp, desc);
```

----------------------------------------

TITLE: Changing Image Type from 8UC1 to 32FC1 with OpenCV in Python
DESCRIPTION: Converts an 8-bit image ndarray to float32 dtype in Python by NumPy astype. Can be used with cv2.convertScaleAbs for scaling. Required for some numerical algorithms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_39

LANGUAGE: Python
CODE:
```
floatMat = img.astype(np.float32)
```

----------------------------------------

TITLE: Configuring Java Tutorials Compilation - CMake - CMake
DESCRIPTION: This CMake script automates the identification and compilation of Java tutorial directories within the OpenCV project. It requires ANT_EXECUTABLE and a compiled opencv_java target, uses CMake commands to traverse subdirectories for Java sources, and employs add_custom_target and add_custom_command to compile each detected tutorial directory with Apache Ant. Key parameters include the OpenCV source and binary directories, and it outputs compiled Java classes to a designated bin directory. The process is limited to environments with Ant and a properly configured opencv_java target, and is not intended for standalone use outside the build environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/java/tutorial_code/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
# ----------------------------------------------------------------------------\n#  CMake file for Java tutorials compilation.\n#\n# ----------------------------------------------------------------------------\nif(NOT ANT_EXECUTABLE OR NOT TARGET opencv_java)\n  return()\nendif()\n\nproject(compile_java_tutorials)\n\nset(curdir "${CMAKE_CURRENT_SOURCE_DIR}")\nset(opencv_tutorial_java_bin_dir "${CMAKE_CURRENT_BINARY_DIR}/.compiled")\nset(TUTORIALS_DIRS "")\n\nfile(GLOB children RELATIVE ${curdir} ${curdir}/*/*)\nforeach(child ${children})\n  if(IS_DIRECTORY ${curdir}/${child})\n    file(GLOB contains_java_files "${child}/*.java")\n    if(contains_java_files)\n      list(APPEND TUTORIALS_DIRS ${child})\n    endif()\n  endif()\nendforeach()\n\nadd_custom_target("${PROJECT_NAME}"\n                  DEPENDS opencv_java\n                 )\n\nforeach(TUTORIAL_DIR ${TUTORIALS_DIRS})\n  get_filename_component(TUTORIAL_NAME ${TUTORIAL_DIR} NAME_WE)\n  add_custom_command(TARGET "${PROJECT_NAME}"\n                     COMMAND ${ANT_EXECUTABLE} -q\n                          -DocvJarDir="${OpenCV_BINARY_DIR}/bin"\n                          -DsrcDir="${TUTORIAL_DIR}"\n                          -DdstDir="${opencv_tutorial_java_bin_dir}/${TUTORIAL_NAME}"\n                     WORKING_DIRECTORY "${curdir}"\n                     COMMENT "Compile the tutorial: ${TUTORIAL_NAME}"\n                    )\nendforeach()
```

----------------------------------------

TITLE: Updating Maven POM Version to Match OpenCV Core Version
DESCRIPTION: Complex Maven command that uses the versions plugin to automatically extract and set the version number across all project POMs to match the core OpenCV version. Used by maintainers to ensure version consistency.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/maven/README.md#2025-04-22_snippet_4

LANGUAGE: shell
CODE:
```
mvn versions:set -DnewVersion=$(. ./opencv/scripts/functions && cd ./opencv/scripts && extract_version && echo $REPLY)
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Logic in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm. It compares pixel values at different offsets around a central pixel to determine if it's a corner. The algorithm uses nested if-else statements to check various conditions based on pixel intensity comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_20

LANGUAGE: C++
CODE:
```
if(ptr[offset8] < c_b)
  if(ptr[offset10] < c_b)
    if(ptr[offset4] < c_b)
      goto is_a_corner;
    else
      if(ptr[offset11] < c_b)
        goto is_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        goto is_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;

// ... (additional nested if-else statements)
```

----------------------------------------

TITLE: Configuring OpenCV Applications and Documentation in CMake
DESCRIPTION: This snippet sets up and reports the status of OpenCV applications and documentation options. It uses custom CMake functions to build feature strings and display their status.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_18

LANGUAGE: CMake
CODE:
```
ocv_build_features_string(apps_status
  IF BUILD_TESTS AND HAVE_opencv_ts THEN "tests"
  IF BUILD_PERF_TESTS AND HAVE_opencv_ts THEN "perf_tests"
  IF BUILD_EXAMPLES THEN "examples"
  IF BUILD_opencv_apps THEN "apps"
  IF BUILD_ANDROID_SERVICE THEN "android_service"
  IF (BUILD_ANDROID_EXAMPLES OR INSTALL_ANDROID_EXAMPLES) AND CAN_BUILD_ANDROID_PROJECTS THEN "android_examples"
  ELSE "-")
status("    Applications:" "${apps_status}")
ocv_build_features_string(docs_status
    IF TARGET doxygen_cpp THEN "doxygen"
    IF TARGET doxygen_python THEN "python"
    IF TARGET doxygen_javadoc THEN "javadoc"
    IF BUILD_opencv_js OR DEFINED OPENCV_JS_LOCATION THEN "js"
    ELSE "NO"
)
status("    Documentation:" "${docs_status}")
status("    Non-free algorithms:" OPENCV_ENABLE_NONFREE THEN "YES" ELSE "NO")
```

----------------------------------------

TITLE: Template Matching Formula: TM_CCORR_NORMED (LaTeX)
DESCRIPTION: Mathematical formula for the Normalized Cross Correlation (TM_CCORR_NORMED) template matching method used in OpenCV's `matchTemplate` function. R(x,y) is the result, T is the template, and I is the image. Normalization provides robustness against illumination and contrast changes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_4

LANGUAGE: latex
CODE:
```
\f[R(x,y)= \frac{\sum_{x',y'} (T(x',y') \cdot I(x+x',y+y'))}{\sqrt{\sum_{x',y'}T(x',y')^2 \cdot \sum_{x',y'} I(x+x',y+y')^2}}\f]
```

----------------------------------------

TITLE: Escape Time Algorithm for Mandelbrot Set - Pseudocode
DESCRIPTION: This pseudocode describes the core logic for generating the Mandelbrot fractal using the escape time algorithm, iterating each pixel over the complex plane and determining pixel coloring based on iteration counts. Inputs are image pixel indices, outputs are color-mapped pixel values; not an executable routine but a step-by-step reference for real implementations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_7

LANGUAGE: Pseudocode
CODE:
```
For each pixel (Px, Py) on the screen, do:
{
  x0 = scaled x coordinate of pixel (scaled to lie in the Mandelbrot X scale (-2, 1))
  y0 = scaled y coordinate of pixel (scaled to lie in the Mandelbrot Y scale (-1, 1))
  x = 0.0
  y = 0.0
  iteration = 0
  max_iteration = 1000
  while (x*x + y*y < 2*2  AND  iteration < max_iteration) {
    xtemp = x*x - y*y + x0
    y = 2*x*y + y0
    x = xtemp
    iteration = iteration + 1
  }
  color = palette[iteration]
  plot(Px, Py, color)
}

```

----------------------------------------

TITLE: Creating and Displaying Image Window in Java
DESCRIPTION: Creates a named window titled "Pyramids Demo" and shows the source image in it using `HighGui.namedWindow` and `HighGui.imshow`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_4

LANGUAGE: java
CODE:
```
        //![show_image]
        // Create window
        HighGui.namedWindow( window_name, HighGui.WINDOW_AUTOSIZE );
        HighGui.imshow( window_name, src );
        //![show_image]
```

----------------------------------------

TITLE: Verifying Dependency Configuration in OpenCV (CMake)
DESCRIPTION: When this CMake option is enabled, the configuration process verifies that all required dependencies (specified with WITH_*) are present and active. If dependencies are missing, configuration fails rather than silently disabling features. Useful for packaging systems requiring consistent library dependencies.
Activate with -DENABLE_CONFIG_VERIFICATION=ON.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_27

LANGUAGE: cmake
CODE:
```
ENABLE_CONFIG_VERIFICATION
```

----------------------------------------

TITLE: Calculating Object Orientation via PCA in Java using OpenCV
DESCRIPTION: Defines a `getOrientation` method that computes the orientation of a shape represented by a `MatOfPoint` (contour). It converts the points to a `Mat` of type `CV_64F`, applies PCA using `Core.PCACompute`, retrieves the mean, eigenvectors, and eigenvalues, and then visualizes the principal axes. Depends on OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_7

LANGUAGE: java
CODE:
```
//! [pca]
// Perform PCA analysis
private static double getOrientation(MatOfPoint pts, Mat img) {
    //Construct a buffer used by the PCA analysis
    int sz = (int) pts.total();
    Mat dataPts = new Mat(sz, 2, CvType.CV_64F);

    double[] dataPtsData = new double[(int) (dataPts.total()*dataPts.channels())];
    Point[] points = pts.toArray();
    for (int i = 0; i < dataPts.rows(); i++) {
        dataPtsData[i*dataPts.cols()] = points[i].x;
        dataPtsData[i*dataPts.cols()+1] = points[i].y;
    }
    dataPts.put(0, 0, dataPtsData);

    //Perform PCA analysis
    Mat mean = new Mat();
    Mat eigenvectors = new Mat();
    Mat eigenvalues = new Mat();
    Core.PCACompute2(dataPts, mean, eigenvectors, eigenvalues); // note: eigenvalues are sorted in descending order

    //Store the center of the object
    double[] meanData = new double[(int) (mean.total()*mean.channels())];
    mean.get(0, 0, meanData);
    Point cntr = new Point(meanData[0], meanData[1]);

    //Store the eigenvalues and eigenvectors
    double[] B = new double[(int) (eigenvectors.total()*eigenvectors.channels())];
    eigenvectors.get(0, 0, B);
    double[] C = new double[(int) (eigenvalues.total()*eigenvalues.channels())];
    eigenvalues.get(0, 0, C);
    Point[] eigen_vecs = new Point[2];
    eigen_vecs[0] = new Point(B[0],B[1]);
    eigen_vecs[1] = new Point(B[2],B[3]);

    double[] eigen_val = new double[2];
    eigen_val[0] = C[0];
    eigen_val[1] = C[1];

    // Draw the principal components
    circle(img, cntr, 3, new Scalar(255, 0, 255), 2);
    Point p1 = new Point(cntr.x + 0.02 * eigen_vecs[0].x * eigen_val[0], cntr.y + 0.02 * eigen_vecs[0].y * eigen_val[0]);
    Point p2 = new Point(cntr.x - 0.02 * eigen_vecs[1].x * eigen_val[1], cntr.y - 0.02 * eigen_vecs[1].y * eigen_val[1]);
    drawAxis(img, cntr, p1, new Scalar(0, 255, 0), 1);
    drawAxis(img, cntr, p2, new Scalar(255, 255, 0), 5);

    double angle = atan2(eigen_vecs[0].y, eigen_vecs[0].x); // orientation in radians

    return angle;
}
//! [pca]
```

----------------------------------------

TITLE: Aggregating Headers, Sources, and Dependencies for OpenCV World (CMake)
DESCRIPTION: Initializes empty lists `headers_list`, `sources_list`, and `link_deps`. It then iterates through the dependencies of the `world` module (`OPENCV_MODULE_${the_module}_DEPS`, where `the_module` is 'world') and the `opencv_world` module itself. For each dependency `m` that is designated as part of the world (`OPENCV_MODULE_${m}_IS_PART_OF_WORLD`), its headers (`OPENCV_MODULE_${m}_HEADERS`) and sources (`OPENCV_MODULE_${m}_SOURCES`) are appended to the respective lists. Non-empty link dependencies (`OPENCV_MODULE_${m}_LINK_DEPS`) are also collected into the `link_deps` list.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
set(headers_list)
set(sources_list)
set(link_deps "")
foreach(m ${OPENCV_MODULE_${the_module}_DEPS} opencv_world)
  if(OPENCV_MODULE_${m}_IS_PART_OF_WORLD)
    list(APPEND headers_list ${OPENCV_MODULE_${m}_HEADERS})
    list(APPEND sources_list ${OPENCV_MODULE_${m}_SOURCES})
  endif()
  if(NOT " ${OPENCV_MODULE_${m}_LINK_DEPS}" STREQUAL " ")
    list(APPEND link_deps ${OPENCV_MODULE_${m}_LINK_DEPS})
  endif()
endforeach()
```

----------------------------------------

TITLE: Creating Images in Java
DESCRIPTION: Initializing blank images for drawing shapes in OpenCV Java. Creates two black images for drawing an atom and a rook chess piece.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_7

LANGUAGE: java
CODE:
```
// Windows names
String atom_window = "Drawing 1: Atom";
String rook_window = "Drawing 2: Rook";

// Create empty black images
Mat atom_image = Mat.zeros(w, w, CvType.CV_8UC3);
Mat rook_image = Mat.zeros(w, w, CvType.CV_8UC3);
```

----------------------------------------

TITLE: Running the OpenCV.js Face Detection Example in Node.js
DESCRIPTION: Command-line instruction to execute the face detection Node.js script. The command runs the JavaScript file that processes the image and generates an output file with detected faces and eyes highlighted.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_nodejs/js_nodejs.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
node exampleNodeCanvasData.js
```

----------------------------------------

TITLE: Drawing Epilines with Custom Function - Python
DESCRIPTION: Defines a custom function `drawlines` to draw epilines corresponding to points in an image on the other image. Inputs are two images, epilines, and matching points, outputs are images with drawn lines and points. Requires OpenCV and NumPy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
def drawlines(img1,img2,lines,pts1,pts2):
    ''' img1 - image on which we draw the epilines for the points in img2
        lines - corresponding epilines '''
    r,c = img1.shape
    img1 = cv.cvtColor(img1,cv.COLOR_GRAY2BGR)
    img2 = cv.cvtColor(img2,cv.COLOR_GRAY2BGR)
    for r,pt1,pt2 in zip(lines,pts1,pts2):
        color = tuple(np.random.randint(0,255,3).tolist())
        x0,y0 = map(int, [0, -r[2]/r[1] ])
        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])
        img1 = cv.line(img1, (x0,y0), (x1,y1), color,1)
        img1 = cv.circle(img1,tuple(pt1),5,color,-1)
        img2 = cv.circle(img2,tuple(pt2),5,color,-1)
    return img1,img2
```

----------------------------------------

TITLE: Implementing FAST Corner Detection in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm implementation. It performs pixel comparisons against thresholds to determine if a point is a corner. The algorithm uses a decision tree structure with multiple nested conditions to efficiently classify points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
goto homogeneous;
                        else
                          goto homogeneous;
                    else
                      if(ptr[offset7] < c_b)
                        if(ptr[offset3] < c_b)
                          if(ptr[offset5] < c_b)
                            if(ptr[offset1] < c_b)
                              goto success_structured;
                            else
                              if(ptr[offset4] < c_b)
                                if(ptr[offset6] < c_b)
                                  goto success_structured;
                                else
                                  goto structured;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset1] < c_b)
                              goto success_homogeneous;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset6] < c_b)
                            if(ptr[offset5] < c_b)
                              if(ptr[offset1] < c_b)
                                goto success_structured;
                              else
                                if(ptr[offset4] < c_b)
                                  goto success_structured;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset1] < c_b)
                                goto success_homogeneous;
                              else
                                goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        if(ptr[offset3] < c_b)
                          if(ptr[offset5] < c_b)
                            if(ptr[offset1] < c_b)
                              if(ptr[offset4] < c_b)
                                goto success_structured;
                              else
                                goto homogeneous;
                            else
                              if(ptr[offset4] < c_b)
                                if(ptr[offset6] < c_b)
                                  goto success_structured;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset1] < c_b)
                              if(ptr[offset4] < c_b)
                                goto success_homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          goto homogeneous;
                  else
                    if(ptr[offset5] > cb)
                      if(ptr[offset3] > cb)
                        if(ptr[offset2] > cb)
                          if(ptr[offset1] > cb)
                            if(ptr[offset4] > cb)
                              goto success_structured;
                            else
                              goto homogeneous;
                          else
                            if(ptr[offset4] > cb)
                              if(ptr[offset6] > cb)
                                goto success_structured;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset7] > cb)
                            if(ptr[offset4] > cb)
                              if(ptr[offset6] > cb)
                                goto success_structured;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        goto homogeneous;
                    else
                      if(ptr[offset5] < c_b)
                        if(ptr[offset7] < c_b)
                          if(ptr[offset6] < c_b)
                            if(ptr[offset1] < c_b)
                              goto success_homogeneous;
                            else
                              if(ptr[offset4] < c_b)
                                goto success_homogeneous;
                              else
                                goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        goto homogeneous;
                else
                  if(ptr[offset3] > cb)
                    if(ptr[offset5] > cb)
                      if(ptr[offset2] > cb)
                        if(ptr[offset1] > cb)
                          if(ptr[offset4] > cb)
                            goto success_homogeneous;
                          else
                            goto homogeneous;
                        else
                          if(ptr[offset4] > cb)
                            if(ptr[offset6] > cb)
                              goto success_homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        if(ptr[offset7] > cb)
                          if(ptr[offset4] > cb)
                            if(ptr[offset6] > cb)
                              goto success_homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                    else
                      goto homogeneous;
                  else
                    if(ptr[offset3] < c_b)
                      if(ptr[offset5] < c_b)
                        if(ptr[offset2] < c_b)
                          if(ptr[offset1] < c_b)
                            if(ptr[offset4] < c_b)
                              goto success_homogeneous;
                            else
                              goto homogeneous;
                          else
                            if(ptr[offset4] < c_b)
                              if(ptr[offset6] < c_b)
                                goto success_homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset7] < c_b)
                            if(ptr[offset4] < c_b)
                              if(ptr[offset6] < c_b)
                                goto success_homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        goto homogeneous;
                    else
                      goto homogeneous;
            }
          }
          structured:
          {
            x++;
            if(x > xsizeB)
                break;
            else
            {
                const unsigned char* const ptr = img.ptr() + y*width + x;
                const int cb = *ptr + threshold;
                const int c_b = *ptr - threshold;
                if(ptr[offset0] > cb)
                  if(ptr[offset2] > cb)
                    if(ptr[offset3] > cb)
                      if(ptr[offset5] > cb)
                        if(ptr[offset7] > cb)
                          if(ptr[offset1] > cb)
                            goto success_structured;
                          else
                            if(ptr[offset4] > cb)
                              if(ptr[offset6] > cb)
                                goto success_structured;
                              else
                                goto structured;
                            else
                              goto structured;
                        else
                          if(ptr[offset1] > cb)
                            if(ptr[offset4] > cb)
                              goto success_structured;
                            else
                              goto structured;
                          else
                            if(ptr[offset4] > cb)
                              if(ptr[offset6] > cb)
                                goto success_structured;
                              else
                                goto structured;
                            else
                              goto structured;
                      else
                        if(ptr[offset7] > cb)
                          if(ptr[offset1] > cb)
                            goto success_structured;
                          else
                            goto structured;
                        else
                          if(ptr[offset1] > cb)
                            if(ptr[offset4] > cb)
                              goto success_structured;
                            else
                              goto structured;
                          else
                            goto structured;
                    else
                      if(ptr[offset7] > cb)
                        if(ptr[offset6] > cb)
                          if(ptr[offset5] > cb)
                            if(ptr[offset1] > cb)
```

----------------------------------------

TITLE: OpenCV YAML Output Format Example
DESCRIPTION: Example of the YAML output format produced by OpenCV's file writing operations, showing how various data types are serialized.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_23

LANGUAGE: yaml
CODE:
```
%YAML:1.0
iterationNr: 100
strings:
   - "image1.jpg"
   - Awesomeness
   - "baboon.jpg"
Mapping:
   One: 1
   Two: 2
R: !!opencv-matrix
   rows: 3
   cols: 3
   dt: u
   data: [ 1, 0, 0, 0, 1, 0, 0, 0, 1 ]
T: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [ 0., 0., 0. ]
MyData:
   A: 97
   X: 3.1415926535897931e+000
   id: mydata1234
```

----------------------------------------

TITLE: Defining Basic Pixel Type Enumerations in OpenCV (C++)
DESCRIPTION: Defines a C++ enumeration listing the fixed, primitive data types supported for array elements in OpenCV. Each enumerator (e.g., CV_8U, CV_16S, CV_32F) corresponds to a specific data type like 8-bit unsigned integer, 16-bit signed integer, or 32-bit float, respectively. These constants are fundamental for specifying the data layout of cv::Mat objects and other array types.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
    enum { CV_8U=0, CV_8S=1, CV_16U=2, CV_16S=3, CV_32S=4, CV_32F=5, CV_64F=6 };
```

----------------------------------------

TITLE: Implementing Hit-or-Miss Transform in C++ using OpenCV
DESCRIPTION: This code demonstrates how to apply the Hit-or-Miss transform to find specific patterns in a binary image using OpenCV's morphologyEx() function with MORPH_HITMISS operation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/hitOrMiss/hitOrMiss.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include "opencv2/imgproc.hpp"
#include "opencv2/highgui.hpp"
#include <iostream>

using namespace cv;
using namespace std;

int main( void )
{
    // Create an image
    Mat input_image = (Mat_<uchar>(8, 8) <<
        0, 0, 0, 0, 0, 0, 0, 0,
        0, 255, 255, 255, 0, 0, 0, 255,
        0, 255, 255, 255, 0, 0, 0, 0,
        0, 255, 255, 255, 0, 255, 0, 0,
        0, 0, 255, 0, 0, 0, 0, 0,
        0, 0, 255, 0, 0, 255, 255, 0,
        0, 255, 0, 255, 0, 0, 255, 0,
        0, 255, 255, 255, 0, 0, 0, 0);

    Mat kernel = (Mat_<int>(3, 3) <<
        0, 1, 0,
        1, -1, 1,
        0, 1, 0);

    Mat output_image;
    morphologyEx(input_image, output_image, MORPH_HITMISS, kernel);

    const int rate = 50;
    kernel = (kernel + 1) * 127;
    kernel.convertTo(kernel, CV_8U);

    resize(kernel, kernel, Size(), rate, rate, INTER_NEAREST);
    resize(input_image, input_image, Size(), rate, rate, INTER_NEAREST);
    resize(output_image, output_image, Size(), rate, rate, INTER_NEAREST);

    imshow("kernel", kernel);
    imshow("Original", input_image);
    imshow("Hit or Miss", output_image);

    waitKey(0);
    return 0;
}
```

----------------------------------------

TITLE: Implementing Meanshift Object Tracking in Java
DESCRIPTION: Java implementation of the Meanshift algorithm using OpenCV. This code processes video frames, converts them to HSV color space, performs histogram calculations, backprojection, and applies the meanshift algorithm to track objects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/meanshift.markdown#2025-04-22_snippet_2

LANGUAGE: Java
CODE:
```
import java.util.List;\nimport javax.swing.*;\n\nimport org.opencv.core.*;\nimport org.opencv.highgui.*;\nimport org.opencv.imgproc.Imgproc;\nimport org.opencv.video.Video;\nimport org.opencv.videoio.VideoCapture;\nimport org.opencv.videoio.Videoio;\n\nclass MeanshiftDemo {\n    public void run(String[] args) {\n        String filename = args.length > 0 ? args[0] : \"../data/slow_traffic_small.mp4\";\n\n        VideoCapture capture = new VideoCapture(filename);\n        if (!capture.isOpened()) {\n            System.out.println(\"Could not initialize capturing...\\n\");\n            System.exit(0);\n        }\n\n        Mat frame = new Mat();\n        capture.read(frame);\n\n        if (frame.empty()) {\n            System.out.println(\"No captured frame -- Break!\");\n            System.exit(0);\n        }\n\n        // setup initial location of window\n        Rect trackWindow = new Rect(300, 200, 100, 50);\n\n        // set up the ROI for tracking\n        Mat roi = frame.submat(trackWindow);\n        Mat hsvRoi = new Mat();\n        Imgproc.cvtColor(roi, hsvRoi, Imgproc.COLOR_BGR2HSV);\n\n        Mat mask = new Mat();\n        Core.inRange(hsvRoi, new Scalar(0, 60, 32), new Scalar(180, 255, 255), mask);\n\n        Mat roiHist = new Mat();\n        int[] channels = {0};\n        int[] histSize = {180};\n        float[] ranges = {0, 180};\n        float[][] histRanges = {ranges};\n\n        Imgproc.calcHist(List.of(hsvRoi), new MatOfInt(channels), mask, roiHist, new MatOfInt(histSize), new MatOfFloat(ranges));\n        Core.normalize(roiHist, roiHist, 0, 255, Core.NORM_MINMAX);\n\n        // Setup the termination criteria, either 10 iteration or move by at least 1 pt\n        TermCriteria termCrit = new TermCriteria(TermCriteria.EPS | TermCriteria.COUNT, 10, 1);\n\n        JFrame jframe = new JFrame(\"Meanshift Demo\");\n        jframe.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n        JLabel vidPanel = new JLabel();\n        jframe.setContentPane(vidPanel);\n        jframe.setSize(frame.cols(), frame.rows());\n        jframe.setVisible(true);\n\n        Mat hsv = new Mat();\n        Mat backProject = new Mat();\n        while (true) {\n            capture.read(frame);\n            if (frame.empty()) {\n                break;\n            }\n\n            Imgproc.cvtColor(frame, hsv, Imgproc.COLOR_BGR2HSV);\n            Imgproc.calcBackProject(List.of(hsv), new MatOfInt(channels), roiHist, backProject, new MatOfFloat(histRanges), 1);\n\n            // apply meanshift to get the new location\n            Video.meanShift(backProject, trackWindow, termCrit, trackWindow);\n\n            // Draw it on image\n            Imgproc.rectangle(frame, trackWindow, new Scalar(255, 0, 0), 2);\n\n            ImageIcon image = new ImageIcon(Mat2BufferedImage.getImage(frame));\n            vidPanel.setIcon(image);\n            vidPanel.repaint();\n        }\n        System.out.println(\"Video processing done!\\n\");\n    }\n\n    public static void main(String[] args) {\n        // Load the native OpenCV library\n        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);\n        new MeanshiftDemo().run(args);\n    }\n}
```

----------------------------------------

TITLE: Extracting 3D Model Points and Descriptors in C++
DESCRIPTION: Retrieves 3D coordinates and descriptors from a model assumed to be part of a 3D recognition or pose estimation process. Typically used in applications like augmented reality or 3D reconstruction.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
// Get the MODEL INFO

std::vector<cv::Point3f> list_points3d_model = model.get_points3d();  // list with model 3D coordinates
cv::Mat descriptors_model = model.get_descriptors();                  // list with descriptors of each 3D coordinate
```

----------------------------------------

TITLE: Running G-API Streaming Pipeline
DESCRIPTION: Shows the main pipeline execution loop that pulls processed frames from the streaming pipeline. Handles both headless and GUI modes with blocking and non-blocking pull operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
cv::TickMeter tm;
tm.start();
pipeline.setSource(cv::gin(cap));
pipeline.start();
size_t frames = 0;
cv::Mat out;
std::vector<cv::Rect> faces;
std::vector<cv::Str> age_strings, emo_strings;

while (true) {
    if (cmd.get<bool>("pure")) {
        if (!pipeline.pull(cv::gout(out, faces, age_strings, emo_strings))) {
            break;
        }
        frames++;
    } else {
        if (!pipeline.try_pull(cv::gout(out, faces, age_strings, emo_strings))) {
            // Use this time to show the latest frame
            cv::imshow("Out", out);
            const int key = cv::waitKey(1);
            if (key == 27) break;
            continue;
        }
        frames++;
        cv::imshow("Out", out);
        const int key = cv::waitKey(1);
        if (key == 27) break;
    }
}
tm.stop();
```

----------------------------------------

TITLE: Including Sample Utilities for OpenCV Build in CMake
DESCRIPTION: Includes the `samples_utils.cmake` file located in the same directory as the current `CMakeLists.txt`. This script likely contains helper functions and macros specific to building and installing OpenCV samples when built alongside the main library. This is executed only when building as part of OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
include("${CMAKE_CURRENT_LIST_DIR}/samples_utils.cmake")
```

----------------------------------------

TITLE: Edge Tapering Function in C++
DESCRIPTION: Applies edge tapering to an image to mitigate the ringing effect post-restoration. This step is crucial for enhancing visual quality after employing the Wiener filter.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/motion_deblur_filter/motion_deblur_filter.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
@snippet samples/cpp/tutorial_code/ImgProc/motion_deblur_filter/motion_deblur_filter.cpp edgetaper
```

----------------------------------------

TITLE: Implementing Gamma Correction with Look-Up Table in Python using OpenCV
DESCRIPTION: This Python code snippet applies gamma correction using OpenCV and NumPy. A look-up table (`look_up_table`), implemented as a NumPy array, is created by applying the gamma formula (O = ((I/255)^gamma) * 255) to all possible pixel values (0-255). The `cv.LUT` function then utilizes this table to efficiently transform the input image (`img_original`), producing the gamma-corrected image (`gamma_corrected`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
# [changing-contrast-brightness-gamma-correction]
    ## [changing-contrast-brightness-gamma-correction]
    look_up_table = np.empty((1,256), np.uint8)
    for i in range(256):
        look_up_table[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)

    gamma_corrected = cv.LUT(img_original, look_up_table)
    ## [changing-contrast-brightness-gamma-correction]
```

----------------------------------------

TITLE: Configuring OpenCV CMake Build for NVIDIA Jetson TK1
DESCRIPTION: CMake configuration options for building OpenCV with CUDA support on the NVIDIA Jetson TK1 platform. Uses CUDA 6.5 and enables ARM NEON optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DCMAKE_CXX_FLAGS=-Wa,-mimplicit-it=thumb \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_python2=ON \
    -DBUILD_opencv_python3=OFF \
    -DENABLE_NEON=ON \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-6.5 \
    -DCUDA_ARCH_BIN=3.2 \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=OFF \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Upsampling Image using pyrUp in Python
DESCRIPTION: Upsamples the input image `tmp` using `cv.pyrUp`. The output image `dst` will be twice the dimensions of the input. The destination size is inferred by the function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_11

LANGUAGE: python
CODE:
```
        elif c == ord('i'):
            dst = cv.pyrUp(tmp)
            print ('** Zoom In: Image x 2')
```

----------------------------------------

TITLE: Converting UIImage to cv::Mat in Objective-C
DESCRIPTION: This code snippet demonstrates how to convert a UIImage to an OpenCV Mat object. It handles both color and grayscale images, creating a CV_8UC4 or CV_8UC1 Mat respectively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/image_manipulation/image_manipulation.markdown#2025-04-22_snippet_0

LANGUAGE: Objective-C
CODE:
```
- (cv::Mat)cvMatFromUIImage:(UIImage *)image
{
  CGColorSpaceRef colorSpace = CGImageGetColorSpace(image.CGImage);
  CGFloat cols = image.size.width;
  CGFloat rows = image.size.height;

  cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels (color channels + alpha)

  CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to  data
                                                 cols,                       // Width of bitmap
                                                 rows,                       // Height of bitmap
                                                 8,                          // Bits per component
                                                 cvMat.step[0],              // Bytes per row
                                                 colorSpace,                 // Colorspace
                                                 kCGImageAlphaNoneSkipLast |
                                                 kCGBitmapByteOrderDefault); // Bitmap info flags

  CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), image.CGImage);
  CGContextRelease(contextRef);

  return cvMat;
}
```

LANGUAGE: Objective-C
CODE:
```
- (cv::Mat)cvMatGrayFromUIImage:(UIImage *)image
{
  CGColorSpaceRef colorSpace = CGImageGetColorSpace(image.CGImage);
  CGFloat cols = image.size.width;
  CGFloat rows = image.size.height;

  cv::Mat cvMat(rows, cols, CV_8UC1); // 8 bits per component, 1 channels

  CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to data
                                                 cols,                       // Width of bitmap
                                                 rows,                       // Height of bitmap
                                                 8,                          // Bits per component
                                                 cvMat.step[0],              // Bytes per row
                                                 colorSpace,                 // Colorspace
                                                 kCGImageAlphaNoneSkipLast |
                                                 kCGBitmapByteOrderDefault); // Bitmap info flags

  CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), image.CGImage);
  CGContextRelease(contextRef);

  return cvMat;
 }
```

----------------------------------------

TITLE: Loading Images and Exposure Times for HDR Processing in OpenCV
DESCRIPTION: This code snippet demonstrates how to load a sequence of exposure images and their corresponding exposure times from a specified directory. The exposure data is read from a 'list.txt' file that contains the filename and inverse exposure time for each image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/hdr_imaging.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
vector<Mat> images;
vector<float> times;
loadExposureSeq(samples::findFile(path), images, times);
```

LANGUAGE: java
CODE:
```
List<Mat> images = new ArrayList<>();
List<Float> times = new ArrayList<>();
loadExposureSeq(path, images, times);
```

LANGUAGE: python
CODE:
```
images = []
times = []
load_exposure_seq(path, images, times)
```

----------------------------------------

TITLE: VideoIO Plugins Configuration Options in OpenCV
DESCRIPTION: Defines options to control the plugin mechanism for video I/O backends in OpenCV 4.1.0+, allowing certain backends to be built as plugins rather than direct dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_16

LANGUAGE: markdown
CODE:
```
| Option | Default | Description |
| --------| ------ | ------- |
| `VIDEOIO_ENABLE_PLUGINS` | _ON_ | Enable or disable plugins completely. |
| `VIDEOIO_PLUGIN_LIST` | _empty_ | Comma- or semicolon-separated list of backend names to be compiled as plugins. Supported names are _ffmpeg_, _gstreamer_, _msmf_, _mfx_ and _all_. |
```

----------------------------------------

TITLE: Matching Descriptors with BruteForceMatcher in OpenCV C++
DESCRIPTION: Uses BruteForceMatcher to find the closest matches between descriptors from the first image to the second image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/detection_of_planar_objects/detection_of_planar_objects.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
// matching descriptors
BruteForceMatcher<L2<float> > matcher;
vector<DMatch> matches;
matcher.match(descriptors1, descriptors2, matches);
```

----------------------------------------

TITLE: Splitting Image into BGR Planes in Python
DESCRIPTION: Python snippet using OpenCV's `cv.split` function to separate a 3-channel source image (assumed to be in BGR format) into three individual single-channel NumPy arrays (representing the B, G, and R planes). The input is the source image array, and the output is a tuple/list of plane arrays.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Separate the image in 3 places ( B, G and R )
```

----------------------------------------

TITLE: Drawing an Ellipse in Python
DESCRIPTION: Implementation of the MyEllipse function that draws a rotated ellipse in OpenCV Python. The function takes the image and angle, and uses the ellipse() function to draw the shape with specified center, axes, and color.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_20

LANGUAGE: python
CODE:
```
def MyEllipse(img, angle):
    thickness = 2
    lineType = 8

    cv.ellipse(img,
                (w//2, w//2),
                (w//4, w//16),
                angle,
                0,
                360,
                (255, 0, 0),
                thickness,
                lineType)
```

----------------------------------------

TITLE: Training SVM Model with Non-Linearly Separable Data (C++)
DESCRIPTION: Trains the Support Vector Machine using the previously prepared training data that contains both linearly separable and non-linearly separable examples. The high iteration count accommodates the complexity of finding decision boundaries for overlapping classes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
// Train the SVM
printf("\nTraining the SVM...");
svm->train(completeTrainData, ROW_SAMPLE, completeTrainLabels);
printf("Finished training\n");
```

----------------------------------------

TITLE: Creating and Displaying Image Window in Python
DESCRIPTION: Establishes a named window called "Pyramids Demo" using `cv.namedWindow` and displays the loaded source image using `cv.imshow`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
    #![show_image]
    # Create window
    cv.namedWindow(window_name, cv.WINDOW_AUTOSIZE)
    cv.imshow(window_name, src)
    #![show_image]
```

----------------------------------------

TITLE: Calculating Image Histogram Demo in Java (Full Code)
DESCRIPTION: Complete Java program demonstrating how to load an image, split it into B, G, R channels, calculate the histogram for each channel using `HighGui.imshow`, `Imgproc.calcHist`, `Core.split`, `Core.normalize`, and display the histograms in a window. Depends on the OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
@include samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java
```

----------------------------------------

TITLE: Setting OpenCV DNN Sample Dependencies
DESCRIPTION: Defines and checks required OpenCV module dependencies for DNN samples including core, imgproc, dnn, objdetect, video, imgcodecs, videoio, and highgui modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
set(OPENCV_DNN_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_dnn
  opencv_objdetect
  opencv_video
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui)
ocv_check_dependencies(${OPENCV_DNN_SAMPLES_REQUIRED_DEPS})
```

----------------------------------------

TITLE: Setting Up Parallel Backend Configuration
DESCRIPTION: Configures parallel processing backend options with conditional logic for different platforms like Emscripten, iOS, and WinRT.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
set(PARALLEL_ENABLE_PLUGINS_DEFAULT ON)
if(EMSCRIPTEN OR IOS OR XROS OR WINRT)
  set(PARALLEL_ENABLE_PLUGINS_DEFAULT OFF)
endif()
set(PARALLEL_ENABLE_PLUGINS "${PARALLEL_ENABLE_PLUGINS_DEFAULT}" CACHE BOOL "Allow building parallel plugin support")
```

----------------------------------------

TITLE: Constructing Point Structures in OpenCV.js (JavaScript)
DESCRIPTION: Demonstrates two equivalent ways to create a Point structure using OpenCV.js: via the cv.Point constructor and via a plain object literal with x and y properties. This approach provides developers with flexibility depending on their coding style. Required dependencies include OpenCV.js and initialized numeric values for x and y, representing the point's coordinates.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
// The first way
let point = new cv.Point(x, y);
// The second way
let point = {x: x, y: y};
```

----------------------------------------

TITLE: Computing Transformed Corner Coordinates with OpenCV - Java
DESCRIPTION: The Java snippet uses Core.perspectiveTransform to compute new corner positions for the chessboard based on homography. Inputs are MatOfPoint2f and the 3x3 transformation matrix. Output is a set of points in the new perspective, suitable for visualization or accuracy checking.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_19

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/features2D/Homography/PerspectiveCorrection.java compute-transformed-corners
```

----------------------------------------

TITLE: Warping Image with OpenCV warpPerspective - C++
DESCRIPTION: This C++ snippet uses OpenCV’s cv::warpPerspective to apply the estimated homography and transform the source chessboard view to match the desired perspective. Requires the homography matrix, input image, and destination size. Produces a warped image with corrected perspective. Input/output are Mat.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_14

LANGUAGE: cpp
CODE:
```
@snippet perspective_correction.cpp warp-chessboard
```

----------------------------------------

TITLE: Calculating Contour Equivalent Diameter in OpenCV Python
DESCRIPTION: This snippet computes the equivalent diameter of a contour. This is the diameter of a circle that has the same area as the contour. It calculates the area using `cv.contourArea` and then applies the formula sqrt(4 * area / pi) using NumPy's `np.sqrt` function. Requires an existing contour variable `cnt` and the NumPy library imported as `np`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
area = cv.contourArea(cnt)
equi_diameter = np.sqrt(4*area/np.pi)
```

----------------------------------------

TITLE: Mask Operations with Vector Registers in C++
DESCRIPTION: Illustrates mask operations including v_check_all(), v_check_any(), and v_select() for conditional operations on vector registers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
v_uint8 a;                           // {a1, .., an}
v_uint8 b;                           // {b1, ..., bn}

v_int32x4 mask:                      // {0xff, 0, 0, 0xff, ..., 0xff, 0}

v_uint8 Res = v_select(mask, a, b)   // {a1, b2, b3, a4, ..., an-1, bn}

/*
    "Res" will contain the value from "a" if mask is true (all bits set to 1),
    and value from "b" if mask is false (all bits set to 0)

    We can use comparison operators to generate mask and v_select to obtain results based on conditionals.
    It is common to set all values of b to 0. Thus, v_select will give values of "a" or 0 based on the mask.
*/
```

----------------------------------------

TITLE: Installing CMake via Homebrew on macOS
DESCRIPTION: This command uses the Homebrew package manager to install CMake on macOS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
brew install cmake
```

----------------------------------------

TITLE: Calculating SSIM on GPU (Basic) in C++
DESCRIPTION: Defines a C++ function `getMSSIM_GPU` for calculating MSSIM using basic OpenCV GPU functions. It uploads the input CPU matrices (`I1`, `I2`) to GPU matrices (`gI1`, `gI2`) and then invokes the GPU-accelerated `ssim` function. This represents a direct port from CPU without specific performance optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
//![getssimcuda]
Scalar getMSSIM_GPU( const Mat& i1, const Mat& i2)
{
    gpu::GpuMat d_i1, d_i2;
    d_i1.upload(i1);
    d_i2.upload(i2);

    return ssim(d_i1, d_i2);
}
//![getssimcuda]
```

----------------------------------------

TITLE: Final Visualization Call in Python using OpenCV
DESCRIPTION: Shows the invocation of `cv.drawContours` to outline the detected object and the call to `getOrientation` which performs PCA and draws the resulting orientation axes onto the `src` image within the main contour processing loop.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_14

LANGUAGE: python
CODE:
```
#! [visualization1]
    # Draw each contour only for visualisation purposes
    cv.drawContours(src, contours, i, (0, 0, 255), 2)
    # Find the orientation of each shape
    getOrientation(c, src)
#! [visualization1]
```

----------------------------------------

TITLE: Extracting Rotational Component Using OpenCV in C++
DESCRIPTION: This snippet demonstrates extracting the rotational component from two images captured by a rotating camera using the OpenCV library in C++. Dependencies include OpenCV, which should be initialized with appropriate camera parameters. Inputs are image views and the outcome is the rotational component between them.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_28

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>

void extractRotation(cv::Mat image1, cv::Mat image2) {
    // Code to extract rotation component
    // ...
}
```

----------------------------------------

TITLE: OpenCV Installation Script for Git Bash
DESCRIPTION: Comprehensive installation script for building OpenCV and OpenCV contrib modules using Git Bash. The script clones repositories if needed, configures CMake build settings, and compiles both debug and release configurations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
#!/bin/bash -e
myRepo=$(pwd)
CMAKE_GENERATOR_OPTIONS=-G"Visual Studio 16 2019"
#CMAKE_GENERATOR_OPTIONS=-G"Visual Studio 15 2017 Win64"
#CMAKE_GENERATOR_OPTIONS=(-G"Visual Studio 16 2019" -A x64)  # CMake 3.14+ is required
if [  ! -d "$myRepo/opencv"  ]; then
    echo "cloning opencv"
    git clone https://github.com/opencv/opencv.git
else
    cd opencv
    git pull --rebase
    cd ..
fi
if [  ! -d "$myRepo/opencv_contrib"  ]; then
    echo "cloning opencv_contrib"
    git clone https://github.com/opencv/opencv_contrib.git
else
    cd opencv_contrib
    git pull --rebase
    cd ..
fi
RepoSource=opencv
mkdir -p build_opencv
pushd build_opencv
CMAKE_OPTIONS=(-DBUILD_PERF_TESTS:BOOL=OFF -DBUILD_TESTS:BOOL=OFF -DBUILD_DOCS:BOOL=OFF  -DWITH_CUDA:BOOL=OFF -DBUILD_EXAMPLES:BOOL=OFF -DINSTALL_CREATE_DISTRIB=ON)
set -x
cmake "${CMAKE_GENERATOR_OPTIONS[@]}" "${CMAKE_OPTIONS[@]}" -DOPENCV_EXTRA_MODULES_PATH="$myRepo"/opencv_contrib/modules -DCMAKE_INSTALL_PREFIX="$myRepo/install/$RepoSource" "$myRepo/$RepoSource"
echo "************************* $Source_DIR -->debug"
cmake --build .  --config debug
echo "************************* $Source_DIR -->release"
cmake --build .  --config release
cmake --build .  --target install --config release
cmake --build .  --target install --config debug
popd
```

----------------------------------------

TITLE: Initializing OpenCV Java Test Project in CMake
DESCRIPTION: Sets up the initial conditions and variables for building OpenCV Java tests. It checks for required components and sets up the project directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/pure_test/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(NOT ANT_EXECUTABLE
    OR NOT BUILD_opencv_imgcodecs
    OR NOT BUILD_opencv_calib3d)
  return()
endif()

project(opencv_test_java)

set(OPENCV_JAR_FILE "${OPENCV_JAR_FILE}")
get_filename_component(JAR_NAME "${OPENCV_JAR_FILE}" NAME)

set(OPENCV_JAVA_TEST_DIR "${OpenCV_BINARY_DIR}/java_test" CACHE INTERNAL "")
file(REMOVE_RECURSE "${OPENCV_JAVA_TEST_DIR}")
file(MAKE_DIRECTORY "${OPENCV_JAVA_TEST_DIR}")
file(REMOVE "${OPENCV_DEPHELPER}/${the_module}_test_source_copy")

set(test_dir ${CMAKE_CURRENT_SOURCE_DIR})

set(depends "")
```

----------------------------------------

TITLE: Building OpenCV Framework with Specific Architectures in Bash
DESCRIPTION: Command to build the OpenCV framework for iOS specifying particular architectures for iOS devices and simulator.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/ios_install/ios_install.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
cd ~/<my_working_directory>
python opencv/platforms/ios/build_framework.py ios --contrib opencv_contrib --iphoneos_archs arm64 --iphonesimulator_archs x86_64
```

----------------------------------------

TITLE: Adding Various Types of Borders to an Image using OpenCV in Python
DESCRIPTION: This script demonstrates adding borders to an image using the `cv.copyMakeBorder()` function. It imports necessary libraries (`cv2`, `numpy`, `matplotlib.pyplot`), loads an image, defines a color (BLUE), and then applies various border types (`BORDER_REPLICATE`, `BORDER_REFLECT`, `BORDER_REFLECT_101`, `BORDER_WRAP`, `BORDER_CONSTANT`) with specified widths. Finally, it uses Matplotlib to display the original image and the images with different borders side-by-side.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_10

LANGUAGE: python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

BLUE = [255,0,0]

img1 = cv.imread('opencv-logo.png')
assert img1 is not None, "file could not be read, check with os.path.exists()"

replicate = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REPLICATE)
reflect = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT)
reflect101 = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT_101)
wrap = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_WRAP)
constant= cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_CONSTANT,value=BLUE)

plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')
plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')
plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')
plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')
plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')
plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')

plt.show()
```

----------------------------------------

TITLE: OpenCV Library Naming Convention
DESCRIPTION: Demonstrates the naming convention for OpenCV library files, including module name and version number.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
opencv_(The Name of the module)(The version Number of the library you use)d.lib
```

----------------------------------------

TITLE: Building OpenCV with Orbbec SDK Support - bash
DESCRIPTION: This snippet provides the commands for building OpenCV from source with Orbbec SDK support, which is required for Mac OS starting from OpenCV 4.11. It uses cmake with the -DOBSENSOR_USE_ORBBEC_SDK=ON flag, followed by standard make and install commands. Users must ensure the appropriate development tools are installed and may require sudo privileges for the final installation step.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_uvc.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
cmake -DOBSENSOR_USE_ORBBEC_SDK=ON ..\nmake\nsudo make install
```

----------------------------------------

TITLE: Including Plugin-Specific CMake Configuration - CMake
DESCRIPTION: This statement includes a plugin-specific CMake configuration file ('plugin.cmake') located in the same directory. It allows extension and customization of the build process. Parameter is the relative path to the included CMake file; no special inputs or outputs beyond file presence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
include(${CMAKE_CURRENT_LIST_DIR}/cmake/plugin.cmake)
```

----------------------------------------

TITLE: Calculating Circular Point Spread Function (PSF) in OpenCV C++
DESCRIPTION: Generates a 2D matrix representing a circular Point Spread Function (PSF) suitable for modeling out-of-focus blur. Takes the output PSF matrix `out`, the desired filter size, and the blur radius `R` as input. It creates a circle of value 1 within the specified radius centered in the matrix and sets the rest to 0, then normalizes the PSF by dividing by its sum. Requires OpenCV `Mat`, `Point`, `circle`, and `Scalar` types.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/out_of_focus_deblur_filter/out_of_focus_deblur_filter.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
void calcPSF(Mat& outputImg, Size filterSize, int R)
{
    Mat h(filterSize, CV_32F, Scalar(0));
    Point point(filterSize.width / 2, filterSize.height / 2);
    circle(h, point, R, 255, -1, 8);
    Scalar summa = sum(h);
    outputImg = h / summa[0];
}
```

----------------------------------------

TITLE: Calculating Homography Using OpenCV in Python
DESCRIPTION: This Python code performs the computation of the homography matrix using OpenCV, required for stitching. The dependencies are OpenCV and NumPy libraries. Inputs consist of images and camera parameters, yielding a homography matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_35

LANGUAGE: Python
CODE:
```
import cv2
import numpy as np

def compute_homography(image1, image2):
    # Code to compute homography
    # ...

```

----------------------------------------

TITLE: Calculate Histogram using OpenCV
DESCRIPTION: Demonstrates how to calculate an image histogram using cv.calcHist() function. Takes a grayscale image and returns a 256x1 array containing pixel value counts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
img = cv.imread('home.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
hist = cv.calcHist([img],[0],None,[256],[0,256])
```

----------------------------------------

TITLE: Running OpenCV.js Tests Headlessly with Puppeteer - Sh
DESCRIPTION: Moves into the build_js/bin output directory, installs Node.js dependencies (including Puppeteer), and runs the test runner with Node. This enables automated, headless browser testing (Chromium via Puppeteer). Dependencies: Node.js, npm, puppeteer, and Chromium bundle. Output: test results in CLI; useful for CI environments. Use PUPPETEER_SKIP_CHROMIUM_DOWNLOAD and PUPPETEER_EXECUTABLE_PATH environment variables to adjust browser executable path or skip Chromium download as needed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_13

LANGUAGE: sh
CODE:
```
cd build_js/bin\nnpm install\nnpm install --no-save puppeteer    # automatically downloads Chromium package\nnode run_puppeteer.js
```

----------------------------------------

TITLE: Drawing a Rook Chess Piece in Python
DESCRIPTION: Drawing a rook chess piece using lines, rectangles, and polygons in OpenCV Python. Demonstrates creating a complex shape by combining multiple basic drawing functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_14

LANGUAGE: python
CODE:
```
# 2. Draw a rook
# ------------------

# 2.a. Create a convex polygon
MyPolygon(rook_image)

# 2.b. Creating rectangles
rectangle(rook_image, (0, 7*w//8), (w, w), (0, 255, 255), -1, cv.LINE_8)

# 2.c. Create a few lines
MyLine(rook_image, (0, 15*w//16), (w, 15*w//16))
MyLine(rook_image, (w//4, 7*w//8), (w//4, w))
MyLine(rook_image, (w//2, 7*w//8), (w//2, w))
MyLine(rook_image, (3*w//4, 7*w//8), (3*w//4, w))
```

----------------------------------------

TITLE: Drawing a Rook Chess Piece in Java
DESCRIPTION: Drawing a rook chess piece using lines, rectangles, and polygons in OpenCV Java. Demonstrates creating a complex shape by combining multiple basic drawing functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_13

LANGUAGE: java
CODE:
```
// 2. Draw a rook
// ------------------

// 2.a. Create a convex polygon
MyPolygon(rook_image);

// 2.b. Creating rectangles
Rectangle(rook_image, new Point(0, 7*w/8), new Point(w, w), new Scalar(0, 255, 255), Core.FILLED, Core.LINE_8, 0);

// 2.c. Create a few lines
MyLine(rook_image, new Point(0, 15*w/16), new Point(w, 15*w/16));
MyLine(rook_image, new Point(w/4, 7*w/8), new Point(w/4, w));
MyLine(rook_image, new Point(w/2, 7*w/8), new Point(w/2, w));
MyLine(rook_image, new Point(3*w/4, 7*w/8), new Point(3*w/4, w));
```

----------------------------------------

TITLE: Creating Trackbars in C++
DESCRIPTION: Creates trackbars to adjust HSV value ranges for thresholding operations in a C++ application using OpenCV. This feature enables dynamic parameter tuning.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold_inRange/threshold_inRange.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
cv::createTrackbar("Trackbar Name", "Window Name", &value, max_value);
```

----------------------------------------

TITLE: Loading Images and Homography with OpenCV in C++
DESCRIPTION: This snippet loads grayscale images and a homography matrix in C++ using OpenCV's FileStorage. The images and homography are necessary for processing using the AKAZE algorithm.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
samples/cpp/tutorial_code/features2D/AKAZE_match.cpp load
```

----------------------------------------

TITLE: Loading Images and Homography with OpenCV in Python
DESCRIPTION: Python code snippet that demonstrates loading grayscale images and reading a homography matrix, which are used later for AKAZE processing in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py load
```

----------------------------------------

TITLE: FAST Corner Detection Pixel Comparison Logic
DESCRIPTION: Nested conditional logic for comparing pixel values against brightness thresholds (c_b and cb) with multiple branching paths leading to homogeneous or structured success cases. The code compares pixel values at different offsets to determine corner characteristics.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_8

LANGUAGE: C
CODE:
```
else
  goto homogeneous;
else
  if(ptr[offset3] < c_b)
    if(ptr[offset4] < c_b)
      if(ptr[offset5] < c_b)
        if(ptr[offset1] < c_b)
          if(ptr[offset6] < c_b)
            goto success_homogeneous;
          else
            if(ptr[offset11] < c_b)
              goto success_homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset7] < c_b)
              if(ptr[offset8] < c_b)
                goto success_homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto success_homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
```

----------------------------------------

TITLE: Configuring and Building FastCV HAL Library in CMake
DESCRIPTION: Sets up FastCV HAL configuration variables, builds the static library, configures include paths and dependencies, and handles installation settings. The configuration is only applied when HAVE_FASTCV is enabled.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/fastcv/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(HAVE_FASTCV)
  set(FASTCV_HAL_VERSION 0.0.1 CACHE INTERNAL "")
  set(FASTCV_HAL_LIBRARIES "fastcv_hal" CACHE INTERNAL "")
  set(FASTCV_HAL_INCLUDE_DIRS "${CMAKE_CURRENT_SOURCE_DIR}/include" CACHE INTERNAL "")
  set(FASTCV_HAL_HEADERS
    "${CMAKE_CURRENT_SOURCE_DIR}/include/fastcv_hal_core.hpp"
    "${CMAKE_CURRENT_SOURCE_DIR}/include/fastcv_hal_imgproc.hpp"
    CACHE INTERNAL "")

  file(GLOB FASTCV_HAL_FILES    "${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp")

  add_library(fastcv_hal STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${FASTCV_HAL_FILES})

  target_include_directories(fastcv_hal PRIVATE
    ${CMAKE_SOURCE_DIR}/modules/core/include
    ${CMAKE_SOURCE_DIR}/modules/imgproc/include
    ${FASTCV_HAL_INCLUDE_DIRS} ${FastCV_INCLUDE_PATH})

  target_link_libraries(fastcv_hal PUBLIC ${FASTCV_LIBRARY})

  set_target_properties(fastcv_hal PROPERTIES ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH})

  if(NOT BUILD_SHARED_LIBS)
    ocv_install_target(fastcv_hal EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev)
  endif()

  if(ENABLE_SOLUTION_FOLDERS)
    set_target_properties(fastcv_hal PROPERTIES FOLDER "3rdparty")
  endif()
else()
  message(STATUS "FastCV is not available, disabling related HAL")
endif(HAVE_FASTCV)
```

----------------------------------------

TITLE: Affine Transformation Matrix Definition
DESCRIPTION: Mathematical representation of an affine transformation using 2x3 matrix notation, showing how to combine linear transformation matrix A (2x2) with translation vector B (2x1) to form transformation matrix M (2x3).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.markdown#2025-04-22_snippet_0

LANGUAGE: latex
CODE:
```
A = \begin{bmatrix}
    a_{00} & a_{01} \\
    a_{10} & a_{11}
    \end{bmatrix}_{2 \times 2}
B = \begin{bmatrix}
    b_{00} \\
    b_{10}
    \end{bmatrix}_{2 \times 1}
```

LANGUAGE: latex
CODE:
```
M = \begin{bmatrix}
    A & B
    \end{bmatrix}
=
\begin{bmatrix}
    a_{00} & a_{01} & b_{00} \\
    a_{10} & a_{11} & b_{10}
\end{bmatrix}_{2 \times 3}
```

LANGUAGE: latex
CODE:
```
T =  \begin{bmatrix}
    a_{00}x + a_{01}y + b_{00} \\
    a_{10}x + a_{11}y + b_{10}
    \end{bmatrix}
```

----------------------------------------

TITLE: Generating the Mandelbrot Set Sequentially - C++
DESCRIPTION: This code snippet shows how to sequentially render the Mandelbrot set as a grayscale image using a nested for-loop to iterate over each pixel, transform its coordinates to the complex plane, run the escape time algorithm, and assign pixel values accordingly. Requires OpenCV (for Mat) and the escape time algorithm. Takes an image Mat, max iteration counter, and pixel size as input; outputs a filled Mat. Not suited for very large images due to sequential bottlenecks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
// Sequential Mandelbrot implementation
void mandelbrotSequential(cv::Mat& image, int maxIter)
{
    for (int row = 0; row < image.rows; ++row)
    {
        for (int col = 0; col < image.cols; ++col)
        {
            double x0 = (col / (double)image.cols) * 3.0 - 2.0;
            double y0 = (row / (double)image.rows) * 2.0 - 1.0;
            int iter = mandelbrot(cv::Point2d(x0, y0), maxIter);
            image.at<uchar>(row, col) = grayscaleValue(iter, maxIter);
        }
    }
}

```

----------------------------------------

TITLE: Configuring VideoIO Module Build
DESCRIPTION: Sets up the OpenCV VideoIO module build by setting sources, creating the module, adding tests, and linking dependencies. Handles plugin support and external target installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
ocv_set_module_sources(HEADERS ${videoio_ext_hdrs} ${videoio_hdrs} SOURCES ${videoio_srcs})
ocv_module_include_directories()
ocv_create_module()
ocv_add_accuracy_tests(${tgts})
ocv_add_perf_tests(${tgts})

if(VIDEOIO_ENABLE_PLUGINS)
  ocv_target_compile_definitions(${the_module} PRIVATE ENABLE_PLUGINS)
endif()

ocv_target_link_libraries(${the_module} LINK_PRIVATE ${tgts})
```

----------------------------------------

TITLE: Copying Matrices with OpenCV.js - JavaScript
DESCRIPTION: Shows how to make a copy of a cv.Mat, either by deep cloning or via selective masked copying. The clone() method makes a complete duplicate, while copyTo() with a mask copies only specified entries. Proper usage of these methods allows safe manipulation of image data without affecting the original.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_3

LANGUAGE: JavaScript
CODE:
```
// 1. Clone
let dst = src.clone();
// 2. CopyTo(only entries indicated in the mask are copied)
src.copyTo(dst, mask);
```

----------------------------------------

TITLE: Performing Point Polygon Test with OpenCV in Python
DESCRIPTION: This Python script uses OpenCV's cv2.pointPolygonTest to evaluate if a given point is inside, outside, or on a polygon. It defines contours as numpy arrays and applies the function to several test points. Dependencies include numpy and OpenCV (cv2). The script visualizes the results using cv2.imshow and expects a standard OpenCV and numpy setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/point_polygon_test/point_polygon_test.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2\nimport numpy as np\n\n# Define a polygon (contour)\ncontour = np.array([[100,100], [200,100], [200,200], [100,200]], dtype=np.int32)\n\n# Test points\ntestPoint1 = (150,150) # inside\ntestPoint2 = (250,150) # outside\n\n# Run pointPolygonTest\nresult1 = cv2.pointPolygonTest(contour, testPoint1, False)\nresult2 = cv2.pointPolygonTest(contour, testPoint2, False)\n\nprint(f'Test Point 1 {testPoint1}: {{result1}}')\nprint(f'Test Point 2 {testPoint2}: {{result2}}')\n\n# Visualization\nimg = np.zeros((300, 300, 3), dtype=np.uint8)\ncv2.polylines(img, [contour], isClosed=True, color=(255,255,255), thickness=2)\ncv2.circle(img, testPoint1, 5, (0,255,0), -1)\ncv2.circle(img, testPoint2, 5, (0,0,255), -1)\ncv2.imshow('Point Polygon Test', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n
```

----------------------------------------

TITLE: Setting Up First Frame for Planar Tracking in C++
DESCRIPTION: This code snippet initializes the tracking process by detecting keypoints and computing descriptors for the first frame. It also draws the bounding box and title on the frame.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_tracking/akaze_tracking.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
void Tracker::setFirstFrame(const Mat frame, vector<Point2f> bb, string title, Stats& stats)
{
    first_frame = frame.clone();
    (*detector)(first_frame, noArray(), first_kp, first_desc);
    stats.keypoints = (int)first_kp.size();
    drawBoundingBox(first_frame, bb);
    putText(first_frame, title, Point(0, 60), FONT_HERSHEY_PLAIN, 5, Scalar::all(0), 4);
    object_bb = bb;
}
```

----------------------------------------

TITLE: Detecting and Filtering Contours in Java using OpenCV
DESCRIPTION: Identifies contours in the preprocessed binary image `bw` using `findContours`. It loops through the contours, calculates their area using `contourArea`, and filters out contours smaller than a predefined minimum size (1e2). Depends on OpenCV Java bindings and requires a binary Mat `bw`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_4

LANGUAGE: java
CODE:
```
//! [contours]
// Find all the contours in the thresholded image
List<MatOfPoint> contours = new ArrayList<>();
Mat hierarchy = new Mat();
findContours(bw, contours, hierarchy, RETR_LIST, CHAIN_APPROX_NONE);

for (int i = 0; i < contours.size(); ++i)
{
    // Calculate the area of each contour
    double area = contourArea(contours.get(i));
    // Ignore contours that are too small or too large
    if (area < 1e2 || 1e5 < area)
        continue;

    // Draw each contour only for visualisation purposes
    drawContours(src, contours, i, new Scalar(0, 0, 255), 2);
    // Find the orientation of each shape
    getOrientation(contours.get(i), src);
}
//! [contours]
```

----------------------------------------

TITLE: Converting HDR Images to 8-bit and Saving using OpenCV Python
DESCRIPTION: Converts HDR images into 8-bit for saving and displaying, ensuring they fit within the [0..255] range to prevent overflow.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_hdr/py_hdr.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
# Convert datatype to 8-bit and save
res_debevec_8bit = np.clip(res_debevec*255, 0, 255).astype('uint8')
res_robertson_8bit = np.clip(res_robertson*255, 0, 255).astype('uint8')
res_mertens_8bit = np.clip(res_mertens*255, 0, 255).astype('uint8')

cv.imwrite("ldr_debevec.jpg", res_debevec_8bit)
cv.imwrite("ldr_robertson.jpg", res_robertson_8bit)
cv.imwrite("fusion_mertens.jpg", res_mertens_8bit)
```

----------------------------------------

TITLE: Initializing BackgroundSubtractorMOG2 with OpenCV.js in JavaScript
DESCRIPTION: Demonstrates how to create a BackgroundSubtractorMOG2 object in OpenCV.js for background/foreground segmentation. The constructor takes three main parameters: 'history' (length of background modeling history), 'varThreshold' (variance threshold for pixel classification), and 'detectShadows' (enables shadow detection). Ensure OpenCV.js is loaded and available as 'cv'. Outputs an instance that can be reused for multiple frames; manual deletion is required to free memory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_video/js_bg_subtraction/js_bg_subtraction.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
let history = 500;
let varThreshold = 16;
let detectShadows = true; // if false, disables shadow detection
let bgSubtractor = new cv.BackgroundSubtractorMOG2(history, varThreshold, detectShadows);
// ... use bgSubtractor for processing frames
// When done:
bgSubtractor.delete(); // required to free WASM-allocated memory
```

----------------------------------------

TITLE: Optimizing Huffman Tables in libjpeg (C)
DESCRIPTION: A C boolean field within the compression parameters structure (`cinfo`). When set to TRUE, libjpeg performs an extra pass over the image data to compute optimal Huffman coding tables, potentially reducing file size slightly at the cost of increased compression time and memory usage. The default is FALSE (use default or pre-supplied tables). This parameter has no effect in progressive/lossless modes, with 12-bit precision (unless tables are supplied), or when using arithmetic coding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_34

LANGUAGE: C
CODE:
```
boolean optimize_coding
```

----------------------------------------

TITLE: Drawing a Rectangle in C++
DESCRIPTION: Example of using the rectangle() function in OpenCV C++ to draw a filled yellow rectangle. The function specifies two opposite corners of the rectangle along with color and fill options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_27

LANGUAGE: cpp
CODE:
```
rectangle( rook_image,
       Point( 0, 7*w/8 ),
       Point( w, w),
       Scalar( 0, 255, 255 ),
       FILLED,
       LINE_8 );
```

----------------------------------------

TITLE: Normalizing Histogram Results in Java
DESCRIPTION: Java snippet normalizing the calculated histograms (`bHist`, `gHist`, `rHist`) to fit the display image height. It uses `Core.normalize` for each histogram Mat, specifying the input and output Mats, the target range (0 to `histImage.rows()`), the normalization type (`Core.NORM_MINMAX`), data type (-1 for same as input), and no mask (`new Mat()`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_25

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Normalize the result to ( 0, histImage.rows )
```

----------------------------------------

TITLE: Building a GComputation Graph for Face Analytics Pipeline
DESCRIPTION: Code snippet demonstrating how to build a G-API graph (GComputation) for a face analytics pipeline. The pipeline includes face detection, post-processing to extract face ROIs, and running age/gender and emotion classification on each detected face.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
// The pipeline is expressed as a sequence of G-API operations
cv::GMat in;
cv::GMat faces = cv::gapi::infer<Faces>(in);
cv::GArray<cv::Rect> faces_rc = custom::PostProc::on(faces, in, 0.5f, 1.0f); // 0.5f = confidence, 1.0f = scales

cv::GArray<cv::GMat> age_gender_info = cv::gapi::infer<AgeGender>(faces_rc, in);
cv::GArray<cv::GMat> age, gender;
std::tie(age, gender) = cv::gapi::split(age_gender_info);

cv::GArray<cv::GMat> emotions = cv::gapi::infer<Emotions>(faces_rc, in);

cv::GMat out = custom::Viz::on(in, faces_rc, age, gender, emotions);

cv::GComputation pipeline(cv::GIn(in), cv::GOut(out));
```

----------------------------------------

TITLE: Creating Trackbar in C++
DESCRIPTION: This C++ snippet creates a trackbar using `createTrackbar`. It sets the trackbar's name, associates it with the "Linear Blend" window, links it to the `alpha_slider` variable, defines the maximum value (`alpha_slider_max`), and specifies `on_trackbar` as the callback function executed when the slider position changes. It also calls the callback once initially.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
//![create_trackbar]
char TrackbarName[50];
sprintf( TrackbarName, "Alpha x %d", alpha_slider_max );
createTrackbar( TrackbarName, "Linear Blend", &alpha_slider, alpha_slider_max, on_trackbar );

// Show some stuff
on_trackbar( alpha_slider, 0 );
//![create_trackbar]
```

----------------------------------------

TITLE: Conditionally Including Test Subdirectories in CMake
DESCRIPTION: This CMake code checks if tests are enabled (`BUILD_TESTS` is true). If they are, it further checks if the build is targeting Android (`ANDROID` is true). If building for Android, it includes the `test/android_test` subdirectory. Otherwise (for non-Android builds with tests enabled), it includes the `test/pure_test` subdirectory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
if(BUILD_TESTS)
  if(ANDROID)
    add_subdirectory(test/android_test)
  else()
    add_subdirectory(test/pure_test)
  endif()
endif()
```

----------------------------------------

TITLE: Creating a Simple Hello World Application (Java)
DESCRIPTION: This Java code defines a very basic 'Hello World' style application named `HelloOpenCV`. It serves as an initial test to ensure the SBT project structure and build process are working correctly before adding OpenCV-specific code and dependencies. It simply prints 'Hello, OpenCV' to the console.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_15

LANGUAGE: java
CODE:
```
public class HelloOpenCV {
  public static void main(String[] args) {
    System.out.println("Hello, OpenCV");
 }
}
```

----------------------------------------

TITLE: Drawing a Polygon in Python
DESCRIPTION: Implementation of the MyPolygon function that draws a filled polygon in OpenCV Python. The function creates a NumPy array with the polygon vertices and uses the fillPoly() function to draw a white polygon.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_26

LANGUAGE: python
CODE:
```
def MyPolygon(img):
    lineType = cv.LINE_8

    # Create some points
    pts = np.array([[w//4, 7*w//8], [3*w//4, 7*w//8], 
                     [3*w//4, 13*w//16], [11*w//16, 13*w//16], 
                     [19*w//32, 3*w//8], [3*w//4, 3*w//8], 
                     [3*w//4, w//8], [26*w//40, w//8], 
                     [26*w//40, w//4], [22*w//40, w//4], 
                     [22*w//40, w//8], [18*w//40, w//8], 
                     [18*w//40, w//4], [14*w//40, w//4], 
                     [14*w//40, w//8], [w//4, w//8], 
                     [w//4, 3*w//8], [13*w//32, 3*w//8], 
                     [5*w//16, 13*w//16], [w//4, 13*w//16]], 
                    np.int32)
    pts = pts.reshape((-1, 1, 2))

    cv.fillPoly(img, 
                 [pts], 
                 (255, 255, 255), 
                 lineType)
```

----------------------------------------

TITLE: Image Stitching Using OpenCV in Java
DESCRIPTION: This Java function utilizes OpenCV to conduct image stitching based on a computed homography matrix. It requires OpenCV's Java integration. The function processes two image inputs and provides a stitched panoramic output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_39

LANGUAGE: Java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.Mat;

public void stitchImages(Mat image1, Mat image2, Mat homography) {
    // Code to stitch images
    // ...
}
```

----------------------------------------

TITLE: Fourier Analysis of Spatial Filters using Numpy and Matplotlib - Python
DESCRIPTION: This code defines several spatial filters (mean, Gaussian, Laplacian, Sobel, Scharr) as Numpy arrays, computes their FFTs, and visualizes their magnitude spectra using Matplotlib. Dependencies: OpenCV (cv), Numpy (np), Matplotlib (plt). The script demonstrates how each filter affects frequency regions, illustrating why some act as low-pass or high-pass filters. Key parameters: no image needed, just 2D filters. Outputs: subplots showing frequency-domain characteristics for each kernel. Useful for educational exploration of filter design.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

# simple averaging filter without scaling parameter
mean_filter = np.ones((3,3))

# creating a gaussian filter
x = cv.getGaussianKernel(5,10)
gaussian = x*x.T

# different edge detecting filters
# scharr in x-direction
scharr = np.array([[-3, 0, 3],
                   [-10,0,10],
                   [-3, 0, 3]])
# sobel in x direction
sobel_x= np.array([[-1, 0, 1],
                   [-2, 0, 2],
                   [-1, 0, 1]])
# sobel in y direction
sobel_y= np.array([[-1,-2,-1],
                   [0, 0, 0],
                   [1, 2, 1]])
# laplacian
laplacian=np.array([[0, 1, 0],
                    [1,-4, 1],
                    [0, 1, 0]])

filters = [mean_filter, gaussian, laplacian, sobel_x, sobel_y, scharr]
filter_name = ['mean_filter', 'gaussian','laplacian', 'sobel_x', \
                'sobel_y', 'scharr_x']
fft_filters = [np.fft.fft2(x) for x in filters]
fft_shift = [np.fft.fftshift(y) for y in fft_filters]
mag_spectrum = [np.log(np.abs(z)+1) for z in fft_shift]

for i in range(6):
    plt.subplot(2,3,i+1),plt.imshow(mag_spectrum[i],cmap = 'gray')
    plt.title(filter_name[i]), plt.xticks([]), plt.yticks([])

plt.show()
```

----------------------------------------

TITLE: Using Stitcher Class for Image Stitching C++
DESCRIPTION: This snippet demonstrates how to utilize the high-level stitching API from OpenCV in C++. The code includes additional options for image division and error handling not found in the Python example. Key dependencies include OpenCV libraries, and it expects input images to stitch into a panorama. Outputs include the stitched panorama image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/stitcher.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp> // OpenCV library headers
int main(int argc, char* argv[]) {
    cv::Mat pano;
    cv::Stitcher::Mode mode = cv::Stitcher::PANORAMA;
    std::vector<cv::Mat> imgs;
    // Imaginary function to load images
    // loadImages(argv, imgs);
    cv::Stitcher::Status status = cv::Stitcher::create(mode)->stitch(imgs, pano);
    if (status != cv::Stitcher::OK) {
        // Handle error
    }
    cv::imwrite("result.jpg", pano);
    return 0;
}
```

----------------------------------------

TITLE: Generating ChArUco Board Pattern with Custom Dictionary using Python Script (Shell)
DESCRIPTION: Uses 'gen_pattern.py' to generate a ChArUco board pattern named 'charuco_board.svg' with 7 rows and 5 columns. This command specifically uses a custom ArUco dictionary defined in 'my_dictionary.json'. Requires Python, the 'gen_pattern.py' script, and the custom dictionary file ('my_dictionary.json').
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_pattern/camera_calibration_pattern.markdown#2025-04-22_snippet_5

LANGUAGE: shell
CODE:
```
python gen_pattern.py -o charuco_board.svg --rows 7 --columns 5 -T charuco_board -f my_dictionary.json
```

----------------------------------------

TITLE: Generating Non-Linearly Separable Training Data for SVM (Python)
DESCRIPTION: Python implementation for creating non-linearly separable training data by adding points that overlap between classes, demonstrating how real-world data often requires non-linear SVM approaches.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_9

LANGUAGE: Python
CODE:
```
# Set up the non-linearly separable part of the training data
FRAC_LINEAR_SEP = 0.9  # Fraction of the training samples which will be linearly separable
trainingSamplesToAdd = int(2 * NTRAINING_SAMPLES * (1 - FRAC_LINEAR_SEP))
extraTrainData = np.empty((trainingSamplesToAdd, 2), dtype=np.float32)
extraTrainLabels = np.empty((trainingSamplesToAdd, 1), dtype=np.int32)
rng2 = np.random.RandomState(100)

# Generate extra non-linearly separable points
for i in range(trainingSamplesToAdd):
    clsIdx = i % 2
    x = rng2.uniform()
    y = rng2.uniform()
    extraTrainData[i, 0] = x
    extraTrainData[i, 1] = y
    extraTrainLabels[i, 0] = labels[clsIdx]

# Merge all the training data
completeTrainData = np.vstack((trainData, extraTrainData))
completeTrainLabels = np.vstack((trainLabels, extraTrainLabels))
```

----------------------------------------

TITLE: Using Stitcher Class for Image Stitching Python
DESCRIPTION: This Python snippet shows how to employ the high-level stitching API provided by OpenCV. It simplifies the stitching process using pre-configured modes. It requires OpenCV (cv2) as a dependency and takes image paths as input to produce a panoramic output. The Python code lacks some of the advanced error management available in C++.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/stitcher.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import cv2
import sys
# Load images, this part assumes images are given as command-line arguments
imgs = [cv2.imread(img_path) for img_path in sys.argv[1:]]
stitcher = cv2.Stitcher_create(cv2.Stitcher_PANORAMA)
status, pano = stitcher.stitch(imgs)
if status == cv2.Stitcher_OK:
    cv2.imwrite('result.jpg', pano)
else:
    print('Error during stitching')
```

----------------------------------------

TITLE: Drawing Line with OpenCV in Python
DESCRIPTION: Creates a black image and draws a blue diagonal line from top-left to bottom-right corners with a thickness of 5 pixels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

# Create a black image
img = np.zeros((512,512,3), np.uint8)

# Draw a diagonal blue line with thickness of 5 px
cv.line(img,(0,0),(511,511),(255,0,0),5)
```

----------------------------------------

TITLE: YOLOX Model Download and Execution
DESCRIPTION: Shell commands for downloading and running the YOLOX detector model using OpenCV's example.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown#2025-04-22_snippet_4

LANGUAGE: sh
CODE:
```
git clone https://github.com/opencv/opencv_extra.git
cd opencv_extra/testdata/dnn
python download_models.py yolox_s_inf_decoder
cd ..
export OPENCV_TEST_DATA_PATH=$(pwd)
cd <build directory of OpenCV>
./bin/example_dnn_yolo_detector
```

----------------------------------------

TITLE: Calculating Contour Solidity in OpenCV Python
DESCRIPTION: This snippet calculates the solidity of a contour, defined as the ratio of the contour's area to the area of its convex hull. It uses `cv.contourArea` for the contour area, `cv.convexHull` to find the convex hull of the contour, and `cv.contourArea` again to get the hull's area. Requires an existing contour variable `cnt`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
area = cv.contourArea(cnt)
hull = cv.convexHull(cnt)
hull_area = cv.contourArea(hull)
solidity = float(area)/hull_area
```

----------------------------------------

TITLE: Accessing Single Pixel in 3-Channel Image with OpenCV in C++
DESCRIPTION: Retrieves color pixel values from a 3-channel (BGR) cv::Mat at (row, column). Uses cv::Vec3b and at<> method. Output is a vector with blue, green, red intensities in that order. Each channel value ranges 0-255.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_13

LANGUAGE: C++
CODE:
```
cv::Vec3b intensity = img.at<cv::Vec3b>(y, x);\nuchar blue = intensity[0];\nuchar green = intensity[1];\nuchar red = intensity[2];
```

----------------------------------------

TITLE: Declaring Constant-Sized SIMD Registers in OpenCV Intrinsics (C++)
DESCRIPTION: This snippet shows how to declare constant-sized SIMD register structures in OpenCV's intrinsics, following the type and dimension conventions. Registers such as v_int32x8 and v_float64x8 specify both the data type, width, and number of values. These should be used when precise control over register size is necessary. The hardware SIMD support must match the specified sizes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
v_int32x8 reg1                       // holds 8 32-bit signed integers.
v_float64x8 reg2                     // reg2.nlanes = 8
```

----------------------------------------

TITLE: Initializing Barcode Detector in OpenCV C++
DESCRIPTION: The snippet demonstrates how to initialize a BarcodeDetector object in OpenCV C++. The initialization can optionally use a super-resolution model from an external source. Dependencies include OpenCV and potentially the super-resolution model files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/barcode_detect_and_decode.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
@snippet cpp/barcode.cpp initialize
```

----------------------------------------

TITLE: Pose Estimation with ArUco Markers using OpenCV C++
DESCRIPTION: This snippet and associated function calls implement pose estimation using detected ArUco markers. The process uses the camera calibration matrix, distortion coefficients, marker corners, and dimensions to compute rotation and translation vectors, providing a 3D transformation from the marker to camera coordinates. The detailed code is referenced in `detect_markers.cpp`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/objectDetection/detect_markers.cpp aruco_pose_estimation1
```

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/objectDetection/detect_markers.cpp aruco_pose_estimation2
```

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/objectDetection/detect_markers.cpp aruco_pose_estimation3
```

----------------------------------------

TITLE: Checking Image Load Success in OpenCV Python
DESCRIPTION: This snippet checks if an image was successfully loaded in Python by verifying if the image variable is None. It allows for appropriate error handling when the image cannot be found or opened.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
if image is None:
    print('Could not open or find the image!')
    exit(0)
```

----------------------------------------

TITLE: Creating Display Window in C++
DESCRIPTION: This C++ snippet creates a window named "Linear Blend" using `namedWindow`. This window will display the blended image and host the trackbar.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
//![window]
/// Create Windows
namedWindow("Linear Blend", WINDOW_AUTOSIZE); // Create Window
//![window]
```

----------------------------------------

TITLE: Drawing Probabilistic Hough Line Segments in OpenCV (C++)
DESCRIPTION: This C++ snippet draws the line segments detected by HoughLinesP. For each segment, it draws a line between the endpoints using cv::line. Inputs are the array of segment points and the display image. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_15

LANGUAGE: C++
CODE:
```
for( size_t i = 0; i < linesP.size(); i++ )\n{\n    Vec4i l = linesP[i];\n    line( cdstP, Point(l[0], l[1]), Point(l[2], l[3]), Scalar(0,255,0), 3, LINE_AA);\n}\n
```

----------------------------------------

TITLE: Implementing Camshift Object Tracking in C++
DESCRIPTION: C++ implementation of the Camshift algorithm using OpenCV. This code extends the Meanshift approach by adapting the size and rotation of the tracking window based on object appearance changes. The implementation includes histogram calculation, backprojection, and the Camshift tracking function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/meanshift.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
#include "opencv2/imgproc.hpp"\n#include "opencv2/videoio.hpp"\n#include "opencv2/highgui.hpp"\n#include <iostream>\n\nusing namespace cv;\nusing namespace std;\n\nMat frame, hsv, hue, mask, hist, histimg = Mat::zeros(200, 320, CV_8UC3), backproj;\n\nint main( int argc, char** argv )\n{\n    VideoCapture cap;\n    Rect trackWindow;\n    int hsize = 16;\n    float hranges[] = {0,180};\n    const float* phranges = hranges;\n\n    cap.open( samples::findFile(argc > 1 ? argv[1] : \"video.avi\") );\n\n    if( !cap.isOpened() )\n    {\n        cout << \"Could not initialize capturing...\" << endl;\n        return 0;\n    }\n\n    namedWindow( \"Histogram\", 0 );\n    namedWindow( \"CamShift Demo\", 0 );\n    setMouseCallback( \"CamShift Demo\", onMouse, 0 );\n    createTrackbar( \"Vmin\", \"CamShift Demo\", &vmin, 256, 0 );\n    createTrackbar( \"Vmax\", \"CamShift Demo\", &vmax, 256, 0 );\n    createTrackbar( \"Smin\", \"CamShift Demo\", &smin, 256, 0 );\n\n    for(;;)\n    {\n        cap >> frame;\n        if( frame.empty() )\n            break;\n\n        frame.copyTo(image);\n        cvtColor(image, hsv, COLOR_BGR2HSV);\n\n        if( trackObject )\n        {\n            int _vmin = vmin, _vmax = vmax;\n\n            inRange(hsv, Scalar(0, smin, MIN(_vmin,_vmax)),\n                    Scalar(180, 256, MAX(_vmin, _vmax)), mask);\n            int ch[] = {0, 0};\n            hue.create(hsv.size(), hsv.depth());\n            mixChannels(&hsv, 1, &hue, 1, ch, 1);\n\n            if( trackObject < 0 )\n            {\n                Mat roi(hue, selection), maskroi(mask, selection);\n                calcHist(&roi, 1, 0, maskroi, hist, 1, &hsize, &phranges);\n                normalize(hist, hist, 0, 255, NORM_MINMAX);\n\n                trackWindow = selection;\n                trackObject = 1;\n\n                histimg = Scalar::all(0);\n                int binW = histimg.cols / hsize;\n                Mat buf(1, hsize, CV_8UC3);\n                for( int i = 0; i < hsize; i++ )\n                    buf.at<Vec3b>(i) = Vec3b(saturate_cast<uchar>(i*180./hsize), 255, 255);\n                cvtColor(buf, buf, COLOR_HSV2BGR);\n\n                for( int i = 0; i < hsize; i++ )\n                {\n                    int val = saturate_cast<int>(hist.at<float>(i)*histimg.rows/255);\n                    rectangle( histimg, Point(i*binW,histimg.rows),\n                            Point((i+1)*binW,histimg.rows - val),\n                            Scalar(buf.at<Vec3b>(i)), -1, 8 );\n                }\n            }\n\n            calcBackProject(&hue, 1, 0, hist, backproj, &phranges);\n            backproj &= mask;\n            RotatedRect trackBox = CamShift(backproj, trackWindow,\n                                TermCriteria( TermCriteria::EPS | TermCriteria::COUNT, 10, 1 ));\n            if( trackWindow.area() <= 1 )\n            {\n                int cols = backproj.cols, rows = backproj.rows, r = (MIN(cols, rows) + 5)/6;\n                trackWindow = Rect(trackWindow.x - r, trackWindow.y - r,\n                                 trackWindow.x + r, trackWindow.y + r) &\n                            Rect(0, 0, cols, rows);\n            }\n\n            if( backprojMode )\n                cvtColor( backproj, image, COLOR_GRAY2BGR );\n            ellipse( image, trackBox, Scalar(0,0,255), 3, LINE_AA );\n        }\n\n        if( selectObject && selection.width > 0 && selection.height > 0 )\n        {\n            Mat roi(image, selection);\n            bitwise_not(roi, roi);\n        }\n\n        imshow( \"CamShift Demo\", image );\n        imshow( \"Histogram\", histimg );\n\n        char c = (char)waitKey(30);\n        if( c == 27 )\n            break;\n        switch(c)\n        {\n        case 'b':\n            backprojMode = !backprojMode;\n            break;\n        case 'c':\n            trackObject = 0;\n            histimg = Scalar::all(0);\n            break;\n        case 'h':\n            showHist = !showHist;\n            if( !showHist )\n                destroyWindow( \"Histogram\" );\n            else\n                namedWindow( \"Histogram\", 1 );\n            break;\n        case 'p':\n            paused = !paused;\n            break;\n        default:\n            ;\n        }\n    }\n\n    return 0;\n}
```

----------------------------------------

TITLE: Applying Laplacian Derivative with OpenCV.js - JavaScript
DESCRIPTION: This snippet shows how to compute the Laplacian (second-order derivative) of an image with the cv.Laplacian function in OpenCV.js. Requires OpenCV.js loaded in the environment and expects input and output cv.Mat objects, with selectable depth and kernel size. It calculates the sum of second-order derivatives in both axes, returning an edge-highlighted output with kernel and datatype constraints as described.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_gradients/js_gradients.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
cv.Laplacian(src, dst, ddepth, ksize = 1, scale = 1, delta = 0, borderType = cv.BORDER_DEFAULT);
```

----------------------------------------

TITLE: Defining Default Output Directory for Converted Models - Python
DESCRIPTION: This Python class snippet leverages dataclasses to provide a configuration container for directory paths. 'CommonConfig' defines the default path ('dnn_model_runner/dnn_conversion') for storing all converted model artifacts. Requires Python 3.7+ (for dataclasses), and used for centralizing file management/configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
@dataclass\nclass CommonConfig:\n    output_data_root_dir: str = "dnn_model_runner/dnn_conversion"
```

----------------------------------------

TITLE: Creating Zlib Static Library in CMake
DESCRIPTION: Adds a static library target for Zlib with all source files and headers, and sets the ZLIB_DLL define symbol. This is the main library creation command for Zlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
add_library(${ZLIB_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${ZLIB_SRCS} ${ZLIB_PUBLIC_HDRS} ${ZLIB_PRIVATE_HDRS})
set_target_properties(${ZLIB_LIBRARY} PROPERTIES DEFINE_SYMBOL ZLIB_DLL)
```

----------------------------------------

TITLE: Reading ONNX Model with OpenCV DNN
DESCRIPTION: This Python code snippet loads an ONNX model file specified by `full_model_path` using OpenCV's Deep Neural Network (DNN) module. The `cv2.dnn.readNetFromONNX` function parses the ONNX file and creates an OpenCV `cv.dnn_Net` object (`opencv_net`) ready for inference. Requires the `cv2` (OpenCV) library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
# read converted .onnx model with OpenCV API
opencv_net = cv2.dnn.readNetFromONNX(full_model_path)
```

----------------------------------------

TITLE: Basic TIFF Software Installation Commands
DESCRIPTION: Standard commands for configuring, building, and installing the TIFF library on Unix-like systems. These commands should be executed in sequence to install the software system-wide.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/README.md#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
% ./configure
% make
% su
# make install
```

----------------------------------------

TITLE: Building OpenCV Core Modules on Linux
DESCRIPTION: Quick start script for building OpenCV core modules on Linux. It downloads the source, creates a build directory, configures CMake, and builds the project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
unzip opencv.zip
mkdir -p build && cd build
cmake  ../opencv-4.x
cmake --build .
```

----------------------------------------

TITLE: Splitting and Merging Image Channels with OpenCV.js - JavaScript
DESCRIPTION: Shows how to decompose an image Mat into its separate RGBA channels using cv.split and MatVector. Demonstrates accessing a single channel, then recombining them all using cv.merge. Highlights importance of memory management (delete) to prevent leaks in long-running applications.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_9

LANGUAGE: JavaScript
CODE:
```
let src = cv.imread("canvasInput");
let rgbaPlanes = new cv.MatVector();
// Split the Mat
cv.split(src, rgbaPlanes);
// Get R channel
let R = rgbaPlanes.get(0);
// Merge all channels
cv.merge(rgbaPlanes, src);
src.delete(); rgbaPlanes.delete(); R.delete();
```

----------------------------------------

TITLE: Illustrating Separate Layer Computations Before Fusing (Pseudocode)
DESCRIPTION: This pseudocode illustrates the sequential computation of Convolution (`conv`), Scale (`scale`), and ReLU (`relu`) layers. It serves as a conceptual baseline to understand how these distinct operations can be combined into a single, more efficient function through layer fusing in the Halide backend.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide_scheduling/dnn_halide_scheduling.markdown#2025-04-22_snippet_1

LANGUAGE: pseudocode
CODE:
```
conv(x, y, c, n) = sum(...) + bias(c);
scale(x, y, c, n) = conv(x, y, c, n) * weights(c);
relu(x, y, c, n) = max(scale(x, y, c, n), 0);
```

----------------------------------------

TITLE: Initializing and Configuring SVM Parameters for Non-Linear Classification (C++)
DESCRIPTION: Sets up parameters for Support Vector Machine to handle non-linearly separable data. Configures a small C value to allow some misclassification and uses a termination criteria with high iterations to ensure convergence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
// Set up SVM's parameters
Ptr<SVM> svm = SVM::create();
svm->setType(SVM::C_SVC);
svm->setKernel(SVM::RBF);
// When C is small, the decision boundary will be smooth
// When C is large, the decision boundary can better classify all training points but may lead to overfitting
svm->setC(0.1);
// Set termination criteria for the optimization
svm->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER, (int)1e7, 1e-6));
```

----------------------------------------

TITLE: Fitting an Ellipse to Contours in Python with OpenCV
DESCRIPTION: This snippet demonstrates how to fit an ellipse to a contour and draw it using cv.fitEllipse() and cv.ellipse() functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_10

LANGUAGE: Python
CODE:
```
ellipse = cv.fitEllipse(cnt)
cv.ellipse(img,ellipse,(0,255,0),2)
```

----------------------------------------

TITLE: Negative Sample Description File Format
DESCRIPTION: Example of a negative sample description file (bg.txt) containing paths to background images used for training.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/traincascade.markdown#2025-04-22_snippet_1

LANGUAGE: text
CODE:
```
img/img1.jpg
img/img2.jpg
```

----------------------------------------

TITLE: Drawing a Filled Circle in Java
DESCRIPTION: Implementation of the MyFilledCircle function that draws a filled circle in OpenCV Java. The function takes the image and center point, and uses the circle() function with a negative thickness value to create a solid filled circle.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_22

LANGUAGE: java
CODE:
```
private static void MyFilledCircle(Mat img, Point center) {
    Imgproc.circle(img,
            center,
            w/32,
            new Scalar(0, 0, 255),
            Core.FILLED,
            Core.LINE_8);
}
```

----------------------------------------

TITLE: Computing 2D Object Points for Homography in OpenCV C++
DESCRIPTION: Code to project 3D object points to 2D by removing the Z coordinate. This creates a set of 2D points that can be used for homography estimation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
std::vector<cv::Point2f> objectPointsPlanar;
for (size_t i = 0; i < objectPoints.size(); ++i) {
    objectPointsPlanar.push_back(cv::Point2f(objectPoints[i].x, objectPoints[i].y));
}
```

----------------------------------------

TITLE: Test Configuration for Classification Module (Python)
DESCRIPTION: Defines the TestClsModuleConfig Python dataclass for test mode, specifying file paths, model parameters, preprocessing options, and label paths for inference. Sourced from test_config.py, dependencies include a valid Python environment and compatible data. Key fields allow fine-grained control over test datasets, preprocessing, and parameter settings. Inputs are controlled via dataclass fields; outputs impact model inference paths. Limitations come from the accuracy of file paths and correct parameterization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
@dataclass
class TestClsModuleConfig:
    cls_test_data_dir: str = "../data"
    test_module_name: str = "classification"
    test_module_path: str = "classification.py"
    input_img: str = os.path.join(cls_test_data_dir, "squirrel_cls.jpg")
    model: str = ""

    frame_height: str = str(TestClsConfig.frame_size)
    frame_width: str = str(TestClsConfig.frame_size)
    scale: str = "1.0"
    mean: List[str] = field(default_factory=lambda: ["0.0", "0.0", "0.0"])
    std: List[str] = field(default_factory=list)
    crop: str = "False"
    rgb: str = "True"
    rsz_height: str = ""
    rsz_width: str = ""
    classes: str = os.path.join(cls_test_data_dir, "dnn", "classification_classes_ILSVRC2012.txt")
```

----------------------------------------

TITLE: Loading 3D Textured Object Model - OpenCV C++
DESCRIPTION: This code snippet demonstrates how to load a 3D textured object model from a YAML file using a Model class in C++. It extracts 3D points and descriptors needed for pose estimation, utilizing OpenCV's FileStorage functionalities. Key requirements include OpenCV library and a valid path to a YAML file containing the model data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
/* Load a YAML file using OpenCV */
void Model::load(const std::string path)
{
    cv::Mat points3d_mat;

    cv::FileStorage storage(path, cv::FileStorage::READ);
    storage["points_3d"] >> points3d_mat;
    storage["descriptors"] >> descriptors_;

    points3d_mat.copyTo(list_points3d_in_);

    storage.release();
}

```

----------------------------------------

TITLE: Defining Buffer Structure for Optimized PSNR in C++
DESCRIPTION: Defines a C++ structure `BufferPSNR` intended to optimize GPU calculations by pre-allocating necessary `gpu::GpuMat` objects. This avoids expensive repeated memory allocations within functions called multiple times. It contains `GpuMat` members for input images (`gI1`, `gI2`), intermediate results (`gs`, `t1`, `t2`), and a general buffer (`buf`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
struct BufferPSNR                                     // Optimized GPU versions
  {   // Data allocations are very expensive on GPU. Use a buffer to solve: allocate once reuse later.
  gpu::GpuMat gI1, gI2, gs, t1,t2;

  gpu::GpuMat buf;
};
```

----------------------------------------

TITLE: Ratio Test Filtering in OpenCV using Java
DESCRIPTION: Java code applying a ratio test to filter matching keypoints for improved accuracy in matching using OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_10

LANGUAGE: Java
CODE:
```
samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java ratio test filtering
```

----------------------------------------

TITLE: Setting JPEG Compression Parameters in C
DESCRIPTION: This snippet shows how to set parameters for JPEG compression, including the color space. The 'cinfo.in_color_space' is set to 'JCS_RGB' to specify the colorspace and 'jpeg_set_defaults(&cinfo)' is called to initialize default settings. These settings precede the start of a compression cycle and must be configured before invoking 'jpeg_start_compress'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_5

LANGUAGE: C
CODE:
```
cinfo.in_color_space = JCS_RGB; /* colorspace of input image */
jpeg_set_defaults(&cinfo); /* Make optional parameter settings here */
```

----------------------------------------

TITLE: Classifying and Visualizing SVM Regions with OpenCV - Java
DESCRIPTION: This Java snippet uses OpenCV to train an SVM, classify pixels on a Cartesian grid, and color points according to the predicted class (green or blue). Dependencies include the OpenCV Java API and appropriate imports. It demonstrates preparing training data, setting SVM parameters, training the model, and mapping the predicted regions visually. Inputs include a 2D pixel grid and labeled sample data; outputs are colored images showing SVM classification regions and boundaries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_5

LANGUAGE: java
CODE:
```
// Training and visualizing SVM in Java with OpenCV
// ... (full code from samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java, show)
```

----------------------------------------

TITLE: Setting Environment Variables for OpenCV Android Build (Shell)
DESCRIPTION: Sets the JAVA_HOME and ANDROID_HOME environment variables required by the build scripts. These variables point to the Java Runtime Environment (often bundled with Android Studio) and the Android SDK installation directories, respectively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/android/aar-template/README.md#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
export JAVA_HOME=~/Android Studio/jbr
export ANDROID_HOME=~/Android/SDK
```

----------------------------------------

TITLE: Calculating Distance from Camera using L2 Norm in C++
DESCRIPTION: After obtaining a 3D point in the camera's coordinate system, this snippet calculates the distance from the camera's origin to the point using the L2 norm. This requires already computed translations and rotations from the solvePnP function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_square_chess/camera_calibration_square_chess.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
// assuming 'point' is the 3D position of a chessboard corner in the camera coordinate system
double distance = norm(point);
```

----------------------------------------

TITLE: Building OpenCV with Ninja
DESCRIPTION: Command to build OpenCV using Ninja build system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_15

LANGUAGE: bash
CODE:
```
ninja
```

----------------------------------------

TITLE: Initializing PnPProblem with Camera Parameters in C++
DESCRIPTION: Illustrates the declaration of the PnPProblem class by setting intrinsic camera parameters necessary for pose estimation using a webcam, including focal length and sensor dimensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_14

LANGUAGE: cpp
CODE:
```
// Intrinsic camera parameters: UVC WEBCAM

double f = 55;                           // focal length in mm
double sx = 22.3, sy = 14.9;             // sensor size
double width = 640, height = 480;        // image size

double params_WEBCAM[] = { width*f/sx,   // fx
                           height*f/sy,  // fy
```

----------------------------------------

TITLE: Evaluating Corner Detection Conditionals in C/C++
DESCRIPTION: This snippet performs a series of nested conditional checks on the values pointed to by 'ptr' at different offsets to determine if a pixel represents a corner. It compares pixel intensities against threshold values ('cb' and 'c_b') and uses goto statements to transfer control to 'is_a_corner' or 'is_not_a_corner' labels depending on the result. External dependencies include the correct initialization of 'ptr', the offset variables, and the threshold constants. It expects an array or pointer representing image data. Outputs are control flow jumps that can affect corner classification logic elsewhere.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_2

LANGUAGE: C
CODE:
```
goto is_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset8] > cb)
    if(ptr[offset9] > cb)
      if(ptr[offset10] > cb)
        if(ptr[offset11] > cb)
          if(ptr[offset12] > cb)
            if(ptr[offset13] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
if(ptr[offset14] < c_b)
  if(ptr[offset8] < c_b)
    if(ptr[offset9] < c_b)
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          if(ptr[offset12] < c_b)
            if(ptr[offset13] < c_b)
              if(ptr[offset6] < c_b)
                goto is_a_corner;
              else
                if(ptr[offset15] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset14] > cb)
    if(ptr[offset15] > cb)
      if(ptr[offset1] > cb)
        if(ptr[offset3] > cb)
          if(ptr[offset6] > cb)
            goto is_a_corner;
          else
            if(ptr[offset13] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              if(ptr[offset12] > cb)
                if(ptr[offset13] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset8] > cb)
          if(ptr[offset9] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset12] > cb)
                  if(ptr[offset13] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
if(ptr[offset5] < c_b)
  if(ptr[offset12] > cb)
    if(ptr[offset13] > cb)
      if(ptr[offset14] > cb)
        if(ptr[offset15] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              goto is_a_corner;
            else
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset8] > cb)
              if(ptr[offset9] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset7] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset9] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
  if(ptr[offset12] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset9] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset6] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset14] < c_b)
                    if(ptr[offset15] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset12] > cb)
    if(ptr[offset13] > cb)
      if(ptr[offset14] > cb)
        if(ptr[offset15] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              goto is_a_corner;
            else
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset8] > cb)
              if(ptr[offset9] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
```

----------------------------------------

TITLE: Drawing Back Projection in C++ with OpenCV
DESCRIPTION: This snippet shows how to display the back projection result using OpenCV in C++. It creates a window and shows the back projection image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
imshow("BackProj", backproj);
```

----------------------------------------

TITLE: Computing Rotation Displacement Using OpenCV in Java
DESCRIPTION: This Java snippet shows how to compute rotation displacement for the corresponding transformation between images using OpenCV. The OpenCV library needs to be included in the project. It processes images to output the rotation displacement matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_33

LANGUAGE: Java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.Mat;

public void computeRotationDisplacement(Mat image1, Mat image2) {
    // Code to compute rotation displacement
    // ...
}
```

----------------------------------------

TITLE: Creating 2D Histogram using OpenCV calcHist function
DESCRIPTION: This code demonstrates how to create a 2D histogram using OpenCV's calcHist function. It loads an image, converts it from BGR to HSV color space, and then calculates a 2D histogram of the Hue and Saturation channels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_2d_histogram/py_2d_histogram.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('home.jpg')
assert img is not None, "file could not be read, check with os.path.exists()"
hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)

hist = cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
```

----------------------------------------

TITLE: Creating and Displaying an Initial Black Image with OpenCV in C++
DESCRIPTION: Creates a black image represented by a cv::Mat object named 'image'. The image dimensions are specified by 'window_height' and 'window_width', and it uses an 8-bit, 3-channel color format (CV_8UC3). The image is then displayed in a window identified by 'window_name'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
@code{.cpp}
/// Initialize a matrix filled with zeros
Mat image = Mat::zeros( window_height, window_width, CV_8UC3 );

/// Show it in a window during DELAY ms
imshow( window_name, image );
@endcode
```

----------------------------------------

TITLE: Trackbar Callback Method in Java
DESCRIPTION: This Java snippet defines the `on_trackbar` method, which serves as the callback logic. It calculates `alpha` and `beta` based on the trackbar position `pos`, performs image blending using `Core.addWeighted`, and updates the display in the named window (`WINDOW_NAME`) using `HighGui.imshow`. Class member variables `src1`, `src2`, `dst`, `alpha`, `beta`, and `ALPHA_SLIDER_MAX` are used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_10

LANGUAGE: java
CODE:
```
//![on_trackbar]
private void on_trackbar(int pos) {
    alpha = (double) pos / ALPHA_SLIDER_MAX;
    beta = (1.0 - alpha);
    Core.addWeighted(src1, alpha, src2, beta, 0.0, dst);
    HighGui.imshow(WINDOW_NAME, dst);
}
//![on_trackbar]
```

----------------------------------------

TITLE: Upsampling an Image with cv.pyrUp in OpenCV.js
DESCRIPTION: This function signature details how to upsample an input image (`src`) to create a higher-resolution output image (`dst`). It upsamples the image and then blurs it. The `dstsize` parameter specifies the desired size for the output image (defaults to double the input dimensions if Size(0,0)). `borderType` specifies the pixel extrapolation method, with only cv.BORDER_DEFAULT being supported.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_pyramids/js_pyramids.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
cv.pyrUp (src, dst, dstsize = new cv.Size(0, 0), borderType  = cv.BORDER_DEFAULT)
```

----------------------------------------

TITLE: Trackbar Callback in OpenCV C++
DESCRIPTION: Demonstrates creating a trackbar in an OpenCV window and attaching a callback function in C++. The function is triggered when the trackbar's state changes. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
cv::createTrackbar("Trackbar", "Source", &sliderValue, maxValue, on_trackbar);
```

----------------------------------------

TITLE: Specifying Python Dependency Requirements
DESCRIPTION: This snippet lists minimum required versions for the svglib (>=1.5.1) and reportlab (>=4.0.0) Python packages. It is intended to be used with pip or similar Python package managers to ensure the correct dependencies are present. There are no parameters or code logic involved, only package specifications as prerequisites for the project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/pattern_tools/test_requirements.txt#2025-04-22_snippet_0

LANGUAGE: requirements
CODE:
```
svglib>=1.5.1\nreportlab>=4.0.0
```

----------------------------------------

TITLE: Defining the OpenCV G-API Module in CMake
DESCRIPTION: Defines the 'gapi' module using the `ocv_add_module` function. It specifies `opencv_imgproc` as a required dependency and `opencv_video` and `opencv_calib3d` as optional dependencies. It also indicates that Python wrappers should be generated for this module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
set(the_description "OpenCV G-API Core Module")

ocv_add_module(gapi
    REQUIRED
      opencv_imgproc
    OPTIONAL
      opencv_video opencv_calib3d
    WRAP
      python
)
```

----------------------------------------

TITLE: Refining ArUco Marker Detection with Board Context in C++
DESCRIPTION: Code that shows how to refine ArUco marker detection by leveraging board information. This function attempts to identify marker candidates that weren't initially detected by analyzing their position relative to the board.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_board_detection/aruco_board_detection.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
cv::Mat imageCopy;
image.copyTo(imageCopy);

// detect markers
cv::aruco::DetectorParameters detectorParams = cv::aruco::DetectorParameters();
cv::aruco::Dictionary dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);
cv::aruco::ArucoDetector detector(dictionary, detectorParams);

std::vector<int> markerIds;
std::vector<std::vector<cv::Point2f>> markerCorners, rejectedCandidates;
detector.detectMarkers(image, markerCorners, markerIds, rejectedCandidates);

// refine detected markers
cv::Ptr<cv::aruco::Board> board;
readDetectorParameters(parser.get<std::string>("cd"), board, dictionary);
detector.refineDetectedMarkers(image, board, markerCorners, markerIds, rejectedCandidates);
```

----------------------------------------

TITLE: Loading Source Image in Python
DESCRIPTION: Python snippet demonstrating how to load an image from a file using OpenCV's `cv.imread` function. The first command-line argument (accessed via `sys.argv[1]`) is expected to be the path to the image file. Includes error handling using `if src is None:` check.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Load image
```

----------------------------------------

TITLE: Defining a Compound Kernel Implementation with GAPI_COMPOUND_KERNEL (OpenCV G-API, C++)
DESCRIPTION: Defines a compound kernel implementation using the GAPI_COMPOUND_KERNEL macro to represent a high-level operation as a composition of multiple sub-kernels (subgraph). Useful for complex semantics where a single backend may map the functionality to several primitives. Requires G-API and its macro facilities. Compound implementation is backend-dependent and simplifies dispatching of multi-stage operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/doc/20-kernel-api.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
#define GAPI_COMPOUND_KERNEL(CompoundName, Interface)
// Example usage would compose a backend compound kernel for a multi-stage algorithm (e.g. goodFeaturesToTrack)
// Actual implementation will call Interface::on(...) with a sequence of lower-level kernel calls specifying the desired operation in terms of primitives
```

----------------------------------------

TITLE: Orchestrating Out-of-Focus Deblurring Process in OpenCV C++
DESCRIPTION: This is the main function demonstrating the workflow for deblurring an out-of-focus image using the Wiener filter. It handles command-line argument parsing for the input image path, PSF radius, and SNR. It loads the image, performs necessary conversions and padding, calculates the PSF and Wiener filter using helper functions, applies the filter in the frequency domain, normalizes the result, and displays both the original and the restored images. Depends on OpenCV core, imgproc, and highgui modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/out_of_focus_deblur_filter/out_of_focus_deblur_filter.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
int main(int argc, char *argv[])
{
    const char* KERNEL_USAGE = "Usage: %s [OPTIONS] image [output]\\n"
                             "EXAMPLE:\\n    %s ../data/lena.jpg 53 5200 \\n"
                             "OPTIONS:\\n"
                             "-h, --help                    : Print help message\\n"
                             "-R R                          : Radius of PSF, R > 0 (int) \\n"
                             "-SNR SNR                      : Signal-to-Noise Ratio, SNR > 0 (double)";
    const char* about = "This program demonstrates the use of the Wiener filter for image deblurring.";
    cv::CommandLineParser parser(argc, argv, KERNEL_USAGE);
    parser.about(about);
    if (parser.has("help"))
    {
        parser.printMessage();
        return 0;
    }
    int R = parser.get<int>("R");
    double SNR = parser.get<double>("SNR");
    if (R <= 0)
    {
        parser.printMessage();
        return -1;
    }
    if (SNR <= 0)
    {
        parser.printMessage();
        return -1;
    }
    String imgInFileName = parser.get<String>("@image");
    if (imgInFileName.empty())
    {
        parser.printMessage();
        return -1;
    }
    String imgOutFileName = parser.get<String>("@output");
    if (!parser.check()) {
        parser.printErrors();
        return -1;
    }

    Mat imgIn;
    imgIn = imread(samples::findFile(imgInFileName), IMREAD_GRAYSCALE);
    if (imgIn.empty()) //check whether the image is loaded or not
    {
        cout << "ERROR : Image cannot be loaded..!!" << endl;
        return -1;
    }

    Mat imgOut;

    // it needs to process even image only
    Rect roi = Rect(0, 0, imgIn.cols & -2, imgIn.rows & -2);

    //Hw calculation (start)
    Mat Hw, h;
    calcPSF(h, roi.size(), R);
    calcWnrFilter(h, Hw, 1.0 / SNR);
    //Hw calculation (stop)

    // filtering (start)
    filter2DFreq(imgIn(roi), imgOut, Hw);
    // filtering (stop)

    imgOut.convertTo(imgOut, CV_8U);
    normalize(imgOut, imgOut, 0, 255, NORM_MINMAX);

    if (!imgOutFileName.empty())
    {
        imwrite(imgOutFileName, imgOut);
    }

    imshow("original", imgIn);
    imshow("result", imgOut);

    waitKey(0);

    return 0;
}
```

----------------------------------------

TITLE: Goto-Based Corner Detection Logic C++
DESCRIPTION: This snippet features nested conditional statements using goto to classify points as corners based on pixel intensity comparisons. The algorithm depends on the values of 'ptr[offsetX]' and threshold comparisons with 'cb' or 'c_b'. It returns control either to 'is_a_corner' or 'is_not_a_corner'. Main constraints include its hard-coded logical structure and use of conditional branches, related to classical high-speed corner detection methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_5

LANGUAGE: C/C++
CODE:
```
goto is_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset3] > cb)
    if(ptr[offset4] > cb)
      if(ptr[offset5] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset7] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset1] > cb)
    if(ptr[offset12] > cb)
      if(ptr[offset13] > cb)
        if(ptr[offset14] > cb)
          if(ptr[offset15] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
if(ptr[offset9] < c_b)
  if(ptr[offset7] < c_b)
    if(ptr[offset8] < c_b)
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          if(ptr[offset6] < c_b)
            if(ptr[offset5] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset12] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset12] < c_b)
                if(ptr[offset13] < c_b)
                  if(ptr[offset14] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset12] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset0] < c_b)
    if(ptr[offset2] > cb)
      if(ptr[offset9] > cb)
        if(ptr[offset7] > cb)
          if(ptr[offset8] > cb)
            if(ptr[offset6] > cb)
              if(ptr[offset5] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset3] > cb)
                    if(ptr[offset1] > cb)
                      goto is_a_corner;
                    else
                      if(ptr[offset10] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        if(ptr[offset12] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      if(ptr[offset12] > cb)
                        if(ptr[offset13] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    if(ptr[offset12] > cb)
                      if(ptr[offset13] > cb)
                        if(ptr[offset14] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset12] > cb)
                    if(ptr[offset13] > cb)
                      if(ptr[offset14] > cb)
                        if(ptr[offset15] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
      if(ptr[offset9] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset12] < c_b)
                if(ptr[offset13] < c_b)
                  if(ptr[offset14] < c_b)
                    if(ptr[offset15] < c_b)
                      goto is_a_corner;
                    else
                      if(ptr[offset6] < c_b)
                        if(ptr[offset7] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      if(ptr[offset5] < c_b)
                        if(ptr[offset6] < c_b)
                          if(ptr[offset7] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      if(ptr[offset4] < c_b)
                        if(ptr[offset5] < c_b)
                          if(ptr[offset6] < c_b)
                            if(ptr[offset7] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
        else
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset5] < c_b)
                if(ptr[offset6] < c_b)
                  if(ptr[offset7] < c_b)
                    goto is_a_corner;

```

----------------------------------------

TITLE: Using OpenCV's Built-in Histogram Equalization Function
DESCRIPTION: This code demonstrates how to use OpenCV's built-in equalizeHist() function to perform histogram equalization. It loads a grayscale image, applies equalization, and displays the original and equalized images side by side for comparison.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_equalization/py_histogram_equalization.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
img = cv.imread('wiki.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
equ = cv.equalizeHist(img)
res = np.hstack((img,equ)) #stacking images side-by-side
cv.imwrite('res.png',res)
```

----------------------------------------

TITLE: Random Number Generator Functor for Thrust
DESCRIPTION: A functor that generates random floating-point values within a specified range. It uses the Thrust random number generator with a linear congruential engine.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_3

LANGUAGE: CUDA
CODE:
```
struct prg
{
    float a, b;

    __host__ __device__ prg(float _a=0.f, float _b=1.f) : a(_a), b(_b) {}

    __host__ __device__
    float operator()(const unsigned int n) const
    {
        thrust::default_random_engine rng;
        thrust::uniform_real_distribution<float> dist(a, b);
        rng.discard(n);
        return dist(rng);
    }
};
```

----------------------------------------

TITLE: Configuring Stream Parameters for Astra Camera Sensors
DESCRIPTION: Sets up the frame parameters for both depth and color streams to use VGA resolution (640x480), which is the maximum available for both sensors. This ensures consistent resolution between color and depth data for easier registration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
// Set stream parameters
depthStream.set(CAP_PROP_FRAME_WIDTH, 640);
depthStream.set(CAP_PROP_FRAME_HEIGHT, 480);

colorStream.set(CAP_PROP_FRAME_WIDTH, 640);
colorStream.set(CAP_PROP_FRAME_HEIGHT, 480);
```

----------------------------------------

TITLE: Configuring OpenCV Cascade Trainer Build
DESCRIPTION: CMake configuration that disables specific compiler warnings and sets up the opencv_traincascade application build with required OpenCV module dependencies. Includes all CPP source files in the current directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/traincascade/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
ocv_warnings_disable(CMAKE_CXX_FLAGS -Woverloaded-virtual -Winconsistent-missing-override -Wsuggest-override)
file(GLOB SRCS *.cpp)
ocv_add_application(opencv_traincascade
    MODULES opencv_core opencv_imgproc opencv_objdetect opencv_imgcodecs opencv_highgui opencv_calib3d opencv_features2d
    SRCS ${SRCS})
```

----------------------------------------

TITLE: Enabling OpenVINO Backend Option and Handling nGraph Dependency - CMake
DESCRIPTION: Defines an option to enable OpenVINO backend, validates nGraph presence, and adds the plugin subdirectory or required runtime libraries based on list membership. Contains logic to support OpenVINO plugin for inference acceleration using the appropriate backend. Inputs: TARGET ocv.3rdparty.openvino, DNN_PLUGIN_LIST, nGraph library flags; output: plugin inclusion or required runtime dependency determination.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_22

LANGUAGE: CMake
CODE:
```
ocv_option(OPENCV_DNN_OPENVINO "Build with OpenVINO support (2021.4+)" (TARGET ocv.3rdparty.openvino))
if(TARGET ocv.3rdparty.openvino AND OPENCV_DNN_OPENVINO)
  if(NOT HAVE_OPENVINO AND NOT HAVE_NGRAPH)
    message(FATAL_ERROR "DNN: Inference Engine is not supported without enabled 'nGraph'. Check build configuration.")
  endif()
  if("openvino" IN_LIST DNN_PLUGIN_LIST OR DNN_PLUGIN_LIST STREQUAL "all")
    # plugin doesn't support PCH, separate directory scope is necessary
    # opencv_world requires absolute path
    add_subdirectory("${CMAKE_CURRENT_LIST_DIR}/misc/plugin/openvino" "${CMAKE_CURRENT_BINARY_DIR}/dnn_plugin_openvino")
  elseif(NOT OPENCV_DNN_BUILTIN_BACKEND)
    list(APPEND dnn_runtime_libs ocv.3rdparty.openvino)
  endif()
endif()
```

----------------------------------------

TITLE: Drawing a Rectangle in Java
DESCRIPTION: Example of using the Rectangle() function in OpenCV Java to draw a filled yellow rectangle. The function specifies two opposite corners of the rectangle along with color and fill options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_28

LANGUAGE: java
CODE:
```
Rectangle(rook_image, new Point(0, 7*w/8), new Point(w, w), new Scalar(0, 255, 255), Core.FILLED, Core.LINE_8, 0);
```

----------------------------------------

TITLE: Corner Detection Conditional Logic - OpenCV C++
DESCRIPTION: Multiple nested conditional statements comparing pixel values at different offsets to determine if a point is a corner. Uses pointer arithmetic and goto statements for control flow between 'is_a_corner' and 'is_not_a_corner' states based on threshold comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_17

LANGUAGE: C++
CODE:
```
if(ptr[offset6] < c_b)
  goto is_not_a_corner;
else
  if(ptr[offset6] > cb)
    if(ptr[offset8] > cb)
      if(ptr[offset4] > cb)
        if(ptr[offset3] > cb)
          goto is_a_corner;
        else
          if(ptr[offset10] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
```

----------------------------------------

TITLE: Installing ARM Hard Float Toolchain - Bash
DESCRIPTION: Installs the gcc-arm-linux-gnueabihf package for compiling ARM binaries with hardware floating-point (hard-float) ABI. Requires apt-get and the correct repository configuration. The main parameter is the package name and the command should be executed with sudo. This is meant for targets supporting hard-float ABI.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/arm_crosscompile_with_cmake.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
sudo apt-get install gcc-arm-linux-gnueabihf
```

----------------------------------------

TITLE: Defining a Scalar Color in C++
DESCRIPTION: Creating a Scalar object to represent a BGR color in OpenCV C++. The Scalar represents a 3-element vector with Blue, Green, and Red values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
Scalar( a, b, c )
```

----------------------------------------

TITLE: Displaying Training Data for Non-Linear SVM in OpenCV
DESCRIPTION: This snippet shows how to display the training data points for non-linear SVM classification. It uses different colors to distinguish between the two classes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_13

LANGUAGE: C++
CODE:
```
for (int i = 0; i < trainData.rows; ++i)
{
    int x = (int)(trainData.at<float>(i,0) * WIDTH);
    int y = (int)(trainData.at<float>(i,1) * HEIGHT);
    if (labels.at<int>(i) == 1)
    {
        circle(res, Point(x,y), 5, Scalar(0, 100, 0), -1);
        circle(res, Point(x,y), 4, Scalar(0, 255, 0), -1);
    }
    else
    {
        circle(res, Point(x,y), 5, Scalar(100, 0, 0), -1);
        circle(res, Point(x,y), 4, Scalar(255, 0, 0), -1);
    }
}
```

LANGUAGE: Java
CODE:
```
for (int i = 0; i < trainData.rows(); i++) {
    int x = (int) (trainData.get(i, 0)[0] * WIDTH);
    int y = (int) (trainData.get(i, 1)[0] * HEIGHT);
    if (labels.get(i, 0)[0] == 1) {
        Imgproc.circle(res, new Point(x, y), 5, new Scalar(0, 100, 0), -1);
        Imgproc.circle(res, new Point(x, y), 4, new Scalar(0, 255, 0), -1);
    } else {
        Imgproc.circle(res, new Point(x, y), 5, new Scalar(100, 0, 0), -1);
        Imgproc.circle(res, new Point(x, y), 4, new Scalar(255, 0, 0), -1);
    }
}
```

LANGUAGE: Python
CODE:
```
for i in range(train_data.shape[0]):
    x = int(train_data[i,0]*WIDTH)
    y = int(train_data[i,1]*HEIGHT)
    if labels[i] == 1:
        cv.circle(res, (x,y), 5, (0, 100, 0), -1)
        cv.circle(res, (x,y), 4, (0, 255, 0), -1)
    else:
        cv.circle(res, (x,y), 5, (100, 0, 0), -1)
        cv.circle(res, (x,y), 4, (255, 0, 0), -1)
```

----------------------------------------

TITLE: Applying Black Hat Transform with OpenCV Python
DESCRIPTION: Demonstrates black hat transformation which finds the difference between the closing of input image and input image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_6

LANGUAGE: Python
CODE:
```
blackhat = cv.morphologyEx(img, cv.MORPH_BLACKHAT, kernel)
```

----------------------------------------

TITLE: Setting OpenCV C++ Sample Required Dependencies
DESCRIPTION: Defines a list of required OpenCV modules for building C++ sample projects. This includes various OpenCV components such as core, imgproc, flann, and others. These are necessary for building the samples, and their availability is checked before proceeding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(OPENCV_CPP_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_flann
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui
  opencv_ml
  opencv_video
  opencv_objdetect
  opencv_photo
  opencv_features2d
  opencv_calib3d
  opencv_stitching
  opencv_dnn
  opencv_gapi
  ${OPENCV_MODULES_PUBLIC}
  ${OpenCV_LIB_COMPONENTS})
ocv_check_dependencies(${OPENCV_CPP_SAMPLES_REQUIRED_DEPS})
```

----------------------------------------

TITLE: Saving Animation with OpenCV
DESCRIPTION: Demonstrates how to save an animation structure back to a file using cv::imwriteanimation, supporting formats like WebP, GIF, AVIF, and APNG.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/animations.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
cv::imwriteanimation("output.webp", animation);
```

LANGUAGE: Python
CODE:
```
cv.imwriteanimation("output.webp", animation)
```

----------------------------------------

TITLE: Nested Conditional Branching for Feature Detection in OpenCV
DESCRIPTION: A segment of OpenCV's feature detection algorithm showing deeply nested conditional logic. The code compares pixel values at different offsets against threshold values (cb and c_b) to determine whether to continue processing ('goto structured') or confirm a feature detection ('goto success_structured').
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_11

LANGUAGE: C/C++
CODE:
```
goto structured;
else
  goto structured;
else
  if(ptr[offset6] > cb)
    if(ptr[offset4] > cb)
      if(ptr[offset3] > cb)
        goto success_structured;
      else
        if(ptr[offset10] > cb)
          goto success_structured;
        else
          goto structured;
    else
      if(ptr[offset10] > cb)
        if(ptr[offset11] > cb)
          goto success_structured;
        else
          goto structured;
      else
        goto structured;
  else
    goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
  if(ptr[offset5] < c_b)
    if(ptr[offset9] > cb)
      if(ptr[offset3] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset11] > cb)
            if(ptr[offset1] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset2] > cb)
                    goto success_structured;
                  else
                    if(ptr[offset7] > cb)
                      goto success_structured;
                    else
                      goto structured;
                else
                  goto structured;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset2] < c_b)
                    if(ptr[offset7] < c_b)
                      if(ptr[offset8] < c_b)
                        goto success_structured;
                      else
                        goto structured;
                    else
                      goto structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset10] > cb)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset2] < c_b)
                    if(ptr[offset7] < c_b)
                      if(ptr[offset1] < c_b)
                        goto success_structured;
                      else
                        if(ptr[offset8] < c_b)
                          goto success_structured;
                        else
                          goto structured;
                    else
                      goto structured;
                  else
                    goto structured;
                else
                  goto structured;
          else
            if(ptr[offset2] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset1] < c_b)
                  if(ptr[offset6] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset8] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
              else
                goto structured;
            else
              goto structured;
        else
          if(ptr[offset11] > cb)
            if(ptr[offset8] > cb)
              if(ptr[offset10] > cb)
                if(ptr[offset1] > cb)
                  if(ptr[offset2] > cb)
                    goto success_structured;
                  else
                    if(ptr[offset7] > cb)
                      goto success_structured;
                    else
                      goto structured;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
              else
                goto structured;
            else
              goto structured;
          else
            goto structured;
      else
        if(ptr[offset11] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset1] > cb)
                if(ptr[offset2] > cb)
                  goto success_structured;
                else
                  if(ptr[offset7] > cb)
                    if(ptr[offset8] > cb)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset7] > cb)
                    if(ptr[offset8] > cb)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset8] > cb)
                if(ptr[offset1] > cb)
                  if(ptr[offset2] > cb)
                    goto success_structured;
                  else
                    if(ptr[offset7] > cb)
                      goto success_structured;
                    else
                      goto structured;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
              else
                goto structured;
          else
            goto structured;
        else
          goto structured;
    else
      if(ptr[offset9] < c_b)
        if(ptr[offset2] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset10] > cb)
                if(ptr[offset3] > cb)
                  if(ptr[offset11] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
```

----------------------------------------

TITLE: Loading Source Image in OpenCV
DESCRIPTION: Loads the input image that will be used for remapping operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/remap/remap.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
Mat src = imread( samples::findFile("chessboard.png"), IMREAD_COLOR );
```

LANGUAGE: Java
CODE:
```
Mat src = Imgcodecs.imread(samplesDir + "/chessboard.png");
```

LANGUAGE: Python
CODE:
```
src = cv.imread(cv.samples.findFile("chessboard.png"))
```

----------------------------------------

TITLE: Constructing Rect Structures in OpenCV.js (JavaScript)
DESCRIPTION: Shows two standard ways to create a Rect: via the cv.Rect constructor and via an object literal with x, y, width, and height. These define rectangles by their top-left corner and dimensions. Needs OpenCV.js and coordinate/size values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_4

LANGUAGE: JavaScript
CODE:
```
// The first way
let rect = new cv.Rect(x, y, width, height);
// The second way
let rect = {x : x, y : y, width : width, height : height};
```

----------------------------------------

TITLE: C-Style Formatting for OpenCV Mat Output in C++
DESCRIPTION: Demonstrates formatting OpenCV Mat output using C-style syntax with the format() method and FormatC flag.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_14

LANGUAGE: C++
CODE:
```
cout << "R (c) = " << endl << format(R, Formatter::FMT_C) << endl << endl;
```

----------------------------------------

TITLE: Configuring OpenCV Installation Options in CMake
DESCRIPTION: This snippet defines CMake options for configuring the installation of OpenCV. It includes options for installing examples, documentation, and controlling installation paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
OCV_OPTION(INSTALL_CREATE_DISTRIB   "Change install rules to build the distribution package" OFF )
OCV_OPTION(INSTALL_BIN_EXAMPLES     "Install prebuilt examples" WIN32 IF BUILD_EXAMPLES)
OCV_OPTION(INSTALL_C_EXAMPLES       "Install C examples"        OFF )
OCV_OPTION(INSTALL_PYTHON_EXAMPLES  "Install Python examples"   OFF )
OCV_OPTION(INSTALL_ANDROID_EXAMPLES "Install Android examples"  OFF IF ANDROID )
OCV_OPTION(INSTALL_TO_MANGLED_PATHS "Enables mangled install paths, that help with side by side installs." OFF IF (UNIX AND NOT ANDROID AND NOT APPLE_FRAMEWORK AND BUILD_SHARED_LIBS) )
OCV_OPTION(INSTALL_TESTS            "Install accuracy and performance test binaries and test data" OFF)
```

----------------------------------------

TITLE: Create and Display Windows with OpenCV C++
DESCRIPTION: This snippet shows how to create an OpenCV window and display an image in it using C++. Requires OpenCV 3.0 or higher.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cv::namedWindow("Source", cv::WINDOW_AUTOSIZE);
cv::imshow("Source", src);
```

----------------------------------------

TITLE: Building OpenCV Shared AAR for Android (Python Command)
DESCRIPTION: Executes the Python script `build_java_shared_aar.py` to create an AAR package containing OpenCV Java bindings and the shared C++ library (.so files). Requires the path to the downloaded OpenCV Android SDK as an argument. The output AAR and Maven repository will be generated in the 'outputs' directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/android/aar-template/README.md#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
python build_java_shared_aar.py "~/opencv-4.7.0-android-sdk/OpenCV-android-sdk"
```

----------------------------------------

TITLE: Using Sobel and Scharr Derivatives with OpenCV.js - JavaScript
DESCRIPTION: These snippets demonstrate how to compute first-order image gradients using the cv.Sobel and cv.Scharr functions in OpenCV.js. Required dependencies include OpenCV.js properly loaded and initialized in your JavaScript environment. Core parameters include the input and output image matrices, image depth, derivative orders in the x and y directions, and kernel size or scaling factors. The expected input is an image matrix; the output is an image matrix representing the first derivative response, with kernel size and datatype restrictions as specified.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_gradients/js_gradients.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
cv.Sobel(src, dst, ddepth, dx, dy, ksize = 3, scale = 1, delta = 0, borderType = cv.BORDER_DEFAULT);
```

LANGUAGE: javascript
CODE:
```
cv.Scharr(src, dst, ddepth, dx, dy, scale = 1, delta = 0, borderType = cv.BORDER_DEFAULT);
```

----------------------------------------

TITLE: Finding OpenCV Library Paths and Linker Flags using pkg-config in Bash
DESCRIPTION: This Bash command uses `pkg-config` to determine the linker flags required for linking against OpenCV libraries. It provides the library search paths (`-L` flags) and the specific libraries to link against (`-l` flags), which are needed for the linker settings in Eclipse.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
pkg-config --libs opencv
```

----------------------------------------

TITLE: Setting Input Blob for Network in C++
DESCRIPTION: This snippet highlights how to set the prepared blob as the input to the neural network. Passing the formatted input blob allows the network to perform the necessary forward passes for inference.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
@snippet dnn/classification.cpp Set input blob
```

----------------------------------------

TITLE: Implementing AGAST-5-8 Corner Detector in OpenCV (C++)
DESCRIPTION: This snippet is the implementation of the AGAST_5_8 function, which detects corners in a grayscale image using the AGAST accelerated segment test approach. It operates by iteratively evaluating pixel neighborhoods in an input image, utilizing pointer arithmetic and multiple offset comparisons to efficiently check for corner-like structures based on a threshold. Dependencies include OpenCV data structures (Mat, InputArray, KeyPoint) and prior definition of makeAgastOffsets and AgastFeatureDetector. Inputs are the image, output vector for keypoints, and a threshold; it outputs a list of detected keypoints. The snippet assumes input is single-channel and image data is continuous or can be cloned for continuity.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include "precomp.hpp"
#include "agast_score.hpp"

#ifdef _MSC_VER
#pragma warning( disable : 4127 )
#endif

namespace cv
{

static void AGAST_5_8(InputArray _img, std::vector<KeyPoint>& keypoints, int threshold)
{

    cv::Mat img;
    if(!_img.getMat().isContinuous())
      img = _img.getMat().clone();
    else
      img = _img.getMat();

    size_t total = 0;
    int xsize = img.cols;
    int ysize = img.rows;
    size_t nExpectedCorners = keypoints.capacity();
    int x, y;
    int xsizeB = xsize - 2;
    int ysizeB = ysize - 1;
    int width;

    keypoints.resize(0);

    int pixel_5_8_[16];
    makeAgastOffsets(pixel_5_8_, (int)img.step, AgastFeatureDetector::AGAST_5_8);

    short offset0 = (short) pixel_5_8_[0];
    short offset1 = (short) pixel_5_8_[1];
    short offset2 = (short) pixel_5_8_[2];
    short offset3 = (short) pixel_5_8_[3];
    short offset4 = (short) pixel_5_8_[4];
    short offset5 = (short) pixel_5_8_[5];
    short offset6 = (short) pixel_5_8_[6];
    short offset7 = (short) pixel_5_8_[7];

    width = xsize;

    for(y = 1; y < ysizeB; y++)
    {
        x = 0;
        while(true)
        {
          homogeneous:
          {
            x++;
            if(x > xsizeB)
                break;
            else
            {
                const unsigned char* const ptr = img.ptr() + y*width + x;
                const int cb = *ptr + threshold;
                const int c_b = *ptr - threshold;
                if(ptr[offset0] > cb)
                  if(ptr[offset2] > cb)
                    if(ptr[offset3] > cb)
                      if(ptr[offset5] > cb)
                        if(ptr[offset1] > cb)
                          if(ptr[offset4] > cb)
                            goto success_structured;
                          else
                            if(ptr[offset7] > cb)
                              goto success_structured;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset4] > cb)
                            if(ptr[offset6] > cb)
                              goto success_structured;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        if(ptr[offset1] > cb)
                          if(ptr[offset4] > cb)
                            goto success_homogeneous;
                          else
                            if(ptr[offset7] > cb)
                              goto success_homogeneous;
                            else
                              goto homogeneous;
                        else
                          goto homogeneous;
                    else
                      if(ptr[offset7] > cb)
                        if(ptr[offset6] > cb)
                          if(ptr[offset5] > cb)
                            if(ptr[offset1] > cb)
                              goto success_structured;
                            else
                              if(ptr[offset4] > cb)
                                goto success_structured;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset1] > cb)
                              goto success_homogeneous;
                            else
                              goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        if(ptr[offset5] < c_b)
                          if(ptr[offset3] < c_b)
                            if(ptr[offset7] < c_b)
                              if(ptr[offset4] < c_b)
                                if(ptr[offset6] < c_b)
                                  goto success_structured;
                                else
                                  goto structured;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                  else
                    if(ptr[offset5] > cb)
                      if(ptr[offset7] > cb)
                        if(ptr[offset6] > cb)
                          if(ptr[offset1] > cb)
                            goto success_homogeneous;
                          else
                            if(ptr[offset4] > cb)
                              goto success_homogeneous;
                            else
                              goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        goto homogeneous;
                    else
                      if(ptr[offset5] < c_b)
                        if(ptr[offset3] < c_b)
                          if(ptr[offset2] < c_b)
                            if(ptr[offset1] < c_b)
                              if(ptr[offset4] < c_b)
                                goto success_structured;
                              else
                                goto homogeneous;
                            else
                              if(ptr[offset4] < c_b)
                                if(ptr[offset6] < c_b)
                                  goto success_structured;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset7] < c_b)
                              if(ptr[offset4] < c_b)
                                if(ptr[offset6] < c_b)
                                  goto success_structured;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        goto homogeneous;
                else
                if(ptr[offset0] < c_b)
                  if(ptr[offset2] < c_b)
                    if(ptr[offset7] > cb)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset5] < c_b)
                          if(ptr[offset1] < c_b)
                            if(ptr[offset4] < c_b)
                              goto success_structured;
                            else
                              goto structured;
                          else
                            if(ptr[offset4] < c_b)
                              if(ptr[offset6] < c_b)
                                goto success_structured;
                              else
                                goto structured;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset1] < c_b)
                            if(ptr[offset4] < c_b)
                              goto success_structured;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        if(ptr[offset5] > cb)
                          if(ptr[offset3] > cb)
                            if(ptr[offset4] > cb)
                              if(ptr[offset6] > cb)
                                goto success_structured;
                              else
                                goto structured;
                            else
                              goto homogeneous;
                          else
```

----------------------------------------

TITLE: Calculating Back Projection with OpenCV in Java
DESCRIPTION: This Java sample shows the equivalent process: reading an image, converting it to HSV, extracting the Hue channel, providing GUI controls for bin count, and computing the histogram and back projection using OpenCV Java bindings. Required dependencies are OpenCV for Java. Inputs are user-supplied images, and the outputs are GUI windows for visualization. The number of histogram bins is the main adjustable parameter. The code leverages Imgproc.cvtColor, Core.mixChannels, Imgproc.calcHist, and Imgproc.calcBackProject. User adjustments are propagated via a trackbar listener.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
// Read the input image\nMat src = Imgcodecs.imread(filename);\nif (src.empty()) {\n    System.out.println(\"Could not open or find the image!\");\n    return;\n}\n
```

LANGUAGE: Java
CODE:
```
// Transform to HSV\nMat hsv = new Mat();\nImgproc.cvtColor(src, hsv, Imgproc.COLOR_BGR2HSV);\n
```

LANGUAGE: Java
CODE:
```
// Use only the Hue value\nList<Mat> hsvList = Arrays.asList(hsv);\nMat hue = new Mat(hsv.rows(), hsv.cols(), CvType.CV_8UC1);\nCore.mixChannels(hsvList, Arrays.asList(hue), new MatOfInt(0, 0));\n
```

LANGUAGE: Java
CODE:
```
// Set up Trackbar for bins (with GUI slider)\nJSlider binsSlider = new JSlider(2, 180, 30);\nbinsSlider.addChangeListener(e -> Hist_and_Backproj());\n
```

LANGUAGE: Java
CODE:
```
// Show Image and wait for user\nHighGui.imshow(\"Source image\", src);\nHighGui.waitKey();\n
```

LANGUAGE: Java
CODE:
```
// Initialize histogram parameters for callback\nvoid Hist_and_Backproj() {\n    int histSize = Math.max(bins, 2);\n    float[] hueRange = {0, 180};\n    // ... hist/backproj logic\n}\n
```

LANGUAGE: Java
CODE:
```
// Calculate histogram and normalize\nImgproc.calcHist(Arrays.asList(hue), new MatOfInt(0), new Mat(), hist, new MatOfInt(histSize), new MatOfFloat(hueRange));\nCore.normalize(hist, hist, 0, 255, Core.NORM_MINMAX);\n
```

LANGUAGE: Java
CODE:
```
// Backprojection\nImgproc.calcBackProject(Arrays.asList(hue), new MatOfInt(0), hist, backproj, new MatOfFloat(hueRange), 1);\n
```

----------------------------------------

TITLE: Writing and Reading Primitive Types to XML/YAML/JSON - OpenCV C++
DESCRIPTION: This C++ snippet shows how to write primitive types (text, numbers) to XML/YAML/JSON files with OpenCV's FileStorage. The << operator is used to insert both the name and value. Reading is performed via the FileStorage's [] operator or the >> operator. Requires OpenCV and <opencv2/core.hpp>. Key parameters include the entry name and the variable for output or input.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
FileStorage fs("test.yml", FileStorage::WRITE);\nint number = 5;\nfs << "number" << number;\nfs.release();\n\nfs.open("test.yml", FileStorage::READ);\nint read_number;\nfs["number"] >> read_number;\nfs.release();
```

----------------------------------------

TITLE: Setting Up Gradle Wrapper for Android Tests in CMake
DESCRIPTION: Copies Gradle wrapper files and configures the wrapper properties for the Android test project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/android_test/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
file(COPY "${OpenCV_SOURCE_DIR}/platforms/android/gradle-wrapper/gradlew" DESTINATION "${OPENCV_ANDROID_TEST_DIR}")
file(COPY "${OpenCV_SOURCE_DIR}/platforms/android/gradle-wrapper/gradlew.bat" DESTINATION "${OPENCV_ANDROID_TEST_DIR}")
file(COPY "${OpenCV_SOURCE_DIR}/platforms/android/gradle-wrapper/gradle/wrapper/gradle-wrapper.jar" DESTINATION "${OPENCV_ANDROID_TEST_DIR}/gradle/wrapper")

configure_file("${OpenCV_SOURCE_DIR}/platforms/android/gradle-wrapper/gradle/wrapper/gradle-wrapper.properties.in" "${OPENCV_ANDROID_TEST_DIR}/gradle/wrapper/gradle-wrapper.properties" @ONLY)
```

----------------------------------------

TITLE: Initializing Face Detector (FaceDetectorYN) - OpenCV DNN Python
DESCRIPTION: This snippet demonstrates how to initialize the cv2.FaceDetectorYN class in Python, specifying model path, input size, score threshold, and other parameters. It requires OpenCV (cv2), and an ONNX model for face detection. The result is a FaceDetectorYN object ready for detecting faces in images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
# Initialize FaceDetectorYN
detector = cv2.FaceDetectorYN_create(
    modelPath,                # Path to face detection .onnx model
    "",                       # No config file
    (320, 320),               # Input size
    score_threshold=0.9,      # Detection threshold
    nms_threshold=0.3,        # Non-max suppression threshold
    top_k=5000                # Maximum number of detections
)
```

----------------------------------------

TITLE: Drawing Polygon with OpenCV in Python
DESCRIPTION: Creates a small yellow polygon with four vertices using the cv.polylines() function, showing how to work with arrays of points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)
pts = pts.reshape((-1,1,2))
cv.polylines(img,[pts],True,(0,255,255))
```

----------------------------------------

TITLE: Declaring Variable-Sized SIMD Registers in OpenCV Intrinsics (C++)
DESCRIPTION: This snippet demonstrates how to declare a variable-sized SIMD register using OpenCV's universal intrinsics—specifically, a register for 8-bit unsigned integers—and retrieve its lane count. No external dependencies are required beyond OpenCV's core HAL intrin module. The register type (e.g., v_uint8) automatically adapts to the available hardware SIMD width. 'nlanes' gives the number of elements, and should be queried instead of hardcoding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
v_uint8 a;                            // a is a register supporting uint8(char) data
int n = a.nlanes;                     // n holds 32
```

----------------------------------------

TITLE: Installing Dependencies from requirements.txt - Console
DESCRIPTION: Installs all Python package dependencies listed in a provided requirements.txt file into the currently activated virtual environment. This ensures all necessary libraries for TensorFlow to OpenCV conversion are available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_1

LANGUAGE: console
CODE:
```
pip install -r requirements.txt
```

----------------------------------------

TITLE: Calculating Image Moments using OpenCV Python
DESCRIPTION: Using Python, this snippet demonstrates the application of OpenCV functions like moments, contourArea, and arcLength for shape analysis in images. Python with OpenCV 3.0 or higher is needed. The script processes input images to extract contours and outputs computed moments and related shape descriptors.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/moments/moments.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import cv2
# Original code can be found at the mentioned OpenCV repository
```

----------------------------------------

TITLE: Defining a Custom Data Structure Class for File I/O - OpenCV Python
DESCRIPTION: This Python class illustrates how to define a custom data structure (MyData) suitable for manual serialization with OpenCV FileStorage. Data members are initialized to zeros or empty strings. Additional methods should be added to support reading and writing to FileStorage. Requires only built-in Python features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_12

LANGUAGE: Python
CODE:
```
class MyData:\n    def __init__(self):\n        self.A = self.X = 0\n        self.name = ''
```

----------------------------------------

TITLE: Configuring OpenCV TBB Parallel Plugin Build in CMake
DESCRIPTION: Sets up CMake project configuration for OpenCV's TBB parallel processing plugin. Defines minimum CMake version, configures project paths, enables TBB support, and creates the plugin using OpenCV's plugin system. Requires CMake 3.5+ and TBB dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/misc/plugins/parallel_tbb/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.5)
project(opencv_core_parallel_tbb CXX)

get_filename_component(OpenCV_SOURCE_DIR "${CMAKE_CURRENT_LIST_DIR}/../../../../.." ABSOLUTE)
include("${OpenCV_SOURCE_DIR}/cmake/OpenCVPluginStandalone.cmake")

# scan dependencies
set(WITH_TBB ON)
include("${OpenCV_SOURCE_DIR}/modules/core/cmake/parallel/init.cmake")

message(STATUS "TBB: ver ${TBB_VERSION_MAJOR}.${TBB_VERSION_MINOR} interface ${TBB_INTERFACE_VERSION}")
ocv_create_plugin(core "opencv_core_parallel_tbb" "ocv.3rdparty.tbb" "TBB" "src/parallel/parallel_tbb.cpp")
```

----------------------------------------

TITLE: ABI and Flexible Page Size Linker Flags for Android - CMake
DESCRIPTION: This snippet adds linker flags to support 16k memory pages on ARM64 and x86_64 Android ABIs when required. It checks for the ANDROID_SUPPORT_FLEXIBLE_PAGE_SIZES condition and appropriately appends -Wl,-z,max-page-size=16384 to the shared linker flags for supported ABIs. Prerequisites: NDK configuration, possibly prior to NDK 27. Inputs: system variables; Outputs: modified linker flags to ensure compatibility with larger memory pages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-4-opencl/jni/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
# For 16k pages support with NDK prior 27
# Details: https://developer.android.com/guide/practices/page-sizes?hl=en
if(ANDROID_SUPPORT_FLEXIBLE_PAGE_SIZES)
  if(ANDROID_ABI STREQUAL arm64-v8a OR ANDROID_ABI STREQUAL x86_64)
    set(CMAKE_SHARED_LINKER_FLAGS "${CMAKE_SHARED_LINKER_FLAGS} -Wl,-z,max-page-size=16384")
  endif()
endif()

```

----------------------------------------

TITLE: Changing RANSAC Parameters via Command Line in C++
DESCRIPTION: Demonstrates command-line instruction to adjust RANSAC parameters like error, confidence, iterations, and PnP method in a C++ application.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_20

LANGUAGE: cpp
CODE:
```
./cpp-tutorial-pnp_detection --error=0.25 --confidence=0.90 --iterations=250 --method=3
```

----------------------------------------

TITLE: Utilizing cv Namespace in OpenCV C++
DESCRIPTION: This snippet demonstrates accessing OpenCV classes and functions using the `cv` namespace in C++ code. Dependencies include the `opencv2/core.hpp` header. It shows how to define and use the `cv::Mat` class and functions by importing the namespace with `using namespace cv;` or specifying it explicitly with `cv::`. Key parameters include the `cv::RANSAC` parameter in `cv::findHomography`, used for robust homography estimation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include "opencv2/core.hpp"
...
cv::Mat H = cv::findHomography(points1, points2, cv::RANSAC, 5);
...
```

LANGUAGE: cpp
CODE:
```
    #include "opencv2/core.hpp"
    using namespace cv;
    ...
    Mat H = findHomography(points1, points2, RANSAC, 5 );
    ...
```

LANGUAGE: cpp
CODE:
```
    Mat a(100, 100, CV_32F);
    randu(a, Scalar::all(1), Scalar::all(std::rand()));
    cv::log(a, a);
    a /= std::log(2.);
```

----------------------------------------

TITLE: Estimating Homography using OpenCV's findHomography - C++
DESCRIPTION: This C++ code sample uses OpenCV’s findHomography to calculate the transformation matrix that maps corresponding points between two images. Dependencies include OpenCV C++ with matched point sets as input, resulting in a 3x3 homography matrix. The snippet is essential for geometric transforms in later steps.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_11

LANGUAGE: cpp
CODE:
```
@snippet perspective_correction.cpp estimate-homography
```

----------------------------------------

TITLE: Gradient Structure Tensor Calculation in C++
DESCRIPTION: The code implements anisotropic image segmentation using gradient structure tensor in C++. Dependencies include OpenCV library. The main parts are calculating orientation and coherency, thresholding orientation and coherency, and combining the results. Inputs are the image data and window size, and the output is segmented image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/anisotropic_image_segmentation/anisotropic_image_segmentation.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
@add_toggle_cpp
    @include cpp/tutorial_code/ImgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.cpp
@end_toggle
```

LANGUAGE: C++
CODE:
```
@add_toggle_cpp
    @snippet samples/cpp/tutorial_code/ImgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.cpp main
@end_toggle
```

LANGUAGE: C++
CODE:
```
@add_toggle_cpp
    @snippet samples/cpp/tutorial_code/ImgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.cpp calcGST
@end_toggle
```

LANGUAGE: C++
CODE:
```
@add_toggle_cpp
    @snippet samples/cpp/tutorial_code/ImgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.cpp thresholding
@end_toggle
```

LANGUAGE: C++
CODE:
```
@add_toggle_cpp
    @snippet samples/cpp/tutorial_code/ImgProc/anisotropic_image_segmentation/anisotropic_image_segmentation.cpp combining
@end_toggle
```

----------------------------------------

TITLE: Translating Images in OpenCV Python
DESCRIPTION: Shows how to shift an image's position using a translation matrix and cv.warpAffine(). This example shifts the image by 100 pixels horizontally and 50 pixels vertically, creating the transformation matrix using numpy.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
rows,cols = img.shape

M = np.float32([[1,0,100],[0,1,50]])
dst = cv.warpAffine(img,M,(cols,rows))

cv.imshow('img',dst)
cv.waitKey(0)
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Implementing SURF Feature Detection and Homography Matching in Python
DESCRIPTION: This Python code demonstrates how to use SURF features and FLANN matching to detect a known object in an image. It uses cv2.findHomography to estimate the transformation and cv2.perspectiveTransform to map points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_homography/feature_homography.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\n\nMIN_MATCH_COUNT = 10\n\nimg1 = cv.imread(cv.samples.findFile('box.png'), cv.IMREAD_GRAYSCALE)  # queryImage\nimg2 = cv.imread(cv.samples.findFile('box_in_scene.png'), cv.IMREAD_GRAYSCALE)  # trainImage\n\n# Initiate SIFT detector\nsift = cv.SIFT_create()\n\n# find the keypoints and descriptors with SIFT\nkp1, des1 = sift.detectAndCompute(img1,None)\nkp2, des2 = sift.detectAndCompute(img2,None)\n\nFLANN_INDEX_KDTREE = 1\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks = 50)\n\nflann = cv.FlannBasedMatcher(index_params, search_params)\n\nmatches = flann.knnMatch(des1,des2,k=2)\n\n# store all the good matches as per Lowe's ratio test.\ngood = []\nfor m,n in matches:\n    if m.distance < 0.7*n.distance:\n        good.append(m)\n\nif len(good)>MIN_MATCH_COUNT:\n    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n\n    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n    matchesMask = mask.ravel().tolist()\n\n    h,w = img1.shape\n    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n    dst = cv.perspectiveTransform(pts,M)\n\n    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n\nelse:\n    print( \"Not enough matches are found - {}/{}\"\\\n        .format(len(good), MIN_MATCH_COUNT) )\n    matchesMask = None\n\ndraw_params = dict(matchColor = (0,255,0), # draw matches in green color\n                   singlePointColor = None,\n                   matchesMask = matchesMask, # draw only inliers\n                   flags = 2)\n\nimg3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n\nplt.imshow(img3, 'gray'),plt.show()\n
```

----------------------------------------

TITLE: Detecting Keypoints with AKAZE in OpenCV using Java
DESCRIPTION: Java snippet utilizing OpenCV to create an AKAZE object, detect keypoints, and compute the corresponding descriptors for the images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_4

LANGUAGE: Java
CODE:
```
samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java AKAZE
```

----------------------------------------

TITLE: Selecting Best Match Location Based on Method (Java)
DESCRIPTION: Selects the best match location depending on the chosen `match_method`. If the method is `TM_SQDIFF` or `TM_SQDIFF_NORMED`, the location corresponding to the minimum value (`mmr.minLoc`) is chosen. Otherwise, the location of the maximum value (`mmr.maxLoc`) is used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_32

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java match_loc
```

----------------------------------------

TITLE: Initializing OpenCV Matrices with C++11 Initializer Lists
DESCRIPTION: Creates matrices using C++11 initializer lists, which provides a more modern and concise syntax for matrix initialization. Requires C++11 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
// for small matrices, it's also possible to use initializer list (C++11)
Mat C_ = (Mat_<double>({0, -1, 0, -1, 5, -1, 0, -1, 0})).reshape(3);
cout << "C_ = " << endl << " " << C_ << endl << endl;
```

----------------------------------------

TITLE: Drawing Circle with OpenCV in Python
DESCRIPTION: Draws a filled red circle inside the previously drawn rectangle using the cv.circle() function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
cv.circle(img,(447,63), 63, (0,0,255), -1)
```

----------------------------------------

TITLE: Running the SBT Project (Bash)
DESCRIPTION: This Bash command uses SBT to compile and run the Java application defined in the project. `sbt run` compiles the source code (if necessary) and then executes the main class found in the project (in this case, `HelloOpenCV`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_16

LANGUAGE: bash
CODE:
```
sbt run
```

----------------------------------------

TITLE: Configuring Objective-C Bindings and Build Targets - CMake
DESCRIPTION: This CMake script configures the build system for Objective-C bindings in the OpenCV library. It conditionally adds the 'generator' subdirectory for code/documentation generation when 'OPENCV_INITIAL_PASS' is set, and exits early if not building an Apple framework. It sets the module description, registers the Objective-C bindings module with relevant dependencies, and defines a custom build target for the Objective-C framework, ensuring dependency order with 'gen_opencv_objc_source'. Dependencies include the Objective-C environment, OpenCV core components, and proper CMake setup. Inputs primarily are CMake variables and OpenCV build infrastructure, and outputs are configured build targets and modules. The code assumes a compatible CMake and Apple build setup; usage in other contexts may be limited.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(OPENCV_INITIAL_PASS)
  # generator for Objective-C source code and documentation signatures
  add_subdirectory(generator)
endif()

if(NOT APPLE_FRAMEWORK)
  return()
endif()

set(the_description "The Objective-C bindings")
ocv_add_module(objc BINDINGS opencv_core opencv_imgproc PRIVATE_REQUIRED opencv_objc_bindings_generator)

add_custom_target(${the_module}
    ALL
    COMMENT "Objective-C framework"
)
add_dependencies(${the_module} gen_opencv_objc_source)

#include(${CMAKE_CURRENT_SOURCE_DIR}/common.cmake)
```

----------------------------------------

TITLE: Displaying Status Text Overlays on Images using OpenCV putText in C++
DESCRIPTION: This C++ snippet reference indicates code that utilizes the OpenCV `cv::putText` function to overlay informational text onto the output image, providing feedback to the user about the current state of the camera calibration application.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp output_text
```

----------------------------------------

TITLE: Running the Compiled OpenCV Executable from the Command Line in Bash
DESCRIPTION: This sequence of Bash commands demonstrates how to run the compiled `DisplayImage` executable from the terminal. It changes the directory to the project's root, then to the source folder (`cd src`) containing the executable, and finally executes the program (`./DisplayImage`), passing the relative path to an image file (`../images/HappyLittleFish.png`) as a command-line argument.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
cd <DisplayImage_directory>
cd src
./DisplayImage ../images/HappyLittleFish.png
```

----------------------------------------

TITLE: Treating Compiler Warnings as Errors in OpenCV Builds (CMake)
DESCRIPTION: With this CMake setting, all compiler warnings will be treated as errors, causing the build to halt on any warning. Use -DOPENCV_WARNINGS_ARE_ERRORS=ON to activate. This option has no prerequisites but is intended for environments where code quality is strictly enforced.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_26

LANGUAGE: cmake
CODE:
```
OPENCV_WARNINGS_ARE_ERRORS
```

----------------------------------------

TITLE: Standard Maven Build Command for OpenCV
DESCRIPTION: Basic Maven command to clean the project directory and install OpenCV packages. Used on all architectures to initiate the build process after setting up required environment variables.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/maven/README.md#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
mvn clean install
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree Implementation in C++
DESCRIPTION: Implementation of the FAST corner detection algorithm using a series of nested conditionals to check pixel values around a candidate point. The code compares pixel values at different offsets against threshold values (cb and c_b) to determine if a point is a corner or not, using goto statements for early termination.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_11

LANGUAGE: C++
CODE:
```
else
  goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset2] < c_b)
      if(ptr[offset7] < c_b)
        if(ptr[offset8] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset6] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset10] > cb)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset6] < c_b)
      if(ptr[offset2] < c_b)
        if(ptr[offset7] < c_b)
          if(ptr[offset1] < c_b)
            goto is_a_corner;
          else
            if(ptr[offset8] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset2] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset1] < c_b)
        if(ptr[offset6] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset8] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset11] > cb)
    if(ptr[offset8] > cb)
      if(ptr[offset10] > cb)
        if(ptr[offset1] > cb)
          if(ptr[offset2] > cb)
            goto is_a_corner;
          else
            if(ptr[offset7] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset7] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset11] > cb)
    if(ptr[offset10] > cb)
      if(ptr[offset3] > cb)
        if(ptr[offset1] > cb)
          if(ptr[offset2] > cb)
            goto is_a_corner;
          else
            if(ptr[offset7] > cb)
              if(ptr[offset8] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset7] > cb)
              if(ptr[offset8] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset8] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset2] > cb)
              goto is_a_corner;
            else
              if(ptr[offset7] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset7] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset9] < c_b)
    if(ptr[offset2] > cb)
      if(ptr[offset1] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset11] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset11] < c_b)
                    if(ptr[offset10] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset7] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset4] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset7] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        if(ptr[offset7] < c_b)
```

----------------------------------------

TITLE: Defining an HTML Canvas for Output (HTML)
DESCRIPTION: Shows the HTML code required to add a `<canvas>` element to the web page. This canvas, identified by `id="outputCanvas"`, serves as the target for displaying image data processed by OpenCV.js using functions like `cv.imshow()`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_usage/js_usage.markdown#2025-04-22_snippet_4

LANGUAGE: html
CODE:
```
<canvas id="outputCanvas"></canvas>
```

----------------------------------------

TITLE: Command Line Parameters for ArUco Board Detection in C++
DESCRIPTION: Defines the command line parameters for the ArUco board detection sample. These parameters allow specifying board dimensions, input sources, and camera calibration data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_board_detection/aruco_board_detection.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
const char* keys  =
        "{w        |       | Number of squares in X direction }"
        "{h        |       | Number of squares in Y direction }"
        "{l        |       | Marker side length (in pixels) }"
        "{s        |       | Separation between two consecutive markers in the grid (in pixels)}"
        "{d        |       | dictionary: DICT_4X4_50=0, DICT_4X4_100=1, DICT_4X4_250=2,"
        "  DICT_4X4_1000=3, DICT_5X5_50=4, DICT_5X5_100=5, DICT_5X5_250=6, DICT_5X5_1000=7, "
        "  DICT_6X6_50=8, DICT_6X6_100=9, DICT_6X6_250=10, DICT_6X6_1000=11, DICT_7X7_50=12,"
        "  DICT_7X7_100=13, DICT_7X7_250=14, DICT_7X7_1000=15, DICT_ARUCO_ORIGINAL = 16}"
        "{cd       |       | File of custom detector parameters}"
        "{c        |       | Output file with calibrated camera parameters }"
        "{v        |       | Input from video file, if empty input comes from camera }"
        "{ci       | 0     | Camera id if input doesnt come from video (-v) }"
        "{dp       |       | File of marker detector parameters }"
        "{rs       | false | Apply refind strategy }"
        "{r        |       | show rejected candidates too }"
        "{refine   |       | Corner refinement: CORNER_REFINE_NONE=0, CORNER_REFINE_SUBPIX=1,"
        "CORNER_REFINE_CONTOUR=2, CORNER_REFINE_APRILTAG=3}"
        "{} ";
```

----------------------------------------

TITLE: Initializing SVM Parameters
DESCRIPTION: Sets up SVM configuration including kernel type, SVM type and termination criteria.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
Ptr<SVM> svm = SVM::create();
svm->setType(SVM::C_SVC);
svm->setKernel(SVM::LINEAR);
svm->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER, 100, 1e-6));
```

----------------------------------------

TITLE: Input Image Preprocessing with blobFromImage - C++
DESCRIPTION: This C++ code performs image resizing and pixel normalization using OpenCV's functions. The frame is optionally resized, converted into a 4D blob, and divided by per-channel standard deviation. This ensures that model inputs match the normalization and preprocessing pipeline used during PyTorch training and ONNX export. Required parameters include frame, desired dimension, mean, std, and scale values for correct normalization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_11

LANGUAGE: cpp
CODE:
```
if (rszWidth != 0 && rszHeight != 0)\n{\n    resize(frame, frame, Size(rszWidth, rszHeight));\n}\n\n// Create a 4D blob from a frame\nblobFromImage(frame, blob, scale, Size(inpWidth, inpHeight), mean, swapRB, crop);\n\n// Check std values.\nif (std.val[0] != 0.0 && std.val[1] != 0.0 && std.val[2] != 0.0)\n{\n    // Divide blob by std.\n    divide(blob, std, blob);\n}
```

----------------------------------------

TITLE: Library Target and Dependency Linking for JNI - CMake
DESCRIPTION: This segment adds include directories, defines the JNI shared library, and links it to OpenCV, and mandatory Android system libraries (GLESv2, EGL, log). It conditionally includes and links OpenCL if found, or sets up custom OpenCL paths if provided. Inputs: discovered or user-specified paths; Outputs: properly linked, configured JNI library that can use OpenCV, Android, and optionally OpenCL APIs. Constraints: OpenCL support is enabled based on availability, and extra defines are added as needed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-4-opencl/jni/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
include_directories("${CMAKE_CURRENT_LIST_DIR}")
add_library(${target} SHARED ${srcs} ${hdrs})

target_link_libraries(${target} ${ANDROID_OPENCV_COMPONENTS} -lGLESv2 -lEGL -llog)

if(OpenCL_FOUND)
  include_directories(${OpenCL_INCLUDE_DIRS})
  target_link_libraries(${target} ${OpenCL_LIBRARIES})
  add_definitions("-DOPENCL_FOUND")
elif(NOT ("${ANDROID_OPENCL_SDK}" STREQUAL ""))
  include_directories(${ANDROID_OPENCL_SDK}/include)
  link_directories(${ANDROID_OPENCL_SDK}/lib)
  target_link_directories(${target} PRIVATE ${ANDROID_OPENCL_SDK}/lib)

  set_target_properties(${target} PROPERTIES LINK_FLAGS "-Wl,--allow-shlib-undefined")
  target_link_libraries(${target} -lOpenCL)

  add_definitions("-DOPENCL_FOUND")
  add_definitions("-DCL_HPP_MINIMUM_OPENCL_VERSION=120")
  add_definitions("-DCL_HPP_TARGET_OPENCL_VERSION=120")
  add_definitions("-DCL_HPP_ENABLE_PROGRAM_CONSTRUCTION_FROM_ARRAY_COMPATIBILITY")
endif()

```

----------------------------------------

TITLE: Implementing FAST Corner Detection Decision Tree in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm that uses a decision tree to determine if a pixel is a corner based on intensity comparisons at specific offsets. The algorithm compares pixel values (ptr[offset]) against threshold values (c_b and cb) and branches to either 'is_a_corner' or 'is_not_a_corner' labels based on these comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_27

LANGUAGE: C++
CODE:
```
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    goto is_not_a_corner;
  else
    if(ptr[offset6] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
if(ptr[offset0] < c_b)
  if(ptr[offset5] < c_b)
    if(ptr[offset9] > cb)
      if(ptr[offset2] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset2] < c_b)
          if(ptr[offset7] > cb)
            if(ptr[offset1] > cb)
              goto is_not_a_corner;
            else
              if(ptr[offset1] < c_b)
                if(ptr[offset6] < c_b)
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset3] < c_b)
                      if(ptr[offset4] < c_b)
                        if(ptr[offset11] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    if(ptr[offset3] < c_b)
                      if(ptr[offset4] < c_b)
                        if(ptr[offset11] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset7] < c_b)
              if(ptr[offset1] > cb)
                if(ptr[offset6] > cb)
                  goto is_not_a_corner;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset3] < c_b)
                      if(ptr[offset4] < c_b)
                        if(ptr[offset8] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset1] < c_b)
                  if(ptr[offset6] < c_b)
                    if(ptr[offset3] < c_b)
                      if(ptr[offset4] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    if(ptr[offset6] > cb)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset11] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset11] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                else
                  if(ptr[offset6] > cb)
                    goto is_not_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset8] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
            else
              if(ptr[offset1] > cb)
                goto is_not_a_corner;
              else
                if(ptr[offset1] < c_b)
                  if(ptr[offset6] < c_b)
                    if(ptr[offset3] < c_b)
                      if(ptr[offset4] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    if(ptr[offset6] > cb)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset11] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset11] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                else
                  goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset9] < c_b)
        if(ptr[offset7] > cb)
          if(ptr[offset2] > cb)
            goto is_not_a_corner;
          else
            if(ptr[offset2] < c_b)
              if(ptr[offset1] > cb)
                goto is_not_a_corner;
              else
                if(ptr[offset1] < c_b)
                  if(ptr[offset6] > cb)
                    if(ptr[offset11] < c_b)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          goto is_a_corner;
                        else
                          if(ptr[offset10] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset8] < c_b)
                          if(ptr[offset10] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          goto is_a_corner;
                        else
                          if(ptr[offset10] < c_b)
                            if(ptr[offset11] < c_b)
```

----------------------------------------

TITLE: Executing Pixel Intensity Comparisons for Feature Detection in C++
DESCRIPTION: This C++ code snippet implements a highly optimized decision tree for analyzing pixel neighborhoods in image processing, likely for feature detection (e.g., FAST corners). It uses deeply nested `if-else` statements and `goto` jumps to efficiently compare pixel intensity values (`ptr[offsetN]`) against upper (`cb`) and lower (`c_b`) thresholds. Based on these comparisons across multiple neighboring pixels (defined by `offsetN`), the code classifies the central pixel's region and jumps to specific labels (`success_homogeneous`, `homogeneous`, `success_structured`, `structured`) indicating the result. The use of `goto` aims to maximize performance in this low-level computation. Dependencies include the `ptr` (pointer to image data) and the threshold values `cb` and `c_b`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
                                      goto success_homogeneous;
                                    else
                                      if(ptr[offset7] > cb)
                                        goto success_homogeneous;
                                      else
                                        goto homogeneous;
                                  else
                                    if(ptr[offset6] > cb)
                                      if(ptr[offset7] > cb)
                                        goto success_homogeneous;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        if(ptr[offset9] < c_b)
                          if(ptr[offset2] > cb)
                            if(ptr[offset1] > cb)
                              if(ptr[offset4] > cb)
                                if(ptr[offset10] > cb)
                                  if(ptr[offset3] > cb)
                                    if(ptr[offset11] > cb)
                                      goto success_structured;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset7] < c_b)
                                      if(ptr[offset8] < c_b)
                                        if(ptr[offset11] < c_b)
                                          if(ptr[offset10] < c_b)
                                            goto success_structured;
                                          else
                                            goto structured;
                                        else
                                          goto structured;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                if(ptr[offset6] < c_b)
                                  if(ptr[offset7] < c_b)
                                    if(ptr[offset8] < c_b)
                                      if(ptr[offset10] < c_b)
                                        if(ptr[offset4] < c_b)
                                          goto success_structured;
                                        else
                                          if(ptr[offset11] < c_b)
                                            goto success_structured;
                                          else
                                            goto structured;
                                      else
                                        if(ptr[offset3] < c_b)
                                          if(ptr[offset4] < c_b)
                                            goto success_structured;
                                          else
                                            goto structured;
                                        else
                                          goto homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset7] < c_b)
                                  if(ptr[offset8] < c_b)
                                    if(ptr[offset4] < c_b)
                                      if(ptr[offset3] < c_b)
                                        goto success_structured;
                                      else
                                        if(ptr[offset10] < c_b)
                                          goto success_structured;
                                        else
                                          goto homogeneous;
                                    else
                                      if(ptr[offset10] < c_b)
                                        if(ptr[offset11] < c_b)
                                          goto success_structured;
                                        else
                                          goto homogeneous;
                                      else
                                        goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset6] < c_b)
                              if(ptr[offset7] < c_b)
                                if(ptr[offset8] < c_b)
                                  if(ptr[offset4] < c_b)
                                    if(ptr[offset3] < c_b)
                                      goto success_homogeneous;
                                    else
                                      if(ptr[offset10] < c_b)
                                        goto success_homogeneous;
                                      else
                                        goto homogeneous;
                                  else
                                    if(ptr[offset10] < c_b)
                                      if(ptr[offset11] < c_b)
                                        goto success_homogeneous;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  if(ptr[offset2] < c_b)
                                    if(ptr[offset1] < c_b)
                                      if(ptr[offset3] < c_b)
                                        if(ptr[offset4] < c_b)
                                          goto success_structured;
                                        else
                                          goto homogeneous;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset2] > cb)
                            if(ptr[offset1] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto success_homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            if(ptr[offset2] < c_b)
                              if(ptr[offset3] < c_b)
                                if(ptr[offset4] < c_b)
                                  if(ptr[offset7] < c_b)
                                    if(ptr[offset1] < c_b)
                                      if(ptr[offset6] < c_b)
                                        goto success_homogeneous;
                                      else
                                        goto homogeneous;
                                    else
                                      if(ptr[offset6] < c_b)
                                        if(ptr[offset8] < c_b)
                                          goto success_homogeneous;
                                        else
                                          goto homogeneous;
                                      else
                                        goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                    else
                      if(ptr[offset2] > cb)
                        if(ptr[offset10] > cb)
                          if(ptr[offset11] > cb)
                            if(ptr[offset9] > cb)
                              if(ptr[offset1] > cb)
                                if(ptr[offset3] > cb)
                                  goto success_homogeneous;
                                else
                                  if(ptr[offset8] > cb)

```

----------------------------------------

TITLE: Running DNN Model Runner in Evaluation Mode
DESCRIPTION: Command to run the model runner in evaluation mode to compare PyTorch and OpenCV DNN performance metrics.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_8

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_cls --model_name <pytorch_cls_model_name>
```

----------------------------------------

TITLE: Using a Helper Function for Random Color Generation in OpenCV C++
DESCRIPTION: Shows the usage of a helper function `randomColor` within the `cv::line` function call. This function takes the cv::RNG object as input and returns a random cv::Scalar value, which is then used as the color parameter for the line.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
@code{.cpp}
randomColor(rng)
@endcode
```

----------------------------------------

TITLE: Defining a Color Tuple in Python
DESCRIPTION: Creating a tuple to represent a BGR color in OpenCV Python. The tuple contains three values representing Blue, Green, and Red channels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
( a, b, c )
```

----------------------------------------

TITLE: Checking Out Latest OpenCV 2.4 Branch using Git (Shell)
DESCRIPTION: Switches the current Git repository to the `2.4` branch. This command retrieves the latest development code available in the OpenCV 2.4 series, as an alternative to checking out a specific tagged release.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_13

LANGUAGE: Shell
CODE:
```
$ git checkout 2.4
```

----------------------------------------

TITLE: Interactive Image Pyramid Loop in Java
DESCRIPTION: Runs an infinite loop processing key events. The 'i' key calls `Imgproc.pyrUp` for upsampling, 'o' calls `Imgproc.pyrDown` for downsampling, and ESC terminates the program. The resulting image is redisplayed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_7

LANGUAGE: java
CODE:
```
        //![loop]
        Mat tmp = src;
        Mat dst = tmp;

        while(true) {
            HighGui.imshow( window_name, dst );
            char c = (char) HighGui.waitKey(0);

            if( c == 27 ) {
                break;
            } else if( c == 'i' ) {
                Imgproc.pyrUp( tmp, dst, new Size( tmp.cols()*2, tmp.rows()*2 ) );
                System.out.println("** Zoom In: Image x 2");
            } else if( c == 'o' ) {
                Imgproc.pyrDown( tmp, dst, new Size( tmp.cols()/2, tmp.rows()/2 ) );
                System.out.println("** Zoom Out: Image / 2");
            }

            tmp = dst;
        }
        //![loop]

        System.exit(0);
    }
```

----------------------------------------

TITLE: Building OpenCV.js Documentation - Bash
DESCRIPTION: Runs the build_js.py script with the --build_doc option to generate documentation using Doxygen. Dependency: emcmake, Python, and Doxygen installed. Parameter: --build_doc. Output is generated documentation files, typically in HTML format, located in the build output directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_8

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --build_doc
```

----------------------------------------

TITLE: Applying Filter Using filter2D
DESCRIPTION: Applies the custom kernel to the source image using OpenCV's filter2D function. Parameters include source/destination images, depth, kernel, and anchor point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
filter2D(src, dst, -1, kernel, Point(-1,-1), 0, BORDER_DEFAULT);
```

----------------------------------------

TITLE: Citing a Publication in OpenCV Documentation
DESCRIPTION: Demonstrates how to cite a publication in OpenCV documentation using the _cite_ command. This snippet shows the syntax for referencing a previously added BibTeX record.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_18

LANGUAGE: markdown
CODE:
```
@cite Bradski98
```

----------------------------------------

TITLE: Calculating Convex Hull of Contours in Python with OpenCV
DESCRIPTION: This code snippet shows how to compute the convex hull of a contour using cv.convexHull(). It corrects convexity defects in the contour.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
hull = cv.convexHull(cnt)
```

----------------------------------------

TITLE: Check ptrdiff_t Support and Configure ptrdiff_t Alternative in CMake
DESCRIPTION: This segment verifies the compiler support for ptrdiff_t and sets an alternative if unsupported. It determines the size of void pointers and matches them with corresponding integer types to ensure scalability.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: CMake
CODE:
```
#
# check for ptrdiff_t support
#
check_c_source_compiles(
    "#include <stddef.h>
     int main() {
         ptrdiff_t *a;
         (void)a;
         return 0;
    }"
    HAVE_PTRDIFF_T
)
if(NOT HAVE_PTRDIFF_T)
    set(NEED_PTRDIFF_T 1)

    check_type_size("void *" SIZEOF_DATA_PTR)
    message(STATUS "sizeof(void *) is ${SIZEOF_DATA_PTR} bytes")

    if(${SIZEOF_DATA_PTR} MATCHES "4")
        set(PTRDIFF_TYPE "uint32_t")
    elseif(${SIZEOF_DATA_PTR} MATCHES "8")
        set(PTRDIFF_TYPE "uint64_t")
    else()
        message(FATAL_ERROR "sizeof(void *) is neither 32 nor 64 bit")
    endif()
endif()
```

----------------------------------------

TITLE: Setting Histogram Value Range in C++
DESCRIPTION: C++ snippet defining the range of pixel values for the histogram calculation. An array `histRange` is initialized to `[0, 256]`, indicating that pixel values from 0 up to (but not including) 256 will be considered.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Set the ranges ( for B,G,R) )
```

----------------------------------------

TITLE: Displaying Result Image in Python
DESCRIPTION: Displays the final absolute Laplacian image (`abs_dst`) in a window titled "Laplace Demo" using cv2.imshow. Requires cv2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_23

LANGUAGE: python
CODE:
```
#! [display]
# [display]
# Showacilimages
cv.imshow( "Laplace Demo", abs_dst )
# [display]
# ! [display]
```

----------------------------------------

TITLE: Installing Core Sample CMake Files (OpenCV Build) in CMake
DESCRIPTION: Calls the `ocv_install_example_src` function (defined earlier for the OpenCV build context) to install the current `CMakeLists.txt` and `samples_utils.cmake` into the root of the samples source installation path (`${OPENCV_SAMPLES_SRC_INSTALL_PATH}`). This is done when building as part of OpenCV and if `INSTALL_C_EXAMPLES` is enabled.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
ocv_install_example_src("." CMakeLists.txt samples_utils.cmake)
```

----------------------------------------

TITLE: Starting JPEG Decompression in C using libjpeg
DESCRIPTION: This code calls `jpeg_start_decompress` to initialize the internal state, allocate working memory, and prepare for returning decompressed image data. It should be called after setting any desired decompression parameters in the `cinfo` struct. After this call, output dimensions (`output_width`, `output_height`) and component information (`output_components`) become available in `cinfo`. This corresponds to step 5 in the decompression workflow.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_14

LANGUAGE: C
CODE:
```
jpeg_start_decompress(&cinfo);
```

----------------------------------------

TITLE: Reading Primitive Types with Real and getNode - OpenCV Python
DESCRIPTION: This Python snippet demonstrates reading basic numeric values from an XML/YAML/JSON file using the getNode() and real() methods of FileStorage. It is used for extracting individual numeric values from the file, assuming the file was written with FileStorage.write(). The file must contain the specified key. Requires opencv-python installed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_4

LANGUAGE: Python
CODE:
```
fs = cv2.FileStorage('test.yml', cv2.FileStorage_READ)\nnumber = int(fs.getNode('number').real())\nfs.release()
```

----------------------------------------

TITLE: Estimating Homography Matrix in OpenCV C++
DESCRIPTION: Code to estimate the homography matrix between object points and normalized image points using OpenCV's findHomography function with RANSAC for robust estimation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
cv::Mat H = cv::findHomography(objectPointsPlanar, imagePointsNormalized, cv::RANSAC);
```

----------------------------------------

TITLE: Image Addition with OpenCV.js
DESCRIPTION: Demonstrates how to add two images using cv.add() function. Both input images must have the same depth and type. The operation performs pixel-wise addition of the images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_image_arithmetics/js_image_arithmetics.markdown#2025-04-22_snippet_0

LANGUAGE: javascript
CODE:
```
let src1 = cv.imread("canvasInput1");
let src2 = cv.imread("canvasInput2");
let dst = new cv.Mat();
let mask = new cv.Mat();
let dtype = -1;
cv.add(src1, src2, dst, mask, dtype);
src1.delete(); src2.delete(); dst.delete(); mask.delete();
```

----------------------------------------

TITLE: Accessing Single Pixel Intensity with C++ cv::Mat::at with Point
DESCRIPTION: Alternative pixel access via cv::Point for single-channel images in C++. at<uchar>(point) uses a cv::Point(x, y) object for coordinates. Requires C++ OpenCV. Intensity output is in range 0-255. Input is a cv::Mat and a cv::Point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_12

LANGUAGE: C++
CODE:
```
uchar intensity = img.at<uchar>(cv::Point(x, y));
```

----------------------------------------

TITLE: Executing Basic Clojure Expressions
DESCRIPTION: It provides examples of simple Clojure expressions executed within a REPL session, showing foundational usage of arithmetic, string manipulation, and function definition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_7

LANGUAGE: clojure
CODE:
```
user=> (+ 41 1)
42
user=> (println "Hello, OpenCV!")
Hello, OpenCV!
nil
user=> (defn foo [] (str "bar"))
#'user/foo
user=> (foo)
"bar"
```

----------------------------------------

TITLE: Configuring Native Dependencies and Android Project with OpenCV in CMake
DESCRIPTION: This CMake script configures native dependencies for an Android project based on whether a fat Java library is being built or not. It utilizes CMake commands like 'set', 'if', and 'add_android_project'. The script also specifies a specific SDK target version and establishes project dependencies. The 'BUILD_FAT_JAVA_LIB' flag determines if 'opencv_java' or 'opencv_features2d' is included as a native dependency.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-2-mixedprocessing/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(sample example-tutorial-2-mixedprocessing)

if(BUILD_FAT_JAVA_LIB)
  set(native_deps opencv_java)
else()
  set(native_deps opencv_features2d)
endif()

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}" NATIVE_DEPS ${native_deps})
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Configuring OpenCV with CMake for aarch64 and Ninja
DESCRIPTION: Set up OpenCV configuration using CMake for a cross-compilation targeting a Linux aarch64 system, configured to use the Ninja build system. Requires a specified toolchain file and OpenCV extra modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_17

LANGUAGE: bash
CODE:
```
PKG_CONFIG_PATH=/usr/lib/aarch64-linux-gnu/pkgconfig:/usr/share/pkgconfig \
    PKG_CONFIG_LIBDIR=/usr/lib/aarch64-linux-gnu \
    PKG_CONFIG_SYSROOT_DIR=/ \
        cmake -S opencv \
              -B build4-full_arm64 \
              -DCMAKE_TOOLCHAIN_FILE=/home/kmtr/work/opencv/platforms/linux/aarch64-gnu.toolchain.cmake \
              -DOPENCV_EXTRA_MODULES_PATH=opencv_contrib/modules \
              -GNinja
```

----------------------------------------

TITLE: Defining and Linking a Shared Library with OpenCV in CMake
DESCRIPTION: Uses `file(GLOB ...)` to find all `.cpp`/`.c` source files and `.hpp`/`.h` header files in the current directory. Includes the current directory (`CMAKE_CURRENT_LIST_DIR`) for header lookup. Creates a shared library named `mixed_sample` (from the `target` variable) using these source and header files. Finally, links this library against the OpenCV components specified in `ANDROID_OPENCV_COMPONENTS`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-2-mixedprocessing/jni/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
file(GLOB srcs *.cpp *.c)
file(GLOB hdrs *.hpp *.h)

include_directories("${CMAKE_CURRENT_LIST_DIR}")
add_library(${target} SHARED ${srcs} ${hdrs})
target_link_libraries(${target} ${ANDROID_OPENCV_COMPONENTS})
```

----------------------------------------

TITLE: Installing JARs in Local Maven Repository Bash
DESCRIPTION: This Bash command uses the lein-localrepo plugin to install OpenCV JARs in the local Maven repository, making them accessible to Maven-compliant projects. The command specifies the artifact name and version, creating Maven entries for the OpenCV artifacts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
lein localrepo install opencv-247.jar opencv/opencv 2.4.7
```

LANGUAGE: bash
CODE:
```
lein localrepo install opencv-native-247.jar opencv/opencv-native 2.4.7
```

----------------------------------------

TITLE: Generating Random Data on Stream with Thrust
DESCRIPTION: Shows how to generate random values between -1 and 1 in a GpuMat using a custom thrust execution policy on a specific CUDA stream.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_7

LANGUAGE: CUDA
CODE:
```
cv::cuda::Stream stream;
cv::cuda::GpuMat d_random(512, 512, CV_32FC1);
thrust::device_ptr<float> d_random_ptr((float*)d_random.data);

// Generate random values between -1 and 1 on a stream
thrust::transform(
    thrust::system::cuda::par.on(StreamAccessor::getStream(stream)),
    thrust::counting_iterator<int>(0),
    thrust::counting_iterator<int>(d_random.rows * d_random.cols),
    d_random_ptr,
    prg(-1, 1)
);
```

----------------------------------------

TITLE: Import ResizeBilinearLayer from TensorFlow OpenCV C++
DESCRIPTION: Illustrates defining and registering TensorFlow's tf.image.resize_bilinear operation as a custom layer in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp ResizeBilinearLayer
```

----------------------------------------

TITLE: Conditional ITT Support in OpenCV CMake Configuration
DESCRIPTION: Adds support for ITT when both CV_TRACE and HAVE_ITT are defined. The snippet also sets the necessary include directories and links libraries for the specified module using CMake macros. It ensures that ITT functionalities are correctly integrated into the build process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: CMake
CODE:
```
if(CV_TRACE AND HAVE_ITT)
  ocv_target_compile_definitions(${the_module} PRIVATE -DOPENCV_WITH_ITT=1)
  ocv_module_include_directories(${ITT_INCLUDE_DIRS})
  ocv_target_link_libraries(${the_module} PRIVATE ${ITT_LIBRARIES})
endif()
```

----------------------------------------

TITLE: Batch Conversion of PyTorch Classification Models - Console
DESCRIPTION: The command line interface allows conversion of any supported PyTorch classification model to ONNX by specifying model name and toggling evaluation. Replace <pytorch_cls_model_name> with target model (e.g., resnet50). All necessary dependencies and Python modules must be installed prior to execution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_6

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_cls --model_name <pytorch_cls_model_name> --evaluate False
```

----------------------------------------

TITLE: Calculating Homography Using OpenCV in Java
DESCRIPTION: This Java snippet shows the computation of the homography matrix needed for image stitching using OpenCV. Required libraries include OpenCV Java bindings. It takes image views and calibration data as input and provides the matrix for homography.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_36

LANGUAGE: Java
CODE:
```
import org.opencv.core.Core;
import org.opencv.core.Mat;

public void computeHomography(Mat image1, Mat image2) {
    // Code to compute homography
    // ...
}
```

----------------------------------------

TITLE: Calculate Histogram using Numpy
DESCRIPTION: Shows histogram calculation using Numpy's histogram() function as an alternative to OpenCV. Returns both histogram and bin edges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_begins/py_histogram_begins.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
hist,bins = np.histogram(img.ravel(),256,[0,256])
```

----------------------------------------

TITLE: Constructing Scalar Structures in OpenCV.js (JavaScript)
DESCRIPTION: Shows two equivalent methods to create a Scalar value: using the cv.Scalar constructor and an array literal containing R, G, B, and Alpha channel values. Scalar is used for representing color in 4 channels. Inputs must be numeric; OpenCV.js is the primary dependency.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
// The first way
let scalar = new cv.Scalar(R, G, B, Alpha);
// The second way
let scalar = [R, G, B, Alpha];
```

----------------------------------------

TITLE: Blending Images with OpenCV in Python
DESCRIPTION: This Python snippet shows how to blend two images using OpenCV's addWeighted() function. Both input images should have the same size and format. A Numpy alternative is also shown. Python bindings for OpenCV are required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/adding_images/adding_images.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
"@snippet python/tutorial_code/core/AddingImages/adding_images.py load"
```

LANGUAGE: Python
CODE:
```
"@snippet python/tutorial_code/core/AddingImages/adding_images.py blend_images"
```

LANGUAGE: Python
CODE:
```
"@snippet python/tutorial_code/core/AddingImages/adding_images.py display"
```

----------------------------------------

TITLE: Setting Highgui Module Description in CMake
DESCRIPTION: Sets a CMake variable `the_description` to hold the string "High-level GUI", which likely serves as a description for the OpenCV highgui module within the build system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(the_description "High-level GUI")
```

----------------------------------------

TITLE: Constructing Matrices from Arrays and ImageData with OpenCV.js - JavaScript
DESCRIPTION: Demonstrates creating a cv.Mat matrix from a JavaScript array and from HTML5 canvas ImageData. Useful when data is already accessible in JS primitives or extracted from canvas elements. Requires OpenCV.js and, for the ImageData method, access to a canvas and 2D rendering context.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_2

LANGUAGE: JavaScript
CODE:
```
// 1. Use JS array to construct a mat.
// For example: let mat = cv.matFromArray(2, 2, cv.CV_8UC1, [1, 2, 3, 4]);
let mat = cv.matFromArray(rows, cols, type, array);
// 2. Use imgData to construct a mat
let ctx = canvas.getContext("2d");
let imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
let mat = cv.matFromImageData(imgData);
```

----------------------------------------

TITLE: Including Optional Components in OpenCV CMake
DESCRIPTION: Conditionally includes CMake files for various optional components like OpenCL, Halide, Vulkan, WebNN, Inference Engine, DirectX, DirectML, VTK, OpenVX, QUIRC, and ONNX based on build options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_15

LANGUAGE: CMake
CODE:
```
if(WITH_OPENCL)
  include(cmake/OpenCVDetectOpenCL.cmake)
endif()

if(WITH_HALIDE)
  include(cmake/OpenCVDetectHalide.cmake)
endif()

if(WITH_VULKAN)
  include(cmake/OpenCVDetectVulkan.cmake)
endif()

if(WITH_WEBNN)
  include(cmake/OpenCVDetectWebNN.cmake)
endif()

if(WITH_INF_ENGINE OR WITH_OPENVINO)
  include(cmake/OpenCVDetectInferenceEngine.cmake)
endif()

if(WITH_DIRECTX)
  include(cmake/OpenCVDetectDirectX.cmake)
endif()

if(WITH_DIRECTML)
  include(cmake/OpenCVDetectDirectML.cmake)
endif()

if(WITH_VTK)
  include(cmake/OpenCVDetectVTK.cmake)
endif()

if(WITH_OPENVX)
  include(cmake/FindOpenVX.cmake)
endif()

if(WITH_QUIRC)
  add_subdirectory(3rdparty/quirc)
  set(HAVE_QUIRC TRUE)
endif()

if(WITH_ONNX)
  include(cmake/FindONNX.cmake)
endif()
```

----------------------------------------

TITLE: Constructing Circle Structures in OpenCV.js (JavaScript)
DESCRIPTION: Explains two approaches for defining a Circle: invoking the cv.Circle constructor or using an object literal with center and radius. Center is typically a Point structure, and radius a numeric value. Requires OpenCV.js and appropriate parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_3

LANGUAGE: JavaScript
CODE:
```
// The first way
let circle = new cv.Circle(center, radius);
// The second way
let circle = {center : center, radius : radius};
```

----------------------------------------

TITLE: Setting Pose Estimation Criteria and Axis Points with OpenCV (Python)
DESCRIPTION: Initializes the termination criteria for sub-pixel corner refinement, defines the chessboard's 3D object points (assuming Z=0 for planarity), and specifies 3D world coordinates for the axes. Relies on NumPy for array creation and OpenCV for constants. The parameters are used as core inputs for pose estimation and result projection in the main image processing loop.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_pose/py_pose.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\nobjp = np.zeros((6*7,3), np.float32)\nobjp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n\naxis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)
```

----------------------------------------

TITLE: Configuring Framebuffer Backend for HighGUI in CMake
DESCRIPTION: Sets up the Framebuffer backend for OpenCV HighGUI when WITH_FRAMEBUFFER is enabled. Adds necessary source files, header files, and definitions including optional XVFB support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: CMake
CODE:
```
if(WITH_FRAMEBUFFER AND HAVE_FRAMEBUFFER)
  set(OPENCV_HIGHGUI_BUILTIN_BACKEND "FB")
  add_definitions(-DHAVE_FRAMEBUFFER)
  list(APPEND highgui_srcs ${CMAKE_CURRENT_LIST_DIR}/src/window_framebuffer.cpp)
  list(APPEND highgui_hdrs ${CMAKE_CURRENT_LIST_DIR}/src/window_framebuffer.hpp)
  if(HAVE_FRAMEBUFFER_XVFB)
    add_definitions(-DHAVE_FRAMEBUFFER_XVFB)
  endif()
endif()
```

----------------------------------------

TITLE: Importing OpenCV Classes in REPL
DESCRIPTION: Demonstrates importing the OpenCV Java classes within a Clojure REPL to replicate a Java example, showing techniques for matrix operations and modifications.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_17

LANGUAGE: clojure
CODE:
```
user=> (import '[org.opencv.core Mat CvType Scalar])
org.opencv.core.Scalar
```

----------------------------------------

TITLE: Transforming Pixel Coordinates to Complex Plane for Mandelbrot - C++
DESCRIPTION: This helper code translates pixel coordinates (col, row) of the image to the corresponding normalized complex coordinates used for the Mandelbrot set (mapping to [-2, 1] on the real axis, [-1, 1] on the imaginary axis). Accepts pixel indices, image dimensions; outputs corresponding x0, y0. Requires standard C++ math.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
// Map pixel coordinates to the complex plane
// x0 = (col / (double)image.cols) * 3.0 - 2.0;
// y0 = (row / (double)image.rows) * 2.0 - 1.0;
double x0 = (col / (double)image.cols) * 3.0 - 2.0;
double y0 = (row / (double)image.rows) * 2.0 - 1.0;

```

----------------------------------------

TITLE: Corner Detection Conditional Logic in C++
DESCRIPTION: Implementation of corner detection logic using pointer offsets and multiple conditional branches. The code compares pixel values at different offsets to determine corner characteristics, using goto statements to handle different detection scenarios.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
goto success_structured;
else
  if(ptr[offset4] > cb)
    goto success_structured;
  else
    goto structured;
else
  if(ptr[offset1] > cb)
    goto success_structured;
  else
    goto structured;
else
  goto structured;
else
  if(ptr[offset5] < c_b)
    if(ptr[offset3] < c_b)
      if(ptr[offset7] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset6] < c_b)
            goto success_structured;
          else
            goto structured;
        else
          goto structured;
      else
        goto homogeneous;
    else
      goto homogeneous;
  else
    goto structured;
```

----------------------------------------

TITLE: YOLOv8 Model Execution
DESCRIPTION: Shell commands for running YOLOv8 model with specific parameters including preprocessing values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown#2025-04-22_snippet_5

LANGUAGE: sh
CODE:
```
cd opencv_extra/testdata/dnn
python download_models.py yolov8
cd ..
export OPENCV_TEST_DATA_PATH=$(pwd)
cd <build directory of OpenCV>

./bin/example_dnn_yolo_detector --model=onnx/models/yolov8n.onnx --yolo=yolov8 --mean=0.0 --scale=0.003921568627 --paddingmode=2 --padvalue=144.0 --thr=0.5 --nms=0.4 --rgb=0
```

----------------------------------------

TITLE: Segmentation Evaluation Configuration in Python
DESCRIPTION: Defines the configuration for segmentation model evaluation, including paths to PASCAL VOC dataset directories, validation file, and class definitions. This dataclass specifies the required data structure for segmentation evaluation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_10

LANGUAGE: python
CODE:
```
@dataclass
class TestSegmConfig:
    frame_size: int = 500
    img_root_dir: str = "./VOC2012"
    img_dir: str = os.path.join(img_root_dir, "JPEGImages/")
    img_segm_gt_dir: str = os.path.join(img_root_dir, "SegmentationClass/")
    # reduced val: https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/data/pascal/seg11valid.txt
    segm_val_file: str = os.path.join(img_root_dir, "ImageSets/Segmentation/seg11valid.txt")
    colour_file_cls: str = os.path.join(img_root_dir, "ImageSets/Segmentation/pascal-classes.txt")
```

----------------------------------------

TITLE: Creating Images in C++
DESCRIPTION: Initializing blank images for drawing shapes in OpenCV C++. Creates two black images named 'atom_image' and 'rook_image' with specified dimensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
/// Windows names
const char* atom_window = "Drawing 1: Atom";
const char* rook_window = "Drawing 2: Rook";

/// Create black empty images
Mat atom_image = Mat::zeros( w, w, CV_8UC3 );
Mat rook_image = Mat::zeros( w, w, CV_8UC3 );
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree Implementation in C++
DESCRIPTION: Part of the FAST corner detection algorithm showing the nested conditional logic for determining corner pixels. The algorithm compares pixel values against thresholds (c_b and cb) using offsets to neighboring pixels, then jumps to either 'is_a_corner' or 'is_not_a_corner' labels based on the results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_38

LANGUAGE: C++
CODE:
```
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  if(ptr[offset3] < c_b)
                                    if(ptr[offset4] < c_b)
                                      if(ptr[offset10] < c_b)
                                        if(ptr[offset11] < c_b)
                                          goto is_a_corner;
                                        else
                                          goto is_not_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                      else
                        if(ptr[offset9] < c_b)
                          if(ptr[offset1] > cb)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset1] < c_b)
                              if(ptr[offset6] > cb)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    if(ptr[offset3] < c_b)
                                      goto is_a_corner;
                                    else
                                      if(ptr[offset8] < c_b)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                if(ptr[offset6] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      if(ptr[offset3] < c_b)
                                        goto is_a_corner;
                                      else
                                        if(ptr[offset8] < c_b)
                                          goto is_a_corner;
                                        else
                                          goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      if(ptr[offset3] < c_b)
                                        goto is_a_corner;
                                      else
                                        if(ptr[offset8] < c_b)
                                          goto is_a_corner;
                                        else
                                          goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset1] > cb)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset1] < c_b)
                              if(ptr[offset6] > cb)
                                if(ptr[offset3] < c_b)
                                  if(ptr[offset4] < c_b)
                                    if(ptr[offset10] < c_b)
                                      if(ptr[offset11] < c_b)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                if(ptr[offset6] < c_b)
                                  if(ptr[offset3] < c_b)
                                    if(ptr[offset4] < c_b)
                                      if(ptr[offset10] < c_b)
                                        if(ptr[offset11] < c_b)
                                          goto is_a_corner;
                                        else
                                          goto is_not_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  if(ptr[offset3] < c_b)
                                    if(ptr[offset4] < c_b)
                                      if(ptr[offset10] < c_b)
                                        if(ptr[offset11] < c_b)
                                          goto is_a_corner;
                                        else
                                          goto is_not_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                else
                  if(ptr[offset7] < c_b)
                    if(ptr[offset9] > cb)
                      goto is_not_a_corner;
                    else
                      if(ptr[offset9] < c_b)
                        if(ptr[offset1] > cb)
                          if(ptr[offset6] > cb)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] < c_b)
                              if(ptr[offset8] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset1] < c_b)
                            if(ptr[offset6] > cb)
                              if(ptr[offset8] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset8] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                if(ptr[offset8] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset8] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
```

----------------------------------------

TITLE: Refining and Visualizing Detected Calibration Pattern Corners in C++
DESCRIPTION: This C++ snippet reference points to code that processes a detected calibration pattern. It refines corner positions using `cv::cornerSubPix`, adds valid points to storage vectors, and uses `cv::drawChessboardCorners` (or similar) to visualize the found pattern on the image for user feedback. It also handles input delay for live camera feeds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp pattern_found
```

----------------------------------------

TITLE: Defining and Using G-API Kernel Packages in C++
DESCRIPTION: This snippet shows how to define and use kernel packages in G-API with Fluid backend for anisotropic image segmentation. The cv::GKernelPackage is used to collect and specify kernels for graph execution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/porting_anisotropic_image_segmentation/porting_anisotropic_image_segmentation_gapi_fluid.cpp kernel_pkg
```

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/porting_anisotropic_image_segmentation/porting_anisotropic_image_segmentation_gapi_fluid.cpp kernel_pkg_use
```

----------------------------------------

TITLE: Accessing Single Pixel Intensity Value in Grayscale Image with OpenCV in Java
DESCRIPTION: This snippet retrieves the intensity of a pixel in an 8-bit single channel Mat in Java OpenCV. The get method accesses an array of pixel values at specified row and column. Ensure correct indices (row first, column second). Result is an array, with intensity typically at index 0.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_10

LANGUAGE: Java
CODE:
```
double[] intensity = img.get(y, x);
```

----------------------------------------

TITLE: Accessing Single Pixel in 3-Channel Image with OpenCV in Python
DESCRIPTION: Retrieves the color values from a 3-channel (BGR) image in Python. NumPy array img[y, x] returns an array with B,G,R values. Each value is typically an int in range 0-255. Input indices specify row and column.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_14

LANGUAGE: Python
CODE:
```
blue, green, red = img[y, x]
```

----------------------------------------

TITLE: Calculating Contour Extent in OpenCV Python
DESCRIPTION: This snippet computes the extent of a contour, which is the ratio of the contour's area to the area of its bounding rectangle. It uses `cv.contourArea` to find the contour area and `cv.boundingRect` to get the width (w) and height (h) for the bounding rectangle area calculation. Requires an existing contour variable `cnt`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
area = cv.contourArea(cnt)
x,y,w,h = cv.boundingRect(cnt)
rect_area = w*h
extent = float(area)/rect_area
```

----------------------------------------

TITLE: Implementing Erosion Operation in C++
DESCRIPTION: Performs erosion operation on an image using specified kernel parameters
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
void Erosion(int, void*)
{
    int erosion_type = 0;
    if (erosion_elem == 0) { erosion_type = MORPH_RECT; }
    else if (erosion_elem == 1) { erosion_type = MORPH_CROSS; }
    else if (erosion_elem == 2) { erosion_type = MORPH_ELLIPSE; }
    Mat element = getStructuringElement(erosion_type,
        Size(2 * erosion_size + 1, 2 * erosion_size + 1),
        Point(erosion_size, erosion_size));
    erode(src, erosion_dst, element);
    imshow("Erosion Demo", erosion_dst);
}
```

----------------------------------------

TITLE: Updating APT Database (Bash)
DESCRIPTION: Refreshes the local package database after modifying the APT sources list. This command downloads the latest package information from all configured repositories, including the newly added ones for foreign architectures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
sudo apt update
```

----------------------------------------

TITLE: Converting cv::Mat to UIImage in Objective-C
DESCRIPTION: This function converts an OpenCV Mat object back to a UIImage. It handles both grayscale and color images by checking the number of channels in the Mat.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/image_manipulation/image_manipulation.markdown#2025-04-22_snippet_2

LANGUAGE: Objective-C
CODE:
```
-(UIImage *)UIImageFromCVMat:(cv::Mat)cvMat
{
  NSData *data = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize()*cvMat.total()];
  CGColorSpaceRef colorSpace;

  if (cvMat.elemSize() == 1) {
      colorSpace = CGColorSpaceCreateDeviceGray();
  } else {
      colorSpace = CGColorSpaceCreateDeviceRGB();
  }

  CGDataProviderRef provider = CGDataProviderCreateWithCFData((__bridge CFDataRef)data);

  // Creating CGImage from cv::Mat
  CGImageRef imageRef = CGImageCreate(cvMat.cols,                                 //width
                                     cvMat.rows,                                 //height
                                     8,                                          //bits per component
                                     8 * cvMat.elemSize(),                       //bits per pixel
                                     cvMat.step[0],                            //bytesPerRow
                                     colorSpace,                                 //colorspace
                                     kCGImageAlphaNone|kCGBitmapByteOrderDefault,// bitmap info
                                     provider,                                   //CGDataProviderRef
                                     NULL,                                       //decode
                                     false,                                      //should interpolate
                                     kCGRenderingIntentDefault                   //intent
                                     );


  // Getting UIImage from CGImage
  UIImage *finalImage = [UIImage imageWithCGImage:imageRef];
  CGImageRelease(imageRef);
  CGDataProviderRelease(provider);
  CGColorSpaceRelease(colorSpace);

  return finalImage;
 }
```

----------------------------------------

TITLE: Calling Drawing Functions Sequentially in OpenCV C++
DESCRIPTION: This code demonstrates the main loop structure where various drawing functions are called sequentially. Each function takes the image, window name, and RNG object as input, draws a specific type of shape or text randomly, and returns a status code. The loop checks the return code after each call to potentially exit early.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
@code{.cpp}
/// Now, let's draw some lines
c = Drawing_Random_Lines(image, window_name, rng);
if( c != 0 ) return 0;

/// Go on drawing, this time nice rectangles
c = Drawing_Random_Rectangles(image, window_name, rng);
if( c != 0 ) return 0;

/// Draw some ellipses
c = Drawing_Random_Ellipses( image, window_name, rng );
if( c != 0 ) return 0;

/// Now some polylines
c = Drawing_Random_Polylines( image, window_name, rng );
if( c != 0 ) return 0;

/// Draw filled polygons
c = Drawing_Random_Filled_Polygons( image, window_name, rng );
if( c != 0 ) return 0;

/// Draw circles
c = Drawing_Random_Circles( image, window_name, rng );
if( c != 0 ) return 0;

/// Display text in random positions
c = Displaying_Random_Text( image, window_name, rng );
if( c != 0 ) return 0;

/// Displaying the big end!
c = Displaying_Big_End( image, window_name, rng );
@endcode
```

----------------------------------------

TITLE: Displaying Results and Drawing Rectangle (C++)
DESCRIPTION: Draws a rectangle on the display image (`img_display`) around the best matched area using `cv::rectangle`. The top-left corner is `matchLoc` and the bottom-right corner is calculated based on the template dimensions. Finally, it displays the image with the rectangle and the normalized result matrix using `cv::imshow`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_34

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp imshow
```

----------------------------------------

TITLE: Installing wget and unzip on Linux
DESCRIPTION: Command to install wget download tool and unzip utility on Linux using the package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_7

LANGUAGE: bash
CODE:
```
sudo apt-get install wget unzip
```

----------------------------------------

TITLE: Optimized GPU PSNR Function Signature in C++
DESCRIPTION: Shows the function signature for `getPSNR_GPU_optimized`. It takes two constant `Mat` references (`I1`, `I2`) as input images and a reference to a `BufferPSNR` object (`b`). Passing the buffer by reference allows the function to reuse the pre-allocated GPU memory within the buffer.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
double getPSNR_GPU_optimized(const Mat& I1, const Mat& I2, BufferPSNR& b)
```

----------------------------------------

TITLE: Computing BRIEF Descriptors with CenSurE in Python
DESCRIPTION: This Python code snippet uses OpenCV to compute BRIEF descriptors with the help of the CenSurE (STAR) detector. It initializes a FAST detector, detects keypoints, and then computes the BRIEF descriptors. The necessary dependencies are the OpenCV library along with the 'opencv_contrib' module. The input is a grayscale image, and the output includes the keypoints and the descriptor array. The brief.getDescriptorSize() function shows the descriptor size, which is 32 by default.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_brief/py_brief.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('simple.jpg', cv.IMREAD_GRAYSCALE)

# Initiate FAST detector
star = cv.xfeatures2d.StarDetector_create()

# Initiate BRIEF extractor
brief = cv.xfeatures2d.BriefDescriptorExtractor_create()

# find the keypoints with STAR
kp = star.detect(img,None)

# compute the descriptors with BRIEF
kp, des = brief.compute(img, kp)

print( brief.descriptorSize() )
print( des.shape )
```

----------------------------------------

TITLE: Adjusting SURF Parameters and Recomputing Keypoints in OpenCV Python
DESCRIPTION: This code snippet shows how to check and modify the Hessian threshold of a SURF object, and then recompute keypoints with the new threshold. It's useful for controlling the number of detected keypoints.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
# Check present Hessian threshold
>>> print( surf.getHessianThreshold() )
400.0

# We set it to some 50000. Remember, it is just for representing in picture.
# In actual cases, it is better to have a value 300-500
>>> surf.setHessianThreshold(50000)

# Again compute keypoints and check its number.
>>> kp, des = surf.detectAndCompute(img,None)

>>> print( len(kp) )
47
```

----------------------------------------

TITLE: Basic Depth Map Capture with OpenNI
DESCRIPTION: Example showing how to capture depth map data from an OpenNI-compatible sensor using VideoCapture.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/kinect_openni.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
VideoCapture capture( CAP_OPENNI );
for(;;)
{
    Mat depthMap;
    capture >> depthMap;

    if( waitKey( 30 ) >= 0 )
        break;
}
```

----------------------------------------

TITLE: Collecting Java Binding Source Files in CMake
DESCRIPTION: Gathers handwritten C++ and header files for Java bindings from multiple locations, including module-specific Java directories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jni/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
glob_more_specific_sources(H "${CMAKE_CURRENT_SOURCE_DIR}/../generator/src" handwritten_h_sources)
glob_more_specific_sources(CPP "${CMAKE_CURRENT_SOURCE_DIR}/../generator/src" handwritten_cpp_sources)

# grab C++ files from misc/java
foreach(m ${OPENCV_MODULES_BUILD})
  if (";${OPENCV_MODULE_${m}_WRAPPERS};" MATCHES ";java;" AND HAVE_${m})
    set(module_java_dir "${OPENCV_MODULE_${m}_LOCATION}/misc/java")
    include_directories("${module_java_dir}/src/cpp")
    file(GLOB _result "${module_java_dir}/src/cpp/*.h" "${module_java_dir}/src/cpp/*.hpp" "${module_java_dir}/src/cpp/*.cpp")
    list(APPEND handwritten_cpp_sources ${_result})
  endif()
endforeach()
```

----------------------------------------

TITLE: Configuring Android Project with OpenCV in CMake
DESCRIPTION: This CMake snippet configures an Android project with OpenCV dependencies. It checks if the 'BUILD_FAT_JAVA_LIB' flag is set, then assigns different dependencies ('opencv_java' or 'videoio') to 'native_deps'. An Android project is added with these dependencies, targeting SDK version 11. It also adds a dependency relationship to ensure the sample project is built after the OpenCV Android examples. Requires OpenCV and Android SDK installations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/video-recorder/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(sample example-video-recorder)

if(BUILD_FAT_JAVA_LIB)
  set(native_deps opencv_java)
else()
  set(native_deps videoio)
endif()

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}" NATIVE_DEPS ${native_deps})
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Image Preprocessing for PCA using OpenCV in Python
DESCRIPTION: Loads an image specified by a command-line argument, converts it to grayscale, and applies Otsu's thresholding to create a binary image. This standard preprocessing step facilitates object detection. Requires OpenCV Python library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
#! [pre-process]
# Load image
parser = argparse.ArgumentParser(description='Code for Introduction to Principal Component Analysis (PCA) tutorial.')
parser.add_argument('--input', help='Path to input image.', default='pca_test1.jpg')
args = parser.parse_args()

src = cv.imread(cv.samples.findFile(args.input))
if src is None:
    print('Could not open or find the image: ', args.input)
    exit(0)

cv.imshow('src', src)

# Convert image to grayscale
gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)

# Convert image to binary
_, bw = cv.threshold(gray, 50, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)
#! [pre-process]
```

----------------------------------------

TITLE: Detecting ChArUco Corners
DESCRIPTION: Shows the process of detecting ChArUco corners using the CharucoDetector class
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
std::vector<cv::Point2f> charucoCorners;
std::vector<int> charucoIds;
charucoDetector.detectBoard(image, charucoCorners, charucoIds, markerCorners, markerIds);
```

----------------------------------------

TITLE: Adding Images with OpenCV Python
DESCRIPTION: This code snippet demonstrates the use of cv.add() to add two images or an image and a scalar using OpenCV in Python. It highlights the difference between OpenCV's saturated addition and NumPy's modulo addition. The input is two 8-bit unsigned integer arrays, and the output is their sum with a max value of 255.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_image_arithmetics/py_image_arithmetics.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
>>> x = np.uint8([250])
>>> y = np.uint8([10])

>>> print( cv.add(x,y) ) # 250+10 = 260 => 255
[[255]]

>>> print( x+y )          # 250+10 = 260 % 256 = 4
[4]
```

----------------------------------------

TITLE: Applying Median Blur with OpenCV in C++
DESCRIPTION: This C++ snippet details the use of the medianBlur() function by OpenCV to apply a median filter for smoothing images. Dependencies include OpenCV and it requires input image and kernel size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
@snippet cpp/tutorial_code/ImgProc/Smoothing/Smoothing.cpp medianblur
```

----------------------------------------

TITLE: Displaying Results of Histogram Equalization
DESCRIPTION: Code to display both the original grayscale image and the equalized image for comparison of contrast enhancement.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
imshow( "Source image", src );
imshow( "Equalized Image", dst );
```

LANGUAGE: Java
CODE:
```
// Setup the window
Highgui.namedWindow("Source image", WINDOW_AUTOSIZE);
Highgui.namedWindow("Equalized Image", WINDOW_AUTOSIZE);

// Show results
Highgui.imshow("Source image", src);
Highgui.imshow("Equalized Image", dst);
```

LANGUAGE: Python
CODE:
```
cv.imshow('Source image', src)
cv.imshow('Equalized Image', dst)
```

----------------------------------------

TITLE: Displaying Results in Java
DESCRIPTION: Java snippet displaying the original source image and the generated histogram image in separate windows using `HighGui.imshow`. It then waits indefinitely for a key press using `HighGui.waitKey` before exiting the application with `System.exit(0)`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_33

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Display
```

----------------------------------------

TITLE: Generating OpenCV for Windows Phone 8.1 ARM using CMake
DESCRIPTION: Invokes CMake directly to generate Visual Studio 2013 project files for OpenCV targeting Windows Phone 8.1 on the ARM architecture. It specifies the ARM-specific generator, system name, and system version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013 ARM" -DCMAKE_SYSTEM_NAME=WindowsPhone -DCMAKE_SYSTEM_VERSION=8.1 <path-to-source>
```

----------------------------------------

TITLE: Creating Trackbar in Java
DESCRIPTION: This Java snippet creates a trackbar using `HighGui.createTrackbar`. It associates the trackbar with the named window (`WINDOW_NAME`), links its value to an integer array `alphaVal`, sets the maximum value `ALPHA_SLIDER_MAX`, and defines an anonymous `TrackbarCallback` inner class to handle value changes by calling the `on_trackbar` method. It also triggers the callback initially.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_7

LANGUAGE: java
CODE:
```
//![create_trackbar]
// Create trackbar
HighGui.createTrackbar(TRACKBAR_NAME, WINDOW_NAME, new int[]{alphaVal}, ALPHA_SLIDER_MAX, new TrackbarCallback() {
    @Override
    public void onTrackbar(int pos, Object userdata) {
        on_trackbar(pos);
    }
});
// Show default image
on_trackbar(alphaVal);
//![create_trackbar]
```

----------------------------------------

TITLE: Computing Rotation Displacement Using OpenCV in C++
DESCRIPTION: This snippet provides a routine to compute rotation displacement between image views in C++. Requires OpenCV library setup. The function handles images and results in the transformation matrix for displacement.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_31

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>

void computeRotationDisplacement(cv::Mat image1, cv::Mat image2) {
    // Code to compute rotation displacement
    // ...
}
```

----------------------------------------

TITLE: Setting a Pixel Value in an Image with OpenCV in C++
DESCRIPTION: Alters the intensity value of a pixel at (y, x) in a cv::Mat image in C++. Uses the at<>() method for assignment. This operation mutates the input matrix. Requires OpenCV and appropriate image type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_16

LANGUAGE: C++
CODE:
```
img.at<uchar>(y, x) = 128;
```

----------------------------------------

TITLE: Calculating PSNR on GPU (Optimized) in C++
DESCRIPTION: Defines an optimized C++ function `getPSNR_GPU_optimized` for GPU-based PSNR calculation. It uses a pre-allocated buffer (`BufferPSNR`) to avoid repeated GPU memory allocations for intermediate results (`gI1`, `gI2`, `gs`, `t1`, `t2`, `buf`). This function uploads input matrices and calls the GPU `psnr` function, reusing the buffers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
//![getpsnropt]
double getPSNR_GPU_optimized(const Mat& I1, const Mat& I2, BufferPSNR& b)
{
    b.gI1.upload(I1);            // Upload data to GPU
    b.gI2.upload(I2);

    return psnr(b.gI1, b.gI2);
}
//![getpsnropt]
```

----------------------------------------

TITLE: Configuring OpenCV Build Options with CMake
DESCRIPTION: Defines build configuration options for OpenCV using OCV_OPTION macro. Each option specifies a feature that can be enabled/disabled, its visibility conditions, and verification requirements. Options cover hardware acceleration, video capture, GUI frameworks, and external library integrations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
OCV_OPTION(WITH_1394 "Include IEEE1394 support" OFF
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_DC1394_2)
OCV_OPTION(WITH_AVFOUNDATION "Use AVFoundation for Video I/O (iOS/visionOS/Mac)" ON
  VISIBLE_IF APPLE
  VERIFY HAVE_AVFOUNDATION)
OCV_OPTION(WITH_AVIF "Enable AVIF support" ON
  VERIFY HAVE_AVIF)
OCV_OPTION(WITH_CAP_IOS "Enable iOS video capture" ON
  VISIBLE_IF IOS
  VERIFY HAVE_CAP_IOS)
OCV_OPTION(WITH_CAROTENE "Use NVidia carotene acceleration library for ARM platform" (NOT CV_DISABLE_OPTIMIZATION)
  VISIBLE_IF (ARM OR AARCH64) AND NOT IOS AND NOT XROS)
OCV_OPTION(WITH_KLEIDICV "Use KleidiCV library for ARM platforms" (ANDROID AND AARCH64 AND NOT CV_DISABLE_OPTIMIZATION)
  VISIBLE_IF (AARCH64 AND (ANDROID OR UNIX AND NOT IOS AND NOT XROS)))
OCV_OPTION(WITH_NDSRVP "Use Andes RVP extension" (NOT CV_DISABLE_OPTIMIZATION)
  VISIBLE_IF RISCV)
OCV_OPTION(WITH_HAL_RVV "Use HAL RVV optimizations" (NOT CV_DISABLE_OPTIMIZATION)
  VISIBLE_IF RISCV)
OCV_OPTION(WITH_FASTCV "Use Qualcomm FastCV acceleration library for ARM platform" OFF
  VISIBLE_IF ((ARM OR AARCH64) AND (ANDROID OR (UNIX AND NOT APPLE AND NOT IOS AND NOT XROS))))
OCV_OPTION(WITH_CPUFEATURES "Use cpufeatures Android library" ON
  VISIBLE_IF ANDROID
  VERIFY HAVE_CPUFEATURES)
OCV_OPTION(WITH_VTK "Include VTK library support (and build opencv_viz module eiher)" ON
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT AND NOT CMAKE_CROSSCOMPILING
  VERIFY HAVE_VTK)
OCV_OPTION(WITH_CUDA "Include NVidia Cuda Runtime support" OFF
  VISIBLE_IF NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_CUDA)
OCV_OPTION(WITH_CUFFT "Include NVidia Cuda Fast Fourier Transform (FFT) library support" WITH_CUDA
  VISIBLE_IF WITH_CUDA
  VERIFY HAVE_CUFFT)
OCV_OPTION(WITH_CUBLAS "Include NVidia Cuda Basic Linear Algebra Subprograms (BLAS) library support" WITH_CUDA
  VISIBLE_IF WITH_CUDA
  VERIFY HAVE_CUBLAS)
OCV_OPTION(WITH_CUDNN "Include NVIDIA CUDA Deep Neural Network (cuDNN) library support" WITH_CUDA
  VISIBLE_IF WITH_CUDA
  VERIFY HAVE_CUDNN)
OCV_OPTION(WITH_NVCUVID "Include NVidia Video Decoding library support" ON
  VISIBLE_IF WITH_CUDA
  VERIFY HAVE_NVCUVID)
OCV_OPTION(WITH_NVCUVENC "Include NVidia Video Encoding library support" ON
  VISIBLE_IF WITH_CUDA
  VERIFY HAVE_NVCUVENC)
OCV_OPTION(WITH_EIGEN "Include Eigen2/Eigen3 support" (NOT CV_DISABLE_OPTIMIZATION AND NOT CMAKE_CROSSCOMPILING)
  VISIBLE_IF NOT WINRT
  VERIFY HAVE_EIGEN)
OCV_OPTION(WITH_FFMPEG "Include FFMPEG support" (NOT ANDROID)
  VISIBLE_IF NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_FFMPEG)
OCV_OPTION(WITH_GSTREAMER "Include Gstreamer support" ON
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_GSTREAMER AND GSTREAMER_VERSION VERSION_GREATER "0.99")
OCV_OPTION(WITH_GTK "Include GTK support" ON
  VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID
  VERIFY HAVE_GTK)
OCV_OPTION(WITH_GTK_2_X "Use GTK version 2" OFF
  VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID
  VERIFY HAVE_GTK AND NOT HAVE_GTK3)
OCV_OPTION(WITH_FRAMEBUFFER "Include framebuffer support" OFF
  VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID)
OCV_OPTION(WITH_FRAMEBUFFER_XVFB "Include virtual framebuffer support" OFF
  VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID)
OCV_OPTION(WITH_WAYLAND "Include Wayland support" OFF
        VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID
        VERIFY HAVE_WAYLAND)
OCV_OPTION(WITH_IPP "Include Intel IPP support" (NOT MINGW AND NOT CV_DISABLE_OPTIMIZATION)
  VISIBLE_IF (X86_64 OR X86) AND NOT WINRT AND NOT IOS AND NOT XROS
  VERIFY HAVE_IPP)
OCV_OPTION(WITH_HALIDE "Include Halide support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_HALIDE)
OCV_OPTION(WITH_VULKAN "Include Vulkan support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_VULKAN)
```

----------------------------------------

TITLE: Configuring Java Compilation and Documentation Settings
DESCRIPTION: Sets up Java compilation attributes and javadoc configuration, including source/target versions and documentation URL links.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jar/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
if(OPENCV_JAVA_SOURCE_VERSION)
  set(OPENCV_ANT_JAVAC_EXTRA_ATTRS "${OPENCV_ANT_JAVAC_EXTRA_ATTRS} source=\"${OPENCV_JAVA_SOURCE_VERSION}\"")
endif()
if(OPENCV_JAVA_TARGET_VERSION)
  set(OPENCV_ANT_JAVAC_EXTRA_ATTRS "${OPENCV_ANT_JAVAC_EXTRA_ATTRS} target=\"${OPENCV_JAVA_TARGET_VERSION}\"")
endif()

set(OPENCV_JAVADOC_DESTINATION "${OpenCV_BINARY_DIR}/doc/doxygen/html/javadoc" CACHE STRING "")

set(OPENCV_JAVADOC_LINK_URL "" CACHE STRING "See details in modules/java/jar/CMakeLists.txt")
if(OPENCV_JAVADOC_LINK_URL)
  set(CMAKE_CONFIG_OPENCV_JAVADOC_LINK "link=\"${OPENCV_JAVADOC_LINK_URL}\"")
endif()
```

----------------------------------------

TITLE: Keypoint Management Logic
DESCRIPTION: Handles the dynamic allocation and management of keypoints storage, including capacity expansion when needed. Implements the success handling logic for both homogeneous and structured corner detection cases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_17

LANGUAGE: C++
CODE:
```
success_homogeneous:
    if(total == nExpectedCorners)
    {
        if(nExpectedCorners == 0)
        {
            nExpectedCorners = 512;
            keypoints.reserve(nExpectedCorners);
        }
        else
        {
            nExpectedCorners *= 2;
            keypoints.reserve(nExpectedCorners);
        }
    }
    keypoints.push_back(KeyPoint(Point2f((float)x, (float)y), 1.0f));
    total++;
    goto homogeneous;
```

----------------------------------------

TITLE: Setting a Pixel Value in an Image with OpenCV in Python
DESCRIPTION: Alters the intensity value of a pixel at (y, x) in a NumPy ndarray with Python OpenCV. Indexing is direct: img[y, x] = 128. Input matrix must be mutable; assignment is in-place.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_18

LANGUAGE: Python
CODE:
```
img[y, x] = 128
```

----------------------------------------

TITLE: Configuring and Building DirectX Sample Projects - OpenCV - CMake
DESCRIPTION: This snippet initializes, checks, and configures DirectX sample projects for OpenCV using CMake. It ensures the mandatory modules (opencv_core, opencv_imgproc, etc.) are available, defines build targets for each sample file, and links the correct DirectX and Windows libraries based on the specific sample. Prerequisites include enabled BUILD_EXAMPLES and all required dependencies present. Keys parameters include sample source filenames and dependency settings. The inputs are *.cpp and related files, and outputs are configured sample binaries linked to appropriate libraries. Conditional logic is used to link specific DirectX libraries to corresponding interop samples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/directx/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
ocv_install_example_src(directx *.cpp *.hpp CMakeLists.txt)

set(OPENCV_DIRECTX_SAMPLES_REQUIRED_DEPS
    opencv_core
    opencv_imgproc
    opencv_imgcodecs
    opencv_videoio
    opencv_highgui)
ocv_check_dependencies(${OPENCV_DIRECTX_SAMPLES_REQUIRED_DEPS})

if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()

project("directx_samples")
ocv_include_modules_recurse(${tgt} ${OPENCV_DIRECTX_SAMPLES_REQUIRED_DEPS})
file(GLOB all_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
foreach(sample_filename ${all_samples})
  ocv_define_sample(tgt ${sample_filename} directx)
  ocv_target_link_libraries(${tgt} PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_DIRECTX_SAMPLES_REQUIRED_DEPS})
  ocv_target_link_libraries(${tgt} PRIVATE "gdi32")
  if(sample_filename STREQUAL "d3d9_interop.cpp")
    ocv_target_link_libraries(${tgt} PRIVATE d3d9)
  endif()
  if(sample_filename STREQUAL "d3d9ex_interop.cpp")
    ocv_target_link_libraries(${tgt} PRIVATE d3d9)
  endif()
  if(sample_filename STREQUAL "d3d10_interop.cpp")
    ocv_target_link_libraries(${tgt} PRIVATE d3d10)
  endif()
  if(sample_filename STREQUAL "d3d11_interop.cpp")
    ocv_target_link_libraries(${tgt} PRIVATE d3d11)
  endif()
endforeach()

```

----------------------------------------

TITLE: Performing Non-Linear SVM Classification in OpenCV
DESCRIPTION: This snippet demonstrates the main process of non-linear SVM classification. It includes creating the SVM object, setting parameters, training the model, and classifying the data points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_12

LANGUAGE: C++
CODE:
```
Ptr<SVM> svm = SVM::create();
svm->setType(SVM::C_SVC);
svm->setKernel(SVM::RBF);
svm->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER, 100, 1e-6));
svm->train(trainData, ROW_SAMPLE, labels);

Mat green(res.size(), CV_8UC3);
Mat blue(res.size(), CV_8UC3);

for (int i = 0; i < res.rows; ++i)
{
    for (int j = 0; j < res.cols; ++j)
    {
        Mat sampleMat = (Mat_<float>(1,2) << j,i);
        float response = svm->predict(sampleMat);
        if (response == 1)
            green.at<Vec3b>(i,j) = Vec3b(0,255,0);
        else if (response == 2)
            blue.at<Vec3b>(i,j) = Vec3b(255,0,0);
    }
}

green.copyTo(res, green);
blue.copyTo(res, blue);
```

LANGUAGE: Java
CODE:
```
SVM svm = SVM.create();
svm.setType(SVM.C_SVC);
svm.setKernel(SVM.RBF);
svm.setTermCriteria(new TermCriteria(TermCriteria.MAX_ITER, 100, 1e-6));
svm.train(trainData, Ml.ROW_SAMPLE, labels);

Mat green = new Mat(res.size(), CvType.CV_8UC3);
Mat blue = new Mat(res.size(), CvType.CV_8UC3);

for (int i = 0; i < res.rows(); i++) {
    for (int j = 0; j < res.cols(); j++) {
        Mat sampleMat = new Mat(1, 2, CvType.CV_32F) {
            {
                put(0, 0, j);
                put(0, 1, i);
            }
        };
        float response = svm.predict(sampleMat);
        if (response == 1) {
            green.put(i, j, new byte[]{0, (byte) 255, 0});
        } else if (response == 2) {
            blue.put(i, j, new byte[]{(byte) 255, 0, 0});
        }
    }
}

Core.copyTo(green, res, green);
Core.copyTo(blue, res, blue);
```

LANGUAGE: Python
CODE:
```
svm = cv.ml.SVM_create()
svm.setType(cv.ml.SVM_C_SVC)
svm.setKernel(cv.ml.SVM_RBF)
svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, 100, 1e-6))
svm.train(train_data, cv.ml.ROW_SAMPLE, labels)

green = np.zeros((res.shape[0], res.shape[1], 3), np.uint8)
blue = np.zeros((res.shape[0], res.shape[1], 3), np.uint8)

for i in range(res.shape[0]):
    for j in range(res.shape[1]):
        sample = np.matrix([[j, i]], dtype=np.float32)
        response = svm.predict(sample)[1]
        if response == 1:
            green[i, j] = [0, 255, 0]
        elif response == 2:
            blue[i, j] = [255, 0, 0]

mask = np.logical_or(green.any(-1), blue.any(-1))
res[mask] = green[mask] + blue[mask]
```

----------------------------------------

TITLE: Installing GCC Compiler on Linux
DESCRIPTION: Command to install the GCC compiler on Linux using the package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
sudo apt-get install build-essential
```

----------------------------------------

TITLE: Checking Library Dependencies with ldd
DESCRIPTION: Verify installed shared libraries requirements for OpenCV on the target system using the ldd command. Identifies any missing dependencies needing installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_23

LANGUAGE: bash
CODE:
```
ldd /usr/local/lib/libopencv_freetype.so
```

----------------------------------------

TITLE: Building OpenCV with Make
DESCRIPTION: Command to build OpenCV using make with parallel compilation. The -j parameter specifies the number of parallel threads to use, which varies depending on the system resources.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_7

LANGUAGE: bash
CODE:
```
$ make -j6
```

----------------------------------------

TITLE: Dictionary Operations in ArUco
DESCRIPTION: Methods for reading and writing ArUco dictionary data to persistent storage.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_faq/aruco_faq.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
cv::aruco::Dictionary::writeDictionary()
cv::aruco::Dictionary::readDictionary()
```

----------------------------------------

TITLE: Prediction Postprocessing: Extracting Top Class - C++
DESCRIPTION: This C++ snippet finds the class index with maximum confidence from model output and assigns it to 'classId'. This allows retrieval of the most likely prediction after inference. It is standard in classification pipelines where class scores are produced.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_14

LANGUAGE: cpp
CODE:
```
Point classIdPoint;\ndouble confidence;\nminMaxLoc(prob.reshape(1, 1), 0, &confidence, 0, &classIdPoint);\nint classId = classIdPoint.x;
```

----------------------------------------

TITLE: Detecting Thread Support for Standalone Build in CMake
DESCRIPTION: Manages thread support detection and definition for standalone sample builds. If example threads are disabled (`OPENCV_EXAMPLES_DISABLE_THREADS`), it does nothing. Otherwise, it sets a `HAVE_THREADS` variable directly for MSVC or Apple platforms, or uses `find_package(Threads)` for other systems. Finally, if thread support is confirmed (either via `Threads::Threads` target or the `HAVE_THREADS` variable) and not disabled, it adds the `-DHAVE_THREADS=1` preprocessor definition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: cmake
CODE:
```
if(OPENCV_EXAMPLES_DISABLE_THREADS)
  # nothing
elsif(MSVC OR APPLE)
  set(HAVE_THREADS 1)
else()
  find_package(Threads)
endif()
if((TARGET Threads::Threads OR HAVE_THREADS) AND NOT OPENCV_EXAMPLES_DISABLE_THREADS)
  set(HAVE_THREADS 1)
  add_definitions(-DHAVE_THREADS=1)
endif()
```

----------------------------------------

TITLE: Defining and Using Scheduling Patterns in Halide YAML Configuration
DESCRIPTION: This YAML snippet demonstrates how to define a reusable scheduling pattern named `fully_connected` under the `patterns` section. The pattern uses a parameter `c_split`. It then shows how to apply this pattern to a specific layer (`fc8`), providing a concrete value (8) for the `c_split` parameter.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide_scheduling/dnn_halide_scheduling.markdown#2025-04-22_snippet_3

LANGUAGE: yaml
CODE:
```
# At the beginning of the file
patterns:
  fully_connected:
    split: { c: c_split }
    fuse: { src: [x, y, co], dst: block }
    parallel: block
    vectorize: { ci: c_split }
# Somewhere below
fc8:
  pattern: fully_connected
  params: { c_split: 8 }
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree in C++
DESCRIPTION: Part of the FAST corner detection algorithm that uses conditional logic to decide whether a pixel is a corner. The code compares pixel values at various offsets to brightness thresholds (c_b and cb) and branches to either 'is_a_corner' or 'is_not_a_corner' labels based on these comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_40

LANGUAGE: C++
CODE:
```
goto is_a_corner;
else
  if(ptr[offset10] < c_b)
    goto is_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset10] < c_b)
    if(ptr[offset11] < c_b)
      goto is_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset1] < c_b)
    if(ptr[offset6] > cb)
      goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        if(ptr[offset3] < c_b)
          if(ptr[offset4] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset1] > cb)
      if(ptr[offset6] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset8] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset6] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset8] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
else
  if(ptr[offset9] > cb)
    goto is_not_a_corner;
  else
    if(ptr[offset9] < c_b)
      if(ptr[offset1] > cb)
        if(ptr[offset6] > cb)
          goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset6] > cb)
            goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset4] < c_b)
                  if(ptr[offset3] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset4] < c_b)
                  if(ptr[offset3] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset5] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset2] < c_b)
        if(ptr[offset9] < c_b)
          goto is_not_a_corner;
        else
          if(ptr[offset9] > cb)
            if(ptr[offset1] > cb)
              if(ptr[offset6] < c_b)
                goto is_not_a_corner;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset4] > cb)
                      if(ptr[offset3] > cb)
                        goto is_a_corner;
                      else
                        if(ptr[offset10] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset1] < c_b)
                if(ptr[offset6] < c_b)
                  goto is_not_a_corner;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset8] > cb)
                      if(ptr[offset4] > cb)
                        if(ptr[offset3] > cb)
                          goto is_a_corner;
                        else
                          if(ptr[offset10] > cb)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset10] > cb)
                          if(ptr[offset11] > cb)
```

----------------------------------------

TITLE: Building OpenCV Static AAR for Android (Python Command)
DESCRIPTION: Executes the Python script `build_static_aar.py` to create an AAR package containing OpenCV Java bindings and the static C++ libraries (.a files). Requires the path to the downloaded OpenCV Android SDK as an argument. The output AAR and Maven repository will be generated in the 'outputs' directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/android/aar-template/README.md#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
python build_static_aar.py "~/opencv-4.7.0-android-sdk/OpenCV-android-sdk"
```

----------------------------------------

TITLE: Reduce Operations with Vector Registers in C++
DESCRIPTION: Demonstrates reduce operations like v_reduce_min(), v_reduce_max(), and v_reduce_sum() to compute a single value from a vector register.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_8

LANGUAGE: C++
CODE:
```
v_int32 a;                                //  a = {a1, ..., a4}
int mn = v_reduce_min(a);                 // mn = min(a1, ..., an)
int sum = v_reduce_sum(a);                // sum = a1 + ... + an
```

----------------------------------------

TITLE: Setting Fixed Aspect Ratio for Camera Matrix in C++
DESCRIPTION: This snippet shows how to set a fixed aspect ratio for the camera matrix during calibration using OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
fixed_aspect
```

----------------------------------------

TITLE: Corner Detection Conditional Logic in C++
DESCRIPTION: Complex nested if-else statements comparing pixel values at different offsets against brightness thresholds cb and c_b. The code implements corner detection logic with multiple branching paths leading to either success_homogeneous or homogeneous states.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_39

LANGUAGE: cpp
CODE:
```
else
  if(ptr[offset10] < c_b)
    if(ptr[offset11] < c_b)
      {} // goto success_homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  if(ptr[offset8] < c_b)
    if(ptr[offset9] < c_b)
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          {} // goto success_homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset9] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              {} // goto success_homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  if(ptr[offset11] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset12] > cb)
              if(ptr[offset13] > cb)
                if(ptr[offset6] > cb)
                  if(ptr[offset5] > cb)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset14] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  if(ptr[offset14] > cb)
                    if(ptr[offset15] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
```

----------------------------------------

TITLE: Calculating Chessboard Corner Positions in C++
DESCRIPTION: This code calculates the positions of chessboard corners for camera calibration using OpenCV functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
board_corners
```

----------------------------------------

TITLE: Defining calcGST() Function Prototype in G-API
DESCRIPTION: Defines the calcGST() function prototype using G-API, which produces a compute graph instead of calculating actual values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
cv::GMat calcGST(const cv::GMat& inputImage, const int w);
```

----------------------------------------

TITLE: Initializing Flann Based Matcher for Descriptor Matching in C++
DESCRIPTION: Configures the FlannBasedMatcher with LSH index and search parameters for matching binary descriptors efficiently. It sets up matching using tuned parameters to ensure efficient and accurate results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
cv::Ptr<cv::flann::IndexParams> indexParams = cv::makePtr<cv::flann::LshIndexParams>(6, 12, 1); // instantiate LSH index parameters
cv::Ptr<cv::flann::SearchParams> searchParams = cv::makePtr<cv::flann::SearchParams>(50);       // instantiate flann search parameters

cv::DescriptorMatcher * matcher = new cv::FlannBasedMatcher(indexParams, searchParams);         // instantiate FlannBased matcher
rmatcher.setDescriptorMatcher(matcher);                                                         // set matcher
```

----------------------------------------

TITLE: Example Success Output from Model Conversion - Console
DESCRIPTION: This output confirms the ONNX export was successful and provides the relative file path to the resulting ONNX file. It is generated by the prior model export scripts and should match the expected output directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_5

LANGUAGE: console
CODE:
```
PyTorch ResNet-50 model was successfully converted: models/resnet50.onnx
```

----------------------------------------

TITLE: Setting Parameters for Text Detection (EAST) in C++
DESCRIPTION: This C++ snippet configures the parameters for EAST-based text detection using OpenCV. It sets confidence and non-maximum suppression thresholds, scales for input normalization, and specifies input size and mean values for accurate text detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
TextDetectionModel_EAST model("EAST.pb");

float confThreshold = 0.5;
float nmsThreshold = 0.4;
model.setConfidenceThreshold(confThresh)
     .setNMSThreshold(nmsThresh)
;

// Normalization parameters
double detScale = 1.0;
Size detInputSize = Size(320, 320);
Scalar detMean = Scalar(123.68, 116.78, 103.94);
bool swapRB = true;
model.setInputParams(detScale, detInputSize, detMean, swapRB);
```

----------------------------------------

TITLE: Installing Make on Linux
DESCRIPTION: Command to install Make build automation tool on Linux using the package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
sudo apt-get install make
```

----------------------------------------

TITLE: Installing OpenCV Libraries on Target System
DESCRIPTION: Receive and extract the OpenCV library archive from the host to the target system at /usr/local. Finalize installation with ldconfig to refresh shared library cache.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_24

LANGUAGE: bash
CODE:
```
sudo tar zxvf opencv_arm64.tgz -C /usr/local
sudo ldconfig
```

----------------------------------------

TITLE: Converting Image to Grayscale in OpenCV (C++/Java/Python)
DESCRIPTION: Converts the loaded source image from BGR (or color) to grayscale. This is often a prerequisite for thresholding and morphological operations. The `cvtColor` function is used in all three languages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
//![gray]
// Transform source image to gray if it is not already
Mat gray;

if (src.channels() == 3)
{
    cvtColor(src, gray, COLOR_BGR2GRAY);
}
else
{
    gray = src;
}

// Show gray image
show_wait_destroy("gray", gray);
//![gray]
```

LANGUAGE: java
CODE:
```
//![gray]
// Transform source image to gray if it is not already
Mat gray = new Mat();
if (src.channels() == 3) {
    Imgproc.cvtColor(src, gray, Imgproc.COLOR_BGR2GRAY);
} else {
    gray = src;
}

// Show gray image
showWaitDestroy("gray", gray);
//![gray]
```

LANGUAGE: python
CODE:
```
#![gray]
# Transform source image to gray if it is not already
if len(src.shape) != 2:
    gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
else:
    gray = src

# Show gray image
show_wait_destroy("gray", gray)
#![gray]
```

----------------------------------------

TITLE: Performing Closing Operation with OpenCV Python
DESCRIPTION: Shows how to perform closing operation (dilation followed by erosion). Useful for closing small holes inside foreground objects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)
```

----------------------------------------

TITLE: Configuring Qt Build for OpenCV on Windows
DESCRIPTION: Command to configure Qt build with specific features disabled for OpenCV compatibility. Disables webkit, phonon, Qt3 support, multimedia, and other non-essential components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
configure.exe -release -no-webkit -no-phonon -no-phonon-backend -no-script -no-scripttools -no-qt3support -no-multimedia -no-ltcg
```

----------------------------------------

TITLE: Pixel Intensity Comparison for FAST Corner Detection in C++
DESCRIPTION: This code snippet implements part of the FAST corner detection algorithm. It compares pixel intensities at various offsets against threshold values to determine if a pixel is a corner point. The algorithm uses nested conditional statements to check multiple conditions efficiently.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_36

LANGUAGE: C++
CODE:
```
continue; // goto homogeneous;
else
  if(ptr[offset5] < c_b)
    if(ptr[offset6] < c_b)
      if(ptr[offset7] < c_b)
        {} // goto success_homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  if(ptr[offset4] < c_b)
    if(ptr[offset5] < c_b)
      if(ptr[offset6] < c_b)
        if(ptr[offset7] < c_b)
          {} // goto success_homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
// ... (truncated for brevity)
else
  if(ptr[offset2] < c_b)
    if(ptr[offset4] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset7] > cb)
          if(ptr[offset8] > cb)
            if(ptr[offset9] > cb)
              if(ptr[offset10] > cb)
                if(ptr[offset6] > cb)
                  if(ptr[offset5] > cb)
                    if(ptr[offset3] > cb)
                      {} // goto success_homogeneous;
                    else
                      if(ptr[offset12] > cb)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                  else
                    if(ptr[offset12] > cb)
                      if(ptr[offset13] > cb)
                        if(ptr[offset14] > cb)
                          {} // goto success_homogeneous;
                        else
                          continue; // goto homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  if(ptr[offset12] > cb)
                    if(ptr[offset13] > cb)
                      if(ptr[offset14] > cb)
                        if(ptr[offset15] > cb)
                          {} // goto success_homogeneous;
                        else
                          continue; // goto homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
      if(ptr[offset11] < c_b)
        if(ptr[offset12] < c_b)
          if(ptr[offset13] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset14] < c_b)
                if(ptr[offset15] < c_b)
                  if(ptr[offset1] < c_b)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset8] < c_b)
                      if(ptr[offset9] < c_b)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset7] < c_b)
                      if(ptr[offset8] < c_b)
                        if(ptr[offset9] < c_b)
                          {} // goto success_homogeneous;
                        else
                          continue; // goto homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                if(ptr[offset5] < c_b)
                  if(ptr[offset6] < c_b)
                    if(ptr[offset7] < c_b)
                      if(ptr[offset8] < c_b)
                        if(ptr[offset9] < c_b)
                          {} // goto success_homogeneous;
                        else
                          continue; // goto homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset1] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset14] < c_b)
                    if(ptr[offset15] < c_b)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
```

----------------------------------------

TITLE: Finding Keypoints with SIFT in OpenCV - Python
DESCRIPTION: This snippet initializes the SIFT feature detector and finds keypoints and descriptors for left and right images using OpenCV. It requires OpenCV and images to process. Outputs the keypoints and descriptors for further matching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img1 = cv.imread('myleft.jpg', cv.IMREAD_GRAYSCALE)  #queryimage # left image
img2 = cv.imread('myright.jpg', cv.IMREAD_GRAYSCALE) #trainimage # right image

sift = cv.SIFT_create()

# find the keypoints and descriptors with SIFT
kp1, des1 = sift.detectAndCompute(img1,None)
kp2, des2 = sift.detectAndCompute(img2,None)
```

----------------------------------------

TITLE: Configuring U-SURF (Upright SURF) in OpenCV Python
DESCRIPTION: This code shows how to enable U-SURF mode, which doesn't compute orientation, making the process faster. It's useful for applications where rotation invariance is not required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
# Check upright flag, if it False, set it to True
>>> print( surf.getUpright() )
False

>>> surf.setUpright(True)

# Recompute the feature points and draw it
>>> kp = surf.detect(img,None)
>>> img2 = cv.drawKeypoints(img,kp,None,(255,0,0),4)

>>> plt.imshow(img2),plt.show()
```

----------------------------------------

TITLE: Converting Image to Grayscale in Python
DESCRIPTION: Converts the blurred source image to grayscale using cv2.cvtColor with the cv2.COLOR_BGR2GRAY flag. Requires cv2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_14

LANGUAGE: python
CODE:
```
#! [convert_to_gray]
# [convert_to_gray]
# Convert the image to grayscale
src_gray = cv.cvtColor( src, cv.COLOR_BGR2GRAY )
# [convert_to_gray]
# ! [convert_to_gray]
```

----------------------------------------

TITLE: Min/Max Operations with Vector Registers in C++
DESCRIPTION: Shows how to use v_min() and v_max() functions to perform element-wise minimum and maximum operations on vector registers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
v_int32 a;                               // {a1, ..., an}
v_int32 b;                               // {b1, ..., bn}

v_int32 mn = v_min(a, b);                // {min(a1, b1), ..., min(an, bn)}
v_int32 mx = v_max(a, b);                // {max(a1, b1), ..., max(an, bn)}
```

----------------------------------------

TITLE: Setting TIFF Library Dependencies with CMake
DESCRIPTION: This CMake snippet appends required libraries to the TIFF_LIBRARY_DEPS list conditionally, based on the availability of components such as libm, zlib, jpeg, and others. The purpose is to compile the libtiff library accurately by including necessary dependencies for various compression and decoding functionalities.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(TIFF_LIBRARY_DEPS)
if(M_LIBRARY)
  list(APPEND TIFF_LIBRARY_DEPS ${M_LIBRARY})
endif()
if(ZLIB_LIBRARIES)
  list(APPEND TIFF_LIBRARY_DEPS ${ZLIB_LIBRARIES})
endif()
if(JPEG_LIBRARIES)
  list(APPEND TIFF_LIBRARY_DEPS ${JPEG_LIBRARIES})
endif()
if(JPEG12_LIBRARIES)
  list(APPEND TIFF_LIBRARY_DEPS ${JPEG12_LIBRARIES})
endif()
if(JBIG_LIBRARIES)
  list(APPEND TIFF_LIBRARY_DEPS ${JBIG_LIBRARIES})
endif()
if(LIBLZMA_LIBRARIES)
  list(APPEND TIFF_LIBRARY_DEPS ${LIBLZMA_LIBRARIES})
endif()
```

----------------------------------------

TITLE: Setting up Trackbars for Threshold Parameters (Java)
DESCRIPTION: This Java code creates two slider trackbars for threshold type and value in the 'Threshold Demo' window with OpenCV's HighGui API. Each slider is bound to an onChange callback that updates the thresholding result instantly. Requires OpenCV Java GUI support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_10

LANGUAGE: Java
CODE:
```
// [trackbar]\nHighGui.createTrackbar("Type:\n 0:Binary \n 1:BinaryInv \n 2:Trunc \n 3:ToZero \n 4:ToZeroInv", window_name, new int[]{threshold_type}, max_type, (pos)->{\n    threshold_type = pos;\n    update();\n});\nHighGui.createTrackbar("Value", window_name, new int[]{threshold_value}, max_value, (pos)->{\n    threshold_value = pos;\n    update();\n});\n// [trackbar]
```

----------------------------------------

TITLE: Computing Calibration Errors in C++
DESCRIPTION: This code computes the calibration errors by projecting object points and comparing them with detected image points using OpenCV functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_11

LANGUAGE: cpp
CODE:
```
compute_errors
```

----------------------------------------

TITLE: Defining OpenJPEG Library Version Properties in CMake
DESCRIPTION: Sets the VERSION and SOVERSION properties for the OpenJPEG library target using the previously defined version variables. These properties are used by CMake during the library linking and installation phases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
set(OPENJPEG_LIBRARY_PROPERTIES
  VERSION   "${OPENJPEG_VERSION_MAJOR}.${OPENJPEG_VERSION_MINOR}.${OPENJPEG_VERSION_BUILD}"
  SOVERSION "${OPENJPEG_SOVERSION}"
)
```

----------------------------------------

TITLE: Cloning OpenCV Repository and Preparing Build Directory (Bash)
DESCRIPTION: This sequence of Bash commands clones the OpenCV Git repository, navigates into the cloned directory, checks out the 2.4 branch (though newer versions would follow a similar pattern), creates a dedicated 'build' subdirectory, and changes the current directory into 'build' to prepare for the CMake configuration step.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
git clone git://github.com/opencv/opencv.git
cd opencv
git checkout 2.4
mkdir build
cd build
```

----------------------------------------

TITLE: Default OpenCV DNN Model Configuration for SSD MobileNetV1 - YAML
DESCRIPTION: Provides a sample YAML configuration for the OpenCV DNN module. Specifies model and config file paths, preprocessing parameters (mean, scale, input shape, color format), class list, and sample type for SSD MobileNetV1. Dependencies: correct file paths and compatible OpenCV DNN pipeline.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_6

LANGUAGE: yml
CODE:
```
ssd_tf:\n  model: "ssd_mobilenet_v1_coco_2017_11_17.pb"\n  config: "ssd_mobilenet_v1_coco_2017_11_17.pbtxt"\n  mean: [0, 0, 0]\n  scale: 1.0\n  width: 300\n  height: 300\n  rgb: true\n  classes: "object_detection_classes_coco.txt"\n  sample: "object_detection"
```

----------------------------------------

TITLE: Implementing SURF Feature Detection in Java
DESCRIPTION: This Java code showcases the use of OpenCV's SURF detector for keypoint detection in images. It covers image loading, SURF detector creation, keypoint detection, and visualization of the results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/feature_detection/feature_detection.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.Core;\nimport org.opencv.core.Mat;\nimport org.opencv.core.MatOfKeyPoint;\nimport org.opencv.core.Scalar;\nimport org.opencv.features2d.Features2d;\nimport org.opencv.imgcodecs.Imgcodecs;\nimport org.opencv.xfeatures2d.SURF;\n\nclass SURFDetectionDemo {\n    public static void main(String[] args) {\n        // Load the native OpenCV library\n        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);\n\n        // Read image file\n        Mat src = Imgcodecs.imread("box.png", Imgcodecs.IMREAD_GRAYSCALE);\n\n        // Check if image is loaded fine\n        if (src.empty()) {\n            System.out.println("Error opening image!");\n            System.exit(-1);\n        }\n\n        // Detect the keypoints using SURF Detector\n        SURF detector = SURF.create(400);\n        MatOfKeyPoint keypoints = new MatOfKeyPoint();\n        detector.detect(src, keypoints);\n\n        // Draw keypoints\n        Mat outputImage = new Mat();\n        Features2d.drawKeypoints(src, keypoints, outputImage, new Scalar(255, 0, 0), Features2d.DrawMatchesFlags_DEFAULT);\n\n        // Write the image with keypoints\n        Imgcodecs.imwrite("surf_keypoints.jpg", outputImage);\n\n        System.out.println("Finished. See surf_keypoints.jpg for the result.");\n    }\n}
```

----------------------------------------

TITLE: Creating ARM Build Directory and Configuring with CMake - Bash
DESCRIPTION: Demonstrates creation of a dedicated build directory for ARM hard-float configurations, then runs CMake with the appropriate ARM toolchain file. Requires OpenCV source and toolchains to be present in the specified paths. Replace directory names as needed according to project organization. This sets up an isolated build environment for ARM.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/arm_crosscompile_with_cmake.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
cd ~/opencv/platforms/linux
mkdir -p build_hardfp
cd build_hardfp

cmake -DCMAKE_TOOLCHAIN_FILE=../arm-gnueabi.toolchain.cmake ../../..
```

----------------------------------------

TITLE: CMAKE_INSTALL_PREFIX Configuration
DESCRIPTION: Sets up default installation directories based on platform and build type. Uses different paths for Windows vs Unix systems and handles cross-compilation scenarios.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT)
  if(NOT CMAKE_CROSSCOMPILING)
    if(WIN32)
      set(CMAKE_INSTALL_PREFIX "${CMAKE_BINARY_DIR}/install" CACHE PATH "Installation Directory" FORCE)
    else()
      set(CMAKE_INSTALL_PREFIX "/usr/local" CACHE PATH "Installation Directory" FORCE)
    endif()
  else()
    # any cross-compiling
    set(CMAKE_INSTALL_PREFIX "${CMAKE_BINARY_DIR}/install" CACHE PATH "Installation Directory" FORCE)
  endif()
endif()
```

----------------------------------------

TITLE: Setting Python Tests Configuration File Path in CMake for OpenCV
DESCRIPTION: Defines the directory and file path for the Python tests configuration file. These are set as cache variables for use in other parts of the build process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/test/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(OPENCV_PYTHON_TESTS_CONFIG_FILE_DIR "${OpenCV_BINARY_DIR}" CACHE INTERNAL "")
set(OPENCV_PYTHON_TESTS_CONFIG_FILE "${OPENCV_PYTHON_TESTS_CONFIG_FILE_DIR}/opencv_python_tests.cfg" CACHE INTERNAL "")
```

----------------------------------------

TITLE: Installing AArch64 Development Libraries (Bash)
DESCRIPTION: Installs development packages for FFmpeg (libavcodec, libavformat, libavutil, libswscale), FreeType (libfreetype), and HarfBuzz (libharfbuzz) specifically for the `arm64` target architecture onto the host system. The `:arm64` suffix instructs `apt` to install the package for the specified foreign architecture.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_13

LANGUAGE: bash
CODE:
```
sudo apt install -y \
    libavcodec-dev:arm64 \
    libavformat-dev:arm64 \
    libavutil-dev:arm64 \
    libswscale-dev:arm64 \
    libfreetype-dev:arm64 \
    libharfbuzz-dev:arm64
```

----------------------------------------

TITLE: Checking Foreign Architectures with DPKG (Bash)
DESCRIPTION: Lists the foreign architectures that have been added and are currently supported by `dpkg` on the host system. The example output shows that `arm64` and `armhf` have been successfully added.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_9

LANGUAGE: bash
CODE:
```
sudo dpkg --print-foreign-architectures
arm64
armhf
```

----------------------------------------

TITLE: Comparison Operations with Vector Registers in C++
DESCRIPTION: Illustrates comparison operations between vector registers, showing how true/false values are represented in different bit widths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
// let us consider the following code is run in a 128-bit register
v_uint8 a;                               // a = {0, 1, 2, ..., 15}
v_uint8 b;                               // b = {15, 14, 13, ..., 0}

v_uint8 c = a < b;

/*
    let us look at the first 4 values in binary

    a = |00000000|00000001|00000010|00000011|
    b = |00001111|00001110|00001101|00001100|
    c = |11111111|11111111|11111111|11111111|

    If we store the values of c and print them as integers, we will get 255 for true values and 0 for false values.
*/
---
// In a computer supporting 256-bit registers
v_int32 a;                               // a = {1, 2, 3, 4, 5, 6, 7, 8}
v_int32 b;                               // b = {8, 7, 6, 5, 4, 3, 2, 1}

v_int32 c = (a < b);                     // c = {-1, -1, -1, -1, 0, 0, 0, 0}

/*
    The true values are 0xffffffff, which in signed 32-bit integer representation is equal to -1.
*/
```

----------------------------------------

TITLE: Corner Detection Branching Logic in OpenCV
DESCRIPTION: Complex nested conditional logic for determining corner pixels in an image. Uses pointer arithmetic to compare pixel values against threshold values (cb and c_b) and navigates to appropriate labels (is_a_corner or is_not_a_corner) based on the comparison results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_33

LANGUAGE: C
CODE:
```
goto is_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset7] > cb)
    if(ptr[offset9] < c_b)
      if(ptr[offset1] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset6] > cb)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset3] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset8] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset3] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset8] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset3] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset8] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset9] > cb)
        if(ptr[offset1] > cb)
          if(ptr[offset6] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset3] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset6] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset4] < c_b)
                  if(ptr[offset10] > cb)
                    if(ptr[offset8] > cb)
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    if(ptr[offset3] < c_b)
                      if(ptr[offset11] < c_b)
                        if(ptr[offset10] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset8] > cb)
                    if(ptr[offset10] > cb)
                      if(ptr[offset4] > cb)
                        goto is_a_corner;
                      else
                        if(ptr[offset11] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset3] > cb)
                        if(ptr[offset4] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset10] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset8] > cb)
                  if(ptr[offset4] > cb)
                    if(ptr[offset3] > cb)
                      goto is_a_corner;
                    else
                      if(ptr[offset10] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
      else
        if(ptr[offset1] > cb)
          goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
```

----------------------------------------

TITLE: Including OpenJPEG Library Subdirectory Build in CMake
DESCRIPTION: Uses the `add_subdirectory` command to include and process the `CMakeLists.txt` file located in the `openjp2` subdirectory. This is where the actual source files for the OpenJPEG library are compiled and the library target (`libopenjp2`) is defined.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: cmake
CODE:
```
add_subdirectory(openjp2)
```

----------------------------------------

TITLE: Generating Radon Checkerboard Pattern using Python Script (Shell)
DESCRIPTION: Executes 'gen_pattern.py' to generate a Radon checkerboard pattern ('radon_checkerboard') suitable for 'findChessboardCornersSB()', saving it to 'radon_checkerboard.svg'. The board has 10 rows, 15 columns, a square size of 12.1 units (default mm), and includes specific markers at cell coordinates (7,4), (7,5), and (8,5). Requires Python and the 'gen_pattern.py' script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_pattern/camera_calibration_pattern.markdown#2025-04-22_snippet_3

LANGUAGE: shell
CODE:
```
python gen_pattern.py -o radon_checkerboard.svg --rows 10 --columns 15 --type radon_checkerboard -s 12.1 -m 7 4 7 5 8 5
```

----------------------------------------

TITLE: Transforming and Recognizing Text with OpenCV C++
DESCRIPTION: This C++ snippet demonstrates the transformation and cropping of text from an image, followed by text recognition using OpenCV's DNN module. It requires OpenCV libraries, particularly the DNN module, and processes an input image to extract and recognize text. 'recInput' and 'vertices' are used for transformation while 'cropped' holds the result. The recognized text is stored in 'recResult'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```

    // Transform and Crop
    Mat cropped;
    fourPointsTransform(recInput, vertices, cropped);

    String recResult = recognizer.recognize(cropped);

```

----------------------------------------

TITLE: Assigning OpenJPEG Target to Solution Folder in CMake
DESCRIPTION: Conditionally sets the `FOLDER` property for the OpenJPEG library target to "3rdparty" if the `ENABLE_SOLUTION_FOLDERS` option is enabled in CMake. This helps organize targets within IDEs like Visual Studio.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_14

LANGUAGE: cmake
CODE:
```
if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${OPENJPEG_LIBRARY_NAME}
    PROPERTIES
      FOLDER "3rdparty"
  )
endif()
```

----------------------------------------

TITLE: Platform Detection and Base Configuration
DESCRIPTION: Detects ARM/AARCH64 platforms and sets up basic compiler flags including unwind tables for better debugging.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/carotene/hal/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION ${MIN_VER_CMAKE} FATAL_ERROR)

include(CheckCCompilerFlag)
include(CheckCXXCompilerFlag)

set(TEGRA_HAL_DIR "${CMAKE_CURRENT_SOURCE_DIR}")
set(CAROTENE_DIR "${TEGRA_HAL_DIR}/../")

if(CMAKE_SYSTEM_PROCESSOR MATCHES "^(arm.*|ARM.*)")
  set(ARM TRUE)
elseif (CMAKE_SYSTEM_PROCESSOR MATCHES "aarch64.*|AARCH64.*")
  set(AARCH64 TRUE)
endif()

ocv_warnings_disable(CMAKE_CXX_FLAGS -Wunused-function)
```

----------------------------------------

TITLE: Building Halide on Linux using CMake and Make
DESCRIPTION: This snippet provides the steps to build Halide on a Linux system, using CMake and Make. This process compiles Halide with dependencies on the pre-installed LLVM library without additional tests or examples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown#2025-04-22_snippet_3

LANGUAGE: Bash
CODE:
```
cd halide_root
mkdir build && cd build
cmake -DLLVM_DIR=llvm_root/build/lib/cmake/llvm -DCMAKE_BUILD_TYPE=Release -DLLVM_VERSION=40 -DWITH_TESTS=OFF -DWITH_APPS=OFF -DWITH_TUTORIALS=OFF ..
make -j4
```

----------------------------------------

TITLE: Efficient Pixel Assignment with Pointers in OpenCV
DESCRIPTION: Illustrates the use of C-style pointer access for scanning and modifying pixels in an OpenCV image matrix, emphasizing contiguous memory efficiency when accessing color image channels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
@snippet how_to_scan_images.cpp scan-c
```

----------------------------------------

TITLE: Register Custom Cropping Layer OpenCV Python
DESCRIPTION: Registers a Python-implemented custom cropping layer to override existing behavior in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_12

LANGUAGE: Python
CODE:
```
@snippet dnn/edge_detection.py Register
```

----------------------------------------

TITLE: Initializing OpenCL with OpenGL Sharing
DESCRIPTION: C++ code snippet for initializing OpenCL with OpenGL sharing capability. This is necessary for direct sharing of textures between OpenGL and OpenCL without copying data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
// init_opencl
```

----------------------------------------

TITLE: Creating Thrust End Iterator for GpuMat
DESCRIPTION: Defines a function to create a Thrust iterator that points to the end of a GpuMat, marking the boundary for algorithms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
template<typename T>
thrust::transform_iterator<step_functor<T>, thrust::counting_iterator<int> > end_itr(const cv::cuda::GpuMat& mat)
{
    return thrust::make_transform_iterator(
        thrust::counting_iterator<int>(mat.cols * mat.rows),
        step_functor<T>(mat.cols, mat.rows, mat.step / sizeof(T))
    );
}
```

----------------------------------------

TITLE: Obtaining Image Corner Coordinates Using gdalinfo (Bash)
DESCRIPTION: This command-line snippet demonstrates the use of the gdalinfo utility to extract metadata from a geospatial raster file, including its size, coordinate system, and precise corner/center coordinates. This is crucial for aligning imagery with elevation data. Requires gdalinfo (from the GDAL package) and an input raster file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/raster_io_gdal.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
\f$> gdalinfo N37W123.hgt

   Driver: SRTMHGT/SRTMHGT File Format
   Files: N37W123.hgt
   Size is 3601, 3601
   Coordinate System is:
   GEOGCS["WGS 84",
   DATUM["WGS_1984",

   ... more output ...

   Corner Coordinates:
   Upper Left  (-123.0001389,  38.0001389) (123d 0' 0.50\"W, 38d 0' 0.50\"N)
   Lower Left  (-123.0001389,  36.9998611) (123d 0' 0.50\"W, 36d59'59.50\"N)
   Upper Right (-121.9998611,  38.0001389) (121d59'59.50\"W, 38d 0' 0.50\"N)
   Lower Right (-121.9998611,  36.9998611) (121d59'59.50\"W, 36d59'59.50\"N)
   Center      (-122.5000000,  37.5000000) (122d30' 0.00\"W, 37d30' 0.00\"N)

    ... more output ...
```

----------------------------------------

TITLE: Training SVM Model
DESCRIPTION: Trains the SVM model using the prepared training data and parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
svm->train(trainingDataMat, ROW_SAMPLE, labelsMat);
```

----------------------------------------

TITLE: Declaring Neural Network Topologies using G_API_NET in G-API
DESCRIPTION: Code snippet showing how to declare different neural network topologies (face detection, age/gender recognition, and emotion recognition) using the G_API_NET macro in G-API. Each network is defined with a type name, function signature, and unique topology name.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
G_API_NET(Faces, <cv::GMat(cv::GMat)>, "face-detector");
G_API_NET(AgeGender, <std::tuple<cv::GMat,cv::GMat>(cv::GMat)>, "age-gender-recognizer");
G_API_NET(Emotions, <cv::GMat(cv::GMat)>, "emotions-recognizer");
```

----------------------------------------

TITLE: Image Loading and Border Initialization
DESCRIPTION: Loading the source image and initializing border dimensions as 5% of image size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/copyMakeBorder/copyMakeBorder.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
int top = (int) (0.05*src.rows);
int bottom = top;
int left = (int) (0.05*src.cols);
int right = left;
```

LANGUAGE: Java
CODE:
```
int top = (int) (0.05*src.rows());
int bottom = top;
int left = (int) (0.05*src.cols());
int right = left;
```

LANGUAGE: Python
CODE:
```
top = int(0.05 * src.shape[0])
bottom = top
left = int(0.05 * src.shape[1])
right = left
```

----------------------------------------

TITLE: Training SVM Model with Non-Linearly Separable Data (Python)
DESCRIPTION: Trains the SVM model in Python using the prepared non-linearly separable training data. The training process uses high iteration counts to handle the complexity of finding optimal decision boundaries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
# Train the SVM
print('\nTraining the SVM...')
svm.train(completeTrainData, cv.ml.ROW_SAMPLE, completeTrainLabels)
print('Finished training')
```

----------------------------------------

TITLE: Implementing Image Erosion with OpenCV Python
DESCRIPTION: Demonstrates how to perform erosion on an image using a 5x5 kernel. Erosion reduces the boundaries of foreground objects and is useful for removing small white noise.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np

img = cv.imread('j.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
kernel = np.ones((5,5),np.uint8)
erosion = cv.erode(img,kernel,iterations = 1)
```

----------------------------------------

TITLE: Defining and Configuring the IlmImf Target Library
DESCRIPTION: This code creates the IlmImf static library target with the collected source files. It configures output properties, links against zlib, sets up installation rules, and handles folders for solution organization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: CMake
CODE:
```
add_library(IlmImf STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${lib_hdrs} ${lib_srcs})
target_link_libraries(IlmImf ${ZLIB_LIBRARIES})

set_target_properties(IlmImf
    PROPERTIES
    OUTPUT_NAME "IlmImf"
    DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
    COMPILE_PDB_NAME "IlmImf"
    COMPILE_PDB_NAME_DEBUG "IlmImf${OPENCV_DEBUG_POSTFIX}"
    ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
    )

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(IlmImf PROPERTIES FOLDER "3rdparty")
endif()

if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(IlmImf EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(openexr LICENSE AUTHORS.ilmbase AUTHORS.openexr)

set(OPENEXR_INCLUDE_PATHS ${OPENEXR_INCLUDE_PATHS} PARENT_SCOPE)
```

----------------------------------------

TITLE: Converting Image to Grayscale
DESCRIPTION: Converting the source image to grayscale for circle detection preprocessing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_circle/hough_circle.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
Mat gray;
cvtColor(src, gray, COLOR_BGR2GRAY);
```

LANGUAGE: Java
CODE:
```
Mat gray = new Mat();
Imgproc.cvtColor(src, gray, Imgproc.COLOR_BGR2GRAY);
```

LANGUAGE: Python
CODE:
```
gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
```

----------------------------------------

TITLE: Multi-frame Video Denoising with OpenCV Python
DESCRIPTION: Shows how to implement video denoising using cv.fastNlMeansDenoisingMulti() which processes multiple frames to remove noise. The example includes creating synthetic noise and applying denoising across temporal frames.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_non_local_means/py_non_local_means.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

cap = cv.VideoCapture('vtest.avi')

# create a list of first 5 frames
img = [cap.read()[1] for i in range(5)]

# convert all to grayscale
gray = [cv.cvtColor(i, cv.COLOR_BGR2GRAY) for i in img]

# convert all to float64
gray = [np.float64(i) for i in gray]

# create a noise of variance 25
noise = np.random.randn(*gray[1].shape)*10

# Add this noise to images
noisy = [i+noise for i in gray]

# Convert back to uint8
noisy = [np.uint8(np.clip(i,0,255)) for i in noisy]

# Denoise 3rd frame considering all the 5 frames
dst = cv.fastNlMeansDenoisingMulti(noisy, 2, 5, None, 4, 7, 35)

plt.subplot(131),plt.imshow(gray[2],'gray')
plt.subplot(132),plt.imshow(noisy[2],'gray')
plt.subplot(133),plt.imshow(dst,'gray')
plt.show()
```

----------------------------------------

TITLE: Implementing Gamma Correction with Look-Up Table in C++ using OpenCV
DESCRIPTION: This C++ code snippet demonstrates gamma correction on an image using OpenCV. It pre-calculates the gamma transformation for all 256 possible pixel values using the formula O = ((I/255)^gamma) * 255 and stores them in a look-up table (`lookUpTable`) for efficiency. The `LUT` function then applies this table to the input image to produce the gamma-corrected output image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/basic_linear_transform/basic_linear_transform.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
//! [changing-contrast-brightness-gamma-correction]
    Mat lookUpTable(1, 256, CV_8U);
    uchar* p = lookUpTable.ptr();
    for( int i = 0; i < 256; ++i)
        p[i] = saturate_cast<uchar>(pow(i / 255.0, gamma_) * 255.0);

    Mat res = img_original.clone();
    LUT(img_original, lookUpTable, res);
//! [changing-contrast-brightness-gamma-correction]
```

----------------------------------------

TITLE: Implementing FAST Pixel Comparison Logic in C++
DESCRIPTION: This code snippet implements the core pixel comparison logic for the FAST corner detection algorithm. It evaluates surrounding pixels (referenced by offset positions) against brightness thresholds (c_b and cb) to determine if a point is a corner feature, using a series of nested conditional checks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_31

LANGUAGE: C++
CODE:
```
continue; // goto homogeneous;
                            else
                              continue; // goto homogeneous;
                        else
                        if(ptr[offset7] < c_b)
                          if(ptr[offset14] > cb)
                            if(ptr[offset15] > cb)
                              if(ptr[offset1] > cb)
                                if(ptr[offset3] > cb)
                                  if(ptr[offset6] > cb)
                                    {} // goto success_homogeneous;
                                  else
                                    if(ptr[offset13] > cb)
                                      {} // goto success_homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      if(ptr[offset12] > cb)
                                        if(ptr[offset13] > cb)
                                          {} // goto success_homogeneous;
                                        else
                                          continue; // goto homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                  else
                                    continue; // goto homogeneous;
                              else
                                if(ptr[offset8] > cb)
                                  if(ptr[offset9] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        if(ptr[offset12] > cb)
                                          if(ptr[offset13] > cb)
                                            {} // goto success_homogeneous;
                                          else
                                            continue; // goto homogeneous;
                                        else
                                          continue; // goto homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                  else
                                    continue; // goto homogeneous;
                                else
                                  continue; // goto homogeneous;
                            else
                              continue; // goto homogeneous;
                          else
                          if(ptr[offset14] < c_b)
                            if(ptr[offset8] < c_b)
                              if(ptr[offset9] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    if(ptr[offset12] < c_b)
                                      if(ptr[offset13] < c_b)
                                        if(ptr[offset6] < c_b)
                                          {} // goto success_homogeneous;
                                        else
                                          if(ptr[offset15] < c_b)
                                            {} // goto success_homogeneous;
                                          else
                                            continue; // goto homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                  else
                                    continue; // goto homogeneous;
                                else
                                  continue; // goto homogeneous;
                              else
                                continue; // goto homogeneous;
                            else
                              continue; // goto homogeneous;
                          else
                            continue; // goto homogeneous;
                        else
                          if(ptr[offset14] > cb)
                            if(ptr[offset15] > cb)
                              if(ptr[offset1] > cb)
                                if(ptr[offset3] > cb)
                                  if(ptr[offset6] > cb)
                                    {} // goto success_homogeneous;
                                  else
                                    if(ptr[offset13] > cb)
                                      {} // goto success_homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      if(ptr[offset12] > cb)
                                        if(ptr[offset13] > cb)
                                          {} // goto success_homogeneous;
                                        else
                                          continue; // goto homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                  else
                                    continue; // goto homogeneous;
                              else
                                if(ptr[offset8] > cb)
                                  if(ptr[offset9] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        if(ptr[offset12] > cb)
                                          if(ptr[offset13] > cb)
                                            {} // goto success_homogeneous;
                                          else
                                            continue; // goto homogeneous;
                                        else
                                          continue; // goto homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                  else
                                    continue; // goto homogeneous;
                                else
                                  continue; // goto homogeneous;
                            else
                              continue; // goto homogeneous;
                          else
                            continue; // goto homogeneous;
                      else
                      if(ptr[offset5] < c_b)
                        if(ptr[offset12] > cb)
                          if(ptr[offset13] > cb)
                            if(ptr[offset14] > cb)
                              if(ptr[offset15] > cb)
                                if(ptr[offset1] > cb)
                                  if(ptr[offset3] > cb)
                                    {} // goto success_homogeneous;
                                  else
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        {} // goto success_homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                else
                                  if(ptr[offset8] > cb)
                                    if(ptr[offset9] > cb)
                                      if(ptr[offset10] > cb)
                                        if(ptr[offset11] > cb)
                                          {} // goto success_homogeneous;
                                        else
                                          continue; // goto homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                  else
                                    continue; // goto homogeneous;
                              else
                                if(ptr[offset6] > cb)
                                  if(ptr[offset7] > cb)
                                    if(ptr[offset8] > cb)
                                      if(ptr[offset9] > cb)
                                        if(ptr[offset10] > cb)
                                          if(ptr[offset11] > cb)
                                            {} // goto success_homogeneous;
                                          else
                                            continue; // goto homogeneous;
                                        else
                                          continue; // goto homogeneous;
                                      else
                                        continue; // goto homogeneous;
                                    else
                                      continue; // goto homogeneous;
                                  else
                                    continue; // goto homogeneous;
                                else
```

----------------------------------------

TITLE: Running TensorFlow Classification Evaluation via OpenCV dnn CLI (Console)
DESCRIPTION: Demonstrates the command-line usage for running the dnn_model_runner evaluation pipeline in Python. This call reads the specified TensorFlow classification model into an OpenCV cv.dnn_Net and evaluates its accuracy, inference time, and L1 metrics. Dependencies include a valid Python environment and the dnn_model_runner module. Parameters such as <tf_cls_model_name> should be replaced with the actual model name. Outputs include log files with metrics and charts visualizing inference results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_0

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.classification.py_to_py_cls --model_name <tf_cls_model_name>
```

----------------------------------------

TITLE: Computing Normalized Image Points in OpenCV C++
DESCRIPTION: Code to convert image corner points to normalized image coordinates by undistorting them using camera intrinsic parameters. This transforms points from pixel coordinates to the normalized camera coordinate system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
std::vector<cv::Point2f> imagePointsNormalized;
cv::undistortPoints(corners, imagePointsNormalized, cameraMatrix, distCoeffs);
```

----------------------------------------

TITLE: Computing Homography from Camera Displacement using OpenCV C++
DESCRIPTION: The code snippet demonstrates how to compute the homography matrix from two camera poses. It leverages OpenCV's functions to perform multiple interpolated warping operations. The focus is on computing N intermediate homographies, enabling visualization of transformations through a series of warps. Key parameters include camera poses, image sources, and the number of interpolations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_26

LANGUAGE: C++
CODE:
```
@snippet decompose_homography.cpp compute-homography-from-camera-displacement
```

----------------------------------------

TITLE: Calculating Image Moments using OpenCV C++
DESCRIPTION: This snippet demonstrates the use of OpenCV's moments, contourArea, and arcLength functions in C++. These functions are used to compute various shape descriptors from an image. Required dependencies include OpenCV 3.0 or higher. The input is an image from which contours are extracted, and the output includes calculated moments and related data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/moments/moments.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>
// Original code can be found at the mentioned OpenCV repository
```

----------------------------------------

TITLE: Detecting Build Context in CMake
DESCRIPTION: This CMake code block checks if the current list directory (`CMAKE_CURRENT_LIST_DIR`) is different from the main CMake source directory (`CMAKE_SOURCE_DIR`). This condition is true when the samples are being built as part of the main OpenCV project, triggering the first block of logic. The `else()` block handles the case where the samples are being built standalone (e.g., from an installed samples directory).
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(NOT CMAKE_SOURCE_DIR STREQUAL CMAKE_CURRENT_LIST_DIR)
#===================================================================================================
#
# Build as part of OpenCV
#
#===================================================================================================

  ...

else()
#===================================================================================================
#
#  Standalone mode
#
#===================================================================================================

  ...

endif()
```

----------------------------------------

TITLE: Trackbar Callback Function in C++
DESCRIPTION: This C++ snippet defines the `on_trackbar` callback function. It calculates the `alpha` (0.0-1.0) and `beta` values based on the integer trackbar position (`alpha_slider`), performs weighted image blending using `addWeighted`, and updates the "Linear Blend" window display using `imshow`. `src1`, `src2`, `dst`, `alpha`, `beta`, and `alpha_slider` are assumed to be accessible (e.g., global variables).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
//![on_trackbar]
/**
 * @function on_trackbar
 * @brief Callback for trackbar
 */
void on_trackbar( int, void* )
{
 alpha = (double) alpha_slider/alpha_slider_max ;
 beta = ( 1.0 - alpha );
 addWeighted( src1, alpha, src2, beta, 0.0, dst);
 imshow( "Linear Blend", dst );
}
//![on_trackbar]
```

----------------------------------------

TITLE: Applying Convolution and Normalization to Backprojection Result in Python OpenCV
DESCRIPTION: This code performs convolution with a circular disc kernel on the backprojection result to improve object detection. It then normalizes the values to 0-255 range to create a clearer probability map of the object location.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_backprojection/py_histogram_backprojection.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
disc = cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))
cv.filter2D(B,-1,disc,B)
B = np.uint8(B)
cv.normalize(B,B,0,255,cv.NORM_MINMAX)
```

----------------------------------------

TITLE: Configuring Video Source for G-API Pipeline
DESCRIPTION: Demonstrates setting up a video input source for the G-API pipeline using GCaptureSource. Creates a stream source from either a video file or camera input.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
std::shared_ptr<cv::gapi::wip::IStreamSource> cap;
if (!cmd.get<std::string>("input").empty()) {
    cap = std::make_shared<cv::gapi::wip::GCaptureSource>(cmd.get<std::string>("input"));
} else {
    cap = std::make_shared<cv::gapi::wip::GCaptureSource>(0);
}
```

----------------------------------------

TITLE: Homography Check for Matches with OpenCV in Java
DESCRIPTION: Java snippet using OpenCV to check if matches fit a homography model, ensuring only inliers are used in the result set.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_13

LANGUAGE: Java
CODE:
```
samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java homography check
```

----------------------------------------

TITLE: Calculating SSIM on CPU in C++
DESCRIPTION: Defines a C++ function `getMSSIM` that calculates the Mean Structural Similarity Index (MSSIM) between two input images (`I1`, `I2`) using CPU-based OpenCV functions. It calls the `ssim` function (defined elsewhere) to perform the core calculation and returns the result as an OpenCV `Scalar` object, typically containing MSSIM values for each color channel.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
//![getssim]
Scalar getMSSIM( const Mat& I1, const Mat& I2)
{
    return ssim(I1, I2);
}
//![getssim]
```

----------------------------------------

TITLE: Accessing Single Pixel Intensity Value in Grayscale Image with OpenCV in C++
DESCRIPTION: Shows how to access a pixel's intensity in an 8-bit single channel image (cv::Mat) in C++. The at<>() method is used with row and column indices: first y (row), then x (column). Requires OpenCV. Returns intensity in the range 0-255. Input coordinates must be within image bounds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
uchar intensity = img.at<uchar>(y, x);
```

----------------------------------------

TITLE: Defining ArUco Dictionary Structure in C++
DESCRIPTION: This snippet shows the structure of the cv::aruco::Dictionary class, which contains the parameters for defining an ArUco marker dictionary. It includes the bytesList for marker code information, markerSize for the number of bits per dimension, and maxCorrectionBits for error correction.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
    class Dictionary {
    public:

        cv::Mat bytesList;      // marker code information
        int markerSize;         // number of bits per dimension
        int maxCorrectionBits;  // maximum number of bits that can be corrected

        ...

    }
```

----------------------------------------

TITLE: Exporting OpenJPEG Build Information to Parent Scope in CMake
DESCRIPTION: Sets several CMake variables (`OPENJPEG_LIBRARIES`, `OPENJPEG_VERSION`, version components, `OPENJPEG_INCLUDE_DIRS`) in the `PARENT_SCOPE`. This makes the library name, version details, and include directories (obtained using `get_target_property`) available to the main OpenCV CMake script that included this file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_16

LANGUAGE: cmake
CODE:
```
# Setting all necessary variables
set(OPENJPEG_LIBRARIES     ${OPENJPEG_LIBRARY_NAME}  PARENT_SCOPE)
set(OPENJPEG_VERSION       ${OPENJPEG_VERSION}       PARENT_SCOPE)
set(OPENJPEG_MAJOR_VERSION ${OPENJPEG_VERSION_MAJOR} PARENT_SCOPE)
set(OPENJPEG_MINOR_VERSION ${OPENJPEG_VERSION_MINOR} PARENT_SCOPE)
set(OPENJPEG_BUILD_VERSION ${OPENJPEG_VERSION_BUILD} PARENT_SCOPE)
get_target_property(_openjpeg_include_dirs ${OPENJPEG_LIBRARY_NAME} INCLUDE_DIRECTORIES)
set(OPENJPEG_INCLUDE_DIRS  ${_openjpeg_include_dirs} PARENT_SCOPE)
```

----------------------------------------

TITLE: Retrieving and Extracting Frozen DeepLab Graph in Python
DESCRIPTION: This Python function retrieves the pre-trained DeepLabV3 model from a specified URL and extracts the frozen TensorFlow graph from the downloaded archive. It requires 'urllib' for downloading and 'tarfile' for extraction. The key purpose is to prepare the model for graph optimization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
def get_deeplab_frozen_graph():
    # define model path to download
    models_url = 'http://download.tensorflow.org/models/'
    mobilenetv2_voctrainval = 'deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz'

    # construct model link to download
    model_link = models_url + mobilenetv2_voctrainval

    try:
        urllib.request.urlretrieve(model_link, mobilenetv2_voctrainval)
    except Exception:
        print("TF DeepLabV3 was not retrieved: {}".format(model_link))
        return

    tf_model_tar = tarfile.open(mobilenetv2_voctrainval)

    # iterate the obtained model archive
    for model_tar_elem in tf_model_tar.getmembers():
        # check whether the model archive contains frozen graph
        if TF_FROZEN_GRAPH_NAME in os.path.basename(model_tar_elem.name):
            # extract frozen graph
            tf_model_tar.extract(model_tar_elem, FROZEN_GRAPH_PATH)

    tf_model_tar.close()
```

----------------------------------------

TITLE: Extracting and Displaying SVM Support Vectors - Java
DESCRIPTION: This Java code fetches support vectors from a trained SVM using OpenCV Java methods and marks them visually on the output. It depends on a trained OpenCV SVM model and the Java API. The input includes the SVM model and data points; output consists of custom rendering (e.g., gray rings) around points that are support vectors. This clarifies which training examples significantly affect the SVM boundary.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_8

LANGUAGE: java
CODE:
```
// Java: Display SVM support vectors using OpenCV
// ... (full code from samples/java/tutorial_code/ml/introduction_to_svm/IntroductionToSVMDemo.java, show_vectors)
```

----------------------------------------

TITLE: Reading Image Data from HTML Canvas in JavaScript
DESCRIPTION: This code snippet demonstrates how to retrieve image data from an HTML canvas element using JavaScript. It requires a canvas element with an ID, accesses its 2D context, and uses the getImageData method to extract pixel data into an ImageData object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_image_display/js_image_display.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
let canvas = document.getElementById(canvasInputId);
let ctx = canvas.getContext('2d');
let imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
```

----------------------------------------

TITLE: Configuring Installation for OpenCV Java Library in CMake
DESCRIPTION: Sets up installation rules for the OpenCV Java library, handling different components and destinations based on the build configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jni/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
set(__install_export "")
if(BUILD_FAT_JAVA_LIB)
  set(__install_export EXPORT OpenCVModules)
endif()

ocv_install_target(${the_module} OPTIONAL ${__install_export}
    RUNTIME DESTINATION ${OPENCV_JNI_BIN_INSTALL_PATH} COMPONENT java
    LIBRARY DESTINATION ${OPENCV_JNI_INSTALL_PATH} COMPONENT java
    ARCHIVE DESTINATION ${OPENCV_JNI_INSTALL_PATH} COMPONENT java
)
```

----------------------------------------

TITLE: Defining and Adding the OpenCV Java Module in CMake
DESCRIPTION: This snippet first sets a variable `the_description` to describe the module. Then, it uses the `ocv_add_module` command to formally define the `java` module as a BINDINGS module. It declares dependencies on `opencv_core` and `opencv_imgproc`, and specifies a private requirement on `opencv_java_bindings_generator`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
set(the_description "The java bindings")
ocv_add_module(java BINDINGS opencv_core opencv_imgproc PRIVATE_REQUIRED opencv_java_bindings_generator)
```

----------------------------------------

TITLE: Configuring OpenJPEG Library Build
DESCRIPTION: Configures the OpenJPEG library build with compiler warnings, static library definition, and linking options. Sets up the target properties and includes necessary directories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/openjp2/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
ocv_warnings_disable(CMAKE_C_FLAGS
    -Wundef -Wstrict-prototypes -Wcast-function-type
    -Wshadow   # v2.4.0: GCC
    -Wunused-function   # v2.4.0: Clang
)

ocv_warnings_disable(CMAKE_C_FLAGS /wd4819) # vs2019 Win64

add_library(${OPENJPEG_LIBRARY_NAME} STATIC ${OPENJPEG_SRCS})

target_compile_definitions(${OPENJPEG_LIBRARY_NAME} PUBLIC OPJ_STATIC)

ocv_include_directories("${CMAKE_CURRENT_LIST_DIR}" "${CMAKE_CURRENT_BINARY_DIR}")

if(UNIX)
  target_link_libraries(${OPENJPEG_LIBRARY_NAME} PRIVATE m)
endif()
```

----------------------------------------

TITLE: Adding SBT Eclipse Plugin (Scala)
DESCRIPTION: This Scala code snippet, placed in `project/plugins.sbt`, adds the `sbteclipse-plugin` to the SBT build. This plugin provides the `eclipse` command within SBT, which automatically generates Eclipse IDE project configuration files based on the SBT build definition.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_13

LANGUAGE: scala
CODE:
```
addSbtPlugin("com.typesafe.sbteclipse" % "sbteclipse-plugin" % "2.1.0")
```

----------------------------------------

TITLE: Eye Contour Generation from Facial Landmarks
DESCRIPTION: Function that generates a contour for an eye region by approximating an ellipse based on the eye corner landmarks, creating a realistic eye region mask.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
// Helper functions for landmarks post-processing
inline double getLineInclinationAngleDegrees(const cv::Point& p1, const cv::Point& p2) {
    auto diff = p2 - p1;
    return -atan2(diff.y, diff.x) * 180.0 / CV_PI;
}

// Generate a contour for an eye based on two landmark points
inline Contour getEyeContour(const std::vector<cv::Point>& landmarks) {
    // landmarks is a vector of two points marking the left and right corners of an eye
    GAPI_Assert(landmarks.size() == 2);
    
    // Sort points from left to right
    auto pts = landmarks;
    if (pts[0].x > pts[1].x) std::swap(pts[0], pts[1]);
    
    // Calculate ellipse parameters
    cv::Point center((pts[0].x + pts[1].x) / 2, (pts[0].y + pts[1].y) / 2);
    int axis_x = (pts[1].x - pts[0].x) / 2;
    int axis_y = axis_x / 3;  // Assume eye height is 1/3 of width
    double angle = getLineInclinationAngleDegrees(pts[0], pts[1]);
    
    // Generate eye contour as a half-ellipse
    std::vector<cv::Point> contour;
    cv::ellipse2Poly(center, cv::Size(axis_x, axis_y), angle, 0, 180, 5, contour);
    return contour;
}
```

----------------------------------------

TITLE: Using ArUco Detector Methods in OpenCV
DESCRIPTION: Key method calls for marker detection and refinement in the ArUco module, including marker detection and refinement for boards.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_faq/aruco_faq.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
cv::aruco::ArucoDetector::detectMarkers()
cv::aruco::ArucoDetector::refineDetectedMarkers()
```

----------------------------------------

TITLE: Processing Common Source and Template Files for Java Bindings in CMake
DESCRIPTION: Gathers common dependency files required for Java bindings generation using `file(GLOB_RECURSE)`. This includes files from the generator's `src` directory, Android-specific directories, and `templates`. It then calls the `ocv_remap_files` macro to process any files ending in `.in` found within this list, performing variable substitutions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/generator/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
# common files
file(GLOB_RECURSE deps "${CMAKE_CURRENT_SOURCE_DIR}/src/*" "${CMAKE_CURRENT_SOURCE_DIR}/android*/*" "${CMAKE_CURRENT_SOURCE_DIR}/templates/*")
ocv_remap_files(deps)
```

----------------------------------------

TITLE: Exporting YOLOv10 Model and Environment Setup Using Bash
DESCRIPTION: Describes commands to clone a specialized YOLOv10 repository fork with pre-modified postprocessing, create a Python environment via conda, install dependencies, and export the YOLOv10 PyTorch model to ONNX format using a custom export script. Prerequisites include git, conda, pip for requirements, and the referenced forked YOLOv10 repository. Key parameters are --model (model variant) and --imgsz (model input image size). Produces an ONNX file (e.g., yolov10s.onnx) for OpenCV inference, and defaults are provided for typical use cases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
git clone git@github.com:Abdurrahheem/yolov10.git\nconda create -n yolov10 python=3.9\nconda activate yolov10\npip install -r requirements.txt\npython export_opencv.py --model=<model-name> --imgsz=<input-img-size>
```

----------------------------------------

TITLE: Reading Camera Parameters from XML/YAML using OpenCV in C++
DESCRIPTION: This code reads camera intrinsics and distortion coefficients from a stored XML/YAML file using OpenCV’s FileStorage class. It assumes that a correct file path is provided and that the file contains the necessary parameters stored under 'camera_matrix' and 'distortion_coefficients' keys.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_square_chess/camera_calibration_square_chess.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
FileStorage fs(filename, FileStorage::READ);
Mat intrinsics, distortion;
fs["camera_matrix"] >> intrinsics;
fs["distortion_coefficients"] >> distortion;
```

----------------------------------------

TITLE: Building and Linking SYCL Sample Executables with OpenCV - CMake
DESCRIPTION: This part of the script configures the actual compilation and linking process for SYCL-based OpenCV sample executables. It sets global compiler and linker flags based on the selected SYCL implementation, includes necessary directories and modules, enumerates all \*.cpp samples, and defines them as individual targets. It also adds ComputeCpp-specific build steps if required. This ensures each executable is properly linked against SYCL and all OpenCV modules, with support for SDK-specific build requirements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/sycl/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
project(sycl_samples)

if(SYCL_FLAGS)  # "target_link_libraries(... ${SYCL_TARGET})" is not enough. Hacking...
  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${SYCL_FLAGS}")
  set(CMAKE_EXE_LINKER_FLAGS "${CMAKE_EXE_LINKER_FLAGS} ${SYCL_FLAGS}")
endif()

ocv_include_modules_recurse(${OPENCV_SYCL_SAMPLES_REQUIRED_DEPS})
ocv_include_directories(${OpenCL_INCLUDE_DIR})
file(GLOB all_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
foreach(sample_filename ${all_samples})
  ocv_define_sample(tgt ${sample_filename} sycl)
  ocv_target_link_libraries(${tgt} PRIVATE
    ${OPENCV_LINKER_LIBS}
    ${OPENCV_SYCL_SAMPLES_REQUIRED_DEPS}
    ${SYCL_TARGET})

  if(COMMAND add_sycl_to_target)  # ComputeCpp
    add_sycl_to_target(TARGET ${tgt} SOURCES ${sample_filename})
  endif()
endforeach()
```

----------------------------------------

TITLE: Defining HTML Trackbar and Associated Text Field - HTML
DESCRIPTION: This snippet defines an HTML range input (trackbar) and an associated text input for displaying the current trackbar value. The range input includes properties for initial value, minimum, maximum, step, and an oninput callback for event handling. The dependencies are standard HTML support and a callback function named 'callback'. Inputs: User slider interaction. Outputs: Value updated in the text field.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_trackbar/js_trackbar.markdown#2025-04-22_snippet_3

LANGUAGE: HTML
CODE:
```
Weight: <input type=\"range\" id=\"trackbar\" value=\"50\" min=\"0\" max=\"100\" step=\"1\" oninput=\"callback()\">
<input type=\"text\" id=\"weightValue\" size=\"3\" value=\"50\"/>
```

----------------------------------------

TITLE: Splitting and Merging Image Channels using OpenCV Functions in Python
DESCRIPTION: Demonstrates splitting a BGR image into its individual Blue, Green, and Red channels using `cv.split()` and then merging them back into a BGR image using `cv.merge()`. Note that `cv.split()` is mentioned as a potentially costly operation in terms of processing time.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_7

LANGUAGE: python
CODE:
```
>>> b,g,r = cv.split(img)
>>> img = cv.merge((b,g,r))
```

----------------------------------------

TITLE: Creating Standard SBT Project Structure (Bash)
DESCRIPTION: These Bash commands set up the standard directory structure expected by SBT within the 'JavaSample' directory. `mkdir -p src/main/java` creates the nested directories where Java source files will reside. `mkdir project` creates the directory where SBT build definition files (`.scala`, `.sbt`) are placed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_11

LANGUAGE: bash
CODE:
```
cd JavaSample
mkdir -p src/main/java # This is where SBT expects to find Java sources
mkdir project # This is where the build definitions live
```

----------------------------------------

TITLE: Setting C++ Standard for OpenCV
DESCRIPTION: This snippet sets the C++ standard when building OpenCV using `CMAKE_CXX_STANDARD`. OpenCV 4.x defaults to C++11, while 5.x defaults to C++17. Errors occur if the standard is unsupported, but checks can be skipped with `OPENCV_SKIP_CMAKE_CXX_STANDARD`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_2

LANGUAGE: sh
CODE:
```
cmake -DCMAKE_CXX_STANDARD=17 ../opencv
cmake --build .
```

----------------------------------------

TITLE: Building OpenCV with Make (Unix) (Bash)
DESCRIPTION: This Bash command executes the 'make' utility to compile the OpenCV library based on the Makefiles generated by CMake. The '-j8' flag suggests using 8 parallel jobs for potentially faster compilation; adjust the number based on system cores.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
make -j8
```

----------------------------------------

TITLE: Calculating Lookup Table with C++ Stream
DESCRIPTION: This snippet demonstrates how to convert a command line argument to an integer using C++ stringstream and compute a lookup table for color space reduction. It includes basic C++ operations without specific OpenCV dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
@snippet how_to_scan_images.cpp dividewith
```

----------------------------------------

TITLE: Custom Layer Interp Caffe Implementation
DESCRIPTION: Defines an Interp custom layer without trainable weights, using hyper-parameters for output size in Caffe.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp InterpLayer
```

----------------------------------------

TITLE: Exporting Structs as Python Dicts Using OpenCV Macros in C++
DESCRIPTION: This snippet shows how to export a C++ struct as a native Python dict using CV_EXPORTS_W_MAP. The Moments class encapsulates image moment fields, annotated with CV_PROP_RW to expose members for direct attribute access in Python. The exported instance is presented as a dictionary. Dependencies: none beyond OpenCV core types. All double-precision moment fields can be accessed from Python as dict keys.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
class CV_EXPORTS_W_MAP Moments
{
public:
    //! spatial moments
    CV_PROP_RW double  m00, m10, m01, m20, m11, m02, m30, m21, m12, m03;
    //! central moments
    CV_PROP_RW double  mu20, mu11, mu02, mu30, mu21, mu12, mu03;
    //! central normalized moments
    CV_PROP_RW double  nu20, nu11, nu02, nu30, nu21, nu12, nu03;
};
```

----------------------------------------

TITLE: Accessing 2D Histogram Bin Value in C++
DESCRIPTION: C++ code example demonstrating how to access the value of a specific bin in a 2D histogram stored in a `cv::Mat`. It uses the `.at<float>(i, j)` method, where `i` and `j` are the indices for the two dimensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_31

LANGUAGE: cpp
CODE:
```
b_hist.at<float>( i, j )
```

----------------------------------------

TITLE: Building Only for Mac Catalyst with Specific Architectures - Python/Bash
DESCRIPTION: This code example shows how to build an OpenCV xcframework only for Mac Catalyst, specifying x86_64 and arm64 architectures. The --build_only_specified_archs flag ensures that only the explicitly listed architectures are included. Python, CMake, and Xcode dependencies apply. Input is a command-line invocation tailored to exclude all but the catalyst build. Output is a customized xcframework in the specified directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/apple/readme.md#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
python build_xcframework.py --out somedir --catalyst_archs x86_64,arm64 --build_only_specified_archs
```

----------------------------------------

TITLE: Converting Training Data to Mat Format in C++
DESCRIPTION: Converts training data arrays into OpenCV Mat objects required by the SVM training function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_svm.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
Mat trainingDataMat(N, 2, CV_32F, trainingData);
Mat labelsMat(N, 1, CV_32F, labels);
```

----------------------------------------

TITLE: Initializing and Opening OpenCV VideoWriter (C++)
DESCRIPTION: Shows the process of initializing a `cv::VideoWriter` object (`outputVideo`). It retrieves the frame width and height from an existing `VideoCapture` object (`inputVideo`) to create a `cv::Size` object (`S`). It then calls the `open` method with the output filename (`NAME`), integer codec identifier (`ex`), frames per second (retrieved from `inputVideo`), frame size (`S`), and a boolean flag (`true`) indicating color video output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
VideoWriter outputVideo;
Size S = Size((int) inputVideo.get(CAP_PROP_FRAME_WIDTH),    //Acquire input size
              (int) inputVideo.get(CAP_PROP_FRAME_HEIGHT));
outputVideo.open(NAME , ex, inputVideo.get(CAP_PROP_FPS),S, true);
```

----------------------------------------

TITLE: Generating ChArUco Diamond Marker Image with OpenCV ArUco (C++)
DESCRIPTION: This snippet demonstrates how to generate an image of a ChArUco diamond marker using the cv::aruco::CharucoBoard::generateImage() function in OpenCV C++. It sets square and marker sizes as well as the four marker IDs in a cv::Vec4i object, outputting a PNG or similar image. Dependencies include OpenCV's aruco module. The user can specify square length, marker length, dictionary, and marker IDs. The output is a new diamond marker image file, with limitations set by the requirements that diamonds must be 3x3 squares with four markers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_diamond_detection/charuco_diamond_detection.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/aruco/charuco.hpp>
#include <opencv2/highgui.hpp>

// Parameters: squareLength=200, markerLength=120, dictionary=DICT_4X4_50, ids={0,1,2,3}
cv::Ptr<cv::aruco::Dictionary> dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_4X4_50);
cv::Mat diamondImg;
cv::Vec4i ids(0, 1, 2, 3);
int squareLength = 200;
int markerLength = 120;
cv::aruco::CharucoBoard::generateImage(dictionary, squareLength, markerLength, ids, diamondImg);
cv::imwrite("mydiamond.png", diamondImg);
```

----------------------------------------

TITLE: Loading Source, Template, and Mask Images (Python)
DESCRIPTION: Loads the source image and template image using `cv2.imread` based on command-line arguments. It also supports loading an optional mask image if the corresponding argument is provided. Basic command-line argument parsing is included.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_15

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py load_image
```

----------------------------------------

TITLE: Row-Split Parallel Convolution with OpenCV
DESCRIPTION: This snippet provides an alternative approach to parallel convolution by splitting computation across rows of the image. Leveraging OpenCV's parallel_for_, this method illustrates row-wise division for parallel execution, maintaining similar performance yet differing in memory access patterns.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_new/how_to_use_OpenCV_parallel_for_new.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp overload-row-split
```

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp convolution-parallel-function-row
```

----------------------------------------

TITLE: Installing PaddlePaddle and ONNX Conversion Dependencies (Shell)
DESCRIPTION: Installs the necessary Python packages for running PaddlePaddle models, using Paddle Hub, and converting PaddlePaddle models to the ONNX format. These dependencies are required for the subsequent steps involving model download, conversion, and execution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/dnn_model_runner/dnn_conversion/paddlepaddle/README.md#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
pip install paddlepaddle-gpu
pip install paddlehub
pip install paddle2onnx
```

----------------------------------------

TITLE: Applying Median Blur in OpenCV Python
DESCRIPTION: This code shows how to use median blurring with cv.medianBlur(), which replaces each pixel with the median value of neighboring pixels. This method is particularly effective against salt-and-pepper noise while preserving edges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_filtering/py_filtering.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
median = cv.medianBlur(img,5)
```

----------------------------------------

TITLE: Creating Images in Python
DESCRIPTION: Initializing blank images for drawing shapes in OpenCV Python. Creates two black images named 'atom_image' and 'rook_image' with specified dimensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
# Windows names
atom_window = "Drawing 1: Atom"
rook_window = "Drawing 2: Rook"

# Create black empty images
atom_image = np.zeros((w, w, 3), dtype=np.uint8)
rook_image = np.zeros((w, w, 3), dtype=np.uint8)
```

----------------------------------------

TITLE: Setting CMake Policies and Project Definition for OpenJPEG
DESCRIPTION: Initializes the CMake build process for the OpenJPEG library. It sets the CMake policy CMP0003 and CMP0042 to NEW, defines the internal library name variable `OPENJPEG_LIBRARY_NAME`, and declares the project named 'openjpeg' specifying C as the primary language.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_policy(SET CMP0003 NEW)
if(POLICY CMP0042)
  cmake_policy(SET CMP0042 NEW)
endif()

set(OPENJPEG_LIBRARY_NAME libopenjp2)

project(openjpeg C)
```

----------------------------------------

TITLE: Creating Documentation Tables - Markdown/plaintext
DESCRIPTION: Demonstrates how to structure tables in documentation using vertical bars for columns as supported by markdown and doxygen. Inputs are header and cell contents; outputs as a formatted table in HTML or rendered markdown output. No dependencies required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_6

LANGUAGE: plaintext
CODE:
```
First Header  | Second Header
------------- | -------------
Content Cell  | Content Cell
Content Cell  | Content Cell
```

----------------------------------------

TITLE: Implementing ORB Feature Detection with OpenCV in Python
DESCRIPTION: This code demonstrates how to use OpenCV's ORB implementation to detect keypoints in an image. It initializes an ORB detector, detects keypoints, computes descriptors, and visualizes the results using matplotlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_orb/py_orb.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('simple.jpg', cv.IMREAD_GRAYSCALE)

# Initiate ORB detector
orb = cv.ORB_create()

# find the keypoints with ORB
kp = orb.detect(img,None)

# compute the descriptors with ORB
kp, des = orb.compute(img, kp)

# draw only keypoints location,not size and orientation
img2 = cv.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)
plt.imshow(img2), plt.show()
```

----------------------------------------

TITLE: Loading OpenCV Libraries in Clojure
DESCRIPTION: This snippet shows how to load the OpenCV native library in a Clojure REPL environment to enable OpenCV functionality. This loading is essential for using Java classes within Clojure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_8

LANGUAGE: clojure
CODE:
```
user=> (clojure.lang.RT/loadLibrary org.opencv.core.Core/NATIVE_LIBRARY_NAME)
nil
```

----------------------------------------

TITLE: Setting Up Image Resources for OpenCV Project
DESCRIPTION: A bash snippet to prepare directories and organize static resources such as images required for OpenCV projects, facilitating better project structure and resources management.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_20

LANGUAGE: bash
CODE:
```
mkdir -p resources/images
cp ~/opt/opencv/doc/tutorials/introduction/desktop_java/images/lena.png resource/images/
```

----------------------------------------

TITLE: Setting Up Chessboard Detection with OpenCV in Python
DESCRIPTION: This snippet initializes the chessboard detection setup required for camera calibration. It prepares 3D object points in real-world space and reads 2D image points. Dependencies include OpenCV and NumPy, with key functions like cv.findChessboardCorners() to find chessboard corners in images. Inputs are image files and outputs are object and image points for calibration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv
import glob

# termination criteria
criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)
objp = np.zeros((6*7,3), np.float32)
objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)

# Arrays to store object points and image points from all the images.
objpoints = [] # 3d point in real world space
imgpoints = [] # 2d points in image plane.

images = glob.glob('*.jpg')

for fname in images:
    img = cv.imread(fname)
    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

    # Find the chess board corners
    ret, corners = cv.findChessboardCorners(gray, (7,6), None)

    # If found, add object points, image points (after refining them)
    if ret == True:
        objpoints.append(objp)

        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)
        imgpoints.append(corners2)

        # Draw and display the corners
        cv.drawChessboardCorners(img, (7,6), corners2, ret)
        cv.imshow('img', img)
        cv.waitKey(500)

cv.destroyAllWindows()
```

----------------------------------------

TITLE: Defining a Custom Data Structure Class for File I/O - OpenCV C++
DESCRIPTION: This C++ code defines a custom class (MyData) for use with OpenCV FileStorage-based serialization. It contains public data members and can be extended with custom reading and writing methods. Requires standard C++ headers and OpenCV for integration with the XML/YAML/JSON system. Members should be simple types or OpenCV structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_11

LANGUAGE: C++
CODE:
```
class MyData\n{\npublic:\n      MyData() : A(0), X(0), id() {}\npublic:   // Data Members\n   int A;\n   double X;\n   string id;\n};
```

----------------------------------------

TITLE: Installing OpenCV System-wide with Ninja
DESCRIPTION: Command to install OpenCV system-wide using Ninja, requires root privileges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_19

LANGUAGE: bash
CODE:
```
sudo ninja install
```

----------------------------------------

TITLE: Setting libjasper Library Properties in CMake
DESCRIPTION: This snippet sets various properties for the libjasper library target, including output names, debug postfixes, and output directories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjasper/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
set_target_properties(${JASPER_LIBRARY}
  PROPERTIES
  OUTPUT_NAME ${JASPER_LIBRARY}
  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
  COMPILE_PDB_NAME ${JASPER_LIBRARY}
  COMPILE_PDB_NAME_DEBUG "${JASPER_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
  )

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${JASPER_LIBRARY} PROPERTIES FOLDER "3rdparty")
endif()
```

----------------------------------------

TITLE: Applying Median Blur with OpenCV in Java
DESCRIPTION: This Java snippet shows how to apply median blur on images using OpenCV's medianBlur() function, which requires OpenCV and kernel size parameter along with source and destination images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/Smoothing/Smoothing.java medianblur
```

----------------------------------------

TITLE: Conditionally Including xfeatures2d Module in CMake
DESCRIPTION: Checks if the `opencv_xfeatures2d` module is available (`HAVE_opencv_xfeatures2d` is true). If it is, it uses `ocv_include_modules_recurse` to include its headers and settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
if(HAVE_opencv_xfeatures2d)
  ocv_include_modules_recurse(opencv_xfeatures2d)
endif()
```

----------------------------------------

TITLE: Source and Header File Resolution for JNI Library - CMake
DESCRIPTION: This section uses file globbing to automatically collect all source and header files with .cpp, .c, .hpp, or .h extensions in the current directory. Essential for compiling all relevant code into the JNI shared library, it removes the need to manually maintain file lists. Prerequisites: relevant files must be present in the directory. Inputs: source and header file patterns; Outputs: lists of files to be built.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-4-opencl/jni/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
file(GLOB srcs *.cpp *.c)
file(GLOB hdrs *.hpp *.h)

```

----------------------------------------

TITLE: Configuring OpenCV Build for Arm Semihosting with CMake
DESCRIPTION: This command configures the OpenCV build process using CMake for an Arm semihosting target. It specifies the custom toolchain file located in `opencv/platforms/semihosting/`, provides the path to the Arm baremetal toolchain binaries via `SEMIHOSTING_TOOLCHAIN_PATH`, enables the compilation of example applications (`BUILD_EXAMPLES=ON`), and uses Ninja as the build system generator (`-GNinja`). Ensure the specified toolchain path and OpenCV source path (`../opencv/`) are correct relative to the build directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/semihosting/README.md#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
cmake ../opencv/ \
    -DCMAKE_TOOLCHAIN_FILE=../opencv/platforms/semihosting/aarch64-semihosting.toolchain.cmake \
    -DSEMIHOSTING_TOOLCHAIN_PATH=/path/to/baremetal-toolchain/bin/ \
    -DBUILD_EXAMPLES=ON -GNinja
```

----------------------------------------

TITLE: Predefined Dictionary Selection for ArUco in C++
DESCRIPTION: The code demonstrates how to select a predefined marker dictionary using OpenCV's ArUco module for robust marker detection. Predefined dictionaries such as `DICT_6X6_250` provide a balance of size and unique markers based on application requirements. This helps achieve a high inter-marker distance for better error correction.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
cv::aruco::Dictionary dictionary = cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);
```

----------------------------------------

TITLE: Configure Compression Strategies and Memory Options in CMake
DESCRIPTION: This section configures specific allowances and strategies for data compression (e.g., deflate_quick and deflate_medium) and builds tailored inflating strategies. It can reduce memory footprint or allow broad operation ranges based on flags like WITH_INFLATE_STRICT.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_15

LANGUAGE: CMake
CODE:
```
#
# Enable deflate_quick at level 1
#
if(NOT WITH_NEW_STRATEGIES)
    add_definitions(-DNO_QUICK_STRATEGY)
endif()
#
# Enable deflate_medium at level 4-6
#
if(NOT WITH_NEW_STRATEGIES)
    add_definitions(-DNO_MEDIUM_STRATEGY)
endif()
#
# Enable inflate compilation options
#
if(WITH_INFLATE_STRICT)
    add_definitions(-DINFLATE_STRICT)
    message(STATUS "Inflate strict distance checking enabled")
endif()
if(WITH_INFLATE_ALLOW_INVALID_DIST)
    add_definitions(-DINFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR)
    message(STATUS "Inflate zero data for invalid distances enabled")
endif()
#
# Enable reduced memory configuration
```

----------------------------------------

TITLE: Setting Qt Environment Variable
DESCRIPTION: Windows command to set the QTDIR environment variable for Qt integration with OpenCV
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
setx -m QTDIR D:/OpenCV/dep/qt/qt-everywhere-opensource-src-4.7.3
```

----------------------------------------

TITLE: Drawing Pose Axis with ArUco Markers using OpenCV C++
DESCRIPTION: This referenced snippet involves drawing axis lines to represent pose estimation visually on an image. It uses the camera matrix, distortion coefficients, and rotation and translation vectors for each detected marker. The axis drawing provides a visual accuracy check of the estimated poses, using specified axis length in same units as translation vector.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/objectDetection/detect_markers.cpp aruco_draw_pose_estimation
```

----------------------------------------

TITLE: Handling CUDA Source Exclusion, Includes, and Library Linking for DNN Module - CMake
DESCRIPTION: Configures inclusion of CUDA and cuDNN libraries, include paths, and compute capability checks for the DNN module when CUDA is enabled. Validates required CUDA version and available architectures, fails the build if unsupported. Adds additional libraries for CUDA if the build system supports first-class CUDA language targets. If dependencies are not met, CUDA-related sources are excluded.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_18

LANGUAGE: CMake
CODE:
```
if(OPENCV_DNN_CUDA AND HAVE_CUDA AND HAVE_CUBLAS AND HAVE_CUDNN)
  list(APPEND include_dirs ${CUDA_TOOLKIT_INCLUDE} ${CUDNN_INCLUDE_DIRS})
  set(CC_LIST ${CUDA_ARCH_BIN})
  separate_arguments(CC_LIST)
  foreach(cc ${CC_LIST})
    if(cc VERSION_LESS 3.0)
      message(FATAL_ERROR "CUDA backend for DNN module requires CC 3.0 or higher. Please remove unsupported architectures from CUDA_ARCH_BIN option or disable OPENCV_DNN_CUDA=OFF.")
    endif()
  endforeach()
  unset(CC_LIST)
  if(ENABLE_CUDA_FIRST_CLASS_LANGUAGE)
    list(APPEND libs ${CUDNN_LIBRARIES} CUDA::cublas${CUDA_LIB_EXT})
    if(NOT CUDA_VERSION VERSION_LESS 10.1)
      list(APPEND libs CUDA::cublasLt${CUDA_LIB_EXT})
    endif()
  endif()
else()
  set(sources_options ${sources_options} EXCLUDE_CUDA)
endif()
```

----------------------------------------

TITLE: Replace Default Optimization Level in CMake
DESCRIPTION: This snippet replaces the default optimization level from 3 to 2 unless specific build conditions (such as code coverage or MSVC usage) are met. It modifies the CMAKE_C_FLAGS_RELEASE variable for release builds. Such changes apply to non-MSVC compilers and when the default optimization flag is -O3.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
# Replace optimization level 3 added by default with level 2
if(NOT WITH_CODE_COVERAGE AND NOT MSVC AND NOT CMAKE_C_FLAGS MATCHES "([\\/\\-]O)3")
    string(REGEX REPLACE "([\\/\\-]O)3" "\\12"
        CMAKE_C_FLAGS_RELEASE "${CMAKE_C_FLAGS_RELEASE}")
endif()
```

----------------------------------------

TITLE: Loading a Mesh from PLY File - OpenCV C++
DESCRIPTION: This snippet details how to load and parse a 3D object mesh from a PLY file using a Mesh class in C++. It reads vertex and triangle data, updating mesh attributes accordingly. Dependencies include a CSV reader capable of reading PLY format.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
/* Load a CSV with *.ply format */
void Mesh::load(const std::string path)
{

    // Create the reader
    CsvReader csvReader(path);

    // Clear previous data
    list_vertex_.clear();
    list_triangles_.clear();

    // Read from .ply file
    csvReader.readPLY(list_vertex_, list_triangles_);

    // Update mesh attributes
    num_vertexs_ = list_vertex_.size();
    num_triangles_ = list_triangles_.size();

}

```

----------------------------------------

TITLE: Loading Images and Text Detection Model in C++
DESCRIPTION: This C++ snippet shows how to load an image for text detection and initialize a TextDetectionModel_DB with ONNX weights. The snippet prepares the environment for performing text detection using a specified DB model.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
// Load an image
// you can find some images for testing in "Images Testing"
Mat frame = imread("/path/to/text_det_test.png");
```

----------------------------------------

TITLE: Microsoft Media Foundation Configuration Option in OpenCV
DESCRIPTION: Defines the WITH_MSMF build option for Windows platforms to enable the Media Foundation framework backend for camera capture and video processing, with optional hardware acceleration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_13

LANGUAGE: markdown
CODE:
```
`WITH_MSMF` (Windows; default: _ON_)
```

----------------------------------------

TITLE: Controlling Shared and Static Libraries in OpenCV
DESCRIPTION: This code controls whether the build produces shared or static libraries using `BUILD_SHARED_LIBS`. The default setting is typically `ON` but can be modified. The code mentions considerations for position-independent code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_4

LANGUAGE: sh
CODE:
```
cmake -DBUILD_SHARED_LIBS=OFF ../opencv
```

----------------------------------------

TITLE: Cloning OpenCV Contrib Repository in Bash
DESCRIPTION: Commands to clone the OpenCV contrib repository for extra modules from GitHub using Git in the Terminal on macOS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/ios_install/ios_install.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
cd ~/<my_working _directory>
git clone https://github.com/opencv/opencv_contrib.git
```

----------------------------------------

TITLE: Applying Bilateral Filtering for Edge-Preserving Smoothing in C++
DESCRIPTION: Explains cv.bilateralFilter(), used for advanced noise removal while preserving sharp edges through bilateral filtering. This technique combines Gaussian filtering based on both space and pixel intensity, offering effective noise reduction without blurring edges. OpenCV is required, and key parameters include diameter, sigma for color and space, and border type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_filtering/js_filtering.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
cv::bilateralFilter(src, dst, d, sigmaColor, sigmaSpace, cv::BORDER_DEFAULT);
```

----------------------------------------

TITLE: Downloading Face Detector Model
DESCRIPTION: Command to download OpenCV Face Detector model weights and save them to a specific directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/README.md#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
python download_models.py --save_dir FaceDetector opencv_fd
```

----------------------------------------

TITLE: Defining Functions with Output Parameters Using OpenCV Macros in C++
DESCRIPTION: This snippet shows how to annotate a function with both input and output parameters for Python binding generation. The minEnclosingCircle function uses CV_EXPORTS_W for export, InputArray for input, and CV_OUT for parameters to clarify their usage as outputs. These macro annotations enable scripts to automatically wrap the function for Python. The function expects points as input and writes results into center and radius.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
CV_EXPORTS_W void minEnclosingCircle( InputArray points,
                                     CV_OUT Point2f& center, CV_OUT float& radius );
```

----------------------------------------

TITLE: Installing OpenCV System-wide on macOS
DESCRIPTION: This command installs the built OpenCV libraries and headers system-wide, requiring sudo privileges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
sudo make install
```

----------------------------------------

TITLE: SVM Basic Linear Separability Formula
DESCRIPTION: Mathematical formula showing the minimization function for finding optimal decision boundary in linearly separable case with constraints.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_svm/py_svm_basics/py_svm_basics.markdown#2025-04-22_snippet_0

LANGUAGE: latex
CODE:
```
\min_{w, b_0} L(w, b_0) = \frac{1}{2}||w||^2 \; \text{subject to} \; t_i(w^Tx+b_0) \geq 1 \; \forall i
```

----------------------------------------

TITLE: Compiling Kernel Packages in C++
DESCRIPTION: This snippet creates a kernel package that includes both custom kernels and optimizations using the Fluid backend to manage memory efficiently within G-API's standard kernels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/face_beautification/face_beautification.cpp kern_pass_1
```

----------------------------------------

TITLE: AgastFeatureDetector Implementation Class
DESCRIPTION: Implementation of the AgastFeatureDetector class that provides the interface for AGAST feature detection. It handles image conversion, parameter settings, and delegates actual detection to the AGAST function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_43

LANGUAGE: C++
CODE:
```
class AgastFeatureDetector_Impl : public AgastFeatureDetector
{
public:
    AgastFeatureDetector_Impl( int _threshold, bool _nonmaxSuppression, int _type )
    : threshold(_threshold), nonmaxSuppression(_nonmaxSuppression), type((short)_type)
    {}

    void detect( InputArray _image, std::vector<KeyPoint>& keypoints, InputArray _mask )
    {
        Mat mask = _mask.getMat(), grayImage;
        UMat ugrayImage;
        _InputArray gray = _image;
        if( _image.type() != CV_8U )
        {
            _OutputArray ogray = _image.isUMat() ? _OutputArray(ugrayImage) : _OutputArray(grayImage);
            cvtColor( _image, ogray, COLOR_BGR2GRAY );
            gray = ogray;
        }
        AGAST( gray, keypoints, threshold, nonmaxSuppression, type );
        KeyPointsFilter::runByPixelsMask( keypoints, mask );
    }

    void set(int prop, double value)
    {
        if(prop == THRESHOLD)
            threshold = cvRound(value);
        else if(prop == NONMAX_SUPPRESSION)
            nonmaxSuppression = value != 0;
        else
            CV_Error(Error::StsBadArg, "");
    }

    double get(int prop) const
    {
        if(prop == THRESHOLD)
            return threshold;
        if(prop == NONMAX_SUPPRESSION)
            return nonmaxSuppression;
        CV_Error(Error::StsBadArg, "");
        return 0;
    }

    void setThreshold(int threshold_) { threshold = threshold_; }
    int getThreshold() const { return threshold; }

    void setNonmaxSuppression(bool f) { nonmaxSuppression = f; }
    bool getNonmaxSuppression() const { return nonmaxSuppression; }

    void setType(int type_) { type = type_; }
    int getType() const { return type; }

    int threshold;
    bool nonmaxSuppression;
    int type;
};
```

----------------------------------------

TITLE: Constructing Output Filename for OpenCV VideoWriter (C++)
DESCRIPTION: Demonstrates how to create a new filename for the output video. It takes the base name of the input video file (from `argv[1]`), finds the position of the file extension, extracts the base name, appends the selected channel character (from `argv[2]`), and adds the `.avi` extension. Requires the `string` library and command-line arguments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
const string source      = argv[1];            // the source file name
string::size_type pAt = source.find_last_of('.');   // Find extension point
const string NAME = source.substr(0, pAt) + argv[2][0] + ".avi";   // Form the new name with container
```

----------------------------------------

TITLE: Creating and Updating Filter Kernel
DESCRIPTION: Creates a normalized box filter kernel of varying sizes. Kernel is filled with 1's and normalized by dividing by total number of elements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
kernel_size = 3 + 2*( ind%5 );
Mat kernel = Mat::ones( kernel_size, kernel_size, CV_32F )/ (float)(kernel_size*kernel_size);
```

----------------------------------------

TITLE: Enabling Debug Message Print for Each CMake Hook Script Call (CMake)
DESCRIPTION: When activated, this debug option emits a message each time a CMake hook script is called during OpenCV configuration. Intended for debugging and tracking custom hook execution. No prerequisites. Enable with -DOPENCV_DUMP_HOOKS_FLOW=ON.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_29

LANGUAGE: cmake
CODE:
```
OPENCV_DUMP_HOOKS_FLOW
```

----------------------------------------

TITLE: Setting Up CMake Project for Histogram Sample
DESCRIPTION: The snippet initializes a CMake project for a histogram sample using OpenCV. It declares the project, specifies dependencies, checks for available dependencies, and configures target directories and libraries. The configuration requires OpenCV core and image processing modules, among others, and ensures that all necessary components are included before proceeding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/semihosting/histogram/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(PROJECT_NAME histogram)
project(${PROJECT_NAME})

ocv_install_example_src(histogram *.cpp *.hpp CMakeLists.txt)

set(LOCAL_DEPS
  opencv_core
  opencv_imgproc
  ${OPENCV_MODULES_PUBLIC}
  ${OpenCV_LIB_COMPONENTS})
ocv_check_dependencies(${LOCAL_DEPS})

if(NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()

ocv_define_sample(histogram histogram.cpp ${SEMIHOSTING_SUFFIX})
ocv_include_modules_recurse(${LOCAL_DEPS})
target_include_directories(${histogram} PRIVATE ${CMAKE_CURRENT_BINARY_DIR})
target_include_directories(${histogram} PRIVATE ${RAW_PIXEL_INCLUDE})
ocv_target_link_libraries(${histogram} PRIVATE ${OPENCV_LINKER_LIBS}
  ${LOCAL_DEPS})
```

----------------------------------------

TITLE: Loading Source Images in Java
DESCRIPTION: This Java snippet loads two source images using `Imgcodecs.imread`. It checks if the images loaded correctly and exits if either fails. It also initializes the destination matrix `dst` and a default alpha value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
//![load]
// Read images
Mat src1 = Imgcodecs.imread(args.length > 0 ? args[0] : "../data/LinuxLogo.jpg");
Mat src2 = Imgcodecs.imread(args.length > 1 ? args[1] : "../data/WindowsLogo.jpg");
if (src1.empty()) {
    System.out.println("Error loading src1");
    System.exit(-1);
}
if (src2.empty()) {
    System.out.println("Error loading src2");
    System.exit(-1);
}
alpha = 0.5; // Default value
dst = new Mat();
//![load]
```

----------------------------------------

TITLE: Forcing Compilation of Dispatchable Layer Files with CPU Extensions - CMake
DESCRIPTION: Multiple calls to 'ocv_add_dispatched_file_force_all' register source files for the DNN module with specific CPU extension flags (AVX, AVX2, AVX512_SKX, RVV, LASX, NEON, NEON_FP16). This ensures these layers are compiled for multiple architectures. Parameters specify which CPU architectures should be built. Inputs are source file paths and CPU flags; outputs are configured build targets.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
ocv_add_dispatched_file_force_all("layers/layers_common" AVX AVX2 AVX512_SKX RVV LASX)
ocv_add_dispatched_file_force_all("int8layers/layers_common" AVX2 AVX512_SKX RVV LASX)
ocv_add_dispatched_file_force_all("layers/cpu_kernels/conv_block" AVX AVX2 NEON NEON_FP16)
ocv_add_dispatched_file_force_all("layers/cpu_kernels/conv_depthwise" AVX AVX2 RVV LASX)
```

----------------------------------------

TITLE: Initializing and Exporting PyTorch ResNet-50 Model to ONNX - Python
DESCRIPTION: This Python snippet instantiates a pretrained ResNet-50 model using PyTorch, then exports it to ONNX format using a utility function. The function 'get_pytorch_onnx_model' is expected to handle ONNX export and path management. Dependencies include torch, torchvision, and a correctly defined export function. The script prints the output location of the converted ONNX model.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
# initialize PyTorch ResNet-50 model\noriginal_model = models.resnet50(pretrained=True)\n\n# get the path to the converted into ONNX PyTorch model\nfull_model_path = get_pytorch_onnx_model(original_model)\nprint("PyTorch ResNet-50 model was successfully converted: ", full_model_path)
```

----------------------------------------

TITLE: Normalizing Histogram Results in C++
DESCRIPTION: C++ snippet normalizing the calculated histograms (`b_hist`, `g_hist`, `r_hist`) to fit within the height of the display image (`histImage.rows`). It uses `cv::normalize` with `NORM_MINMAX` to scale the histogram values linearly between 0 and `histImage.rows`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_24

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Normalize the result to ( 0, histImage.rows )
```

----------------------------------------

TITLE: Enabling Debug Build for OpenCV
DESCRIPTION: The snippet enables debug builds using the `CMAKE_BUILD_TYPE` option. It provides different command scenarios based on platform requirements and mentions options for GNU libstdc++ and disabling optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_3

LANGUAGE: sh
CODE:
```
cmake -DCMAKE_BUILD_TYPE=Debug ../opencv
cmake --build .
```

----------------------------------------

TITLE: Setting Estimated Projection Matrix from Kalman Filter Output in C++ (OpenCV)
DESCRIPTION: This C++ snippet (Step 6 of the algorithm) shows how to use the estimated pose (rotation `rotation_estimated` and translation `translation_estimated` matrices) derived from the Kalman Filter. It calls the `set_P_matrix` method of a `pnp_detection_est` object (likely representing the estimated pose state), providing the filtered rotation and translation matrices as arguments to update the object's internal projection matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_26

LANGUAGE: cpp
CODE:
```
// -- Step 6: Set estimated projection matrix
pnp_detection_est.set_P_matrix(rotation_estimated, translation_estimated);
```

----------------------------------------

TITLE: Loading Source, Template, and Mask Images (C++)
DESCRIPTION: Loads the source image and the template image using `cv::imread`. It also attempts to load an optional mask image if provided via command-line arguments. Includes error handling if images cannot be loaded.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_13

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp load_image
```

----------------------------------------

TITLE: Custom IO Operations in Python with OpenCV
DESCRIPTION: Code snippet showing custom input/output operations in Python using OpenCV's file system functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_18

LANGUAGE: python
CODE:
```
python/tutorial_code/core/file_input_output/file_input_output.py customIO
```

----------------------------------------

TITLE: Downloading and Extracting PaddleSeg Model (Shell)
DESCRIPTION: Downloads the pre-trained PaddleSeg Human Segmentation inference model (`humanseg_hrnet18_small_v1.zip`) using `wget` and then extracts its contents using `unzip`. This provides the necessary model files (`.pdmodel`, `.pdiparams`) for conversion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/dnn_model_runner/dnn_conversion/paddlepaddle/README.md#2025-04-22_snippet_2

LANGUAGE: shell
CODE:
```
wget https://x2paddle.bj.bcebos.com/inference/models/humanseg_hrnet18_small_v1.zip
unzip humanseg_hrnet18_small_v1.zip
```

----------------------------------------

TITLE: Installing Third-Party Licenses using OpenCV Macro in CMake
DESCRIPTION: Calls the OpenCV-specific CMake macro `ocv_install_3rdparty_licenses` to handle the installation of license-related files (README.md, LICENSE) associated with the OpenJPEG library target.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_15

LANGUAGE: cmake
CODE:
```
ocv_install_3rdparty_licenses(${OPENJPEG_LIBRARY_NAME} README.md LICENSE)
```

----------------------------------------

TITLE: Running TensorFlow Classification Module in Test Mode via OpenCV dnn CLI (Console)
DESCRIPTION: Demonstrates launching the classification module in test mode, which enables model inference using specific or default image preprocessing parameters. Required dependencies include tested models, corresponding data, and dnn_model_runner. Key parameters are --test (enables testing), --default_img_preprocess (toggles default or custom preprocessing), and --evaluate (prevents evaluation metrics). Inputs are model and preprocessing settings; outputs are predictions and possibly visualized results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_4

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.classification.py_to_py_cls --model_name <tf_cls_model_name> --test True --default_img_preprocess <True/False> --evaluate False
```

----------------------------------------

TITLE: Initializing PnPProblem with Camera Parameters in C++
DESCRIPTION: The snippet shows a constructor for the PnPProblem class, initializing intrinsic camera matrices using an array of parameters. It sets up matrices for intrinsic values, rotation, translation, and combined rotation-translation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_15

LANGUAGE: cpp
CODE:
```
// Custom constructor given the intrinsic camera parameters

PnPProblem::PnPProblem(const double params[])
{
  _A_matrix = cv::Mat::zeros(3, 3, CV_64FC1);   // intrinsic camera parameters
  _A_matrix.at<double>(0, 0) = params[0];       //      [ fx   0  cx ]
  _A_matrix.at<double>(1, 1) = params[1];       //      [  0  fy  cy ]
  _A_matrix.at<double>(0, 2) = params[2];       //      [  0   0   1 ]
  _A_matrix.at<double>(1, 2) = params[3];
  _A_matrix.at<double>(2, 2) = 1;
  _R_matrix = cv::Mat::zeros(3, 3, CV_64FC1);   // rotation matrix
  _t_matrix = cv::Mat::zeros(3, 1, CV_64FC1);   // translation matrix
  _P_matrix = cv::Mat::zeros(3, 4, CV_64FC1);   // rotation-translation matrix

}
```

----------------------------------------

TITLE: Initializing OpenCV Mat with MATLAB-Style Functions in C++
DESCRIPTION: Creates matrices using MATLAB-style initializers like zeros(), ones(), and eye(). These functions create matrices filled with zeros, ones, or identity matrices respectively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
// MATLAB style initializer: zeros, ones, eye
Mat E = Mat::eye(4, 4, CV_64F);
cout << "E = " << endl << " " << E << endl << endl;
Mat O = Mat::ones(2, 2, CV_32F);
cout << "O = " << endl << " " << O << endl << endl;
Mat Z = Mat::zeros(3,3, CV_8UC1);
cout << "Z = " << endl << " " << Z << endl << endl;
```

----------------------------------------

TITLE: Checking Dependencies for CUDA Samples in CMake
DESCRIPTION: Calls the custom `ocv_check_dependencies` CMake function to verify if all modules listed in the `OPENCV_CUDA_SAMPLES_REQUIRED_DEPS` variable are found and available in the current build configuration. It likely sets the `OCV_DEPENDENCIES_FOUND` variable based on the result.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
ocv_check_dependencies(${OPENCV_CUDA_SAMPLES_REQUIRED_DEPS})
```

----------------------------------------

TITLE: Calculating Orientation using OpenCV.js
DESCRIPTION: Finds the orientation (angle) of a contour by fitting an ellipse to it. Also provides major and minor axis lengths (implicitly via the `rotatedRect` object). Requires a contour (`cnt`). Uses the `cv.fitEllipse` function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_properties/js_contour_properties.markdown#2025-04-22_snippet_4

LANGUAGE: javascript
CODE:
```
let rotatedRect = cv.fitEllipse(cnt);
let angle = rotatedRect.angle;
```

----------------------------------------

TITLE: Estimating Camera Response Function with OpenCV Python
DESCRIPTION: Estimates the camera response function (CRF) for the HDR processing using Debevec and Robertson calibration methods. This CRF allows more accurate HDR image creation by relating scene radiance to intensity values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_hdr/py_hdr.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
# Estimate camera response function (CRF)
cal_debevec = cv.createCalibrateDebevec()
crf_debevec = cal_debevec.process(img_list, times=exposure_times)
hdr_debevec = merge_debevec.process(img_list, times=exposure_times.copy(), response=crf_debevec.copy())
cal_robertson = cv.createCalibrateRobertson()
crf_robertson = cal_robertson.process(img_list, times=exposure_times)
hdr_robertson = merge_robertson.process(img_list, times=exposure_times.copy(), response=crf_robertson.copy())
```

----------------------------------------

TITLE: Visualizing PCA Axis in Java using OpenCV
DESCRIPTION: Provides a helper method `drawAxis` to visualize a principal component axis. It draws a line segment between a center point `p` and a scaled point `q` on the image `img` with a specified color. It also adds arrowhead hooks for clarity. Requires OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_10

LANGUAGE: java
CODE:
```
//! [visualization]
// Function to draw the axes of the object detected by PCA
private static void drawAxis(Mat img, Point p, Point q, Scalar colour, double scale) {
    double angle = atan2(p.y - q.y, p.x - q.x); // angle in radians
    double hypotenuse = Math.sqrt(Math.pow(p.y - q.y, 2) + Math.pow(p.x - q.x, 2));

    // Here we lengthen the arrow by a factor of scale
    q.x = (p.x - scale * hypotenuse * Math.cos(angle));
    q.y = (p.y - scale * hypotenuse * Math.sin(angle));
    line(img, p, q, colour, 1, LINE_AA);

    // create the arrow hooks
    p.x = (q.x + 9 * Math.cos(angle + Math.PI / 4));
    p.y = (q.y + 9 * Math.sin(angle + Math.PI / 4));
    line(img, p, q, colour, 1, LINE_AA);

    p.x = (q.x + 9 * Math.cos(angle - Math.PI / 4));
    p.y = (q.y + 9 * Math.sin(angle - Math.PI / 4));
    line(img, p, q, colour, 1, LINE_AA);
}
//! [visualization]
```

----------------------------------------

TITLE: Configuring Compiler Flags and Definitions for MSVC and Other Compilers - CMake
DESCRIPTION: Configures a wide range of compiler warning flags and macro definitions, particularly for MSVC (Microsoft Visual C++). Suppresses specific warnings and sets platform compliance flags. Conditions check for compiler version and platform (MSVC, Apple, Android), setting defines or flags accordingly. Parameters include MSVC version, C++11 support, and Android status; outputs are compiler command line options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: CMake
CODE:
```
if(MSVC)
  add_definitions( -D_CRT_SECURE_NO_WARNINGS=1 )
  ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4244 /wd4267 /wd4018 /wd4355 /wd4800 /wd4251 /wd4996 /wd4146
                                       /wd4305 /wd4127 /wd4100 /wd4512 /wd4125 /wd4389 /wd4510 /wd4610
                                       /wd4702 /wd4456 /wd4457 /wd4065 /wd4310 /wd4661 /wd4506
  )
  if(MSVC_VERSION LESS 1920)  # MSVS 2015/2017, .pb.cc generated files
    ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4309)  # 'static_cast': truncation of constant value
  endif()
  if(MSVC_VERSION LESS 1920)  # <MSVS2019, .pb.cc generated files
    ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4189)  # local variable is initialized but not referenced
    ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4592)  # symbol will be dynamically initialized (implementation limitation)
  endif()
else()
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wno-deprecated -Wmissing-prototypes -Wmissing-declarations -Wshadow
                                       -Wunused-parameter -Wsign-compare
  )
endif()
if(HAVE_CUDA)
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wundef)
endif()
if(NOT HAVE_CXX11)
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wno-undef)  # LANG_CXX11 from protobuf files
endif()

if(APPLE_FRAMEWORK)
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wshorten-64-to-32)
endif()

if(ANDROID)
  add_definitions(-DDISABLE_POSIX_MEMALIGN -DTH_DISABLE_HEAP_TRACKING)
endif()

if(NOT BUILD_PROTOBUF)
  ocv_target_compile_definitions(${the_module} PRIVATE "OPENCV_DNN_EXTERNAL_PROTOBUF=1")
endif()
```

----------------------------------------

TITLE: Archiving OpenCV Build Artifacts with Tar
DESCRIPTION: Archive the OpenCV built libraries and headers into a tarball named opencv_arm64.tgz, using the tar command. This step is done after installation of the build artifacts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_20

LANGUAGE: bash
CODE:
```
tar czvf opencv_arm64.tgz -C build4-full_arm64/install .
```

----------------------------------------

TITLE: Configuring Installation Root with a Relative Path in CMake - Shell
DESCRIPTION: Uses CMake to set up the installation prefix to a directory named 'install' relative to the current working directory. This adjusts where the final build output will be placed post-install, and is useful for isolated builds. Requires 'cmake' and access to the source directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_21

LANGUAGE: shell
CODE:
```
cmake -DCMAKE_INSTALL_PREFIX=install ../opencv
```

----------------------------------------

TITLE: Asynchronous CUDA Stream Operations in OpenCV
DESCRIPTION: Demonstrates how to use GPU streams for asynchronous operations in OpenCV, including image conversion and multiplication. The stream allows for parallel execution of operations by queuing uploads while the GPU processes other tasks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_15

LANGUAGE: cpp
CODE:
```
gpu::Stream stream;

stream.enqueueConvert(b.gI1, b.t1, CV_32F);    // Upload

gpu::split(b.t1, b.vI1, stream);              // Methods (pass the stream as final parameter).
gpu::multiply(b.vI1[i], b.vI1[i], b.I1_2, stream);        // I1^2
```

----------------------------------------

TITLE: Copying and Installing FFmpeg DLLs with CMake Scripting - CMake
DESCRIPTION: This CMake snippet conditionally copies the appropriate FFmpeg DLLs to the output directories (Debug/Release) and installs them for distribution as part of an OpenCV build on Windows. It determines DLL naming based on architecture (32-bit or 64-bit) and handles Visual Studio IDE specifics. The script relies on the variables WIN32, HAVE_FFMPEG_WRAPPER, CMAKE_SIZEOF_VOID_P, OpenCV_BINARY_DIR, OPENCV_DLLVERSION, MSVC_IDE, CMAKE_COMMAND, EXECUTABLE_OUTPUT_PATH, CMAKE_BUILD_TYPE, OPENCV_BIN_INSTALL_PATH, and INSTALL_CREATE_DISTRIB. Inputs are expected as configured CMake variables and outputs are the copied/installed DLL files. User must ensure the FFmpeg binaries are present in the correct 3rdparty folder.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
# copy FFmpeg dll to the output folder
if(WIN32 AND HAVE_FFMPEG_WRAPPER)
  if(CMAKE_SIZEOF_VOID_P EQUAL 8)
    set(FFMPEG_SUFFIX _64)
  endif()
  set(ffmpeg_dir "${OpenCV_BINARY_DIR}/3rdparty/ffmpeg")
  set(ffmpeg_bare_name "opencv_videoio_ffmpeg${FFMPEG_SUFFIX}.dll")
  set(ffmpeg_bare_name_ver "opencv_videoio_ffmpeg${OPENCV_DLLVERSION}${FFMPEG_SUFFIX}.dll")
  set(ffmpeg_path "${ffmpeg_dir}/${ffmpeg_bare_name}")
  if(MSVC_IDE)
    execute_process(
      COMMAND ${CMAKE_COMMAND} -E copy_if_different "${ffmpeg_path}" "${EXECUTABLE_OUTPUT_PATH}/Release/${ffmpeg_bare_name_ver}"
      COMMAND ${CMAKE_COMMAND} -E copy_if_different "${ffmpeg_path}" "${EXECUTABLE_OUTPUT_PATH}/Debug/${ffmpeg_bare_name_ver}")
  elseif(MSVC AND (CMAKE_GENERATOR MATCHES "Visual"))
    execute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different "${ffmpeg_path}" "${EXECUTABLE_OUTPUT_PATH}/${CMAKE_BUILD_TYPE}/${ffmpeg_bare_name_ver}")
  else()
    execute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different "${ffmpeg_path}" "${EXECUTABLE_OUTPUT_PATH}/${ffmpeg_bare_name_ver}")
  endif()
  install(FILES "${ffmpeg_path}" DESTINATION ${OPENCV_BIN_INSTALL_PATH} COMPONENT libs RENAME "${ffmpeg_bare_name_ver}")
  if(INSTALL_CREATE_DISTRIB)
    install(FILES "${ffmpeg_dir}/opencv_videoio_ffmpeg${FFMPEG_SUFFIX}.dll" DESTINATION "bin/" COMPONENT libs RENAME "opencv_videoio_ffmpeg${OPENCV_DLLVERSION}${FFMPEG_SUFFIX}.dll")
  endif()
endif()
```

----------------------------------------

TITLE: Feature Detection API Changes in OpenCV 2.4 vs 3.0
DESCRIPTION: Illustrates the changes in the feature detection API between OpenCV 2.4 and 3.0, including the use of xfeatures2d namespace and the new create() factory methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
using namespace cv;
// ====== 2.4 =======
#include "opencv2/features2d/features2d.hpp"
BriefDescriptorExtractor brief(32);
GridAdaptedFeatureDetector detector(new FastFeatureDetector(10, true), DESIRED_FTRS, 4, 4);
// ...
detector.detect(gray, query_kpts); //Find interest points
brief.compute(gray, query_kpts, query_desc); //Compute brief descriptors at each keypoint location
// ====== 3.0 =======
#include "opencv2/features2d.hpp"
#include "opencv2/xfeatures2d.hpp"
using namespace cv::xfeatures2d;
Ptr<BriefDescriptorExtractor> brief = BriefDescriptorExtractor::create(32);
Ptr<FastFeatureDetector> detector = FastFeatureDetector::create(10, true);
// ...
detector->detect(gray, query_kpts); //Find interest points
brief->compute(gray, query_kpts, query_desc); //Compute brief descriptors at each keypoint location
```

----------------------------------------

TITLE: Python BeautifulSoup Dependency Check
DESCRIPTION: Checks for the availability of Python's BeautifulSoup package required for documentation post-processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_22

LANGUAGE: cmake
CODE:
```
if(NOT DEFINED HAVE_PYTHON_BS4 AND PYTHON_DEFAULT_EXECUTABLE)
    execute_process(COMMAND "${PYTHON_DEFAULT_EXECUTABLE}" -c "import bs4; from bs4 import BeautifulSoup; print(bs4.__version__)"
                    RESULT_VARIABLE _result
                    OUTPUT_VARIABLE _bs4_version
                    OUTPUT_STRIP_TRAILING_WHITESPACE)

    if(NOT _result EQUAL 0)
      set(HAVE_PYTHON_BS4 0 CACHE INTERNAL "")
    else()
      message(STATUS "Python BeautifulSoup (bs4) version: ${_bs4_version}")
      set(HAVE_PYTHON_BS4 1 CACHE INTERNAL "")
    endif()
  endif()
```

----------------------------------------

TITLE: Collecting Source and Header Files for OpenEXR
DESCRIPTION: This snippet collects source and header files for the OpenEXR library from different directories. It also filters out platform-specific files that aren't needed for the current build target.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
file(GLOB lib_srcs Half/half.cpp Iex/*.cpp IlmThread/*.cpp Imath/*.cpp IlmImf/*.cpp)
file(GLOB lib_hdrs Half/*.h Iex/Iex*.h IlmThread/IlmThread*.h Imath/Imath*.h IlmImf/*.h)
list(APPEND lib_hdrs "${CMAKE_CURRENT_BINARY_DIR}/IlmBaseConfig.h" "${CMAKE_CURRENT_BINARY_DIR}/OpenEXRConfig.h")

if(WIN32)
  ocv_list_filterout(lib_srcs Posix.*cpp)
else()
  ocv_list_filterout(lib_srcs Win32.cpp)
endif()

source_group("Include" FILES ${lib_hdrs} )
source_group("Src" FILES ${lib_srcs})
```

----------------------------------------

TITLE: Saturation Arithmetic with cv::saturate_cast in OpenCV C++
DESCRIPTION: This snippet demonstrates the use of saturation arithmetic to prevent overflow when converting operation results to 8-bit images. It uses the `cv::saturate_cast` function to ensure values are within the uchar range, which is critical for preserving image quality when performing operations that may exceed the typical value range.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
    I.at<uchar>(y, x) = saturate_cast<uchar>(r);
```

----------------------------------------

TITLE: RealSense Camera Property Configuration
DESCRIPTION: Demonstrates how to set and get camera properties using VideoCapture's set and get methods. This example shows setting the depth generator profile and retrieving the FPS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/intelperc.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
    VideoCapture capture(CAP_REALSENSE);
    capture.set( CAP_INTELPERC_DEPTH_GENERATOR | CAP_PROP_INTELPERC_PROFILE_IDX, 0 );
    cout << "FPS    " << capture.get( CAP_INTELPERC_DEPTH_GENERATOR+CAP_PROP_FPS ) << endl;
```

----------------------------------------

TITLE: Project Configuration for OpenCV Dependencies Clojure
DESCRIPTION: This Clojure configuration updates the dependencies section of a Leiningen project to include OpenCV libraries. Prerequisites are a working Leiningen setup and OpenCV libraries locally available. The updated dependencies allow access to OpenCV functionalities within the project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_5

LANGUAGE: clojure
CODE:
```
(defproject simple-sample "0.1.0-SNAPSHOT"\n  description "FIXME: write description"\n  url "http://example.com/FIXME"\n  license {:name "Eclipse Public License"\n  url "http://www.eclipse.org/legal/epl-v10.html"}\n  dependencies [[org.clojure/clojure "1.5.1"]\n            [opencv/opencv "2.4.7"] ; added line\n            [opencv/opencv-native "2.4.7"]]) ;added line
```

----------------------------------------

TITLE: Enabling pkg-config Generation in OpenCV
DESCRIPTION: This option enables generation of `.pc` files using `OPENCV_GENERATE_PKGCONFIG`. These files facilitate integration with non-CMake-based projects but may contain incomplete dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_5

LANGUAGE: sh
CODE:
```
cmake -DOPENCV_GENERATE_PKGCONFIG=ON ../opencv
```

----------------------------------------

TITLE: Running OpenCV.js Performance Test for cvtColor in Node.js
DESCRIPTION: This snippet demonstrates how to run a performance test for the cvtColor function using Node.js. It shows both the command for running all tests and a specific test case using a parameter filter.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/perf/README.md#2025-04-22_snippet_0

LANGUAGE: sh
CODE:
```
node perf_cvtcolor.js
```

LANGUAGE: sh
CODE:
```
node perf_cvtcolor.js --test_param_filter="(1920x1080, COLOR_BGR2GRAY)"
```

----------------------------------------

TITLE: Computing Discrete Fourier Transform Using OpenCV in JavaScript
DESCRIPTION: This snippet shows how to compute the Discrete Fourier Transform (DFT) of an image using the cv.dft function in OpenCV.js. The function requires an input array (src), output array (dst), optional transformation flags, and a parameter to optimize row computation for sparse data (nonzeroRows). Outputs include the transformed frequency domain matrix, with behavior determined by the provided flags. Dependencies: OpenCV.js library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_transforms/js_fourier_transform/js_fourier_transform.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
cv.dft (src, dst, flags = 0, nonzeroRows = 0)
```

----------------------------------------

TITLE: Refined Kernel Package for OpenCV G-API Integration
DESCRIPTION: This snippet reflects the updated version of the kernel package after removing the Fluid version of the Box filter kernel. G-API now utilizes OpenCV's implementation, which circumvents former limitations with kernel size constraints. It ensures the flexibility of backend selection within the graph, enhancing performance outcomes without altering the graph structure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/porting_anisotropic_image_segmentation/porting_anisotropic_image_segmentation_gapi_fluid.cpp kernel_pkg_proper
```

----------------------------------------

TITLE: OpenVX C++ Wrapper Basic Usage Example
DESCRIPTION: Demonstrates core functionality of OpenVX C++ wrappers including context creation, graph operations, image processing, and error handling. Shows how to create and process images using Gaussian blur and threshold operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openvx/README.md#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include "ivx.hpp"
#include "ivx_lib_debug.hpp" // ivx::debug::*

int main()
{
	vx_uint32 width = 640, height = 480;
	try
	{
		ivx::Context context = ivx::Context::create();
		ivx::Graph graph = ivx::Graph::create(context);
		ivx::Image
		    gray = ivx::Image::create(context, width, height, VX_DF_IMAGE_U8),
		    gb   = ivx::Image::createVirtual(graph),
		    res  = ivx::Image::create(context, width, height, VX_DF_IMAGE_U8);

		context.loadKernels("openvx-debug");  // ivx::debug::*

		ivx::debug::fReadImage(context, inputPath, gray);

		ivx::Node::create(graph, VX_KERNEL_GAUSSIAN_3x3, gray, gb);
		ivx::Node::create(
		    graph,
		    VX_KERNEL_THRESHOLD,
		    gb,
		    ivx::Threshold::createBinary(context, VX_TYPE_UINT8, 50),
		    res
		);

		graph.verify();
		graph.process();

		ivx::debug::fWriteImage(context, res, "ovx-res-cpp.pgm");
    }
    catch (const ivx::RuntimeError& e)
    {
        printf("ErrorRuntime: code = %d(%x), message = %s\n", e.status(), e.status(), e.what());
        return e.status();
    }
    catch (const ivx::WrapperError& e)
    {
        printf("ErrorWrapper: message = %s\n", e.what());
        return -1;
    }
    catch(const std::exception& e)
    {
        printf("runtime_error: message = %s\n", e.what());
        return -1;
    }

    return 0;
}
```

----------------------------------------

TITLE: Running the Java Application using SBT (Bash)
DESCRIPTION: Executes the Java face detection application using the SBT 'run' command. SBT compiles the source code if necessary and then runs the main method of the 'HelloOpenCV' class.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_20

LANGUAGE: bash
CODE:
```
sbt run
```

----------------------------------------

TITLE: Embedding Style Transfer Example in HTML - HTML
DESCRIPTION: This HTML snippet embeds an external style transfer example using an iframe. The 'src' attribute points to a JavaScript-powered interactive demo, and the 'onload' handler dynamically resizes the iframe height based on its content. No dependencies are required beyond a modern browser, and there are no input parameters except the iframe attributes. Output is a live preview of the style transfer effect. The snippet is intended for interactive documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_dnn/js_style_transfer/js_style_transfer.markdown#2025-04-22_snippet_0

LANGUAGE: HTML
CODE:
```
<iframe src="../../js_style_transfer.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
```

----------------------------------------

TITLE: Creating Trackbar in Python
DESCRIPTION: This Python snippet uses `cv.createTrackbar` to add a slider to the 'Linear Blend' window. It sets the trackbar's name dynamically, specifies the window name, sets the initial value (0) and maximum value (`alpha_slider_max`), and links it to the `on_trackbar` callback function. The callback is also called initially.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
#![create_trackbar]
# create trackbar
trackbar_name = 'Alpha x %d' % alpha_slider_max
cv.createTrackbar(trackbar_name, 'Linear Blend', 0, alpha_slider_max, on_trackbar)

# Show some stuff
on_trackbar(0)
#![create_trackbar]
```

----------------------------------------

TITLE: Detect Edges with Canny in OpenCV Java
DESCRIPTION: Employs OpenCV's Canny edge detection function in Java for image processing. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_10

LANGUAGE: Java
CODE:
```
Mat edges = new Mat();
Imgproc.Canny(gray, edges, lowThreshold, highThreshold);
```

----------------------------------------

TITLE: Saving Images with OpenCV in C++
DESCRIPTION: This snippet illustrates how to save an image to a file in C++ using OpenCV's cv::imwrite function. The file path and cv::Mat object represent the filename and the image data respectively. Saving is conditional on a specific key press.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_8

LANGUAGE: C++
CODE:
```
if(key == 's') {
    imwrite("starry_night.jpg", image);
    std::cout << "Image saved!" << std::endl;
}
```

----------------------------------------

TITLE: Enabling WebNN Backend in Build - Bash
DESCRIPTION: Appends the --webnn flag to build OpenCV.js with support for the WebNN backend, which enables native neural network computations in browsers supporting WebNN API. Dependency: emcmake, Python, WebNN compatible browser or runtime for testing. Parameter: --webnn. Output: OpenCV.js build with WebNN support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_11

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --webnn
```

----------------------------------------

TITLE: Running PyTorch Model Evaluation with Python
DESCRIPTION: This command runs the module in evaluation mode to assess PyTorch segmentation models with OpenCV. It logs essential metrics such as pixel accuracy, mean IoU, and inference time.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_10

LANGUAGE: shell
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.segmentation.py_to_py_segm --model_name <pytorch_segm_model_name>
```

----------------------------------------

TITLE: Configuring and Building OpenCV PnP Tutorial Executables using CMake
DESCRIPTION: This CMake script segment defines variables for the source directory and target prefix, lists common C++ source files for the PnP examples, includes necessary OpenCV modules, defines two separate executables (`example_tutorial_pnp_registration` and `example_tutorial_pnp_detection`) using their respective main files and the common source list, and finally links both executables against the required OpenCV libraries and dependencies specified by `OPENCV_LINKER_LIBS` and `OPENCV_CPP_SAMPLES_REQUIRED_DEPS`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample_dir ${CMAKE_CURRENT_SOURCE_DIR}/tutorial_code/calib3d/real_time_pose_estimation/src/)
```

LANGUAGE: cmake
CODE:
```
set(target example_tutorial_)
```

LANGUAGE: cmake
CODE:
```
set(sample_pnplib
        ${sample_dir}CsvReader.cpp
        ${sample_dir}CsvWriter.cpp
        ${sample_dir}ModelRegistration.cpp
        ${sample_dir}Mesh.cpp
        ${sample_dir}Model.cpp
        ${sample_dir}PnPProblem.cpp
        ${sample_dir}Utils.cpp
        ${sample_dir}RobustMatcher.cpp
)
```

LANGUAGE: cmake
CODE:
```
ocv_include_modules_recurse(${OPENCV_CPP_SAMPLES_REQUIRED_DEPS})
```

LANGUAGE: cmake
CODE:
```
add_executable( ${target}pnp_registration ${sample_dir}main_registration.cpp ${sample_pnplib} )
```

LANGUAGE: cmake
CODE:
```
add_executable( ${target}pnp_detection ${sample_dir}main_detection.cpp ${sample_pnplib} )
```

LANGUAGE: cmake
CODE:
```
ocv_target_link_libraries(${target}pnp_registration PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_CPP_SAMPLES_REQUIRED_DEPS})
```

LANGUAGE: cmake
CODE:
```
ocv_target_link_libraries(${target}pnp_detection PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_CPP_SAMPLES_REQUIRED_DEPS})
```

----------------------------------------

TITLE: Running TensorFlow MobileNet Model Test via OpenCV dnn CLI (Console)
DESCRIPTION: Displays the full command for launching the model test workflow with default image preprocessing and without evaluation metrics. Dependencies include the dnn_model_runner test infrastructure and a valid MobileNet model. Inputs are the chosen model, test flag, and preprocessing settings; outputs are visually presented predictions. Limitations depend on the correctness of parameters provided.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_7

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.classification.py_to_py_cls --model_name mobilenet --test True --default_img_preprocess True --evaluate False
```

----------------------------------------

TITLE: Preparing the CMake Build Directory for OpenCV - Shell
DESCRIPTION: This shell snippet shows how to create and move into a dedicated build directory outside the source repositories, as recommended for CMake-based projects. This approach ensures build artifacts are separated from source files and enables clean builds. The commands use 'mkdir' to create a new directory and 'cd' to change the current working directory in preparation for running CMake configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_2

LANGUAGE: shell
CODE:
```
$ mkdir build
$ cd build
```

----------------------------------------

TITLE: Running DNN Model Runner in Test Mode
DESCRIPTION: Command to run the model runner in test mode for model inference with customizable preprocessing options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_11

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_cls --model_name <pytorch_cls_model_name> --test True --default_img_preprocess <True/False> --evaluate False
```

----------------------------------------

TITLE: Getting Optimal DFT Size with OpenCV in JavaScript
DESCRIPTION: This snippet demonstrates the use of cv.getOptimalDFTSize to find an efficient DFT size compatible with FFT requirements. The function takes a vector size (vecsize) and returns an optimal, algorithm-friendly value for improved performance. This helps reduce computation time in Fourier analysis. Dependencies: OpenCV.js library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_transforms/js_fourier_transform/js_fourier_transform.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
cv.getOptimalDFTSize (vecsize)
```

----------------------------------------

TITLE: Declaring a Kernel Wrapper Factory Function (OpenCV G-API, C++)
DESCRIPTION: Shows implementation of a C++ function wrapper (factory method) around a G-API kernel to provide a more ergonomic and flexible interface for users. This wrapper can supply optional or default arguments and Doxygen comments, making kernel usage more concise. Depends on the relevant kernel interface definition and standard C++ function syntax.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/doc/20-kernel-api.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
// C++ function wrapper for kernel to enable optional parameters and compact syntax
cv::GMat myFilter2D(const cv::GMat &in, const cv::Mat &kernel, cv::Point anchor = cv::Point(-1, -1))
{
    return Filter2D::on(in, kernel, anchor);
}
// Enables usage like: auto out = myFilter2D(in, kernel);
```

----------------------------------------

TITLE: Generating Linearly Separable Training Data for SVM (Java)
DESCRIPTION: Java implementation for generating linearly separable training data for SVM with random points from two classes. This creates the initial part of the dataset with classes that could be separated by a linear boundary.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_4

LANGUAGE: Java
CODE:
```
// Set up the linearly separable part of the training data
int[] labels = { 1, -1 };
Mat trainData = new Mat(2 * NTRAINING_SAMPLES, 2, CvType.CV_32FC1);
Mat trainLabels = new Mat(2 * NTRAINING_SAMPLES, 1, CvType.CV_32SC1);
Random rng = new Random(100);

// Generate training samples
for (int i = 0; i < 2; i++) {
    Mat trainClass = trainData.rowRange(i * NTRAINING_SAMPLES, (i + 1) * NTRAINING_SAMPLES);
    Mat center = trainClass.colRange(0, 1);
    // randomly generates 100 point samples from a uniform distribution
    // in the range [0, 1].
    Core.randu(center, 0, 1);
    // the x range depends on the class
    // class 0: [0, 0.4 * WIDTH]
    // class 1: [0.6 * WIDTH, WIDTH]
    if (i == 0) {
        // scale the x coordinate
        Core.multiply(center, new Scalar(0.2), center);
        // and add 0.2 to bring it to the range [0.2, 0.4]
        Core.add(center, new Scalar(0.2), center);
    } else {
        // scale the x coordinate
        Core.multiply(center, new Scalar(0.2), center);
        // and add 0.6 to bring it to the range [0.6, 0.8]
        Core.add(center, new Scalar(0.6), center);
    }
    // The y coordinate of the points is in range [0, 1]
    Core.randu(trainClass.colRange(1, 2), 0, 1);

    // Fill the training labels
    trainLabels.rowRange(i * NTRAINING_SAMPLES, (i + 1) * NTRAINING_SAMPLES).setTo(new Scalar(labels[i]));
}
```

----------------------------------------

TITLE: Initializing OpenCV Build Definitions
DESCRIPTION: Sets basic OpenCV build definitions for the project configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
add_definitions(-D__OPENCV_BUILD=1)
add_definitions(-D__OPENCV_APPS=1)
```

----------------------------------------

TITLE: Loading Source, Template, and Mask Images (Java)
DESCRIPTION: Loads the source image and the template image using `Imgcodecs.imread`. It parses command-line arguments to get file paths and optionally loads a mask image. Includes checks to ensure images are loaded successfully.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_14

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java load_image
```

----------------------------------------

TITLE: Enabling libjpeg v8 API/ABI Emulation via CMake Option
DESCRIPTION: Specifies the CMake command-line argument `-DWITH_JPEG8=1` required during the configuration phase of building libjpeg-turbo. This flag instructs the build system to enable emulation of the libjpeg v8 API and ABI, ensuring compatibility with applications originally built against libjpeg v8.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/README.md#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
-DWITH_JPEG8=1
```

----------------------------------------

TITLE: Installing Example Source Files for OpenCV TAPI Samples - CMake
DESCRIPTION: Installs the source files (C++ and header files) and the CMakeLists.txt needed for TAPI examples using the ocv_install_example_src macro. Ensures all relevant files required to build and understand the OpenCV TAPI sample projects are installed as part of the example resources. No external dependencies except those provided by OpenCV build setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/tapi/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
ocv_install_example_src(tapi *.cpp *.hpp CMakeLists.txt)
```

----------------------------------------

TITLE: Drawing a Polygon in Java
DESCRIPTION: Implementation of the MyPolygon function that draws a filled polygon in OpenCV Java. The function creates a MatOfPoint object with the polygon vertices and uses the fillPoly() function to draw a white polygon.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_25

LANGUAGE: java
CODE:
```
private static void MyPolygon(Mat img) {
    int lineType = Core.LINE_8;

    // Create some points
    Point[] pts = new Point[20];
    pts[0] = new Point(w/4, 7*w/8);
    pts[1] = new Point(3*w/4, 7*w/8);
    pts[2] = new Point(3*w/4, 13*w/16);
    pts[3] = new Point(11*w/16, 13*w/16);
    pts[4] = new Point(19*w/32, 3*w/8);
    pts[5] = new Point(3*w/4, 3*w/8);
    pts[6] = new Point(3*w/4, w/8);
    pts[7] = new Point(26*w/40, w/8);
    pts[8] = new Point(26*w/40, w/4);
    pts[9] = new Point(22*w/40, w/4);
    pts[10] = new Point(22*w/40, w/8);
    pts[11] = new Point(18*w/40, w/8);
    pts[12] = new Point(18*w/40, w/4);
    pts[13] = new Point(14*w/40, w/4);
    pts[14] = new Point(14*w/40, w/8);
    pts[15] = new Point(w/4, w/8);
    pts[16] = new Point(w/4, 3*w/8);
    pts[17] = new Point(13*w/32, 3*w/8);
    pts[18] = new Point(5*w/16, 13*w/16);
    pts[19] = new Point(w/4, 13*w/16);

    MatOfPoint ppt = new MatOfPoint(pts);

    List<MatOfPoint> ppts = new ArrayList<>();
    ppts.add(ppt);

    Imgproc.fillPoly(img,
            ppts,
            new Scalar(255, 255, 255),
            lineType);
}
```

----------------------------------------

TITLE: Constructing Matrices (Mat) with OpenCV.js - JavaScript
DESCRIPTION: Illustrates multiple ways to construct cv.Mat objects: default constructor, by size/type, with row/col/type, and initialization values. Also shows using static functions (zeros, ones, eye) for common matrix patterns. Dependencies include OpenCV.js and the correct specification of matrix dimensions and types. Used as the basis for subsequent image or matrix operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
// 1. default constructor
let mat = new cv.Mat();
// 2. two-dimensional arrays by size and type
let mat = new cv.Mat(size, type);
// 3. two-dimensional arrays by rows, cols, and type
let mat = new cv.Mat(rows, cols, type);
// 4. two-dimensional arrays by rows, cols, and type with initialization value
let mat = new cv.Mat(rows, cols, type, new cv.Scalar());
```

LANGUAGE: JavaScript
CODE:
```
// 1. Create a Mat which is full of zeros
let mat = cv.Mat.zeros(rows, cols, type);
// 2. Create a Mat which is full of ones
let mat = cv.Mat.ones(rows, cols, type);
// 3. Create a Mat which is an identity matrix
let mat = cv.Mat.eye(rows, cols, type);
```

----------------------------------------

TITLE: Constructing OCR for Digits using kNN in OpenCV
DESCRIPTION: This Python code demonstrates a simple OCR application for handwritten digits. It leverages OpenCV to read and preprocess an image, splitting it into training and test datasets. The script initializes a kNN classifier to predict handwritten digits' labels, achieving 91% accuracy. Dependencies include OpenCV and NumPy. Inputs are an image containing handwritten digits, and outputs are the accuracy score and label predictions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_knn/py_knn_opencv/py_knn_opencv.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('digits.png')
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)

# Now we split the image to 5000 cells, each 20x20 size
cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]

# Make it into a Numpy array: its size will be (50,100,20,20)
x = np.array(cells)

# Now we prepare the training data and test data
train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)
test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)

# Create labels for train and test data
k = np.arange(10)
train_labels = np.repeat(k,250)[:,np.newaxis]
test_labels = train_labels.copy()

# Initiate kNN, train it on the training data, then test it with the test data with k=1
knn = cv.ml.KNearest_create()
knn.train(train, cv.ml.ROW_SAMPLE, train_labels)
ret,result,neighbours,dist = knn.findNearest(test,k=5)

# Now we check the accuracy of classification
# For that, compare the result with test_labels and check which are wrong
matches = result==test_labels
correct = np.count_nonzero(matches)
accuracy = correct*100.0/result.size
print( accuracy )
```

----------------------------------------

TITLE: Filtering and Configuring OpenCV C++ Samples
DESCRIPTION: This snippet segments and checks available GPU or special module support, and then organizes the list of sample projects accordingly. Samples requiring GPU computation are excluded if the related modules aren\'t available, and other specific directories may be filtered out based on criteria. It also determines package types for samples and manages dependencies, linking them appropriately.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
project(cpp_samples)
ocv_include_modules_recurse(${OPENCV_CPP_SAMPLES_REQUIRED_DEPS})
file(GLOB_RECURSE cpp_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
if(NOT HAVE_opencv_cudaarithm OR NOT HAVE_opencv_cudafilters)
  ocv_list_filterout(cpp_samples "/gpu/")
endif()
ocv_list_filterout(cpp_samples "real_time_pose_estimation/")
ocv_list_filterout(cpp_samples "parallel_backend/")
foreach(sample_filename ${cpp_samples})
  set(package "cpp")
  if(sample_filename MATCHES "tutorial_code/snippet")
    set(package "snippet")
  elseif(sample_filename MATCHES "tutorial_code")
    set(package "tutorial")
  endif()
  ocv_define_sample(tgt ${sample_filename} ${package})
  set(deps ${OPENCV_CPP_SAMPLES_REQUIRED_DEPS})
  if(DEFINED DEPS_${tgt})
    set(deps ${DEPS_${tgt}})
  endif()
  ocv_target_link_libraries(${tgt} PRIVATE ${OPENCV_LINKER_LIBS} ${deps})
  if(sample_filename MATCHES "/gpu/" AND HAVE_opencv_cudaarithm AND HAVE_opencv_cuda_filters)
    ocv_target_link_libraries(${tgt} PRIVATE opencv_cudaarithm opencv_cudafilters)
  endif()
  if(sample_filename MATCHES "/viz/")
    ocv_target_link_libraries(${tgt} PRIVATE ${VTK_LIBRARIES})
    target_compile_definitions(${tgt} PRIVATE -DUSE_VTK)
  endif()
  if(HAVE_OPENGL AND sample_filename MATCHES "detect_mser")
    target_compile_definitions(${tgt} PRIVATE HAVE_OPENGL)
    ocv_target_link_libraries(${tgt} PRIVATE "${OPENGL_LIBRARIES}")
  endif()
  if(sample_filename MATCHES "simd_")
    # disabled intentionally - demonstration purposes only
    #target_include_directories(${tgt} PRIVATE "${CMAKE_CURRENT_LIST_DIR}")
    #target_compile_definitions(${tgt} PRIVATE OPENCV_SIMD_CONFIG_HEADER=opencv_simd_config_custom.hpp)
    #target_compile_definitions(${tgt} PRIVATE OPENCV_SIMD_CONFIG_INCLUDE_DIR=1)
    #target_compile_options(${tgt} PRIVATE -mavx2)
  endif()
endforeach()
```

----------------------------------------

TITLE: Verifying Successful VideoCapture Opening in C++
DESCRIPTION: Illustrates how to use the `isOpened()` method of `cv::VideoCapture` to check if the video source (file or camera) was successfully opened. If not, it prints an error message to the console and suggests returning an error code (-1). Requires `<iostream>` and `<opencv2/videoio.hpp>` headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
if ( !captRefrnc.isOpened())
  {
  cout  << "Could not open reference " << sourceReference << endl;
  return -1;
  }
```

----------------------------------------

TITLE: Drawing Rotated Bounding Rectangle for Contours in Python with OpenCV
DESCRIPTION: This snippet demonstrates how to compute and draw a rotated bounding rectangle with minimum area for a contour using cv.minAreaRect(), cv.boxPoints(), and cv.drawContours() functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
rect = cv.minAreaRect(cnt)
box = cv.boxPoints(rect)
box = np.int0(box)
cv.drawContours(img,[box],0,(0,0,255),2)
```

----------------------------------------

TITLE: Acquiring Input Frames for Calibration from Camera/Video/List in C++
DESCRIPTION: This C++ snippet reference points to code within the main processing loop for camera calibration. It acquires the next input frame from the specified source (camera, video file, or image list) and optionally flips the image if required. It handles conditions where input fails or enough frames have been collected.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp get_input
```

----------------------------------------

TITLE: SIMD Source Files Configuration
DESCRIPTION: Sets up SIMD source files for compilation based on architecture (x86_64 or i386), including various optimized implementations for different instruction sets like SSE2 and AVX2
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
if(CPU_TYPE STREQUAL "x86_64")
  set(SIMD_SOURCES x86_64/jsimdcpu.asm x86_64/jfdctflt-sse.asm
    x86_64/jccolor-sse2.asm x86_64/jcgray-sse2.asm x86_64/jchuff-sse2.asm
    [...additional sources...])
else()
  set(SIMD_SOURCES i386/jsimdcpu.asm i386/jfdctflt-3dn.asm
    [...additional sources...])
endif()
```

----------------------------------------

TITLE: Executing OpenCV Annotation Tool Command
DESCRIPTION: This command initializes the OpenCV annotation tool, which is used for labeling images with object boundaries. It requires paths to the annotations file and image folder and optionally resizes images based on the provided parameters to facilitate easy annotation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/traincascade.markdown#2025-04-22_snippet_4

LANGUAGE: text
CODE:
```
opencv_annotation --annotations=/path/to/annotations/file.txt --images=/path/to/image/folder/
```

----------------------------------------

TITLE: Initializing Face Detector (FaceDetectorYN) - OpenCV DNN C++
DESCRIPTION: This snippet demonstrates how to initialize the cv::FaceDetectorYN object in C++ using pre-trained ONNX models. The constructor typically requires the detection model path, configuration, and detection parameters such as input size and score threshold. It depends on OpenCV's DNN and face module. The primary input is the model file, and the output is a ready-to-use detector object for running face detection on images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_face/dnn_face.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
// Initialize FaceDetectorYN
cv::Ptr<cv::FaceDetectorYN> detector = cv::FaceDetectorYN::create(
    modelPath,                   // Path to face detection .onnx model
    "",                          // No config file usually
    cv::Size(320, 320),          // Input size to the model
    /*scoreThreshold*/ 0.9,      // Detection score threshold
    /*nmsThreshold*/ 0.3,        // Non-max suppression threshold
    /*topK*/ 5000                // Maximum number of detections
);
```

----------------------------------------

TITLE: Computing Rotation Displacement Using OpenCV in Python
DESCRIPTION: This Python snippet computes rotation displacement between two image views using OpenCV. Dependencies are the OpenCV and NumPy packages. The expected input is the image pair and the result is a matrix detailing displacement.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_32

LANGUAGE: Python
CODE:
```
import cv2
import numpy as np

def compute_rotation_displacement(image1, image2):
    # Code to compute rotation displacement
    # ...

```

----------------------------------------

TITLE: Generating Build Files with CMake (Static Libs, Windows) (Batch)
DESCRIPTION: This Batch command runs CMake in the 'build' directory to generate a Visual Studio solution for building OpenCV on Windows. The '-DBUILD_SHARED_LIBS=OFF' option configures the build for static libraries. The '-G "Visual Studio 10"' specifies the generator for Visual Studio 2010 (adjust version as needed). The '..' indicates the source directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_2

LANGUAGE: bat
CODE:
```
cmake -DBUILD_SHARED_LIBS=OFF -G "Visual Studio 10" ..
```

----------------------------------------

TITLE: Generating Build Files with CMake (Static Libs, Unix) (Bash)
DESCRIPTION: This Bash command runs CMake in the 'build' directory to generate build files (e.g., Makefiles) for compiling OpenCV. The '-DBUILD_SHARED_LIBS=OFF' option configures the build for static libraries, meaning the Java bindings dynamic library will contain all necessary OpenCV code. The '..' indicates the source directory is the parent directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
cmake -DBUILD_SHARED_LIBS=OFF ..
```

----------------------------------------

TITLE: Cloning OpenCV Source from GitHub - Bash
DESCRIPTION: Clones the latest OpenCV source code from the official GitHub repository into a specified working directory. Requires git to be installed on the host system and network access to github.com. Replace <my_working_directory> with the desired workspace path. The command downloads the full repository for development and compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/arm_crosscompile_with_cmake.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
cd ~/<my_working _directory>
git clone https://github.com/opencv/opencv.git
```

----------------------------------------

TITLE: Setting Paths for Doxygen Configuration and Input Files in CMake
DESCRIPTION: Defines CMake variables storing paths to essential files and directories used in Doxygen configuration. This includes the Doxyfile output path, the root markdown file path, the main BibTeX file, FAQ markdown file, and paths for core tutorials (general, Python, JavaScript) and samples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
# additional config
set(doxyfile "${CMAKE_CURRENT_BINARY_DIR}/Doxyfile")
set(rootfile "${CMAKE_CURRENT_BINARY_DIR}/root.markdown")
set(bibfile "${CMAKE_CURRENT_SOURCE_DIR}/opencv.bib")
set(faqfile "${CMAKE_CURRENT_SOURCE_DIR}/faq.markdown")
set(tutorial_path "${CMAKE_CURRENT_SOURCE_DIR}/tutorials")
set(tutorial_py_path "${CMAKE_CURRENT_SOURCE_DIR}/py_tutorials")
set(CMAKE_DOXYGEN_TUTORIAL_JS_ROOT "- @ref tutorial_js_root")
set(tutorial_js_path "${CMAKE_CURRENT_SOURCE_DIR}/js_tutorials")
set(example_path "${CMAKE_SOURCE_DIR}/samples")
```

----------------------------------------

TITLE: Selecting Best Match Location Based on Method (C++)
DESCRIPTION: Determines the actual best match location (`matchLoc`) based on the template matching method used. For `TM_SQDIFF` and `TM_SQDIFF_NORMED`, the minimum location (`minLoc`) indicates the best match. For all other methods, the maximum location (`maxLoc`) represents the best match.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_31

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp match_loc
```

----------------------------------------

TITLE: Declaring Variables for Laplacian Demo in Java
DESCRIPTION: Declares necessary Java member variables for the LaplaceDemo class, including Mat objects for source, grayscale, and destination images, and a String for the window name. Requires OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_4

LANGUAGE: java
CODE:
```
//! [variables]
private Mat src, srcGray, dst, absDst;
private JFrame frame;
private JLabel imgLabel;
//! [variables]
```

----------------------------------------

TITLE: Installing CMake on Linux
DESCRIPTION: Command to install CMake build configuration tool on Linux using the package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
sudo apt-get install cmake
```

----------------------------------------

TITLE: Processing Camera Frames with OpenCV T-API
DESCRIPTION: C++ code demonstrating how to process camera frames using OpenCV's Transparent API (T-API). This approach uses UMat but requires copying data between OpenCL buffers and images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_11

LANGUAGE: C++
CODE:
```
// process_tapi
```

----------------------------------------

TITLE: Blending Images with OpenCV in Java
DESCRIPTION: This Java snippet demonstrates how to blend two images using OpenCV. The addWeighted() function is utilized to blend images. Both input images need to be of the same dimensions and format. Requires OpenCV library for Java.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/adding_images/adding_images.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
"@snippet java/tutorial_code/core/AddingImages/AddingImages.java load"
```

LANGUAGE: Java
CODE:
```
"@snippet java/tutorial_code/core/AddingImages/AddingImages.java blend_images"
```

LANGUAGE: Java
CODE:
```
"@snippet java/tutorial_code/core/AddingImages/AddingImages.java display"
```

----------------------------------------

TITLE: Saving an Image to File with OpenCV in C++
DESCRIPTION: Shows saving an image Mat to file using cv::imwrite in C++. Requires OpenCV. The function takes a filename and a Mat object, detecting format by file extension. Returns success as a boolean, and may fail if format is unsupported or path is invalid.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
cv::imwrite("my_image_copy.png", img);
```

----------------------------------------

TITLE: Copying Source Image in Callback (Java)
DESCRIPTION: Within the matching function (triggered by the trackbar), this snippet creates a copy of the original source image using `img.copyTo(img_display)`. Drawing the result rectangle on this copy prevents modification of the base image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_20

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java copy_source
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Algorithm Decision Tree in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm, which examines pixel values in a circular pattern around a candidate point. The nested conditionals compare pixel values at various offsets against threshold values (cb and c_b) to determine if a point is a corner, using goto statements to handle the branching logic.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_14

LANGUAGE: C++
CODE:
```
goto structured;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
                                if(ptr[offset8] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset3] > cb)
                                      goto success_structured;
                                    else
                                      if(ptr[offset10] > cb)
                                        goto success_structured;
                                      else
                                        goto structured;
                                  else
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto structured;
                                else
                                  goto structured;
                              else
                                goto structured;
                            else
                              goto structured;
                        else
                          if(ptr[offset3] < c_b)
                            if(ptr[offset4] < c_b)
                              if(ptr[offset5] < c_b)
                                if(ptr[offset1] < c_b)
                                  if(ptr[offset6] < c_b)
                                    goto success_structured;
                                  else
                                    if(ptr[offset11] < c_b)
                                      goto success_structured;
                                    else
                                      goto structured;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset7] < c_b)
                                      if(ptr[offset8] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto structured;
                                  else
                                    goto structured;
                              else
                                if(ptr[offset1] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      goto success_structured;
                                    else
                                      goto structured;
                                  else
                                    goto structured;
                                else
                                  goto structured;
                            else
                              goto structured;
                          else
                            goto structured;
                      else
                        if(ptr[offset9] < c_b)
                          if(ptr[offset5] < c_b)
                            if(ptr[offset1] < c_b)
                              if(ptr[offset6] < c_b)
                                if(ptr[offset3] < c_b)
                                  if(ptr[offset4] < c_b)
                                    goto success_structured;
                                  else
                                    if(ptr[offset10] < c_b)
                                      if(ptr[offset11] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto structured;
                                else
                                  if(ptr[offset8] < c_b)
                                    if(ptr[offset10] < c_b)
                                      if(ptr[offset11] < c_b)
                                        goto success_structured;
                                      else
                                        if(ptr[offset4] < c_b)
                                          if(ptr[offset7] < c_b)
                                            goto success_structured;
                                          else
                                            goto structured;
                                        else
                                          goto structured;
                                    else
                                      goto structured;
                                  else
                                    goto structured;
                              else
                                if(ptr[offset11] < c_b)
                                  if(ptr[offset3] < c_b)
                                    if(ptr[offset4] < c_b)
                                      goto success_structured;
                                    else
                                      if(ptr[offset10] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                  else
                                    if(ptr[offset8] < c_b)
                                      if(ptr[offset10] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto structured;
                                else
                                  goto structured;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset7] < c_b)
                                  if(ptr[offset8] < c_b)
                                    if(ptr[offset4] < c_b)
                                      if(ptr[offset3] < c_b)
                                        goto success_structured;
                                      else
                                        if(ptr[offset10] < c_b)
                                          goto success_structured;
                                        else
                                          goto structured;
                                    else
                                      if(ptr[offset10] < c_b)
                                        if(ptr[offset11] < c_b)
                                          goto success_structured;
                                        else
                                          goto structured;
                                      else
                                        goto structured;
                                  else
                                    goto structured;
                                else
                                  goto structured;
                              else
                                goto structured;
                          else
                            if(ptr[offset10] < c_b)
                              if(ptr[offset11] < c_b)
                                if(ptr[offset1] < c_b)
                                  if(ptr[offset3] < c_b)
                                    goto success_structured;
                                  else
                                    if(ptr[offset8] < c_b)
                                      goto success_structured;
                                    else
                                      goto structured;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset7] < c_b)
                                      if(ptr[offset8] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto structured;
                                  else
                                    goto structured;
                              else
                                goto structured;
                            else
                              goto structured;
                        else
                          if(ptr[offset3] < c_b)
                            if(ptr[offset4] < c_b)
                              if(ptr[offset5] < c_b)
                                if(ptr[offset1] < c_b)
                                  if(ptr[offset6] < c_b)
                                    goto success_structured;
                                  else
                                    if(ptr[offset11] < c_b)
                                      goto success_structured;
                                    else
                                      goto structured;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset7] < c_b)
                                      if(ptr[offset8] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto structured;
                                  else
                                    goto structured;
                              else
                                if(ptr[offset1] < c_b)
```

----------------------------------------

TITLE: Main Program: Loading a Mesh - OpenCV C++
DESCRIPTION: Demonstrates how to instantiate a Mesh object and load the mesh data using the load function in the main program. Requires a defined path to the PLY file for the mesh data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
Mesh mesh;                // instantiate Mesh object
mesh.load(ply_read_path); // load an object mesh

```

----------------------------------------

TITLE: Normalizing Arrays with cv.normalize in OpenCV.js
DESCRIPTION: Describes the `cv.normalize` function signature in OpenCV.js. This function normalizes the input array (`src`) to a specified range or norm, controlled by `alpha`, `beta`, and `norm_type`. It's often used to scale the output of functions like `cv.calcBackProject` for better visualization or further processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_histograms/js_histogram_backprojection/js_histogram_backprojection.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
cv.normalize (src, dst, alpha = 1, beta = 0, norm_type = cv.NORM_L2, dtype = -1, mask = new cv.Mat())

@param src        input array.
@param dst        output array of the same size as src .
@param alpha      norm value to normalize to or the lower range boundary in case of the range normalization.
@param beta       upper range boundary in case of the range normalization; it is not used for the norm normalization.
@param norm_type  normalization type (see cv.NormTypes).
@param dtype      when negative, the output array has the same type as src; otherwise, it has the same number of channels as src and the depth = CV_MAT_DEPTH(dtype).
@param mask       optional operation mask.
```

----------------------------------------

TITLE: Configuring OpenCV and CUDA Build Environment - CMake
DESCRIPTION: This CMake script initializes a build environment by enforcing CMake version 3.5 or higher, locating the CUDA toolkit and OpenCV library (requiring the core component), and setting the necessary include directories for both. It then uses CUDA_ADD_EXECUTABLE to compile a CUDA source file ('main.cu') into an executable named 'opencv_thrust' and links it with the found OpenCV libraries. Dependencies include a proper CUDA and OpenCV installation, and the script expects all source files and dependencies to be available in the build context. Outputs are the configured build target and linked binaries tailored for CUDA/OpenCV integration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/tutorial_code/gpu/gpu-thrust-interop/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
CMAKE_MINIMUM_REQUIRED(VERSION 3.5)

FIND_PACKAGE(CUDA REQUIRED)
INCLUDE_DIRECTORIES(${CUDA_INCLUDE_DIRS})

FIND_PACKAGE(OpenCV REQUIRED COMPONENTS core)
INCLUDE_DIRECTORIES(${OpenCV_INCLUDE_DIRS})

CUDA_ADD_EXECUTABLE(opencv_thrust main.cu)
TARGET_LINK_LIBRARIES(opencv_thrust ${OpenCV_LIBS})
```

----------------------------------------

TITLE: Building OpenCV Java JAR using Ant
DESCRIPTION: Configures and executes the Ant-based build process for the OpenCV Java JAR when OPENCV_JAVA_SDK_BUILD_TYPE is set to "ANT".
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jar/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
if(OPENCV_JAVA_SDK_BUILD_TYPE STREQUAL "ANT")
  file(MAKE_DIRECTORY "${OPENCV_JAVA_DIR}/build/classes")

  configure_file("${CMAKE_CURRENT_SOURCE_DIR}/build.xml.in" "${OPENCV_JAVA_DIR}/build.xml" @ONLY)
  list(APPEND depends "${OPENCV_JAVA_DIR}/build.xml")

  ocv_cmake_byproducts(__byproducts BYPRODUCTS "${OPENCV_JAR_FILE}")
  add_custom_command(OUTPUT "${OPENCV_DEPHELPER}/${the_module}_jar"
      ${__byproducts}  # required for add_custom_target() by ninja
      COMMAND ${ANT_EXECUTABLE} -noinput -k jar
      COMMAND ${CMAKE_COMMAND} -E touch "${OPENCV_DEPHELPER}/${the_module}_jar"
      WORKING_DIRECTORY "${OPENCV_JAVA_DIR}"
      DEPENDS ${depends}
      COMMENT "Generating ${JAR_NAME}"
  )
  add_custom_target(${the_module}_jar DEPENDS "${OPENCV_DEPHELPER}/${the_module}_jar")
```

----------------------------------------

TITLE: Setting TBB Target Properties and Installation Configuration
DESCRIPTION: Configures the TBB target properties including output names, debug postfixes, and output directories. Sets up the installation paths and license files for proper distribution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: CMake
CODE:
```
if (WIN32)
  set(tbb_debug_postfix "_debug") # to fit pragmas in _windef.h inside TBB
else()
  set(tbb_debug_postfix ${OPENCV_DEBUG_POSTFIX})
endif()

set_target_properties(tbb
  PROPERTIES OUTPUT_NAME tbb
  DEBUG_POSTFIX "${tbb_debug_postfix}"
  COMPILE_PDB_NAME tbb
  COMPILE_PDB_NAME_DEBUG "tbb${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
  RUNTIME_OUTPUT_DIRECTORY ${EXECUTABLE_OUTPUT_PATH}
  )

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(tbb PROPERTIES FOLDER "3rdparty")
endif()

ocv_install_target(tbb EXPORT OpenCVModules
    RUNTIME DESTINATION ${OPENCV_BIN_INSTALL_PATH} COMPONENT libs
    LIBRARY DESTINATION ${OPENCV_LIB_INSTALL_PATH} COMPONENT libs
    ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev
    OPTIONAL
    )

ocv_install_3rdparty_licenses(tbb "${tbb_src_dir}/LICENSE.txt" "${tbb_src_dir}/README.md")

ocv_tbb_read_version("${tbb_src_dir}/include" tbb)
```

----------------------------------------

TITLE: Loading Exposure Images to List using OpenCV Python
DESCRIPTION: Loads multiple exposure images into a list and stores exposure times needed for HDR processing. The images are loaded using OpenCV's `imread` function, and exposure times are stored in a numpy array with float32 type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_hdr/py_hdr.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np

# Loading exposure images into a list
img_fn = ["img0.jpg", "img1.jpg", "img2.jpg", "img3.jpg"]
img_list = [cv.imread(fn) for fn in img_fn]
exposure_times = np.array([15.0, 2.5, 0.25, 0.0333], dtype=np.float32)
```

----------------------------------------

TITLE: Executing Model Conversion Pipeline
DESCRIPTION: This console command runs the model conversion pipeline for ResNet-50 using a specific Python module. It automates the conversion process from PyTorch to ONNX and prepares the model for inference with OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_2

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_resnet50
```

----------------------------------------

TITLE: Loading Source Image in Java
DESCRIPTION: Java snippet demonstrating how to load an image from a file using OpenCV's `Imgcodecs.imread` function. The first command-line argument is expected to be the path to the image file. Includes error handling if the image cannot be loaded.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_4

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Load image
```

----------------------------------------

TITLE: Changing Image Type from 8UC1 to 32FC1 with OpenCV in C++
DESCRIPTION: Converts an 8-bit single-channel Mat to a 32-bit float single-channel Mat in C++. The astype method (cv::Mat::convertTo) performs conversion. May be needed for certain algorithms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_37

LANGUAGE: C++
CODE:
```
cv::Mat floatMat;\nimg.convertTo(floatMat, CV_32F);
```

----------------------------------------

TITLE: Updating Header Inclusions in OpenCV 3.0
DESCRIPTION: Shows how to replace the old module header inclusion pattern with the new simplified pattern in OpenCV 3.0.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
// old header
#include "opencv2/<module>/<module>.hpp"
// new header
#include "opencv2/<module>.hpp"
```

----------------------------------------

TITLE: Installing OpenCV Build Artifacts with CMake - Shell
DESCRIPTION: Performs the install step using CMake, copying all build artifacts to the configured installation prefix directory. Assumes that the project is already built and the configuration step has been completed. No elevated privileges are required if the install location is user-accessible.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_22

LANGUAGE: shell
CODE:
```
cmake --build . --target install
```

----------------------------------------

TITLE: Setting Histogram Value Range in Python
DESCRIPTION: Python snippet defining the range of pixel values for the histogram. A variable `histRange` is assigned a tuple `(0, 256)`, specifying the lower (inclusive) and upper (exclusive) bounds for the histogram calculation using `cv.calcHist`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_14

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Set the ranges ( for B,G,R) )
```

----------------------------------------

TITLE: Instantiating PSNR Buffer in C++
DESCRIPTION: Creates an instance named `bufferPSNR` of the `BufferPSNR` structure. This instance will be used to hold pre-allocated GPU memory buffers passed to optimized GPU functions, thereby reducing memory allocation overhead during repeated function calls.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_11

LANGUAGE: cpp
CODE:
```
BufferPSNR bufferPSNR;
```

----------------------------------------

TITLE: Writing and Reading Sequences (Lists/Arrays) - OpenCV Python
DESCRIPTION: This Python snippet demonstrates writing and reading lists (arrays) to XML/YAML/JSON using FileStorage. Use startWriteStruct() and endWriteStruct() to mark the structure, and write() for the value insertion. To read, use getNode() and at() or .size(). Requires opencv-python installed. Handles lists of numbers as commonly used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
fs.startWriteStruct('sequence', cv2.FileNode_SEQ)\nfs.write('', 1)\nfs.write('', 2)\nfs.write('', 3)\nfs.endWriteStruct()\n\nnode = fs.getNode('sequence')\nfor i in range(node.size()):\n    value = int(node.at(i).real())
```

----------------------------------------

TITLE: Implementing Erosion Operation in Java
DESCRIPTION: Performs erosion operation on an image in Java using OpenCV
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.markdown#2025-04-22_snippet_3

LANGUAGE: java
CODE:
```
private Mat erode(Mat source) {
    Mat element = getKernel();
    Mat imageWithMorphology = new Mat();
    Imgproc.erode(source, imageWithMorphology, element);
    return imageWithMorphology;
}
```

----------------------------------------

TITLE: Interactive Image Pyramid Loop in Python
DESCRIPTION: Implements an infinite loop that captures key presses using `cv.waitKey`. It performs image upsampling (`cv.pyrUp`) on 'i', downsampling (`cv.pyrDown`) on 'o', and breaks the loop on ESC. The modified image is displayed in each iteration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
    #![loop]
    tmp = src
    dst = tmp

    while True:
        cv.imshow(window_name, dst)
        c = cv.waitKey(0)

        if c == 27:
            break
        elif c == ord('i'):
            dst = cv.pyrUp(tmp)
            print ('** Zoom In: Image x 2')
        elif c == ord('o'):
            dst = cv.pyrDown(tmp)
            print ('** Zoom Out: Image / 2')

        tmp = dst
    #![loop]

    cv.destroyAllWindows()
    return 0
```

----------------------------------------

TITLE: Binary Search for Corner Score Threshold in AGAST Algorithm
DESCRIPTION: This code segment implements a binary search algorithm to determine the optimal threshold for corner detection. It calculates the threshold value based on the intensity differences between neighboring pixels, returning the final threshold when the binary search converges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_43

LANGUAGE: C++
CODE:
```
        is_a_corner:
            bmin = b_test;
            goto end;

        is_not_a_corner:
            bmax = b_test;
            goto end;

        end:

        if(bmin == bmax - 1 || bmin == bmax)
            return bmin;
        b_test = (bmin + bmax) / 2;
    }
}
```

----------------------------------------

TITLE: Setting OpenCV Java Library Properties in CMake
DESCRIPTION: Configures additional properties for the OpenCV Java library target, including output names, directories, and export symbols.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jni/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
set_target_properties(${the_module} PROPERTIES
    OUTPUT_NAME "${the_module}${OPENCV_JAVA_LIB_NAME_SUFFIX}"
    ARCHIVE_OUTPUT_DIRECTORY ${LIBRARY_OUTPUT_PATH}
    LIBRARY_OUTPUT_DIRECTORY ${JNI_OUTPUT_PATH}
    RUNTIME_OUTPUT_DIRECTORY ${EXECUTABLE_OUTPUT_PATH}
    DEFINE_SYMBOL CVAPI_EXPORTS
    )
```

----------------------------------------

TITLE: Extracting Rotational Component Using OpenCV in Python
DESCRIPTION: This snippet demonstrates extracting the rotational component from two images captured by a rotating camera using the OpenCV library in Python. Prerequisites include installed libraries of OpenCV and NumPy. Inputs are image views and the result is the rotational component.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_29

LANGUAGE: Python
CODE:
```
import cv2
import numpy as np

def extract_rotation(image1, image2):
    # Code to extract rotation component
    # ...

```

----------------------------------------

TITLE: Configuring OpenVINO™ Network Parameters in G-API
DESCRIPTION: Demonstrates how to configure network parameters for multiple neural networks using cv::gapi::ie::Params structures. Sets up detection, age and emotion networks with paths to model files and target device.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
auto det_net = cv::gapi::ie::Params{
    cmd.get<std::string>("fdm"),
    cmd.get<std::string>("fdw"),
    cmd.get<std::string>("dev")
};
auto age_net = cv::gapi::ie::Params{
    cmd.get<std::string>("agm"),
    cmd.get<std::string>("agw"),
    cmd.get<std::string>("dev")
};
auto emo_net = cv::gapi::ie::Params{
    cmd.get<std::string>("em"),
    cmd.get<std::string>("ew"),
    cmd.get<std::string>("dev")
};
```

----------------------------------------

TITLE: Storing Output Variables for Barcode Detection
DESCRIPTION: This snippet shows how to create variables for storing the output results of barcode detection. These variables will be used to store corners and other detection-related data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/barcode_detect_and_decode.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
@snippet cpp/barcode.cpp output
```

----------------------------------------

TITLE: Capturing and Visualizing Orbbec UVC Depth and Color Images - OpenCV Python
DESCRIPTION: This snippet demonstrates how to use OpenCV in Python to open an Orbbec UVC depth sensor, capture BGR and depth images, normalize and apply a false color map to the depth image, and display both streams in separate windows. Dependencies include OpenCV (cv2) built with Orbbec support on the target platform. The camera is opened with VideoCapture, frames are grabbed and retrieved using dedicated image types, and the process runs in a loop until a keypress event, after which resources are released.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_uvc.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
# Open Orbbec Depth Sensor\norbbec_cap = cv.VideoCapture(0, cv.CAP_OBSENSOR)\nif not orbbec_cap.isOpened():\n    print('Cannot open Orbbec depth sensor!')\n    exit(-1)\n\nwhile True:\n    if not orbbec_cap.grab():\n        continue\n\n    bgr_image = orbbec_cap.retrieve(None, cv.CAP_OBSENSOR_BGR_IMAGE)[1]\n    if bgr_image is not None:\n        cv.imshow('BGR', bgr_image)\n\n    depth_image = orbbec_cap.retrieve(None, cv.CAP_OBSENSOR_DEPTH_MAP)[1]\n    if depth_image is not None:\n        min_depth = 300\n        max_depth = 5000\n        depth_image = np.clip(depth_image, min_depth, max_depth)\n        norm_depth_map = np.uint8(255 * (depth_image - min_depth) / (max_depth - min_depth))\n        color_depth_map = cv.applyColorMap(norm_depth_map, cv.COLORMAP_JET)\n        cv.imshow('DEPTH', color_depth_map)\n\n    if cv.pollKey() >= 0:\n        break\n\norbbec_cap.release()
```

----------------------------------------

TITLE: Configuring Java Support in OpenCV CMake
DESCRIPTION: Sets up Java support for OpenCV, handling different scenarios for Android and non-Android builds. It detects required tools like Apache Ant, Java SDK, and JNI.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: CMake
CODE:
```
if(BUILD_JAVA)
  if(ANDROID)
    include(cmake/android/OpenCVDetectAndroidSDK.cmake)
  else()
    include(cmake/OpenCVDetectApacheAnt.cmake)
    if(ANT_EXECUTABLE AND NOT OPENCV_JAVA_IGNORE_ANT)
      ocv_update(OPENCV_JAVA_SDK_BUILD_TYPE "ANT")
    elseif(NOT ANDROID)
      find_package(Java)
      if(Java_FOUND)
        include(UseJava)
        ocv_update(OPENCV_JAVA_SDK_BUILD_TYPE "JAVA")
      endif()
    endif()
    find_package(JNI)
  endif()
endif()
```

----------------------------------------

TITLE: Saving an Image to File with OpenCV in Python
DESCRIPTION: Displays saving an image to file with OpenCV's cv2.imwrite in Python. Needs opencv-python installed. Arguments are filename and image ndarray. The datatype and shape of img must correspond to standard image expectations for the output format.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
cv2.imwrite('my_image_copy.png', img)
```

----------------------------------------

TITLE: Applying BackgroundSubtractor to Extract Foreground Mask
DESCRIPTION: Processes each frame to generate a foreground mask and updates the background model. The learning rate parameter can be adjusted to control how quickly the background model adapts to changes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/background_subtraction.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
//update the background model
pBackSub->apply(frame, fgMask);
```

LANGUAGE: Java
CODE:
```
// update the background model
backSub.apply(frame, fgMask);
```

LANGUAGE: Python
CODE:
```
# Update the background model
fgMask = backSub.apply(frame)
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Logic in C++
DESCRIPTION: This code snippet is a part of the FAST corner detection algorithm. It contains nested conditional statements comparing pixel values at different offsets to determine if a point is a corner. The algorithm uses goto statements to navigate through different cases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_7

LANGUAGE: C++
CODE:
```
else
  goto structured;
else
  goto homogeneous;
else
  goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset6] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset4] > cb)
            goto success_structured;
          else
            if(ptr[offset11] > cb)
              goto success_structured;
            else
              goto structured;
        else
          if(ptr[offset3] > cb)
            if(ptr[offset4] > cb)
              goto success_structured;
            else
              goto structured;
          else
            goto homogeneous;
      else
        goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  if(ptr[offset6] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset3] > cb)
            goto success_structured;
          else
            if(ptr[offset10] > cb)
              goto success_structured;
            else
              goto homogeneous;
        else
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto success_structured;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  if(ptr[offset3] < c_b)
    if(ptr[offset4] < c_b)
      if(ptr[offset5] < c_b)
        if(ptr[offset1] < c_b)
          if(ptr[offset6] < c_b)
            goto success_homogeneous;
          else
            if(ptr[offset11] < c_b)
              goto success_homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset7] < c_b)
              if(ptr[offset8] < c_b)
                goto success_structured;
              else
                goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto success_homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  if(ptr[offset9] < c_b)
    if(ptr[offset5] < c_b)
      if(ptr[offset1] < c_b)
        if(ptr[offset6] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              goto success_homogeneous;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto success_structured;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset8] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset4] < c_b)
                    if(ptr[offset7] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset11] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset4] < c_b)
                goto success_homogeneous;
              else
                if(ptr[offset10] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            goto homogeneous;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset7] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
    else
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset3] < c_b)
              goto success_homogeneous;
            else
              if(ptr[offset8] < c_b)
                goto success_homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset8] < c_b)
                  goto success_homogeneous;
```

----------------------------------------

TITLE: Including a Whole Example File - Doxygen Markup
DESCRIPTION: Demonstrates including an entire source code file in documentation using @include. The file path is resolved by doxygen according to configured search paths. Input is relative file path; output is the referenced file's content embedded and formatted in output documentation. Line numbers can be included using @includelineno.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_11

LANGUAGE: markdown
CODE:
```
@include samples/cpp/test.cpp
```

----------------------------------------

TITLE: Adding YouTube Video to OpenCV Documentation
DESCRIPTION: Shows how to embed a YouTube video in OpenCV documentation using the _youtube_ command. This snippet demonstrates the syntax for including a video with its unique identifier.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_19

LANGUAGE: markdown
CODE:
```
@youtube{ViPN810E0SU}
```

----------------------------------------

TITLE: Defining CMake Macro for Remapping Configuration Files (`ocv_remap_files`)
DESCRIPTION: Defines a CMake macro `ocv_remap_files` that processes a list of input files. For each file ending with `.in`, it uses `configure_file` to substitute variables and generates an output file in a common `${OpenCV_BINARY_DIR}/configured` directory, preserving the relative path. It maintains internal lists (`__remap_config`, `__remap_targets`) to track the source-to-target mappings (for JSON configuration) and the generated target files (for dependencies).
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/generator/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
set(__remap_config "") # list of remapped ".in" files (configure_file)
set(__remap_targets "")

macro(ocv_remap_files files_list_var)
  set(target_dir "${OpenCV_BINARY_DIR}/configured")
  foreach(f ${${files_list_var}})
    if(NOT "${f}" MATCHES "^(.*)\\.in$")
      #continue()  # since CMake 3.2+
    else()
    set(f_ "${CMAKE_MATCH_1}")
    file(RELATIVE_PATH rel_path0 "${OpenCV_SOURCE_DIR}" "${f}")
    file(RELATIVE_PATH rel_path1 "${OpenCV_SOURCE_DIR}" "${f_}")
    set(__target_file "${target_dir}/${rel_path1}")
    configure_file("${f}" "${__target_file}" @ONLY)
    if(__remap_config)
      set(__remap_config "${__remap_config},\\n")
    endif()
    set(__remap_config "${__remap_config}    { \"src\": \"${rel_path0}\", \"target\": \"${__target_file}\" }")
    list(APPEND __remap_targets "${__target_file}")
    endif()
  endforeach()
endmacro()
```

----------------------------------------

TITLE: Generating Default Progressive JPEG Scan Script (C)
DESCRIPTION: This function generates a default scan script for writing a progressive-JPEG file. It's the recommended method for creating a progressive file unless a custom scan sequence is needed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_28

LANGUAGE: C
CODE:
```
jpeg_simple_progression (j_compress_ptr cinfo)
```

----------------------------------------

TITLE: Applying GaussianBlur in Clojure REPL using OpenCV
DESCRIPTION: Applies a GaussianBlur to the source image stored in 'lena' and outputs the blurred image into the 'blurred' variable, with a kernel size of 5x5.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_24

LANGUAGE: Clojure
CODE:
```
user=> (Imgproc/GaussianBlur lena blurred (Size. 5 5) 3 3)
nil
```

----------------------------------------

TITLE: Writing Scanlines in JPEG Compression Cycle in C
DESCRIPTION: This snippet demonstrates how to write image data scanlines in a JPEG compression cycle using 'jpeg_write_scanlines'. A loop iterates over each scanline, passing it to the compressor. The snippet includes examples for handling various data precisions using 'jpeg12_write_scanlines' or 'jpeg16_write_scanlines'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_7

LANGUAGE: C
CODE:
```
JSAMPROW row_pointer[1];
while (cinfo.next_scanline < cinfo.image_height) {
    row_pointer[0] = image_buffer[cinfo.next_scanline];
    jpeg_write_scanlines(&cinfo, row_pointer, 1);
}
```

----------------------------------------

TITLE: Implementing Basic Histogram Equalization with NumPy and OpenCV
DESCRIPTION: This code demonstrates how to visualize the histogram and cumulative distribution function (CDF) of an image using NumPy and Matplotlib, preparing for histogram equalization. It loads a grayscale image, calculates its histogram and CDF, then plots both to analyze the pixel value distribution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_equalization/py_histogram_equalization.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('wiki.jpg', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"

hist,bins = np.histogram(img.flatten(),256,[0,256])

cdf = hist.cumsum()
cdf_normalized = cdf * float(hist.max()) / cdf.max()

plt.plot(cdf_normalized, color = 'b')
plt.hist(img.flatten(),256,[0,256], color = 'r')
plt.xlim([0,256])
plt.legend(('cdf','histogram'), loc = 'upper left')
plt.show()
```

----------------------------------------

TITLE: Installing Prerequisite Development Packages for OpenCV - Shell
DESCRIPTION: These shell commands install all the Linux dependencies required to build OpenCV with CUDA support on Ubuntu systems. The commands cover enabling the universe repository, updating package lists, and installing package groups for core libraries, GUI, codecs, and optional Python bindings for both Python 2 and Python 3. Key parameters include the package names and the usage of continuation characters for easier shell script readability. The expected outcome is a system ready to configure and compile OpenCV from source.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
$ sudo apt-add-repository universe
$ sudo apt-get update
```

LANGUAGE: shell
CODE:
```
$ sudo apt-get install \
    libglew-dev \
    libtiff5-dev \
    zlib1g-dev \
    libjpeg-dev \
    libpng12-dev \
    libjasper-dev \
    libavcodec-dev \
    libavformat-dev \
    libavutil-dev \
    libpostproc-dev \
    libswscale-dev \
    libeigen3-dev \
    libtbb-dev \
    libgtk2.0-dev \
    pkg-config
```

LANGUAGE: shell
CODE:
```
$ sudo apt-get install python-dev python-numpy python-py python-pytest
# And, optionally:
$ sudo apt-get install python3-dev python3-numpy python3-py python3-pytest
```

----------------------------------------

TITLE: Checking Image Generator Presence
DESCRIPTION: Code to verify if the depth sensor has an image generator capability.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/kinect_openni.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
bool isImageGeneratorPresent = capture.get( CAP_PROP_OPENNI_IMAGE_GENERATOR_PRESENT ) != 0; // or == 1
```

----------------------------------------

TITLE: Formatting CMake Lists into Doxygen Configuration Strings
DESCRIPTION: Converts several CMake lists (containing paths for input files, images, excluded files, example files, include roots) into space or newline-separated strings suitable for Doxygen configuration variables (`CMAKE_DOXYGEN_INPUT_LIST`, `CMAKE_DOXYGEN_IMAGE_PATH`, `CMAKE_DOXYGEN_EXCLUDE_LIST`, `CMAKE_DOXYGEN_EXAMPLE_PATH`, `CMAKE_DOXYGEN_INCLUDE_ROOTS`). It also formats the list of enabled sections and sets variables for the Doxygen layout file, output path, module references, BibTeX files, and QHP generation based on a CMake option.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
# set export variables
string(REPLACE ";" " \\\n" CMAKE_DOXYGEN_INPUT_LIST "${rootfile} ; ${faqfile} ; ${paths_include} ; ${paths_hal_interface} ; ${paths_doc} ; ${tutorial_path} ; ${tutorial_py_path} ; ${tutorial_js_path} ; ${paths_tutorial} ; ${tutorial_contrib_root}")
string(REPLACE ";" " \\\n" CMAKE_DOXYGEN_IMAGE_PATH "${doxygen_image_path}")
string(REPLACE ";" " \\\n" CMAKE_DOXYGEN_EXCLUDE_LIST "${CMAKE_DOXYGEN_EXCLUDE_LIST}")
string(REPLACE ";" " " CMAKE_DOXYGEN_ENABLED_SECTIONS "${CMAKE_DOXYGEN_ENABLED_SECTIONS}")
# TODO: remove paths_doc from EXAMPLE_PATH after face module tutorials/samples moved to separate folders
string(REPLACE ";" " \\\n" CMAKE_DOXYGEN_EXAMPLE_PATH  "${example_path} ; ${paths_doc} ; ${paths_sample}")
string(REPLACE ";" " \\\n" CMAKE_DOXYGEN_INCLUDE_ROOTS "${paths_include}")
set(CMAKE_DOXYGEN_LAYOUT "${CMAKE_CURRENT_BINARY_DIR}/DoxygenLayout.xml")
set(CMAKE_DOXYGEN_OUTPUT_PATH "doxygen")
set(CMAKE_DOXYGEN_MAIN_REFERENCE "${refs_main}")
set(CMAKE_DOXYGEN_EXTRA_REFERENCE "${refs_extra}")
set(CMAKE_EXTRA_BIB_FILES "${bibfile} ${paths_bib}")
if (CMAKE_DOXYGEN_GENERATE_QHP)
  set(CMAKE_DOXYGEN_GENERATE_QHP "YES")
else()
  set(CMAKE_DOXYGEN_GENERATE_QHP "NO")
endif()
```

----------------------------------------

TITLE: Installing Dependency Libraries on Target
DESCRIPTION: Install runtime library dependencies for OpenCV on the target system through apt. It includes libraries necessary for multimedia tasks and text rendering.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_21

LANGUAGE: bash
CODE:
```
sudo apt install -y \
    libavcodec60 \
    libavformat60 \
    libavutil58 \
    libswscale7 \
    libfreetype6 \
    libharfbuzz0b

sudo ldconfig
```

----------------------------------------

TITLE: Creating Abstract Base Renderer for Camera Preview (OpenGL/Camera Integration) - Java
DESCRIPTION: This abstract Java class serves as a base renderer for both Camera and Camera2 APIs in an Android OpenGL camera preview application. It manages camera resource handling, texture update logic, and integrates with GLSurfaceView and SurfaceTexture listeners. Implementations must define camera-specific behaviors; the class is critical for integrating Java rendering logic and facilitating JNI OpenGL interoperability.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_6

LANGUAGE: java
CODE:
```
public abstract class MyGLRendererBase implements GLSurfaceView.Renderer, SurfaceTexture.OnFrameAvailableListener {\n    protected final String LOGTAG = "MyGLRendererBase";\n\n    protected SurfaceTexture mSTex;\n    protected MyGLSurfaceView mView;\n\n    protected boolean mGLInit = false;\n    protected boolean mTexUpdate = false;\n\n    MyGLRendererBase(MyGLSurfaceView view) {\n        mView = view;\n    }\n\n    protected abstract void openCamera();\n    protected abstract void closeCamera();\n    protected abstract void setCameraPreviewSize(int width, int height);\n\n    public void onResume() {\n        Log.i(LOGTAG, "onResume");\n    }\n\n    public void onPause() {\n        Log.i(LOGTAG, "onPause");\n        mGLInit = false;\n        mTexUpdate = false;\n        closeCamera();\n        if(mSTex != null) {\n            mSTex.release();\n            mSTex = null;\n            NativeGLRenderer.closeGL();\n        }\n    }\n\n    @Override\n    public synchronized void onFrameAvailable(SurfaceTexture surfaceTexture) {\n        //Log.i(LOGTAG, "onFrameAvailable");\n        mTexUpdate = true;\n        mView.requestRender();\n    }\n\n    @Override\n    public void onDrawFrame(GL10 gl) {\n        //Log.i(LOGTAG, "onDrawFrame");\n        if (!mGLInit)\n            return;\n\n        synchronized (this) {\n            if (mTexUpdate) {\n                mSTex.updateTexImage();\n                mTexUpdate = false;
```

----------------------------------------

TITLE: Verifying OpenCV-Python Installation
DESCRIPTION: Python code to verify successful installation of OpenCV-Python by importing the library and checking its version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
>>> import cv2 as cv
>>> print( cv.__version__ )
```

----------------------------------------

TITLE: Saving Processed Image with OpenCV in Clojure
DESCRIPTION: Writes the processed blurred image to a file named 'blurred.png', using OpenCV's imwrite method, and confirms the operation with a true value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_25

LANGUAGE: Clojure
CODE:
```
user=> (Highgui/imwrite "resources/images/blurred.png" blurred)
true
user=> (exit)
```

----------------------------------------

TITLE: Generating Symmetric Circle Grid Pattern using Python Script (Shell)
DESCRIPTION: Runs the 'gen_pattern.py' script to generate a symmetric circle grid pattern ('circles') saved as 'circleboard.svg'. The grid has 7 rows and 5 columns, with a circle radius equivalent to a square size of 15mm (radius = square_size / 2). Requires Python and the 'gen_pattern.py' script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_pattern/camera_calibration_pattern.markdown#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
python gen_pattern.py -o circleboard.svg --rows 7 --columns 5 --type circles --square_size 15
```

----------------------------------------

TITLE: Implementing Custom Corner Detectors in C++
DESCRIPTION: C++ implementation of custom Harris and Shi-Tomasi corner detectors using OpenCV functions. Includes file handling, image processing, and visualization of results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/generic_corner_detector/generic_corner_detector.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <iostream>\n#include <stdio.h>\n#include <stdlib.h>\n#include <opencv2/highgui.hpp>\n#include <opencv2/imgproc.hpp>\n\nusing namespace cv;\nusing namespace std;\n\nMat src, src_gray;\nMat myHarris_dst, myHarris_copy, Mc;\nMat myShiTomasi_dst, myShiTomasi_copy;\n\nint myShiTomasi_qualityLevel = 50;\nint myHarris_qualityLevel = 50;\nint max_qualityLevel = 100;\n\ndouble myHarris_minVal, myHarris_maxVal;\ndouble myShiTomasi_minVal, myShiTomasi_maxVal;\n\nRNG rng(12345);\n\nconst char* myHarris_window = "My Harris corner detector";\nconst char* myShiTomasi_window = "My Shi Tomasi corner detector";\n\nvoid myShiTomasi_function( int, void* );\nvoid myHarris_function( int, void* );\n\nint main( int argc, char** argv )\n{\n    CommandLineParser parser( argc, argv, "{@input | pic3.png | input image}" );\n    src = imread( samples::findFile( parser.get<String>( "@input" ) ) );\n    if ( src.empty() )\n    {\n        cout << "Could not open or find the image!\n" << endl;\n        cout << "Usage: " << argv[0] << " <Input image>" << endl;\n        return -1;\n    }\n\n    cvtColor( src, src_gray, COLOR_BGR2GRAY );\n\n    int blockSize = 3, apertureSize = 3;\n\n    cornerEigenValsAndVecs( src_gray, myHarris_dst, blockSize, apertureSize, BORDER_DEFAULT );\n\n    /* calculate Mc */\n    Mc = Mat( src_gray.size(), CV_32FC1 );\n    for( int j = 0; j < src_gray.rows; j++ )\n    {\n        for( int i = 0; i < src_gray.cols; i++ )\n        {\n            float lambda_1 = myHarris_dst.at<Vec6f>(j, i)[0];\n            float lambda_2 = myHarris_dst.at<Vec6f>(j, i)[1];\n            Mc.at<float>(j,i) = lambda_1*lambda_2 - 0.04f*pow( ( lambda_1 + lambda_2 ), 2 );\n        }\n    }\n\n    minMaxLoc( Mc, &myHarris_minVal, &myHarris_maxVal, 0, 0, Mat() );\n\n    /* Create Window and Trackbar */\n    namedWindow( myHarris_window );\n    createTrackbar( "Quality Level:", myHarris_window, &myHarris_qualityLevel, max_qualityLevel, myHarris_function );\n    myHarris_function( 0, 0 );\n\n    cornerMinEigenVal( src_gray, myShiTomasi_dst, blockSize, apertureSize, BORDER_DEFAULT );\n\n    minMaxLoc( myShiTomasi_dst, &myShiTomasi_minVal, &myShiTomasi_maxVal, 0, 0, Mat() );\n\n    /* Create Window and Trackbar */\n    namedWindow( myShiTomasi_window );\n    createTrackbar( "Quality Level:", myShiTomasi_window, &myShiTomasi_qualityLevel, max_qualityLevel, myShiTomasi_function );\n    myShiTomasi_function( 0, 0 );\n\n    waitKey();\n    return 0;\n}\n\nvoid myShiTomasi_function( int, void* )\n{\n    myShiTomasi_copy = src.clone();\n    myShiTomasi_qualityLevel = MAX(myShiTomasi_qualityLevel, 1);\n\n    for( int j = 0; j < src_gray.rows; j++ )\n    {\n        for( int i = 0; i < src_gray.cols; i++ )\n        {\n            if( myShiTomasi_dst.at<float>(j,i) > myShiTomasi_minVal + ( myShiTomasi_maxVal - myShiTomasi_minVal )*myShiTomasi_qualityLevel/max_qualityLevel )\n            {\n                circle( myShiTomasi_copy, Point(i,j), 4, Scalar( rng.uniform(0,255), rng.uniform(0,255), rng.uniform(0,255) ), FILLED );\n            }\n        }\n    }\n    imshow( myShiTomasi_window, myShiTomasi_copy );\n}\n\nvoid myHarris_function( int, void* )\n{\n    myHarris_copy = src.clone();\n    myHarris_qualityLevel = MAX(myHarris_qualityLevel, 1);\n\n    for( int j = 0; j < src_gray.rows; j++ )\n    {\n        for( int i = 0; i < src_gray.cols; i++ )\n        {\n            if( Mc.at<float>(j,i) > myHarris_minVal + ( myHarris_maxVal - myHarris_minVal )*myHarris_qualityLevel/max_qualityLevel )\n            {\n                circle( myHarris_copy, Point(i,j), 4, Scalar( rng.uniform(0,255), rng.uniform(0,255), rng.uniform(0,255) ), FILLED );\n            }\n        }\n    }\n    imshow( myHarris_window, myHarris_copy );\n}
```

----------------------------------------

TITLE: Perspective Projection Model Matrix Equation
DESCRIPTION: Mathematical representation of the perspective projection model showing how 3D world points are projected into 2D image coordinates using camera intrinsic parameters and transformation matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/calib3d/doc/solvePnP.markdown#2025-04-22_snippet_0

LANGUAGE: Mathematical Notation
CODE:
```
\begin{bmatrix}
u \\
v \\
1
\end{bmatrix} =
\bf{A} \hspace{0.1em} \Pi \hspace{0.2em} ^{c}\bf{T}_w
\begin{bmatrix}
X_{w} \\
Y_{w} \\
Z_{w} \\
1
\end{bmatrix}
```

----------------------------------------

TITLE: Initializing Kalman Filter for Pose Estimation in C++
DESCRIPTION: Provides a setup for a Kalman Filter to reject poor pose estimates, by defining its state vector, measurement count, and control actions, and initializing with a specified timeframe in C++.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_21

LANGUAGE: cpp
CODE:
```
cv::KalmanFilter KF;         // instantiate Kalman Filter

int nStates = 18;            // the number of states
int nMeasurements = 6;       // the number of measured states
int nInputs = 0;             // the number of action control

double dt = 0.125;           // time between measurements (1/FPS)

initKalmanFilter(KF, nStates, nMeasurements, nInputs, dt);    // init function
```

----------------------------------------

TITLE: Embedding Histogram Calculation Example with HTML Iframe
DESCRIPTION: This HTML snippet uses an iframe to embed an interactive example demonstrating histogram calculation (`cv.calcHist`) from an external HTML file ('../../js_histogram_begins_calcHist.html'). The iframe's height is dynamically adjusted based on the loaded content's scroll height using JavaScript within the `onload` event.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_histograms/js_histogram_begins/js_histogram_begins.markdown#2025-04-22_snippet_0

LANGUAGE: html
CODE:
```
\htmlonly
<iframe src="../../js_histogram_begins_calcHist.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
\endhtmlonly
```

----------------------------------------

TITLE: Generating Non-Linearly Separable Training Data for SVM (Java)
DESCRIPTION: Java implementation for creating training data with overlapping classes that cannot be separated linearly. This shows how to add points that would require non-linear decision boundaries in an SVM.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_5

LANGUAGE: Java
CODE:
```
// Set up the non-linearly separable part of the training data
float FRAC_LINEAR_SEP = 0.9f; // Fraction of the training samples which will be linearly separable
int trainingSamplesToAdd = (int) (2 * NTRAINING_SAMPLES * (1 - FRAC_LINEAR_SEP));
Mat extraTrainData = new Mat(trainingSamplesToAdd, 2, CvType.CV_32FC1);
Mat extraTrainLabels = new Mat(trainingSamplesToAdd, 1, CvType.CV_32SC1);
Random rng2 = new Random(100);

// Generate extra non-linearly separable points
for (int i = 0; i < trainingSamplesToAdd; i++) {
    int clsIdx = i % 2;
    float x = rng2.nextFloat();
    float y = rng2.nextFloat();
    extraTrainData.put(i, 0, x);
    extraTrainData.put(i, 1, y);
    extraTrainLabels.put(i, 0, labels[clsIdx]);
}

// Merge all the training data
Mat completeTrainData = new Mat();
Mat completeTrainLabels = new Mat();
Core.vconcat(Arrays.asList(trainData, extraTrainData), completeTrainData);
Core.vconcat(Arrays.asList(trainLabels, extraTrainLabels), completeTrainLabels);
```

----------------------------------------

TITLE: Performing Template Matching Operation (C++)
DESCRIPTION: Calls the core OpenCV function `cv::matchTemplate` to perform the template matching. It passes the source image (`img`), template (`templ`), result matrix (`result`), the selected match method (`match_method`), and the optional mask (`mask`). The size of the result matrix is calculated beforehand.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_22

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp match_template
```

----------------------------------------

TITLE: Checking OpenCV Version for Cross-Version Compatibility
DESCRIPTION: Shows how to check the OpenCV library version in source code to conditionally support both version 2 and 3 in the same codebase.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
#include "opencv2/core/version.hpp"
#if CV_MAJOR_VERSION == 2
// do opencv 2 code
#elif CV_MAJOR_VERSION == 3
// do opencv 3 code
#endif
```

----------------------------------------

TITLE: Defining an Ant Build Script for Java OpenCV Application (XML)
DESCRIPTION: This represents the content of a `build.xml` file used by Apache Ant to compile and run a Java application using OpenCV. It defines project properties (like source/build directories), classpath (including the OpenCV JAR), compilation tasks, and execution tasks (setting the `java.library.path` for the native OpenCV library). Specific paths to the OpenCV JAR (`ocvJarDir`) and native library directory (`ocvLibDir`) are expected as properties.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_6

LANGUAGE: xml
CODE:
```
@include samples/java/ant/build.xml
```

----------------------------------------

TITLE: Command Line Parameters for ArUco Calibration in OpenCV
DESCRIPTION: This code snippet shows the command line parameters for running the ArUco board calibration example. It includes parameters for the output calibration file, board dimensions, marker length, marker separation, dictionary ID, and input video or image path.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_calibration/aruco_calibration.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
"camera_calib.txt" -w=5 -h=7 -l=100 -s=10 -d=10 -v=path/aruco_videos_or_images
```

----------------------------------------

TITLE: Establishing Histogram Bin Count in Python
DESCRIPTION: Python snippet defining the number of bins for the histogram calculation. A variable `histSize` is assigned an integer value (e.g., 256), which will be used as the number of bins when calling `cv.calcHist`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_11

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Establish the number of bins
```

----------------------------------------

TITLE: SVM Optimization with Misclassification
DESCRIPTION: Final optimization formula including both margin maximization and misclassification error minimization with slack variables.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_svm/py_svm_basics/py_svm_basics.markdown#2025-04-22_snippet_3

LANGUAGE: latex
CODE:
```
\min_{w, b_{0}} L(w,b_0) = ||w||^{2} + C \sum_{i} {\xi_{i}} \text{ subject to } y_{i}(w^{T} x_{i} + b_{0}) \geq 1 - \xi_{i} \text{ and } \xi_{i} \geq 0 \text{ } \forall i
```

----------------------------------------

TITLE: Displaying Result Image in Java
DESCRIPTION: Updates the JLabel (`imgLabel`) within a JFrame (`frame`) to display the final absolute Laplacian image (`absDst`). This snippet assumes the necessary Swing GUI components have been set up elsewhere in the class.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_22

LANGUAGE: java
CODE:
```
//! [display]
/// Show image
Image img = HighGui.toBufferedImage(absDst);
ImageIcon icon = new ImageIcon(img);
imgLabel.setIcon(icon);
//! [display]
```

----------------------------------------

TITLE: Creating Build Directory for OpenCV on macOS
DESCRIPTION: These commands create a temporary build directory for OpenCV and navigate into it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
mkdir build_opencv
cd build_opencv
```

----------------------------------------

TITLE: Reading Image with OpenCV in Clojure REPL
DESCRIPTION: Initializes and reads an image file into a Mat object using OpenCV's imread function. The image is stored as a 512x512 matrix of CV_8UC3 elements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_22

LANGUAGE: Clojure
CODE:
```
user=> (def lena (Highgui/imread "resources/images/lena.png"))
#'user/lena
user=> lena
#<Mat Mat [ 512*512*CV_8UC3, isCont=true, isSubmat=false, nativeObj=0x7f9ab3054c40, dataAddr=0x19fea9010 ]>
```

----------------------------------------

TITLE: Defining the TBB Library Target with Compiler Settings
DESCRIPTION: Creates the TBB library target and configures its compile definitions and include directories. Sets up the core settings needed for the TBB library to function correctly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: CMake
CODE:
```
add_library(tbb ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${TBB_SOURCE_FILES})
target_compile_definitions(tbb PUBLIC
    TBB_USE_GCC_BUILTINS=1
    __TBB_GCC_BUILTIN_ATOMICS_PRESENT=1
    TBB_SUPPRESS_DEPRECATED_MESSAGES=1
)
target_include_directories(tbb SYSTEM PUBLIC $<BUILD_INTERFACE:${tbb_src_dir}/include>
    PRIVATE "${CMAKE_CURRENT_BINARY_DIR}"
)
```

----------------------------------------

TITLE: Overriding Message Formatting in JPEG Library (C)
DESCRIPTION: Defines the `format_message` function signature, a method within the `jpeg_error_mgr` struct. This function constructs a readable error message string based on the error code and parameters stored in `cinfo->err`, placing the result in the provided `buffer`. It's called internally by `output_message`. Overriding this is rare but can be used to implement internationalization or custom message formats.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_46

LANGUAGE: c
CODE:
```
format_message (j_common_ptr cinfo, char *buffer)
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree in C++
DESCRIPTION: This code snippet implements part of the FAST corner detection algorithm, which efficiently determines if a pixel is a corner by comparing surrounding pixel values. The algorithm uses a decision tree structure with goto statements to quickly navigate through pixel comparisons, checking if pixels at various offsets are brighter than a threshold.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_26

LANGUAGE: C++
CODE:
```
if(ptr[offset4] > cb)
  if(ptr[offset10] > cb)
    if(ptr[offset11] > cb)
      goto is_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset3] > cb)
      if(ptr[offset4] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset3] > cb)
      if(ptr[offset4] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset9] > cb)
    if(ptr[offset1] < c_b)
      goto is_not_a_corner;
    else
      if(ptr[offset1] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              if(ptr[offset3] > cb)
                goto is_a_corner;
              else
                if(ptr[offset8] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset3] > cb)
                  goto is_a_corner;
                else
                  if(ptr[offset8] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset3] > cb)
                  goto is_a_corner;
                else
                  if(ptr[offset8] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset1] < c_b)
      goto is_not_a_corner;
    else
      if(ptr[offset1] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset3] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
      else
        goto is_not_a_corner;
else
  if(ptr[offset7] > cb)
    if(ptr[offset9] < c_b)
      goto is_not_a_corner;
    else
      if(ptr[offset9] > cb)
        if(ptr[offset1] < c_b)
          if(ptr[offset6] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset6] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset8] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset8] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
```

----------------------------------------

TITLE: Setting CMake Version and Policies
DESCRIPTION: Configures minimum CMake version requirements and sets appropriate policy versions based on the CMake version being used
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.5.1)
if(CMAKE_VERSION VERSION_LESS 3.12)
    cmake_policy(VERSION ${CMAKE_VERSION})
else()
    cmake_policy(VERSION 3.5.1...3.29.0)
endif()
message(STATUS "Using CMake version ${CMAKE_VERSION}")
```

----------------------------------------

TITLE: Configuring RISC-V RVV Optimizations for ZLIB in CMake
DESCRIPTION: Checks if RISC-V Vector Extension (RVV) is enabled (WITH_RVV) and if the required intrinsics are available (HAVE_RVV_INTRIN). If both conditions are met, it adds RVV-specific source files (RVV_SRCS) to the ZLIB architecture sources (ZLIB_ARCH_SRCS) and sets specific compile flags (RISCVFLAG, NOLTOFLAG) for these files. Otherwise, it disables RVV support by setting WITH_RVV to OFF.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_19

LANGUAGE: cmake
CODE:
```
            elseif(BASEARCH_RISCV_FOUND)
        check_rvv_intrinsics()
        if(WITH_RVV AND HAVE_RVV_INTRIN)
            add_definitions(-DRISCV_RVV)
            set(RVV_SRCS ${ARCHDIR}/crc32_rvv.c ${ARCHDIR}/chunkset_rvv.c ${ARCHDIR}/compare256_rvv.c ${ARCHDIR}/slide_hash_rvv.c)
            add_feature_info(RVV 1 "Support RISC-V Vector Extension optimizations, using \"${RISCVFLAG}\"")
            list(APPEND ZLIB_ARCH_SRCS ${RVV_SRCS})
            set_property(SOURCE ${RVV_SRCS} PROPERTY COMPILE_FLAGS "${RISCVFLAG} ${NOLTOFLAG}")
        else()
            set(WITH_RVV OFF)
        endif()
```

----------------------------------------

TITLE: Registering Application Target with OpenCV CMake Macro - CMake
DESCRIPTION: This snippet uses the "ocv_add_application" macro to define an application build target named "opencv_visualisation" within an OpenCV CMake project. It specifies critical module dependencies (opencv_core, opencv_highgui, opencv_imgproc, opencv_videoio, opencv_imgcodecs) and lists source files required for the executable. Dependencies include OpenCV libraries, and the macro ensures correct linkage and build configuration. This setup requires CMake and an OpenCV build environment, and does not directly address platform-specific linking constraints.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/visualisation/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
ocv_add_application(opencv_visualisation
    MODULES opencv_core opencv_highgui opencv_imgproc opencv_videoio opencv_imgcodecs
    SRCS opencv_visualisation.cpp)
```

----------------------------------------

TITLE: Using RETR_CCOMP for 2-Level Contour Hierarchy in OpenCV Python
DESCRIPTION: This code snippet shows how to use the RETR_CCOMP mode in OpenCV to structure contours into a two-level hierarchy, distinguishing between external contours and contours of holes within objects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_hierarchy/py_contours_hierarchy.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
>>> hierarchy
array([[[ 3, -1,  1, -1],
        [ 2, -1, -1,  0],
        [-1,  1, -1,  0],
        [ 5,  0,  4, -1],
        [-1, -1, -1,  3],
        [ 7,  3,  6, -1],
        [-1, -1, -1,  5],
        [ 8,  5, -1, -1],
        [-1,  7, -1, -1]]])
```

----------------------------------------

TITLE: Defining Scan Information for Progressive/Noninterleaved JPEG in libjpeg (C)
DESCRIPTION: These C fields within the compression parameters structure (`cinfo`) are used to create multi-scan (progressive or noninterleaved) JPEG files. `scan_info` is a pointer to an array of `jpeg_scan_info` structures, and `num_scans` specifies the number of elements in this array. If `scan_info` is not NULL, the compressor writes a scan for each record; otherwise (default NULL), a single-scan sequential JPEG is created. The `jpeg_simple_progression` function can help create a standard progressive scan sequence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_36

LANGUAGE: C
CODE:
```
const jpeg_scan_info *scan_info
```

LANGUAGE: C
CODE:
```
int num_scans
```

----------------------------------------

TITLE: Selecting Best Match Location Based on Method (Python)
DESCRIPTION: Assigns the correct location (either `minLoc` or `maxLoc`) to the `matchLoc` variable based on the selected `method`. Methods `cv2.TM_SQDIFF` and `cv2.TM_SQDIFF_NORMED` use the minimum location as the best match, while the others use the maximum location.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_33

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py match_loc
```

----------------------------------------

TITLE: Checking System Endianness in CMake
DESCRIPTION: Includes the standard CMake module `TestBigEndian` and runs the `test_big_endian` function to determine if the target system is big-endian. The result is stored in the `OPJ_BIG_ENDIAN` variable. This check is skipped when compiling for Emscripten.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
#-----------------------------------------------------------------------------
# Big endian test:
if (NOT EMSCRIPTEN)
include(TestBigEndian)
test_big_endian(OPJ_BIG_ENDIAN)
endif()
```

----------------------------------------

TITLE: Adding Application with OpenCV in CMake
DESCRIPTION: This snippet demonstrates how to add an OpenCV application using CMake by specifying needed OpenCV modules like opencv_core, opencv_highgui, opencv_imgproc, opencv_imgcodecs, and opencv_videoio. The snippet registers opencv_annotation.cpp as the source file. The code ensures the application links with these specific OpenCV functionalities.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/annotation/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
ocv_add_application(opencv_annotation\n    MODULES opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs opencv_videoio\n    SRCS opencv_annotation.cpp)
```

----------------------------------------

TITLE: Setting Stitching Module Dependencies in CMake
DESCRIPTION: Defines the dependencies for the stitching module, including optional CUDA components and handling for shared library builds. It adjusts dependencies based on build configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/stitching/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
set(STITCHING_CONTRIB_DEPS "opencv_xfeatures2d")
if(BUILD_SHARED_LIBS AND BUILD_opencv_world AND OPENCV_WORLD_EXCLUDE_EXTRA_MODULES)
  set(STITCHING_CONTRIB_DEPS "")
endif()
```

----------------------------------------

TITLE: Defining Destination Buffer State in JPEG Library (C)
DESCRIPTION: Shows the essential fields within a custom `jpeg_destination_mgr` struct required by the JPEG compression library. `next_output_byte` points to the next available byte in the output buffer, and `free_in_buffer` indicates the number of bytes remaining. The library manages these fields, incrementing the pointer and decrementing the count as it writes compressed data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_49

LANGUAGE: c
CODE:
```
JOCTET *next_output_byte;   /* => next byte to write in buffer */
size_t free_in_buffer;      /* # of byte spaces remaining in buffer */
```

----------------------------------------

TITLE: Creating and Importing OpenCV Point in Clojure
DESCRIPTION: The code demonstrates creating an instance of the OpenCV Point class and using import to simplify the access to Java classes from the OpenCV library. It helps reduce boilerplate when working with Java libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_9

LANGUAGE: clojure
CODE:
```
user=> (org.opencv.core.Point. 0 0)
#<Point {0.0, 0.0}>
```

----------------------------------------

TITLE: Setting Image to Black with OpenCV in Java
DESCRIPTION: Demonstrates setting an entire image to zero in Java OpenCV. The setTo method changes all pixel values to black. Input is a Mat; output is the same Mat with all elements zeroed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_29

LANGUAGE: Java
CODE:
```
img.setTo(new Scalar(0));
```

----------------------------------------

TITLE: Building OpenCV for Android with OpenCL Support - Bash
DESCRIPTION: This bash script orchestrates a CMake/Ninja-based build of OpenCV for Android with OpenCL support. It sets up relevant Android environment variables, configures CMake with options for OpenCL, ABI, and example builds, and initiates the build directory. The script should be run with accurate paths for NDK, OpenCL SDK, and OpenCV sources to ensure proper build completion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
cd path_to_opencv && mkdir build && cd build\nexport NDK_VERSION=25.2.9519653\nexport ANDROID_SDK=/home/user/Android/Sdk/\nexport ANDROID_OPENCL_SDK=/path_to_ANDROID_OPENCL_SDK/\nexport ANDROID_HOME=$ANDROID_SDK\nexport ANDROID_NDK_HOME=$ANDROID_SDK/ndk/$NDK_VERSION/\ncmake -GNinja -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=24\n-DANDROID_SDK=$ANDROID_SDK -DANDROID_NDK=$ANDROID_NDK_HOME -DBUILD_JAVA=ON -DANDROID_HOME=$ANDROID_SDK -DBUILD_ANDROID_EXAMPLES=ON\n-DINSTALL_ANDROID_EXAMPLES=ON -DANDROID_ABI=arm64-v8a -DWITH_OPENCL=ON -DANDROID_OPENCL_SDK=$ANDROID_OPENCL_SDK ..
```

----------------------------------------

TITLE: Creating Custom JPEG Quantization Table (C)
DESCRIPTION: This function allows creation of an arbitrary quantization table. The basic_table values are multiplied by scale_factor/100 and clamped to 1-65535 (or 1-255 if force_baseline is TRUE).
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_27

LANGUAGE: C
CODE:
```
jpeg_add_quant_table (j_compress_ptr cinfo, int which_tbl,
                      const unsigned int *basic_table,
                      int scale_factor, boolean force_baseline)
```

----------------------------------------

TITLE: Declaring the OpenCV World Module using ocv_add_module (CMake)
DESCRIPTION: Uses the custom CMake function `ocv_add_module` to formally declare the `world` module. It specifies `opencv_core` as an initial dependency. This function is part of OpenCV's custom CMake script infrastructure and likely sets up basic module properties and dependencies required later in the build process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
ocv_add_module(world opencv_core)
```

----------------------------------------

TITLE: Verifying Pkg-config for AArch64 FFmpeg (Bash)
DESCRIPTION: Uses `pkg-config` with environment variables set for `aarch64` to retrieve compiler and linker flags for the core FFmpeg libraries (libavcodec, libavformat, libavutil, libswscale) installed for the `arm64` architecture. This confirms that the FFmpeg development packages for the target architecture are correctly installed and discoverable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_16

LANGUAGE: bash
CODE:
```
PKG_CONFIG_PATH=/usr/lib/aarch64-linux-gnu/pkgconfig:/usr/share/pkgconfig \
    PKG_CONFIG_LIBDIR=/usr/lib/aarch64-linux-gnu \
    PKG_CONFIG_SYSROOT_DIR=/ \
       pkg-config libavcodec libavformat libavutil libswscale --cflags --libs
-I/usr/include/aarch64-linux-gnu -L/usr/lib/aarch64-linux-gnu -lavcodec -lavformat -lavutil -lswscale
```

----------------------------------------

TITLE: Finalize Method for Custom Layer OpenCV C++
DESCRIPTION: Final preparations after \'getMemoryShapes\', tailored to known input dimensions in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp MyLayer::finalize
```

----------------------------------------

TITLE: Implementing FAST Corner Detection in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm. It compares pixel values at different offsets around a central pixel to determine if it's a corner. The algorithm uses nested if-else statements and goto labels for efficient branching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_37

LANGUAGE: C++
CODE:
```
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset1] > cb)
    goto is_not_a_corner;
  else
    if(ptr[offset1] < c_b)
      if(ptr[offset6] > cb)
        if(ptr[offset3] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset7] < c_b)
    if(ptr[offset9] < c_b)
      if(ptr[offset1] > cb)
        if(ptr[offset6] > cb)
          goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset6] > cb)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset3] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset8] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset3] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset8] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset3] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset8] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
    else
      if(ptr[offset1] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset6] > cb)
            if(ptr[offset3] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
```

----------------------------------------

TITLE: Handling OpenCV Exceptions Using try-catch Blocks (C++)
DESCRIPTION: Demonstrates the standard C++ approach for handling exceptions thrown by OpenCV functions. A `try` block encloses the OpenCV calls that might potentially throw an error. A `catch` block specifically targets `cv::Exception` (or its base `std::exception`), retrieves the error message using the `.what()` method, and prints it. This pattern allows for graceful recovery or reporting of runtime errors.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
    try
    {
        ... // call OpenCV
    }
    catch (const cv::Exception& e)
    {
        const char* err_msg = e.what();
        std::cout << "exception caught: " << err_msg << std::endl;
    }
```

----------------------------------------

TITLE: Loading Recorded Video in Command Line
DESCRIPTION: Demonstrates how to run a C++ program with a video file as input using a command-line argument. The video path needs to be absolute.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
./cpp-tutorial-pnp_detection --video=/absolute_path_to_your_video.mp4
```

----------------------------------------

TITLE: Implementing Shi-Tomasi Corner Detection in Java
DESCRIPTION: Java implementation of the Shi-Tomasi corner detection algorithm using OpenCV's goodFeaturesToTrack function. This sample demonstrates corner detection in an image with Java bindings for OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/trackingmotion/good_features_to_track/good_features_to_track.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
This tutorial code's is shown lines below. You can also download it from
[here](https://github.com/opencv/opencv/tree/4.x/samples/java/tutorial_code/TrackingMotion/good_features_to_track/GoodFeaturesToTrackDemo.java)
```

----------------------------------------

TITLE: Implementing Non-Maximum Suppression for Corner Detection in C++
DESCRIPTION: This code snippet performs non-maximum suppression on a set of detected corners (keypoints). It compares each corner with its neighbors above and to the left, maintaining a list of flags to track local maxima. The algorithm ensures that only the strongest corners in each local neighborhood are retained.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_46

LANGUAGE: C++
CODE:
```
currCorner = kpts.begin();

nmsFlags.resize((int)num_Corners);

// set all flags to MAXIMUM
for(j = 0; j < num_Corners; j++)
    nmsFlags[j] = -1;

for(curr_idx = 0; curr_idx < num_Corners; curr_idx++)
{
    int t;
    // check above
    if(lastRow + 1 < currCorner->pt.y)
    {
        lastRow = next_lastRow;
        lastRowCorner_ind = next_lastRowCorner_ind;
    }
    if(next_lastRow != currCorner->pt.y)
    {
        next_lastRow = (size_t) currCorner->pt.y;
        next_lastRowCorner_ind = curr_idx;
    }
    if(lastRow + 1 == currCorner->pt.y)
    {
        // find the corner above the current one
        while( (kpts[lastRowCorner_ind].pt.x < currCorner->pt.x)
            && (kpts[lastRowCorner_ind].pt.y == lastRow) )
            lastRowCorner_ind++;

            if( (kpts[lastRowCorner_ind].pt.x == currCorner->pt.x)
             && (lastRowCorner_ind != curr_idx) )
            {
                size_t w = lastRowCorner_ind;
                // find the maximum in this block
                while(nmsFlags[w] != -1)
                    w = nmsFlags[w];

                if(kpts[curr_idx].response < kpts[w].response)
                    nmsFlags[curr_idx] = (int)w;
                else
                    nmsFlags[w] = (int)curr_idx;
            }
    }

    // check left
    t = (int)curr_idx - 1;
    if( (curr_idx != 0) && (kpts[t].pt.y == currCorner->pt.y)
     && (kpts[t].pt.x + 1 == currCorner->pt.x) )
    {
        int currCornerMaxAbove_ind = nmsFlags[curr_idx];
        // find the maximum in that area
        while(nmsFlags[t] != -1)
            t = nmsFlags[t];
        // no maximum above
        if(currCornerMaxAbove_ind == -1)
        {
            if((size_t)t != curr_idx)
            {
                if ( kpts[curr_idx].response < kpts[t].response )
                    nmsFlags[curr_idx] = t;
                else
                    nmsFlags[t] = (int)curr_idx;
            }
        }
        else // maximum above
        {
            if(t != currCornerMaxAbove_ind)
            {
                if(kpts[currCornerMaxAbove_ind].response < kpts[t].response)
                {
                    nmsFlags[currCornerMaxAbove_ind] = t;
                    nmsFlags[curr_idx] = t;
                }
                else
                {
                    nmsFlags[t] = currCornerMaxAbove_ind;
                    nmsFlags[curr_idx] = currCornerMaxAbove_ind;
                }
            }
        }
    }
    currCorner++;
}

// collecting maximum corners
for(curr_idx = 0; curr_idx < num_Corners; curr_idx++)
{
    if (nmsFlags[curr_idx] == -1)
        keypoints.push_back(kpts[curr_idx]);
}

```

----------------------------------------

TITLE: Defining Highgui Header Files in CMake
DESCRIPTION: Sets the CMake variable `highgui_hdrs` to a list containing the path to the precompiled header file `precomp.hpp` for the highgui module. This variable will likely be used when defining the module's target to specify its header files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
set(highgui_hdrs
    ${CMAKE_CURRENT_LIST_DIR}/src/precomp.hpp
    )
```

----------------------------------------

TITLE: Running Classification Example from Command Line
DESCRIPTION: The command line snippet demonstrates executing the complete classification example, specifying model files, input file, and preprocessing parameters to obtain the classification result for a provided image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_googlenet/dnn_googlenet.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
@code
./example_dnn_classification --model=bvlc_googlenet.caffemodel --config=bvlc_googlenet.prototxt --width=224 --height=224 --classes=classification_classes_ILSVRC2012.txt --input=space_shuttle.jpg --mean="104 117 123"
@endcode
```

----------------------------------------

TITLE: Cloning OpenCV and OpenCV Contrib Repositories (Shell)
DESCRIPTION: These shell commands use the `git clone` utility to download the source code for the main OpenCV library and the `opencv_contrib` repository from their respective GitHub locations. Cloning both repositories is necessary for building OpenCV with FastCV, as the FastCV module resides within the `opencv_contrib` repository.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_4

LANGUAGE: shell
CODE:
```
git clone https://github.com/opencv/opencv.git
git clone https://github.com/opencv/opencv_contrib.git
```

----------------------------------------

TITLE: Generating Custom ArUco Dictionary using C++ Utility (Shell)
DESCRIPTION: Executes the compiled C++ utility 'example_cpp_aruco_dict_utils.exe' to generate a custom ArUco dictionary and save it to 'my_dict.json'. The dictionary will contain 30 markers, each with a size of 5 bits. Requires the compiled 'aruco_dict_utils.cpp' executable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_pattern/camera_calibration_pattern.markdown#2025-04-22_snippet_6

LANGUAGE: shell
CODE:
```
bin/example_cpp_aruco_dict_utils.exe my_dict.json -nMarkers=30 -markerSize=5
```

----------------------------------------

TITLE: Configuring Quirc Library Build in CMake for OpenCV
DESCRIPTION: This CMake script configures the Quirc QR code decoding library as a static dependency for OpenCV. It sets up include directories, collects source files, configures build properties, and defines installation rules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/quirc/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(quirc)

set(CURR_INCLUDE_DIR "${CMAKE_CURRENT_LIST_DIR}/include")

set_property(GLOBAL PROPERTY QUIRC_INCLUDE_DIR ${CURR_INCLUDE_DIR})
ocv_include_directories(${CURR_INCLUDE_DIR})

file(GLOB_RECURSE quirc_headers RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "include/*.h")
file(GLOB_RECURSE quirc_sources RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "src/*.c")

add_library(${PROJECT_NAME} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${quirc_headers} ${quirc_sources})
ocv_warnings_disable(CMAKE_C_FLAGS -Wunused-variable -Wshadow)

set_target_properties(${PROJECT_NAME}
  PROPERTIES OUTPUT_NAME ${PROJECT_NAME}
  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
  COMPILE_PDB_NAME ${PROJECT_NAME}
  COMPILE_PDB_NAME_DEBUG "${PROJECT_NAME}${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
  )

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${PROJECT_NAME} PROPERTIES FOLDER "3rdparty")
endif()

if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${PROJECT_NAME} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(${PROJECT_NAME} LICENSE)
```

----------------------------------------

TITLE: Performance Benchmark Results
DESCRIPTION: Shows performance comparison between CPU and GPU implementations for PSNR and MSSIM calculations, including optimized GPU versions. The results demonstrate significant performance improvements of nearly 100% using GPU optimization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_16

LANGUAGE: text
CODE:
```
Time of PSNR CPU (averaged for 10 runs): 41.4122 milliseconds. With result of: 19.2506
Time of PSNR GPU (averaged for 10 runs): 158.977 milliseconds. With result of: 19.2506
Initial call GPU optimized:              31.3418 milliseconds. With result of: 19.2506
Time of PSNR GPU OPTIMIZED ( / 10 runs): 24.8171 milliseconds. With result of: 19.2506

Time of MSSIM CPU (averaged for 10 runs): 484.343 milliseconds. With result of B0.890964 G0.903845 R0.936934
Time of MSSIM GPU (averaged for 10 runs): 745.105 milliseconds. With result of B0.89922 G0.909051 R0.968223
Time of MSSIM GPU Initial Call            357.746 milliseconds. With result of B0.890964 G0.903845 R0.936934
Time of MSSIM GPU OPTIMIZED ( / 10 runs): 203.091 milliseconds. With result of B0.890964 G0.903845 R0.936934
```

----------------------------------------

TITLE: Synchronizing and Pairing Depth and Color Frames from Astra Camera
DESCRIPTION: Implements a post-synchronization procedure to pair depth and color frames based on their timestamps. This ensures that frames from both streams represent the same moment in time, which is critical for applications that combine color and depth data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_11

LANGUAGE: cpp
CODE:
```
// Wait for frames from both streams
unique_lock<mutex> depthLk(depthFramesMtx, defer_lock);
unique_lock<mutex> colorLk(colorFramesMtx, defer_lock);
lock(depthLk, colorLk);

// If either queue is empty, wait for frames
while (isRunning.load() && (depthFrames.empty() || colorFrames.empty())) {
    if (depthFrames.empty()) {
        depthLk.unlock();
        depthFramesCV.wait(depthLk);
    }

    if (colorFrames.empty()) {
        colorLk.unlock();
        colorFramesCV.wait(colorLk);
    }
}

// Get the timestamp of the first frame in each queue
auto depthTime = depthFrames.front().timestamp;
auto colorTime = colorFrames.front().timestamp;

// Calculate the time difference between the frames
auto timeDiff = chrono::duration_cast<chrono::milliseconds>(colorTime - depthTime).count();

// Drop frames until synchronization is achieved
if (abs(timeDiff) > 0.5 * 1000 / 30) {  // 0.5 * frame_period
    if (timeDiff > 0) {
        depthFrames.pop_front();
    } else {
        colorFrames.pop_front();
    }
    continue;
}

// Get the synchronized frames
Mat depthFrame = depthFrames.front().frame;
Mat colorFrame = colorFrames.front().frame;

// Remove the frames from the queues
depthFrames.pop_front();
colorFrames.pop_front();

// Now, the frames are synchronized and can be processed together
imshow("Color", colorFrame);
imshow("Depth", depthFrame);
```

----------------------------------------

TITLE: Checking Contour Convexity in Python with OpenCV
DESCRIPTION: This snippet demonstrates how to check if a contour is convex using the cv.isContourConvex() function. It returns a boolean value indicating convexity.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_6

LANGUAGE: Python
CODE:
```
k = cv.isContourConvex(cnt)
```

----------------------------------------

TITLE: Setting Up Project Library Directory and Updating Eclipse with SBT (Bash)
DESCRIPTION: Creates a 'lib' directory, copies the compiled OpenCV JAR file into it for dependency management, and optionally updates the Eclipse project configuration using the SBT command. This makes the OpenCV library available to the Java project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_17

LANGUAGE: bash
CODE:
```
mkdir lib
cp <opencv_dir>/build/bin/opencv_<version>.jar lib/
sbt eclipse
```

----------------------------------------

TITLE: Configuring and Building OpenCV with FastCV for Qualcomm Linux (Shell)
DESCRIPTION: This sequence of shell commands outlines the process for configuring and compiling OpenCV with FastCV enabled for Qualcomm Linux. First, it creates and navigates into a `build` directory. Then, `cmake` is invoked to configure the project for cross-compilation targeting Linux on AArch64 (`-DCMAKE_SYSTEM_NAME=Linux -DCMAKE_SYSTEM_PROCESSOR=aarch64`), enabling FastCV (`-DWITH_FASTCV=ON`), requesting shared libraries (`-DBUILD_SHARED_LIBS=ON`), and specifying the path to the extra modules in `opencv_contrib`, including the FastCV module (`-DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules/fastcv/`). Finally, `make -j$(nproc)` starts the parallel compilation process using all available CPU cores.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_5

LANGUAGE: shell
CODE:
```
mkdir build
cd build
cmake -DCMAKE_SYSTEM_NAME=Linux -DCMAKE_SYSTEM_PROCESSOR=aarch64 -DWITH_FASTCV=ON -DBUILD_SHARED_LIBS=ON -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules/fastcv/ ../opencv
make -j$(nproc)
```

----------------------------------------

TITLE: Random Access with At Method in OpenCV
DESCRIPTION: Examines using the cv::Mat::at() function to randomly access or modify specific image elements by row and column indices, while noting the importance of input type and ensuring bounds safety in debug mode.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_scan_images/how_to_scan_images.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
@snippet how_to_scan_images.cpp scan-random
```

----------------------------------------

TITLE: Complete Implementation of calcGST() Function in G-API
DESCRIPTION: Provides the full implementation of the calcGST() function using G-API operations, including calculation of J matrix and other components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
cv::GMat calcGST(const cv::GMat& inputImage, const int w)
{
    auto img = cv::gapi::convertTo(inputImage, CV_32F);
    auto imgDiffX = cv::gapi::Sobel(img, CV_32F, 1, 0, 3);
    auto imgDiffY = cv::gapi::Sobel(img, CV_32F, 0, 1, 3);
    auto imgDiffXY = cv::gapi::mul(imgDiffX, imgDiffY);
    auto imgDiffXX = cv::gapi::mul(imgDiffX, imgDiffX);
    auto imgDiffYY = cv::gapi::mul(imgDiffY, imgDiffY);

    auto J11 = cv::gapi::boxFilter(imgDiffXX, CV_32F, cv::Size(w,w));
    auto J22 = cv::gapi::boxFilter(imgDiffYY, CV_32F, cv::Size(w,w));
    auto J12 = cv::gapi::boxFilter(imgDiffXY, CV_32F, cv::Size(w,w));

    auto tmp1 = cv::gapi::add(J11, J22);
    auto tmp2 = cv::gapi::sub(J11, J22);
    auto tmp3 = cv::gapi::mul(tmp2, tmp2);
    auto tmp4 = cv::gapi::mul(J12, J12);
    auto tmp5 = cv::gapi::add(tmp3, tmp4);
    auto tmp6 = cv::gapi::sqrt(tmp5);
    auto lambda1 = cv::gapi::addC(tmp6, 1e-15);
    lambda1 = cv::gapi::add(tmp1, lambda1);
    lambda1 = cv::gapi::divC(lambda1, 2);
    auto lambda2 = cv::gapi::subC(tmp6, 1e-15);
    lambda2 = cv::gapi::sub(tmp1, lambda2);
    lambda2 = cv::gapi::divC(lambda2, 2);

    return cv::gapi::sub(lambda1, lambda2);
}
```

----------------------------------------

TITLE: Creating Display Window in Python
DESCRIPTION: This Python snippet creates a display window named 'Linear Blend' using `cv.namedWindow`. This window serves as the container for the trackbar and the output image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
#![window]
# Create Window
cv.namedWindow('Linear Blend')
#![window]
```

----------------------------------------

TITLE: Building OpenCV with Unicode character set for Windows Embedded
DESCRIPTION: Command for building the OpenCV project after configuration, specifying Unicode character set which is required for Windows Embedded platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/wince/readme.md#2025-04-22_snippet_4

LANGUAGE: batch
CODE:
```
cmake --build . -- /p:CharacterSet=Unicode
```

----------------------------------------

TITLE: Running Custom Layer OpenCV C++
DESCRIPTION: Implements the core logic of the layer by computing outputs for the given inputs in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp MyLayer::forward
```

----------------------------------------

TITLE: Drawing and Displaying Results in C++
DESCRIPTION: This snippet draws the detection results on the image and displays it. The outputs distinguish results from the Ballard and Guil methods using different colored rectangles.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/generalized_hough_ballard_guil/generalized_hough_ballard_guil.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
# Draw results and show image
@snippet samples/cpp/tutorial_code/ImgTrans/generalizedHoughTransform.cpp generalized-hough-transform-draw-results
```

----------------------------------------

TITLE: Checking Contour Convexity in JavaScript
DESCRIPTION: This snippet shows how to use the `cv.isContourConvex()` function to determine if a contour is convex. It takes a contour (`cnt`), typically represented as a vector of points, as input and returns a boolean value: true if the contour is convex, and false otherwise. This function requires a pre-calculated contour object (`cnt`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_features/js_contour_features.markdown#2025-04-22_snippet_1

LANGUAGE: js
CODE:
```
cv.isContourConvex(cnt);
```

----------------------------------------

TITLE: Configuring DNN Sample Build Process
DESCRIPTION: Sets up the build configuration for DNN samples, including project setup, module inclusion, and target linking. Processes all CPP files in the directory and creates build targets with necessary library linkages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()

project(dnn_samples)
ocv_include_modules_recurse(${OPENCV_DNN_SAMPLES_REQUIRED_DEPS})
file(GLOB_RECURSE dnn_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
foreach(sample_filename ${dnn_samples})
  ocv_define_sample(tgt ${sample_filename} dnn)
  ocv_target_link_libraries(${tgt} PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_DNN_SAMPLES_REQUIRED_DEPS})
endforeach()
```

----------------------------------------

TITLE: Single Channel Pixel Access with At Methods (ucharAt) in OpenCV.js - JavaScript
DESCRIPTION: Extracts individual channel values at specified (row, col) using ucharAt. This provides read-only access (cannot modify) and is meant for single channel or per-channel per-pixel reading. The method prevents direct memory access errors and is type-safe for matching Mat types.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_7

LANGUAGE: JavaScript
CODE:
```
let row = 3, col = 4;
let src = cv.imread("canvasInput");
let R = src.ucharAt(row, col * src.channels());
let G = src.ucharAt(row, col * src.channels() + 1);
let B = src.ucharAt(row, col * src.channels() + 2);
let A = src.ucharAt(row, col * src.channels() + 3);
```

----------------------------------------

TITLE: Invoking OpenCV cv::parallel_for_ for Parallel Mandelbrot Computation - C++
DESCRIPTION: This code demonstrates the use of cv::parallel_for_ to execute the custom ParallelMandelbrot functor over the whole image (pixel count), enabling parallelized pixel processing. Requires OpenCV's parallel_for_ and a correctly defined ParallelMandelbrot object. Input is the pixel count; output is the modified image Mat. The 'nstripes' parameter can adjust task splitting.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
// Parallel for call for Mandelbrot
cv::parallel_for_(cv::Range(0, image.rows * image.cols), ParallelMandelbrot(image, maxIter));

```

----------------------------------------

TITLE: Implementing the Escape Time Algorithm for the Mandelbrot Set - C++
DESCRIPTION: This snippet implements the 'escape time' algorithm for determining whether a given complex coordinate is part of the Mandelbrot set, using std::complex in C++. The routine computes iterations based on the Mandelbrot recursion formula and returns the number of iterations taken to escape (or reach the maximum). Requires OpenCV and <complex>. The core input is a complex coordinate, output is the iteration count (int); limited by the chosen maximum iteration parameter.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
// Escape time algorithm for Mandelbrot set
int mandelbrot(cv::Point2d pt, int maxIter)
{
    std::complex<double> z(0, 0);
    std::complex<double> c(pt.x, pt.y);
    int iter = 0;
    while (std::norm(z) < 4.0 && iter < maxIter)
    {
        z = z * z + c;
        ++iter;
    }
    return iter;
}

```

----------------------------------------

TITLE: Signaling Successful OpenJPEG Configuration to Parent Scope in CMake
DESCRIPTION: Checks if the variable `OCV_CAN_BUILD_OPENJPEG` is already defined. If not (implying no fatal errors occurred during the configuration checks), it sets `OCV_CAN_BUILD_OPENJPEG` to `TRUE` in the `PARENT_SCOPE`. This informs the main OpenCV build system whether the OpenJPEG dependency can be successfully built.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_17

LANGUAGE: cmake
CODE:
```
# OpenJPEG can't be built only if configuration script doesn't encounter any problem
if(NOT DEFINED OCV_CAN_BUILD_OPENJPEG)
  # all prerequisites are fulfilled
  set(OCV_CAN_BUILD_OPENJPEG TRUE PARENT_SCOPE)
endif()
```

----------------------------------------

TITLE: Applying Laplacian Operator in C++
DESCRIPTION: Applies the Laplacian operator to the grayscale image (`src_gray`) using cv::Laplacian. The output depth (`ddepth`) is set to CV_16S to prevent overflow during calculations involving second derivatives. Kernel size, scale, delta, and border type use the previously defined or default values. Requires OpenCV imgproc module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_15

LANGUAGE: cpp
CODE:
```
//! [laplacian]
/// Apply Laplace function
Mat abs_dst;

Laplacian( src_gray, dst, ddepth, kernel_size, scale, delta, BORDER_DEFAULT );
//! [laplacian]
```

----------------------------------------

TITLE: Applying Mask and Inverse DFT using OpenCV and Numpy - Python
DESCRIPTION: This code applies a frequency mask to a shifted DFT of an image, performs an inverse shift and inverse DFT to reconstruct the filtered image, and plots the original image alongside its filtered magnitude spectrum. Dependencies include cv2 (imported as cv), numpy (imported as np), and matplotlib.pyplot (imported as plt). Key variables: 'img' (input image), 'dft_shift' (initial DFT), and 'mask' (frequency mask). The output is two matplotlib subplots: the input and masked-inverse-DFT image. Requires a previously computed 'dft_shift' and 'mask'. Assumes usage in a Jupyter-style workflow. Limitations: variable definitions like 'img', 'dft_shift', 'mask' assumed present in surrounding code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_transforms/py_fourier_transform/py_fourier_transform.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
# apply mask and inverse DFT
fshift = dft_shift*mask
f_ishift = np.fft.ifftshift(fshift)
img_back = cv.idft(f_ishift)
img_back = cv.magnitude(img_back[:,:,0],img_back[:,:,1])

plt.subplot(121),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(img_back, cmap = 'gray')
plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])
plt.show()
```

----------------------------------------

TITLE: Automatic Data Allocation in OpenCV C++
DESCRIPTION: This code demonstrates automatic memory allocation for output data in OpenCV. It uses `cv::Mat` for video frame capturing and image processing operations, showcasing the allocation of matrices by OpenCV's VideoCapture API and functions like `cvtColor`. It handles frame and edge detection from webcam input, requiring headers like `opencv2/imgproc.hpp` and `opencv2/highgui.hpp`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
    #include "opencv2/imgproc.hpp"
    #include "opencv2/highgui.hpp"

    using namespace cv;

    int main(int, char**)
    {
        VideoCapture cap(0);
        if(!cap.isOpened()) return -1;

        Mat frame, edges;
        namedWindow("edges", WINDOW_AUTOSIZE);
        for(;;)
        {
            cap >> frame;
            cvtColor(frame, edges, COLOR_BGR2GRAY);
            GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);
            Canny(edges, edges, 0, 30, 3);
            imshow("edges", edges);
            if(waitKey(30) >= 0) break;
        }
        return 0;
    }
```

----------------------------------------

TITLE: Setting Up OpenCL SDK Directories and Downloading Required Headers - Bash
DESCRIPTION: This snippet automates the setup of the Android OpenCL SDK directory, copies necessary standard OpenCL headers, and downloads C++ OpenCL header files using wget. Dependencies include the OpenCV source or system OpenCL headers and an internet connection for fetching additional files. The script expects environment variables for source locations and creates the required directory structure for later use by build systems.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
cd your_path/ && mkdir ANDROID_OPENCL_SDK && mkdir ANDROID_OPENCL_SDK/include && cd ANDROID_OPENCL_SDK/include\ncp -r path_to_opencv/opencv/3rdparty/include/opencl/1.2/CL . && cd CL\nwget https://github.com/KhronosGroup/OpenCL-CLHPP/raw/main/include/CL/opencl.hpp\nwget https://github.com/KhronosGroup/OpenCL-CLHPP/raw/main/include/CL/cl2.hpp
```

----------------------------------------

TITLE: Enabling OSGi Integration Tests for OpenCV
DESCRIPTION: Maven profile activation command to run OSGi integration tests as part of the build process. This is optional and applicable to all processor architectures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/maven/README.md#2025-04-22_snippet_3

LANGUAGE: shell
CODE:
```
-Pintegration
```

----------------------------------------

TITLE: Default Preprocessing Configuration for TensorFlow Segmentation
DESCRIPTION: Defines the default preprocessing parameters for TensorFlow segmentation models, including scaling factor, mean values for normalization, and color space configuration. These values are used when default_img_preprocess is set to True.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_13

LANGUAGE: python
CODE:
```
tf_segm_input_blob = {
    "scale": str(1 / 127.5),
    "mean": ["127.5", "127.5", "127.5"],
    "std": [],
    "crop": "False",
    "rgb": "True"
}
```

----------------------------------------

TITLE: Changing Image Type from 8UC1 to 32FC1 with OpenCV in Java
DESCRIPTION: Illustrates changing an image Mat from 8-bit to float type in Java OpenCV using convertTo. Input and output are Mat; output must be declared. Applicable for floating-point processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_38

LANGUAGE: Java
CODE:
```
Mat floatMat = new Mat();\nimg.convertTo(floatMat, CvType.CV_32F);
```

----------------------------------------

TITLE: Linking JNI Target with System OpenCL Library - CMake
DESCRIPTION: This CMake line explicitly links the JNI component of the Android application to the system OpenCL library. It avoids embedding the library into the APK, opting to rely on the system's OpenCL API at runtime. Users must ensure OpenCL is present on the target device; linker errors for missing symbols may be ignored with appropriate flags during build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
target_link_libraries(${target} -lOpenCL)
```

----------------------------------------

TITLE: Finishing JPEG Decompression in C using libjpeg
DESCRIPTION: This snippet shows the call to `jpeg_finish_decompress`, which completes the decompression cycle and releases associated working memory. It must be called after successfully reading all image scanlines (step 7). Calling it prematurely or after an error is incorrect; `jpeg_abort` should be used in those cases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_16

LANGUAGE: C
CODE:
```
jpeg_finish_decompress(&cinfo);
```

----------------------------------------

TITLE: Setting up OpenCV Java Bindings Generator Module in CMake
DESCRIPTION: Initializes the CMake configuration for the Java bindings generator. It defines the module name `java_bindings_generator`, marks it as internal (not part of the main OpenCV world library), adds it using `ocv_add_module`, sets paths for generated signature files and bindings, and removes potentially stale generated directories and dependency helper files. It also includes a common CMake configuration file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/generator/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(MODULE_NAME "java_bindings_generator")
set(OPENCV_MODULE_IS_PART_OF_WORLD FALSE)
ocv_add_module(${MODULE_NAME} INTERNAL)

set(OPENCV_JAVA_SIGNATURES_FILE "${CMAKE_CURRENT_BINARY_DIR}/opencv_java_signatures.json" CACHE INTERNAL "")
set(OPENCV_JAVA_BINDINGS_DIR "${CMAKE_CURRENT_BINARY_DIR}" CACHE INTERNAL "")

file(REMOVE_RECURSE "${OPENCV_JAVA_BINDINGS_DIR}/gen")
file(REMOVE "${OPENCV_DEPHELPER}/gen_opencv_java_source")  # force re-run after CMake

# This file is included from a subdirectory
set(JAVA_SOURCE_DIR "${CMAKE_CURRENT_SOURCE_DIR}/..")
include(${JAVA_SOURCE_DIR}/common.cmake)
```

----------------------------------------

TITLE: Executing C++ Program with Make
DESCRIPTION: Use make to build and execute a C++ program that utilizes OpenCV library, demonstrating successful linking and running of OpenCV code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_27

LANGUAGE: bash
CODE:
```
make a.out
./a.out
```

----------------------------------------

TITLE: Writing JPEG Comment Marker in C
DESCRIPTION: Example showing how to write a COM (comment) marker to a JPEG file using jpeg_write_marker(). The marker is written after compression starts but before scanlines are written.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_61

LANGUAGE: C
CODE:
```
jpeg_write_marker(cinfo, JPEG_COM, comment_text, strlen(comment_text));
```

----------------------------------------

TITLE: Including OpenCV.js Synchronously (HTML)
DESCRIPTION: Demonstrates how to include the OpenCV.js library synchronously in an HTML file using a `<script>` tag. The browser will load and execute `opencv.js` before continuing to parse the rest of the HTML document. The `opencv.js` file is assumed to be in the same folder as the HTML file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_usage/js_usage.markdown#2025-04-22_snippet_1

LANGUAGE: html
CODE:
```
<script src="opencv.js" type="text/javascript"></script>
```

----------------------------------------

TITLE: Cloning OpenCV Repositories on macOS
DESCRIPTION: These commands clone the main OpenCV repository and the contrib repository for additional modules using Git.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
cd ~/<your_working_directory>
git clone https://github.com/opencv/opencv.git
git clone https://github.com/opencv/opencv_contrib.git
```

----------------------------------------

TITLE: Initializing and Configuring SVM Parameters for Non-Linear Classification (Python)
DESCRIPTION: Python implementation for setting up SVM parameters to handle non-linearly separable data. Uses the RBF kernel with a small C value for better generalization and high iteration criteria for convergence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_10

LANGUAGE: Python
CODE:
```
# Set up SVM's parameters
svm = cv.ml.SVM_create()
svm.setType(cv.ml.SVM_C_SVC)
svm.setKernel(cv.ml.SVM_RBF)
# When C is small, the decision boundary will be smooth
# When C is large, the decision boundary can better classify all training points but may lead to overfitting
svm.setC(0.1)
# Set termination criteria for the optimization
svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, int(1e7), 1e-6))
```

----------------------------------------

TITLE: Setting Uniform and Accumulate Flags in Java
DESCRIPTION: Java snippet setting boolean flags for histogram calculation using `Imgproc.calcHist`. `histUniform` is set to true for equal bin sizes, and `accumulate` is set to false to clear the histogram beforehand.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_16

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Set histogram param
```

----------------------------------------

TITLE: Creating Trackbar for Method Selection (C++)
DESCRIPTION: Creates a trackbar in a designated window using `cv::createTrackbar`. This allows the user to interactively select one of the available template matching methods. The trackbar calls a specified callback function (`MatchingMethod`) whenever its value changes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_16

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp create_trackbar
```

----------------------------------------

TITLE: Defining Function to Include Individual OpenCV Module (CMake)
DESCRIPTION: Defines a CMake function `include_one_module` that takes a module name `m` as an argument. It includes the module's `CMakeLists.txt` using the path stored in `OPENCV_MODULE_${m}_LOCATION`. It also ensures that `CMAKE_CXX_FLAGS` and `CMAKE_C_FLAGS` from the included module's scope are propagated back to the parent scope, which is important for maintaining consistent build settings across modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
function(include_one_module m)
  include("${OPENCV_MODULE_${m}_LOCATION}/CMakeLists.txt")
  foreach(var
      CMAKE_CXX_FLAGS CMAKE_C_FLAGS # Propagate warnings settings
  )
    set(${var} "${${var}}" PARENT_SCOPE)
  endforeach()
endfunction()
```

----------------------------------------

TITLE: Configuring an OpenCV Project with CMake in CMakeLists.txt
DESCRIPTION: This CMake snippet provides a minimum configuration to build a C++ project using OpenCV. It sets the CMake minimum version, locates the required OpenCV package, sets up include directories, declares the executable to build, and links it against OpenCV libraries. Dependencies: CMake >= 3.5, OpenCV installed and findable. Inputs: DisplayImage.cpp source file. Outputs: Makefile or build files for compiling the DisplayImage executable. Limitation: assumes OpenCV is installed and find_package can locate it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_gcc_cmake/linux_gcc_cmake.markdown#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.5)\nproject( DisplayImage )\nfind_package( OpenCV REQUIRED )\ninclude_directories( ${OpenCV_INCLUDE_DIRS} )\nadd_executable( DisplayImage DisplayImage.cpp )\ntarget_link_libraries( DisplayImage ${OpenCV_LIBS} )
```

----------------------------------------

TITLE: Blending Images with OpenCV in C++
DESCRIPTION: This C++ snippet demonstrates how to blend two images using OpenCV. The addWeighted() function is used to perform linear blending of two images. The input images must be of the same size and type. Dependencies include OpenCV library installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/adding_images/adding_images.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
"@snippet cpp/tutorial_code/core/AddingImages/AddingImages.cpp load"
```

LANGUAGE: C++
CODE:
```
"@snippet cpp/tutorial_code/core/AddingImages/AddingImages.cpp blend_images"
```

LANGUAGE: C++
CODE:
```
"@snippet cpp/tutorial_code/core/AddingImages/AddingImages.cpp display"
```

----------------------------------------

TITLE: Adding BibTeX Record for Publication Reference in OpenCV Documentation
DESCRIPTION: Shows how to add a BibTeX record for a publication reference in OpenCV documentation files. This snippet demonstrates the format for adding a publication to either the main OpenCV bibliography file or a module-specific file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_17

LANGUAGE: bibtex
CODE:
```
@ARTICLE{Bradski98,
    author = {Bradski, Gary R},
    title = {Computer vision face tracking for use in a perceptual user interface},
    year = {1998},
    publisher = {Citeseer}
}
```

----------------------------------------

TITLE: Calculating PSNR for Image Similarity in OpenCV Python
DESCRIPTION: This Python implementation calculates the Peak Signal-to-Noise Ratio (PSNR) between two images. It computes the mean squared error and converts it to the logarithmic PSNR value. The function returns 100 for identical images to avoid divide-by-zero errors.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
def getPSNR(I1, I2):
    s1 = cv.absdiff(I1, I2) #|I1 - I2|
    s1 = np.float32(s1)  # cannot make a square on 8 bits
    s1 = s1 * s1  # |I1 - I2|^2
    sse = np.sum(s1)  # sum elements per channel
    if sse <= 1e-10:  # sum channels
        return 0  # for small values return zero
    else:
        shape = I1.shape
        mse = sse / (shape[0] * shape[1] * shape[2])
        psnr = 10.0 * np.log10((255 * 255) / mse)
        return psnr
```

----------------------------------------

TITLE: Copying Cascade Classifier File to Resources Directory (Bash)
DESCRIPTION: Copies the LBP cascade classifier XML file for frontal face detection from the OpenCV data directory into the project's 'src/main/resources' directory. This makes the classifier accessible to the Java application at runtime.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_18

LANGUAGE: bash
CODE:
```
cp <opencv_dir>/data/lbpcascades/lbpcascade_frontalface.xml src/main/resources/
```

----------------------------------------

TITLE: Configuring DNN Parameters using OpenVINO and C++
DESCRIPTION: Utilizing OpenVINO Toolkit's Inference Engine, this snippet demonstrates how deep learning networks are configured within the G-API pipeline. It involves setting parameters for networks defined via G_API_NET() and wraps them in a NetworkPackage for further use.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/face_beautification/face_beautification.cpp net_param
```

----------------------------------------

TITLE: Reading Images using OpenCV in Python
DESCRIPTION: This snippet explains how to read an image file using OpenCV's cv.imread function in Python. The image can be loaded in various formats, but the default is 8-bit BGR color. The image data is stored in a NumPy array for subsequent operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
image = cv.imread('starry_night.jpg', cv.IMREAD_COLOR)
```

----------------------------------------

TITLE: Importing OpenCV Framework in Objective-C
DESCRIPTION: This snippet shows how to import the OpenCV framework header into an Objective-C source file. It enables direct access to OpenCV functions and classes from within Objective-C. Dependency: the OpenCV framework must be added to your Xcode project. The snippet should be placed at the top of files that use OpenCV. Input: none; Output: imports the OpenCV API into the current source context.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/doc/README.md#2025-04-22_snippet_0

LANGUAGE: Objective-C
CODE:
```
#import <OpenCV/OpenCV.h>
```

----------------------------------------

TITLE: Running OpenCV Visualisation Tool Command
DESCRIPTION: This command visualizes the trained cascade classifier by displaying selected features and stages complexity. It requires paths to a reference image and the trained model. Optionally, it stores stage output and a feature visualization video in the specified data folder.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/traincascade.markdown#2025-04-22_snippet_5

LANGUAGE: text
CODE:
```
opencv_visualisation --image=/data/object.png --model=/data/model.xml --data=/data/result/
```

----------------------------------------

TITLE: Running OpenCV.js Tests in Browser and with Node.js HTTP-Server - Sh
DESCRIPTION: Demonstrates launching a local web server (Node's http-server) to serve test files, then opening the test page in Firefox to run automated tests. Dependencies: Node.js and http-server package must be installed. Parameters: directory to serve (build_js/bin). Output: test results shown in browser interface.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_12

LANGUAGE: sh
CODE:
```
npx http-server build_js/bin\nfirefox http://localhost:8080/tests.html
```

----------------------------------------

TITLE: Computing Fundamental Matrix with OpenCV - Python
DESCRIPTION: Utilizes matched points to compute the fundamental matrix in OpenCV, filtering for inlier points. Assumes the matched points list is available and uses the LMedS method for robust estimation. The output is the fundamental matrix with a mask of inliers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
pts1 = np.int32(pts1)
pts2 = np.int32(pts2)
F, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)

# We select only inlier points
pts1 = pts1[mask.ravel()==1]
pts2 = pts2[mask.ravel()==1]
```

----------------------------------------

TITLE: Configuring OpenCV Modules in CMake
DESCRIPTION: This snippet sets up and reports the status of OpenCV modules to be built, disabled, or unavailable. It uses CMake commands to process module lists and display their status.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_17

LANGUAGE: CMake
CODE:
```
status("")
status("  OpenCV modules:")
set(OPENCV_MODULES_BUILD_ST "")
foreach(the_module ${OPENCV_MODULES_BUILD})
  if(NOT OPENCV_MODULE_${the_module}_CLASS STREQUAL "INTERNAL" OR the_module STREQUAL "opencv_ts")
    list(APPEND OPENCV_MODULES_BUILD_ST "${the_module}")
  endif()
endforeach()
string(REPLACE "opencv_" "" OPENCV_MODULES_BUILD_ST          "${OPENCV_MODULES_BUILD_ST}")
string(REPLACE "opencv_" "" OPENCV_MODULES_DISABLED_USER_ST  "${OPENCV_MODULES_DISABLED_USER}")
string(REPLACE "opencv_" "" OPENCV_MODULES_DISABLED_AUTO_ST  "${OPENCV_MODULES_DISABLED_AUTO}")
string(REPLACE "opencv_" "" OPENCV_MODULES_DISABLED_FORCE_ST "${OPENCV_MODULES_DISABLED_FORCE}")
list(SORT OPENCV_MODULES_BUILD_ST)
list(SORT OPENCV_MODULES_DISABLED_USER_ST)
list(SORT OPENCV_MODULES_DISABLED_AUTO_ST)
list(SORT OPENCV_MODULES_DISABLED_FORCE_ST)
status("    To be built:"            OPENCV_MODULES_BUILD          THEN ${OPENCV_MODULES_BUILD_ST}          ELSE "-")
status("    Disabled:"               OPENCV_MODULES_DISABLED_USER  THEN ${OPENCV_MODULES_DISABLED_USER_ST}  ELSE "-")
status("    Disabled by dependency:" OPENCV_MODULES_DISABLED_AUTO  THEN ${OPENCV_MODULES_DISABLED_AUTO_ST}  ELSE "-")
status("    Unavailable:"            OPENCV_MODULES_DISABLED_FORCE THEN ${OPENCV_MODULES_DISABLED_FORCE_ST} ELSE "-")
```

----------------------------------------

TITLE: Locating SYCL SDKs and Handling Fallbacks for OpenCV Samples - CMake
DESCRIPTION: This segment attempts to find an available SYCL SDK required for sample compilation, first checking for a default SYCL package, then falling back to oneAPI\'s oneDNN or ComputeCpp SDKs if necessary. It handles environment variables for SDK root locations, configures SDK-specific CMake variables, and uses conditional logic to ensure a SYCL implementation is found, providing diagnostic messages if not. Integration points with dnnl and ComputeCpp help broaden build compatibility across environments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/sycl/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
find_package(SYCL QUIET)  # will oneAPI support this straightforward way?

if(NOT SYCL_FOUND AND NOT OPENCV_SKIP_SAMPLES_SYCL_ONEDNN)
  # lets try scripts from oneAPI:oneDNN component
  if(NOT DEFINED DNNLROOT AND DEFINED ENV{DNNLROOT})
    set(DNNLROOT "$ENV{DNNLROOT}")
  endif()
  # Some verions of called script violate CMake policy and may emit unrecoverable CMake errors
  # Use OPENCV_SKIP_SAMPLES_SYCL=1 / OPENCV_SKIP_SAMPLES_SYCL_ONEDNN to bypass this
  find_package(dnnl CONFIG QUIET HINTS "${DNNLROOT}")
endif()

if(NOT SYCL_FOUND AND NOT OPENCV_SKIP_SAMPLES_SYCL_COMPUTECPP)
  # lets try this SYCL SDK too: https://github.com/codeplaysoftware/computecpp-sdk
  find_package(ComputeCpp QUIET)
  if(ComputeCpp_FOUND)
    set(SYCL_TARGET ComputeCpp::ComputeCpp)
    set(SYCL_FLAGS ${ComputeCpp_FLAGS})
    set(SYCL_INCLUDE_DIRS ${ComputeCpp_INCLUDE_DIRS})
    set(SYCL_LIBRARIES ${ComputeCpp_LIBRARIES})
  endif()
endif()

if(OPENCV_CMAKE_DEBUG_SYCL)
  ocv_cmake_dump_vars("SYCL")  # OpenCV source tree is required
endif()

if(NOT SYCL_TARGET)
  message(STATUS "SYCL/OpenCL samples are skipped: SYCL SDK is required")
  message(STATUS "   - check configuration of SYCL_DIR/SYCL_ROOT/CMAKE_MODULE_PATH")
  message(STATUS "   - ensure that right compiler is selected from SYCL SDK (e.g, clang++): CMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}")
  return()
endif()
```

----------------------------------------

TITLE: Tegra HAL Library Configuration
DESCRIPTION: Sets up the Tegra HAL static library, configures installation paths, and copies required header files to the build directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/carotene/hal/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
add_library(tegra_hal STATIC $<TARGET_OBJECTS:carotene_objs> "dummy.cpp")
set_target_properties(tegra_hal PROPERTIES ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH})
set(OPENCV_SRC_DIR "${CMAKE_SOURCE_DIR}")
if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(tegra_hal EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev)
endif()
target_include_directories(tegra_hal PRIVATE ${CMAKE_CURRENT_SOURCE_DIR} ${OPENCV_SRC_DIR}/modules/core/include)
```

----------------------------------------

TITLE: Threshold Operation Callback Function (C++)
DESCRIPTION: This C++ function applies the cv::threshold operation to the grayscale image using parameters from the trackbars. The thresholded output is displayed in the result window. The function is registered as a callback and is called whenever trackbar values change. Inputs: src_gray image, threshold_value, threshold_type; output: thresholded dst Mat displayed via imshow.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_12

LANGUAGE: C++
CODE:
```
// [Threshold_Demo]\nvoid Threshold_Demo( int, void* )\n{\n  threshold( src_gray, dst, threshold_value, max_BINARY_value, threshold_type );\n  imshow( window_name, dst );\n}\n// [Threshold_Demo]
```

----------------------------------------

TITLE: Reading JPEG Header Information in C using libjpeg
DESCRIPTION: This snippet demonstrates calling `jpeg_read_header` to read JPEG header markers and populate the `cinfo` struct with image information like dimensions and colorspace. The `TRUE` argument indicates that the image data should follow the header. This is typically step 3 in the libjpeg decompression process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_13

LANGUAGE: C
CODE:
```
jpeg_read_header(&cinfo, TRUE);
```

----------------------------------------

TITLE: Opening and Closing XML/YAML/JSON Files with OpenCV FileStorage - Python
DESCRIPTION: This Python snippet shows how to open and close XML/YAML/JSON files using cv2.FileStorage in OpenCV. The constructor and open() method allow specifying the file name and operation mode (WRITE, READ, or APPEND). Use release() to close the file explicitly. Only filenames with suitable extensions (.xml, .yml, .json, etc.) are supported. Requires opencv-python installed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import cv2\n\n# Opening a file for writing\nfs = cv2.FileStorage('output.yml', cv2.FileStorage_WRITE)\n\n# ... perform write operations ...\n\n# Explicitly closing the file\nfs.release()
```

----------------------------------------

TITLE: Creating Actions Runner Configuration
DESCRIPTION: Configuration content for the actions-runner file, including repository information and GitHub access token.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/s390/README.md#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
# Create file /etc/actions-runner
repo=<owner>/<name>
access_token=<ghp_***>
```

----------------------------------------

TITLE: Installing Project Requirements - Console
DESCRIPTION: This command installs all necessary Python dependencies as specified in 'requirements.txt'. This is intended to be run within the already-activated virtual environment. It ensures all Python-side prerequisites for model conversion and utility scripts are available prior to running any code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_c_tutorial.md#2025-04-22_snippet_1

LANGUAGE: console
CODE:
```
pip install -r requirements.txt
```

----------------------------------------

TITLE: Registering ResizeBilinearLayer OpenCV C++
DESCRIPTION: Snippet detailing the registration of a custom layer from TensorFlow to enable model import in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_10

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp Register ResizeBilinearLayer
```

----------------------------------------

TITLE: Pulling libOpenCL.so Library from Android Device - Bash
DESCRIPTION: This snippet pulls the shared OpenCL library from an Android device using adb, placing it in the prepared Android OpenCL SDK 'lib' directory. Requires a device with libOpenCL.so accessible and ADB installed and authorized. The script may need adjustment for device-specific library paths and assumes the device is connected and unlocked.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
cd your_path/ANDROID_OPENCL_SDK && mkdir lib && cd lib\nadb pull /system/vendor/lib64/libOpenCL.so
```

----------------------------------------

TITLE: Destroying JPEG Decompression Object in C using libjpeg
DESCRIPTION: Demonstrates calling `jpeg_destroy_decompress` to release all resources associated with the JPEG decompression object (`cinfo`) when it's no longer needed. This is the final cleanup step (step 8) after finishing decompression or aborting the process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_17

LANGUAGE: C
CODE:
```
jpeg_destroy_decompress(&cinfo);
```

----------------------------------------

TITLE: Building OpenCV Java JAR using Java
DESCRIPTION: Configures and executes the Java-based build process for the OpenCV Java JAR when OPENCV_JAVA_SDK_BUILD_TYPE is set to "JAVA".
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jar/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
elseif(OPENCV_JAVA_SDK_BUILD_TYPE STREQUAL "JAVA")
  configure_file("${CMAKE_CURRENT_SOURCE_DIR}/MANIFEST.MF.in" "${OPENCV_JAVA_DIR}/MANIFEST.MF" @ONLY)
  list(APPEND depends "${OPENCV_JAVA_DIR}/MANIFEST.MF")

  ocv_cmake_byproducts(__byproducts BYPRODUCTS "${OPENCV_JAVA_DIR}/java_sources")
  add_custom_command(OUTPUT "${OPENCV_DEPHELPER}/${the_module}_jar"
      BYPRODUCTS ${__byproducts}  # required for add_custom_target() by ninja
      DEPENDS ${depends}
      COMMAND ${CMAKE_COMMAND} -E touch "${OPENCV_DEPHELPER}/${the_module}_jar"
      COMMAND ${CMAKE_COMMAND}
      -D OPENCV_JAVA_DIR="${OPENCV_JAVA_DIR}/java"
      -D OUTPUT="${OPENCV_JAVA_DIR}/java_sources"
      -P "${CMAKE_CURRENT_SOURCE_DIR}/list_java_sources.cmake"
  )

  add_custom_target(${the_module}_jar_sources
    DEPENDS "${OPENCV_DEPHELPER}/${the_module}_jar"
  )

  list(APPEND CMAKE_JAVA_COMPILE_FLAGS -encoding utf-8 ${OPENCV_EXTRA_JAVA_COMPILE_FLAGS})

  add_jar(${the_module}_jar
          SOURCES "@${OPENCV_JAVA_DIR}/java_sources"
          MANIFEST "${OPENCV_JAVA_DIR}/MANIFEST.MF"
          OUTPUT_NAME "${JAR_NAME_WE}"
          OUTPUT_DIR "${OPENCV_JAR_DIR}")

  add_dependencies(${the_module}_jar ${the_module}_jar_sources)
```

----------------------------------------

TITLE: Defining the Working Folder Structure (Unparsed)
DESCRIPTION: Illustrates the recommended directory structure for the cross-compilation project. It includes separate folders for the OpenCV source, OpenCV Contrib source, and build directories for different target architectures (arm64 and armhf). Users should replace 'kmtr' with their actual account name.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_2

LANGUAGE: unparsed
CODE:
```
/home
  + kmtr                    - please replace your account name.
    + work
      + opencv              - source, cloned from github
      + opencv_contrib      - source, cloned from github
      + build4-full_arm64   - artifact(for aarch64 target), created by cmake
      + build4-full_armhf   - artifact(for armhf target), created by cmake
```

----------------------------------------

TITLE: Configuring Android Color Blob Detection Example
DESCRIPTION: Sets up an Android project for color blob detection using CMake. Defines the project name, adds Android-specific configuration, and establishes OpenCV library dependencies. Sets SDK target to 11 and includes conditional dependency linking.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/color-blob-detection/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-color-blob-detection)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Profiling Memory Usage with Valgrind
DESCRIPTION: These commands profile the memory usage of two implementations of an anisotropic image segmentation algorithm using Valgrind's Massif tool. The output is stored in separate files for each version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
$ valgrind --tool=massif --massif-out-file=ocv.out ./bin/example_tutorial_anisotropic_image_segmentation
```

LANGUAGE: bash
CODE:
```
$ valgrind --tool=massif --massif-out-file=gapi.out ./bin/example_tutorial_porting_anisotropic_image_segmentation_gapi
```

----------------------------------------

TITLE: Creating Algorithm Instances in OpenCV 3.0
DESCRIPTION: Demonstrates the recommended ways to create algorithm instances using makePtr function or static factory methods in OpenCV 3.0, as well as deprecated approaches.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
// good ways
Ptr<SomeAlgo> algo = makePtr<SomeAlgo>(...);
Ptr<SomeAlgo> algo = SomeAlgo::create(...);
```

LANGUAGE: cpp
CODE:
```
// bad ways
Ptr<SomeAlgo> algo = new SomeAlgo(...);
SomeAlgo * algo = new SomeAlgo(...);
SomeAlgo algo(...);
Ptr<SomeAlgo> algo = Algorithm::create<SomeAlgo>("name");
```

----------------------------------------

TITLE: Checking for Alpha Channel Colorspace Extensions at Compile Time in C
DESCRIPTION: Illustrates using the `#ifdef JCS_ALPHA_EXTENSIONS` C preprocessor directive to verify at compile time if the alpha-channel-specific colorspace extensions (like JCS_EXT_RGBA, JCS_EXT_BGRA) are supported by the linked libjpeg-turbo library. This check is useful for applications needing to handle transparency information correctly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/README.md#2025-04-22_snippet_2

LANGUAGE: c
CODE:
```
#ifdef JCS_ALPHA_EXTENSIONS
```

----------------------------------------

TITLE: Applying Adaptive Thresholding in OpenCV - JavaScript
DESCRIPTION: Uses adaptive thresholding to handle images with varying illumination. The threshold is computed for different regions of the image rather than a single global threshold, resulting in better performance under diverse lighting conditions. Dependencies include the OpenCV library for JavaScript. Inputs involve the source and destination arrays, max value, adaptive method, threshold type, block size, and constant C. It outputs an image where each pixel is thresholded according to its neighborhood.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_thresholding/js_thresholding.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
cv.adaptiveThreshold(src, dst, maxValue, adaptiveMethod, thresholdType, blockSize, C);
```

----------------------------------------

TITLE: Keypoint Management in OAST Corner Detection
DESCRIPTION: Handles the dynamic allocation and management of keypoints when corners are detected. Includes logic for expanding capacity when needed and adding new keypoints to the collection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_29

LANGUAGE: C++
CODE:
```
success_homogeneous:
  if(total == nExpectedCorners)
  {
      if(nExpectedCorners == 0)
      {
          nExpectedCorners = 512;
          keypoints.reserve(nExpectedCorners);
      }
      else
      {
          nExpectedCorners *= 2;
          keypoints.reserve(nExpectedCorners);
      }
  }
  keypoints.push_back(KeyPoint(Point2f((float)x, (float)y), 1.0f));
  total++;
  goto homogeneous;
```

----------------------------------------

TITLE: Disabling Compiler Warnings for libtiff
DESCRIPTION: The snippet contains multiple ocv_warnings_disable commands to suppress specific compiler warnings during the build of libtiff. These settings relieve the build process from various unused or compatibility warnings across different compilers and platforms, improving build stability.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
ocv_warnings_disable(CMAKE_C_FLAGS -Wno-unused-but-set-variable -Wmissing-prototypes -Wmissing-declarations -Wundef -Wunused -Wsign-compare
                                   -Wcast-align -Wshadow -Wno-maybe-uninitialized -Wno-pointer-to-int-cast -Wno-int-to-pointer-cast
                                   -Wmisleading-indentation
                                   -Wimplicit-fallthrough
                                   -Wunused-parameter  # clang
                                   -Warray-parameter
                                   -Wstrict-prototypes  # clang15
)
ocv_warnings_disable(CMAKE_CXX_FLAGS -Wmissing-declarations -Wunused-parameter -Wmissing-prototypes
    -Wundef  # tiffiop.h: #if __clang_major__ >= 4
)
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4018 /wd4100 /wd4127 /wd4311 /wd4701 /wd4706) # vs2005
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4244) # vs2008
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4267 /wd4305 /wd4306) # vs2008 Win64
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4703) # vs2012
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4456 /wd4457 /wd4312) # vs2015

ocv_warnings_disable(CMAKE_C_FLAGS /wd4267 /wd4244 /wd4018 /wd4311 /wd4312)
```

----------------------------------------

TITLE: Creating Trackbar for Method Selection (Python)
DESCRIPTION: Uses `cv2.createTrackbar` to add a slider control to the main window. This trackbar allows the user to select the template matching method (represented by an integer). The `MatchingMethod` function is registered as the callback to handle trackbar value changes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_18

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/match_template/match_template.py create_trackbar
```

----------------------------------------

TITLE: Creating Half Image for Testing Histogram Comparison
DESCRIPTION: Creating a half-sized version of the base image to test partial image comparison, which should show a relatively high match with the original.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
Mat hsv_half_down = hsv_base( Range( hsv_base.rows/2, hsv_base.rows ), Range( 0, hsv_base.cols ) );
```

LANGUAGE: java
CODE:
```
Mat hsv_half_down = hsv_base.submat( hsv_base.rows()/2, hsv_base.rows(), 0, hsv_base.cols() );
```

LANGUAGE: python
CODE:
```
hsv_half_down = hsv_base[hsv_base.shape[0]//2:,:]
```

----------------------------------------

TITLE: Configuring OpenCV Build with CMake (Shell)
DESCRIPTION: This shell command runs CMake to configure the OpenCV build, specifying the build system generator, optional configuration options, and the source directory. Required dependencies include CMake, a supported C++ compiler, and platform-appropriate build tools like Make or Ninja. Parameters include <generator> (e.g., "Unix Makefiles" or "Visual Studio 16 2019"), configuration options, and the local path to the OpenCV source code. The output is a set of build configuration files (e.g., Makefiles or IDE projects) in the current directory. Limitations include ensuring all dependencies are available before running this step.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/general_install/general_install.markdown#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
cmake -G<generator> <configuration-options> <source-directory>
```

----------------------------------------

TITLE: Nested Conditional Structure for FAST Corner Detection in C/C++
DESCRIPTION: A complex series of conditionals that implement the pixel comparison logic for the FAST corner detection algorithm. The code compares pixel values at various offsets around a center point against threshold values (c_b and cb) to determine if a pixel is a corner based on intensity differences.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_12

LANGUAGE: C/C++
CODE:
```
goto structured;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset11] < c_b)
          if(ptr[offset10] < c_b)
            goto success_structured;
          else
            goto structured;
        else
          goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    goto structured;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset4] < c_b)
            goto success_structured;
          else
            if(ptr[offset11] < c_b)
              goto success_structured;
            else
              goto structured;
        else
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    goto structured;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset3] < c_b)
            goto success_structured;
          else
            if(ptr[offset10] < c_b)
              goto success_structured;
            else
              goto structured;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    goto structured;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset3] < c_b)
            goto success_structured;
          else
            if(ptr[offset10] < c_b)
              goto success_structured;
            else
              goto structured;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
      else
        if(ptr[offset2] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset4] < c_b)
                goto success_structured;
              else
                goto structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
    else
      goto structured;
  else
    goto structured;
else
  if(ptr[offset2] > cb)
    if(ptr[offset1] > cb)
      if(ptr[offset3] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    if(ptr[offset2] < c_b)
      if(ptr[offset3] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset7] < c_b)
            if(ptr[offset1] < c_b)
              if(ptr[offset6] < c_b)
                goto success_structured;
              else
                goto structured;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset8] < c_b)
                  goto success_structured;
                else
                  goto structured;
              else
                goto structured;
          else
            goto structured;
        else
          goto structured;
      else
        goto structured;
    else
      goto homogeneous;
else
  if(ptr[offset2] > cb)
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              goto success_structured;
            else
              if(ptr[offset8] > cb)
                goto success_structured;
              else
                goto structured;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset7] > cb)
                if(ptr[offset8] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                goto structured;
            else
              goto structured;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                goto success_structured;
              else
                goto structured;
            else
              goto structured;
          else
            goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    if(ptr[offset9] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
```

----------------------------------------

TITLE: Installing Build Scripts and Java Sources in CMake
DESCRIPTION: These CMake commands define installation rules for files related to the Java/Android build. The first `install` command copies the `build.gradle` file from a temporary location (`ANDROID_TMP_INSTALL_BASE_DIR`) to the directory above `JAVA_INSTALL_ROOT`. The second `install` command copies the entire Java source directory (`java_src_dir`) to the `JAVA_INSTALL_ROOT`. Both installations are associated with the `java` component.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
install(FILES "${ANDROID_TMP_INSTALL_BASE_DIR}/opencv/build.gradle" DESTINATION ${JAVA_INSTALL_ROOT}/.. COMPONENT java)

install(DIRECTORY "${java_src_dir}" DESTINATION "${JAVA_INSTALL_ROOT}" COMPONENT java)
```

----------------------------------------

TITLE: Sorting a GpuMat Column In-Place with Thrust
DESCRIPTION: Shows how to sort a column of a GpuMat in-place by using Thrust's sort_by_key algorithm. This example also demonstrates key-value sorting to maintain index correspondence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_5

LANGUAGE: CUDA
CODE:
```
cv::cuda::GpuMat d_random(512, 512, CV_32FC2);
// Fill matrix with random values and indices
thrust::device_ptr<float2> d_random_ptr((float2*)d_random.data);
thrust::transform(
    thrust::counting_iterator<int>(0),
    thrust::counting_iterator<int>(d_random.rows * d_random.cols),
    d_random_ptr,
    [=]__device__(const int idx)
    {
        float2 out;
        // Fill in column 0 with random values
        thrust::default_random_engine rng;
        thrust::uniform_real_distribution<float> dist(0, 10);
        rng.discard(idx);
        out.x = dist(rng);
        // Fill in column 1 with indices
        out.y = idx;
        return out;
    }
);

// Get iterators for column 0 and column 1
auto random_begin = thrust::make_zip_iterator(
    thrust::make_tuple(
        thrust::device_pointer_cast((float*)d_random.data),
        thrust::device_pointer_cast((float*)d_random.data + 1)
    )
);

// Sort column 0 and maintain indices in column 1
thrust::sort_by_key(
    thrust::make_permutation_iterator(
        thrust::device_pointer_cast((float*)d_random.data),
        begin_itr<float2>(d_random)
    ),
    thrust::make_permutation_iterator(
        thrust::device_pointer_cast((float*)d_random.data),
        end_itr<float2>(d_random)
    ),
    thrust::make_permutation_iterator(
        thrust::device_pointer_cast((float*)d_random.data + 1),
        begin_itr<float2>(d_random)
    )
);
```

----------------------------------------

TITLE: Defining a Function to Display Random Text with OpenCV in C++
DESCRIPTION: Defines the function `Displaying_Random_Text` which displays a specific text string ( "Testing text rendering") multiple times (NUMBER) on the input `image`. Within a loop, it generates a random origin point (`org`), font type, font scale, color, and thickness using the `rng` object. It uses `cv::putText` to draw the text and updates the display with `cv::imshow`, including a delay and interruption check via `cv::waitKey`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
@code{.cpp}
int Displaying_Random_Text( Mat image, char* window_name, RNG rng )
{
  int lineType = 8;

  for ( int i = 1; i < NUMBER; i++ )
  {
    Point org;
    org.x = rng.uniform(x_1, x_2);
    org.y = rng.uniform(y_1, y_2);

    putText( image, "Testing text rendering", org, rng.uniform(0,8),
             rng.uniform(0,100)*0.05+0.1, randomColor(rng), rng.uniform(1, 10), lineType);

    imshow( window_name, image );
    if( waitKey(DELAY) >= 0 )
      { return -1; }
  }

  return 0;
}
@endcode
```

----------------------------------------

TITLE: Documenting Enumerations in C++ with Doxygen
DESCRIPTION: Shows how to document enumeration types in C++ using Doxygen, with support for inline comments and autogenerated documentation blocks aligning with Doxygen's comment syntax.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_4

LANGUAGE: c++
CODE:
```
//! type of line
enum LineTypes {
    FILLED  = -1,
    LINE_4  = 4, //!< 4-connected line
    LINE_8  = 8, //!< 8-connected line
    LINE_AA = 16 //!< antialiased line
};
```

----------------------------------------

TITLE: Performing Image Subtraction for Fading Effect in OpenCV C++
DESCRIPTION: This code snippet demonstrates image subtraction using OpenCV. It subtracts a scalar value `Scalar::all(i)` from each pixel of the original `image` and stores the result in `image2`. As `i` increases in the loop, the resulting `image2` becomes progressively darker. OpenCV's subtraction operation includes saturation, ensuring pixel values stay within the valid range (e.g., 0-255 for CV_8UC3).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
@code{.cpp}
image2 = image - Scalar::all(i)
@endcode
```

----------------------------------------

TITLE: Running PyTorch Model Testing with Parameters in Python
DESCRIPTION: This command executes the module in test mode, optionally using default preprocessing for images and parameters. It's designed for PyTorch segmentation model inference.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_12

LANGUAGE: shell
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.segmentation.py_to_py_segm --model_name <pytorch_segm_model_name> --test True --default_img_preprocess <True/False> --evaluate False
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Algorithm in C++
DESCRIPTION: This code snippet implements part of the FAST corner detection algorithm, which checks pixel values against brightness thresholds (cb and c_b) at various offsets to determine if a pixel represents a corner. The algorithm uses multiple conditional branching and goto statements to efficiently identify corner points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset12] > cb)
    if(ptr[offset13] > cb)
      if(ptr[offset14] > cb)
        if(ptr[offset15] > cb)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
if(ptr[offset9] < c_b)
  if(ptr[offset10] < c_b)
    if(ptr[offset11] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset12] < c_b)
          if(ptr[offset13] < c_b)
            if(ptr[offset14] < c_b)
              if(ptr[offset15] < c_b)
                goto is_a_corner;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset7] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset5] < c_b)
                if(ptr[offset6] < c_b)
                  if(ptr[offset7] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset4] < c_b)
              if(ptr[offset5] < c_b)
                if(ptr[offset6] < c_b)
                  if(ptr[offset7] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset5] < c_b)
                if(ptr[offset6] < c_b)
                  if(ptr[offset7] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset12] < c_b)
            if(ptr[offset13] < c_b)
              if(ptr[offset14] < c_b)
                if(ptr[offset15] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset7] > cb)
    if(ptr[offset8] > cb)
      if(ptr[offset9] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset5] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset3] > cb)
                if(ptr[offset2] > cb)
                  if(ptr[offset1] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    if(ptr[offset12] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset12] > cb)
                    if(ptr[offset13] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset12] > cb)
                  if(ptr[offset13] > cb)
                    if(ptr[offset14] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              if(ptr[offset12] > cb)
                if(ptr[offset13] > cb)
                  if(ptr[offset14] > cb)
                    if(ptr[offset15] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
  if(ptr[offset7] < c_b)
    if(ptr[offset8] < c_b)
      if(ptr[offset9] < c_b)
        if(ptr[offset6] < c_b)
          if(ptr[offset5] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset2] < c_b)
                  if(ptr[offset1] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    if(ptr[offset12] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset12] < c_b)
                    if(ptr[offset13] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
```

----------------------------------------

TITLE: Including OpenCV GPU Header in C++
DESCRIPTION: Includes the necessary header file `opencv2/gpu.hpp` to use OpenCV's GPU module functionalities, including GPU-specific data structures like `cv::cuda::GpuMat` and GPU-accelerated algorithms. This header is essential for any C++ code utilizing OpenCV's CUDA features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
#include <opencv2/gpu.hpp>        // GPU structures and methods
```

----------------------------------------

TITLE: Building RISC-V Clang Toolchain and QEMU
DESCRIPTION: This script downloads and builds the RISC-V Clang toolchain and QEMU. It sets up the necessary environment for cross-compiling OpenCV for RISC-V targets.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/riscv/README.md#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
./prepare_riscv_toolchain_qemu.sh
```

----------------------------------------

TITLE: Calculating Image Moments using OpenCV Java
DESCRIPTION: This Java snippet illustrates the calculation of image moments using OpenCV's libraries. Like the C++ version, it utilizes moments, contourArea, and arcLength functions to analyze image shapes. Java OpenCV library (version >= 3.0) is required for running this code. Inputs include images processed for contour detection and outputs are image moments and other related metrics.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/moments/moments.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;
// Original code can be found at the mentioned OpenCV repository
```

----------------------------------------

TITLE: Writing and Reading Maps (Dicts) - OpenCV Python
DESCRIPTION: This Python snippet demonstrates serialization of Python dictionaries to XML/YAML/JSON in OpenCV. Use startWriteStruct() with cv2.FileNode_MAP, then write key-value pairs. Read values by using getNode(key).at() or getNode(key).real(). Requires opencv-python installed. Keys must be strings; values should be primitives or NumPy arrays.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_10

LANGUAGE: Python
CODE:
```
fs.startWriteStruct('mymap', cv2.FileNode_MAP)\nfs.write('one', 1)\nfs.write('two', 2)\nfs.endWriteStruct()\n\nnode = fs.getNode('mymap')\none = int(node.getNode('one').real())
```

----------------------------------------

TITLE: Drawing a Line in C++
DESCRIPTION: Implementation of the MyLine function that draws a line between two points in OpenCV C++. The function takes the image, start and end points, and uses the line() function with specified thickness and line type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_15

LANGUAGE: cpp
CODE:
```
void MyLine( Mat img, Point start, Point end )
{
  int thickness = 2;
  int lineType = LINE_8;

  line( img,
    start,
    end,
    Scalar( 0, 0, 0 ),
    thickness,
    lineType );
}
```

----------------------------------------

TITLE: Classifying Corners Using Pixel Intensity Thresholds - OpenCV - C/C++
DESCRIPTION: Determines whether the center pixel in a candidate patch is a feature corner by comparing pixel intensities at multiple offsets using threshold values `cb` (brighter) and `c_b` (darker). The code is structured using nested if-else statements and gotos for maximal performance, as required in core image processing routines where every CPU cycle counts. Dependencies include a correctly indexed pointer array `ptr[]`, a set of offset indices, and defined threshold variables; inputs are pixel intensities, and the output is branching control flow to either `is_a_corner` or `is_not_a_corner` labels depending on the pattern's match.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_3

LANGUAGE: C
CODE:
```
if(ptr[offset7] > cb)
  if(ptr[offset8] > cb)
    if(ptr[offset9] > cb)
      if(ptr[offset10] > cb)
        if(ptr[offset11] > cb)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
```

LANGUAGE: C
CODE:
```
if(ptr[offset12] < c_b)
  if(ptr[offset7] < c_b)
    if(ptr[offset8] < c_b)
      if(ptr[offset9] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            if(ptr[offset13] < c_b)
              if(ptr[offset14] < c_b)
                if(ptr[offset6] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset15] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
```

LANGUAGE: C
CODE:
```
if(ptr[offset4] < c_b)
  if(ptr[offset11] > cb)
    if(ptr[offset12] > cb)
      if(ptr[offset13] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset14] > cb)
            if(ptr[offset15] > cb)
              if(ptr[offset1] > cb)
                goto is_a_corner;
              else
                if(ptr[offset8] > cb)
                  if(ptr[offset9] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset5] > cb)
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset14] > cb)
                if(ptr[offset15] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset11] < c_b)
      if(ptr[offset7] < c_b)
        if(ptr[offset8] < c_b)
          if(ptr[offset9] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset6] < c_b)
                if(ptr[offset5] < c_b)
                  if(ptr[offset3] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset12] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset12] < c_b)
                    if(ptr[offset13] < c_b)
                      if(ptr[offset14] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    if(ptr[offset14] < c_b)
                      if(ptr[offset15] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset11] > cb)
    if(ptr[offset12] > cb)
      if(ptr[offset13] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset14] > cb)
            if(ptr[offset15] > cb)
              if(ptr[offset1] > cb)
                goto is_a_corner;
              else
                if(ptr[offset8] > cb)
                  if(ptr[offset9] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset5] > cb)
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset14] > cb)
                if(ptr[offset15] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else

```

----------------------------------------

TITLE: Configuring TBB Backend with CMake
DESCRIPTION: This snippet configures TBB as a parallel backend for an OpenCV example project. It attempts to find TBB and TBB headers, setting up the project if found. The `example-tbb.cpp` is included as an executable, and the necessary directories and libraries are linked. It uses the TBB library and the opencv_core module, though support for a deprecated flag is provided until OpenCV 5.0.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/tutorial_code/core/parallel_backend/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
if(NOT OPENCV_EXAMPLES_SKIP_PARALLEL_BACKEND_TBB
    AND NOT OPENCV_EXAMPLES_SKIP_TBB
    AND NOT OPENCV_EXAMPLE_SKIP_TBB  # deprecated (to be removed in OpenCV 5.0)
)
  project(opencv_example_tbb_backend)
  find_package(TBB QUIET)
  if(NOT TBB_FOUND)
    find_path(TBB_INCLUDE_DIR NAMES "tbb/tbb.h")
    find_library(TBB_LIBRARY NAMES "tbb")
  endif()
  if(TBB_INCLUDE_DIR AND TBB_LIBRARY)
    add_executable(opencv_example_tbb_backend example-tbb.cpp)
    target_include_directories(opencv_example_tbb_backend SYSTEM PRIVATE ${TBB_INCLUDE_DIR})
    target_link_libraries(opencv_example_tbb_backend PRIVATE
        opencv_core
        ${TBB_LIBRARY}
    )
  endif()
endif()
```

----------------------------------------

TITLE: Advanced Mouse Event Handling for Drawing Shapes in OpenCV with Python
DESCRIPTION: This advanced demo allows drawing rectangles or circles by dragging the mouse, similar to a paint application. It uses global variables to track drawing state and mode, and demonstrates more complex event handling with cv.setMouseCallback().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_mouse_handling/py_mouse_handling.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

drawing = False # true if mouse is pressed
mode = True # if True, draw rectangle. Press 'm' to toggle to curve
ix,iy = -1,-1

# mouse callback function
def draw_circle(event,x,y,flags,param):
    global ix,iy,drawing,mode

    if event == cv.EVENT_LBUTTONDOWN:
        drawing = True
        ix,iy = x,y

    elif event == cv.EVENT_MOUSEMOVE:
        if drawing == True:
            if mode == True:
                cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)
            else:
                cv.circle(img,(x,y),5,(0,0,255),-1)

    elif event == cv.EVENT_LBUTTONUP:
        drawing = False
        if mode == True:
            cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)
        else:
            cv.circle(img,(x,y),5,(0,0,255),-1)
```

----------------------------------------

TITLE: Compiling OpenCV Example with Makefile
DESCRIPTION: Compile an example OpenCV C++ program using g++ with a Makefile, linking against OpenCV core library. Helps verify OpenCV installation on target system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_25

LANGUAGE: make
CODE:
```
a.out : main.cpp
    g++ main.cpp -o a.out \
        -I/usr/local/include/opencv4 \
        -lopencv_core
```

----------------------------------------

TITLE: Adding TFLite Flatbuffers Support Option for DNN Module - CMake
DESCRIPTION: Defines an option to enable TFLite support based on the presence of Flatbuffers, validating that Flatbuffers is available if TFLite is requested. Adds related libraries and headers when support is enabled. Inputs are the build target for Flatbuffers and OPENCV_DNN_TFLITE; outputs include flatbuffers library and TFLite schema includes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_15

LANGUAGE: CMake
CODE:
```
ocv_option(OPENCV_DNN_TFLITE "Build with TFLite support" (TARGET ocv.3rdparty.flatbuffers))
if(TARGET ocv.3rdparty.flatbuffers AND OPENCV_DNN_TFLITE)
  if(NOT HAVE_FLATBUFFERS)
    message(FATAL_ERROR "DNN: TFLite is not supported without enabled 'flatbuffers'. Check build configuration.")
  endif()
  list(APPEND libs ocv.3rdparty.flatbuffers)
  list(APPEND fw_hdrs "${CMAKE_CURRENT_LIST_DIR}/misc/tflite/schema_generated.h")
  list(APPEND fw_inc "${CMAKE_CURRENT_LIST_DIR}/misc/tflite")

  # Schema is generated by this command:
  #add_custom_command(
  #      OUTPUT "${CMAKE_CURRENT_BINARY_DIR}/schema_generated.h"
  #      COMMAND flatbuffers::flatc --cpp -o "${CMAKE_CURRENT_BINARY_DIR}" "${CMAKE_CURRENT_LIST_DIR}/src/tflite/schema.fbs")
endif()
```

----------------------------------------

TITLE: Extracting a Single Color Channel using OpenCV Split/Merge (C++)
DESCRIPTION: Demonstrates extracting a specific color channel from a BGR source image (`src`). It uses `cv::split` to separate the channels into a vector of Mats (`spl`). It then iterates through the channels (0=B, 1=G, 2=R), replacing the Mats for the *unwanted* channels (where index `i` is not equal to the desired `channel`) with Mats filled with zeros (`Mat::zeros`). Finally, it uses `cv::merge` to combine the selected channel's original Mat with the zeroed Mats back into a 3-channel BGR image (`res`). Requires the source image (`src`), a `std::vector<Mat>` (`spl`), the target channel index (`channel`), and the image size (`S`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
split(src, spl);                 // process - extract only the correct channel
for( int i =0; i < 3; ++i)
   if (i != channel)
      spl[i] = Mat::zeros(S, spl[0].type());
merge(spl, res);
```

----------------------------------------

TITLE: Defining OpenCV Compilation Options
DESCRIPTION: This section lists multiple OCV_OPTION functions that define compilation options for integrating various features and third-party libraries into the OpenCV build. Each option includes a description, default state (ON or OFF), visibility conditions, and verification checks for dependencies. This provides a flexible way to customize the OpenCV build for different environments and requirements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENVINO "Include Intel OpenVINO toolkit support" (WITH_INF_ENGINE)
  VISIBLE_IF TRUE
  VERIFY TARGET ocv.3rdparty.openvino)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_WEBNN "Include WebNN support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_WEBNN)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_JASPER "Include JPEG2K support (Jasper)" ON
  VISIBLE_IF NOT IOS AND NOT XROS
  VERIFY HAVE_JASPER)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENJPEG "Include JPEG2K support (OpenJPEG)" ON
  VISIBLE_IF NOT IOS AND NOT XROS
  VERIFY HAVE_OPENJPEG)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_JPEG "Include JPEG support" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_JPEG)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_JPEGXL "Include JPEG XL support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_JPEGXL)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_WEBP "Include WebP support" ON
  VISIBLE_IF NOT WINRT
  VERIFY HAVE_WEBP)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENEXR "Include ILM support via OpenEXR" ((WIN32 OR ANDROID OR APPLE) OR BUILD_OPENEXR) OR NOT CMAKE_CROSSCOMPILING
  VISIBLE_IF NOT APPLE_FRAMEWORK AND NOT WINRT
  VERIFY HAVE_OPENEXR)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENGL "Include OpenGL support" OFF
  VISIBLE_IF NOT ANDROID AND NOT WINRT
  VERIFY HAVE_OPENGL)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENVX "Include OpenVX support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_OPENVX)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENNI "Include OpenNI support" OFF
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_OPENNI)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENNI2 "Include OpenNI2 support" OFF
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_OPENNI2)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_PNG "Include PNG support" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_PNG)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_SPNG "Include SPNG support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_SPNG)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_GDCM "Include DICOM support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_GDCM)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_PVAPI "Include Prosilica GigE support" OFF
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_PVAPI)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_ARAVIS "Include Aravis GigE support" OFF
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT AND NOT WIN32
  VERIFY HAVE_ARAVIS_API)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_QT "Build with Qt Backend support" OFF
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_QT)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_WIN32UI "Build with Win32 UI Backend support" ON
  VISIBLE_IF WIN32 AND NOT WINRT
  VERIFY HAVE_WIN32UI)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_TBB "Include Intel TBB support" OFF
  VISIBLE_IF NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_TBB)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_HPX "Include Ste||ar Group HPX support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_HPX)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENMP "Include OpenMP support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_OPENMP)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_PTHREADS_PF "Use pthreads-based parallel_for" ON
  VISIBLE_IF NOT WIN32 OR MINGW
  VERIFY HAVE_PTHREADS_PF)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_TIFF "Include TIFF support" ON
  VISIBLE_IF NOT IOS AND NOT XROS
  VERIFY HAVE_TIFF)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_V4L "Include Video 4 Linux support" ON
  VISIBLE_IF UNIX AND NOT ANDROID AND NOT APPLE
  VERIFY HAVE_CAMV4L OR HAVE_CAMV4L2 OR HAVE_VIDEOIO)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_DSHOW "Build VideoIO with DirectShow support" ON
  VISIBLE_IF WIN32 AND NOT ARM AND NOT WINRT
  VERIFY HAVE_DSHOW)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_MSMF "Build VideoIO with Media Foundation support" NOT MINGW
  VISIBLE_IF WIN32
  VERIFY HAVE_MSMF)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_MSMF_DXVA "Enable hardware acceleration in Media Foundation backend" WITH_MSMF
  VISIBLE_IF WIN32
  VERIFY HAVE_MSMF_DXVA)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_XIMEA "Include XIMEA cameras support" OFF
  VISIBLE_IF NOT ANDROID AND NOT WINRT
  VERIFY HAVE_XIMEA)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_UEYE "Include UEYE camera support" OFF
  VISIBLE_IF NOT ANDROID AND NOT APPLE AND NOT WINRT
  VERIFY HAVE_UEYE)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_XINE "Include Xine support (GPL)" OFF
  VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID
  VERIFY HAVE_XINE)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_CLP "Include Clp support (EPL)" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_CLP)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENCL "Include OpenCL Runtime support" (NOT ANDROID AND NOT CV_DISABLE_OPTIMIZATION)
  VISIBLE_IF NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_OPENCL)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENCL_SVM "Include OpenCL Shared Virtual Memory support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_OPENCL_SVM) # experimental
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENCLAMDFFT "Include AMD OpenCL FFT library support" ON
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_CLAMDFFT)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENCLAMDBLAS "Include AMD OpenCL BLAS library support" ON
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_CLAMDBLAS)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_DIRECTX "Include DirectX support" ON
  VISIBLE_IF WIN32 AND NOT WINRT
  VERIFY HAVE_DIRECTX)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_DIRECTML "Include DirectML support" ON
  VISIBLE_IF WIN32 AND NOT WINRT
  VERIFY HAVE_DIRECTML)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OPENCL_D3D11_NV "Include NVIDIA OpenCL D3D11 support" WITH_DIRECTX
  VISIBLE_IF WIN32 AND NOT WINRT
  VERIFY HAVE_OPENCL_D3D11_NV)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_LIBREALSENSE "Include Intel librealsense support" OFF
  VISIBLE_IF NOT WITH_INTELPERC
  VERIFY HAVE_LIBREALSENSE)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_VA "Include VA support" (X86_64 OR X86)
  VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID
  VERIFY HAVE_VA)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_VA_INTEL "Include Intel VA-API/OpenCL support" (X86_64 OR X86)
  VISIBLE_IF UNIX AND NOT APPLE AND NOT ANDROID
  VERIFY HAVE_VA_INTEL)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_MFX "Include Intel Media SDK support" OFF
  VISIBLE_IF (UNIX AND NOT ANDROID) OR (WIN32 AND NOT WINRT AND NOT MINGW)
  VERIFY HAVE_MFX)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_GDAL "Include GDAL Support" OFF
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS AND NOT WINRT
  VERIFY HAVE_GDAL)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_GPHOTO2 "Include gPhoto2 library support" OFF
  VISIBLE_IF UNIX AND NOT ANDROID AND NOT IOS AND NOT XROS
  VERIFY HAVE_GPHOTO2)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_LAPACK "Include Lapack library support" (NOT CV_DISABLE_OPTIMIZATION)
  VISIBLE_IF NOT ANDROID AND NOT IOS AND NOT XROS
  VERIFY HAVE_LAPACK)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_ITT "Include Intel ITT support" ON
  VISIBLE_IF NOT APPLE_FRAMEWORK
  VERIFY HAVE_ITT)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_PROTOBUF "Enable libprotobuf" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_PROTOBUF)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_IMGCODEC_GIF "Include GIF support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_IMGCODEC_GIF)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_IMGCODEC_HDR "Include HDR support" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_IMGCODEC_HDR)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_IMGCODEC_SUNRASTER "Include SUNRASTER support" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_IMGCODEC_SUNRASTER)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_IMGCODEC_PXM "Include PNM (PBM,PGM,PPM) and PAM formats support" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_IMGCODEC_PXM)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_IMGCODEC_PFM "Include PFM formats support" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_IMGCODEC_PFM)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_QUIRC "Include library QR-code decoding" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_QUIRC)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_ANDROID_MEDIANDK "Use Android Media NDK for Video I/O (Android)" (ANDROID_NATIVE_API_LEVEL GREATER 20)
  VISIBLE_IF ANDROID
  VERIFY HAVE_ANDROID_MEDIANDK)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_ANDROID_NATIVE_CAMERA "Use Android NDK for Camera I/O (Android)" (ANDROID_NATIVE_API_LEVEL GREATER 23)
  VISIBLE_IF ANDROID
  VERIFY HAVE_ANDROID_NATIVE_CAMERA)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_ONNX "Include Microsoft ONNX Runtime support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_ONNX)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_TIMVX "Include Tim-VX support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_TIMVX)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(OBSENSOR_USE_ORBBEC_SDK "Use Orbbec SDK as backend to support more camera models and platforms (force to ON on MacOS)" OFF)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_OBSENSOR "Include obsensor support (Orbbec 3D Cameras)" ON
  VISIBLE_IF (WIN32 AND NOT ARM AND NOT WINRT AND NOT MINGW) OR ( UNIX AND NOT APPLE AND NOT ANDROID) OR (APPLE AND AARCH64 AND NOT IOS)
  VERIFY HAVE_OBSENSOR)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_CANN "Include CANN support" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_CANN)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_FLATBUFFERS "Include Flatbuffers support (required by DNN/TFLite importer)" ON
  VISIBLE_IF TRUE
  VERIFY HAVE_FLATBUFFERS)
```

LANGUAGE: CMake
CODE:
```
OCV_OPTION(WITH_ZLIB_NG "Use zlib-ng instead of zlib" OFF
  VISIBLE_IF TRUE
  VERIFY HAVE_ZLIB_NG)
```

----------------------------------------

TITLE: Generating Subset of WinRT Configurations using setup_winrt.bat
DESCRIPTION: Executes the `setup_winrt.bat` script to generate Visual Studio project files for both Windows Phone and Windows Store platforms, version 8.1, targeting only the x86 architecture. Omitting the `-b` flag means manual building is required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_2

LANGUAGE: batch
CODE:
```
setup_winrt.bat "WP,WS" "8.1" "x86"
```

----------------------------------------

TITLE: Find Contours in OpenCV Java
DESCRIPTION: Finds and stores contours in a list structure, utilizing OpenCV in Java. Dependencies include OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_11

LANGUAGE: Java
CODE:
```
List<MatOfPoint> contours = new ArrayList<>();
Mat hierarchy = new Mat();
Imgproc.findContours(edges, contours, hierarchy, Imgproc.RETR_TREE, Imgproc.CHAIN_APPROX_SIMPLE);
```

----------------------------------------

TITLE: Conditionally Configuring CUDA Documentation Exclusion in CMake
DESCRIPTION: Sets a flag `OPENCV_DOCS_EXCLUDE_CUDA` to ON by default. It then checks if the 'cudev' module is present in the `OPENCV_MODULES_EXTRA` list. If 'cudev' is found, it sets the exclusion flag to OFF and adds 'CUDA_MODULES' to the list of enabled Doxygen sections.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
set(OPENCV_DOCS_EXCLUDE_CUDA ON)
if(";${OPENCV_MODULES_EXTRA};" MATCHES ";cudev;")
  set(OPENCV_DOCS_EXCLUDE_CUDA OFF)
  list(APPEND CMAKE_DOXYGEN_ENABLED_SECTIONS "CUDA_MODULES")
endif()
```

----------------------------------------

TITLE: Example CMake Configuration Output for OpenCV Build (Text)
DESCRIPTION: Shows a sample snippet of the text output generated by CMake after configuration. This output verifies that key dependencies like GUI toolkits (GTK+), Video I/O libraries (DC1394, FFMPEG, GStreamer, V4L), third-party libraries (Eigen, TBB), and Python interpreter/libraries/numpy are correctly detected and configured for the build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_14

LANGUAGE: text
CODE:
```
...
--   GUI:
--     GTK+ 2.x:                    YES (ver 2.24.19)
--     GThread :                    YES (ver 2.36.3)

--   Video I/O:
--     DC1394 2.x:                  YES (ver 2.2.0)
--     FFMPEG:                      YES
--       codec:                     YES (ver 54.92.100)
--       format:                    YES (ver 54.63.104)
--       util:                      YES (ver 52.18.100)
--       swscale:                   YES (ver 2.2.100)
--       gentoo-style:              YES
--     GStreamer:
--       base:                      YES (ver 0.10.36)
--       video:                     YES (ver 0.10.36)
--       app:                       YES (ver 0.10.36)
--       riff:                      YES (ver 0.10.36)
--       pbutils:                   YES (ver 0.10.36)

--     V4L/V4L2:                    Using libv4l (ver 1.0.0)

--   Other third-party libraries:
--     Use Eigen:                   YES (ver 3.1.4)
--     Use TBB:                     YES (ver 4.0 interface 6004)

--   Python:
--     Interpreter:                 /usr/bin/python2 (ver 2.7.5)
--     Libraries:                   /lib/libpython2.7.so (ver 2.7.5)
--     numpy:                       /usr/lib/python2.7/site-packages/numpy/core/include (ver 1.7.1)
--     packages path:               lib/python2.7/site-packages

...
```

----------------------------------------

TITLE: Configuring Cocoa Backend for HighGUI in CMake
DESCRIPTION: Sets up the Cocoa backend for OpenCV HighGUI when HAVE_COCOA is enabled on macOS platforms. Adds the necessary source files and links to the Cocoa framework.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_14

LANGUAGE: CMake
CODE:
```
elseif(HAVE_COCOA)
  set(OPENCV_HIGHGUI_BUILTIN_BACKEND "COCOA")
  add_definitions(-DHAVE_COCOA)
  list(APPEND highgui_srcs ${CMAKE_CURRENT_LIST_DIR}/src/window_cocoa.mm)
  list(APPEND HIGHGUI_LIBRARIES "-framework Cocoa")
endif()
```

----------------------------------------

TITLE: Defining Custom Command to Generate OpenCV Java Bindings using Python in CMake
DESCRIPTION: Sets up a CMake custom command to execute the Java bindings generation process. It specifies the expected output files (`java_generated_files`), primarily a timestamp file (`${OPENCV_DEPHELPER}/gen_opencv_java_source`) indicating completion. The command executes the Python script `gen_java.py`, passing paths to helper scripts and the generated `gen_java.json` configuration file. It defines the working directory and lists numerous dependencies, including the generator scripts, common source files (`deps`), and remapped template files (`__remap_targets`), ensuring the command re-runs if any dependency changes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/generator/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
set(java_generated_files
    # "${OPENCV_JAVA_SIGNATURES_FILE}"
    "${OPENCV_DEPHELPER}/gen_opencv_java_source"
)

add_custom_command(
    OUTPUT ${java_generated_files}
    COMMAND ${PYTHON_DEFAULT_EXECUTABLE} "${JAVA_SOURCE_DIR}/generator/gen_java.py" -p "${JAVA_SOURCE_DIR}/../python/src2/gen2.py" -c "${CONFIG_FILE}"
    COMMAND ${CMAKE_COMMAND} -E touch "${OPENCV_DEPHELPER}/gen_opencv_java_source"
    WORKING_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}"
    DEPENDS "${JAVA_SOURCE_DIR}/generator/gen_java.py"
            "${JAVA_SOURCE_DIR}/../python/src2/gen2.py"
            "${JAVA_SOURCE_DIR}/../python/src2/hdr_parser.py"
            # don't, result of file(WRITE): "${CMAKE_CURRENT_BINARY_DIR}/gen_java.json"
            ${deps} ${__remap_targets}
            # not allowed (file(WRITE) result): "${CONFIG_FILE}"
    COMMENT "Generate files for Java bindings"
)
```

----------------------------------------

TITLE: Performing Point Polygon Test with OpenCV in Java
DESCRIPTION: This Java example shows how to utilize OpenCV's Imgproc.pointPolygonTest method to determine if a point is inside, outside, or on the edge of a polygon. The code uses MatOfPoint for contour definition, and Point objects for test points. OpenCV for Java must be properly set up. The code optionally visualizes the results using OpenCV's HighGui.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/point_polygon_test/point_polygon_test.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;\nimport org.opencv.imgproc.Imgproc;\nimport org.opencv.highgui.HighGui;\n\npublic class PointPolygonTestDemo {\n    public static void main(String[] args) {\n        System.loadLibrary(Core.NATIVE_LIBRARY_NAME);\n        // Define the polygon (contour)\n        MatOfPoint contour = new MatOfPoint(\n            new Point(100, 100),\n            new Point(200, 100),\n            new Point(200, 200),\n            new Point(100, 200)\n        );\n        // Test points\n        Point testPoint1 = new Point(150, 150);\n        Point testPoint2 = new Point(250, 150);\n        // Perform the test\n        double result1 = Imgproc.pointPolygonTest(new MatOfPoint2f(contour.toArray()), testPoint1, false);\n        double result2 = Imgproc.pointPolygonTest(new MatOfPoint2f(contour.toArray()), testPoint2, false);\n        // Output results\n        System.out.println("Test Point 1 (" + testPoint1.x + "," + testPoint1.y + "): " + result1);\n        System.out.println("Test Point 2 (" + testPoint2.x + "," + testPoint2.y + "): " + result2);\n        // Visualization (optional)\n        Mat img = Mat.zeros(300, 300, CvType.CV_8UC3);\n        Imgproc.polylines(img, Arrays.asList(contour), true, new Scalar(255,255,255), 2);\n        Imgproc.circle(img, testPoint1, 5, new Scalar(0,255,0), -1);\n        Imgproc.circle(img, testPoint2, 5, new Scalar(0,0,255), -1);\n        HighGui.imshow("Point Polygon Test", img);\n        HighGui.waitKey();\n        System.exit(0);\n    }\n}\n
```

----------------------------------------

TITLE: Appending Multiple TAGFILES in Doxyfile - Doxygen Configuration
DESCRIPTION: This snippet shows how to append multiple TAGFILES replacements in Doxygen, handling more than one external documentation source. By using the backslash (\) for line continuation, additional tag files such as those for libstdc++ can be seamlessly integrated. Dependencies include all referenced .tag files being available at the specified local paths. This is intended to expand cross-referencing: inputs are a continuation of previously set TAGFILES, outputs are doc links to multiple external projects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/cross_referencing/tutorial_cross_referencing.markdown#2025-04-22_snippet_2

LANGUAGE: Doxygen
CODE:
```
TAGFILES = ./docs/doxygen-tags/libstdc++.tag=https://gcc.gnu.org/onlinedocs/libstdc++/latest-doxygen \
           ./docs/doxygen-tags/opencv.tag=http://docs.opencv.org/4.11.0
```

----------------------------------------

TITLE: Defining 12-Bit JPEG Pixel Sample Data Structures in C
DESCRIPTION: Defines C typedefs for handling 12-bit pixel sample data within the libjpeg library. `J12SAMPLE` represents a single 12-bit pixel component (0-4095), typically implemented as `short`. `J12SAMPROW` is a pointer to a row of `J12SAMPLE` values. `J12SAMPARRAY` points to an array of rows. `J12SAMPIMAGE` points to an array of component arrays. This follows the same pointer-per-row structure as the 8-bit version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/structure.txt#2025-04-22_snippet_1

LANGUAGE: c
CODE:
```
    typedef something J12SAMPLE;        a pixel component value, 0..MAXJ12SAMPLE
    typedef J12SAMPLE *J12SAMPROW;      ptr to a row of samples
    typedef J12SAMPROW *J12SAMPARRAY;   ptr to a list of rows
    typedef J12SAMPARRAY *J12SAMPIMAGE; ptr to a list of color-component arrays
```

----------------------------------------

TITLE: Implementing AGAST 7-12 Detector in OpenCV (C++)
DESCRIPTION: This C++ snippet implements the AGAST 7-12d algorithm for corner detection in images using the OpenCV library. It uses nested conditional checks and jump statements to determine if a pixel is a corner by comparing intensity values against a threshold. The function takes an image, a keypoints vector, and a threshold as inputs, reserves space for keypoints, computes pixel offsets, and iterates over pixels to identify corners. Dependencies include OpenCV and specifically the 'cv::Mat' and 'KeyPoint' classes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
static void AGAST_7_12d(InputArray _img, std::vector<KeyPoint>& keypoints, int threshold)
{
    cv::Mat img;
    if(!_img.getMat().isContinuous())
      img = _img.getMat().clone();
    else
      img = _img.getMat();

    size_t total = 0;
    int xsize = img.cols;
    int ysize = img.rows;
    size_t nExpectedCorners = keypoints.capacity();
    int x, y;
    int xsizeB = xsize - 4;
    int ysizeB = ysize - 3;
    int width;

    keypoints.resize(0);

    int pixel_7_12d_[16];
    makeAgastOffsets(pixel_7_12d_, (int)img.step, AgastFeatureDetector::AGAST_7_12d);

    short offset0 = (short) pixel_7_12d_[0];
    short offset1 = (short) pixel_7_12d_[1];
    short offset2 = (short) pixel_7_12d_[2];
    short offset3 = (short) pixel_7_12d_[3];
    short offset4 = (short) pixel_7_12d_[4];
    short offset5 = (short) pixel_7_12d_[5];
    short offset6 = (short) pixel_7_12d_[6];
    short offset7 = (short) pixel_7_12d_[7];
    short offset8 = (short) pixel_7_12d_[8];
    short offset9 = (short) pixel_7_12d_[9];
    short offset10 = (short) pixel_7_12d_[10];
    short offset11 = (short) pixel_7_12d_[11];

    width = xsize;

    for(y = 3; y < ysizeB; y++)
    {
        x = 2;
        while(true)
        {
          homogeneous:
          {
            x++;
            if(x > xsizeB)
                break;
            else
            {
                const unsigned char* const ptr = img.ptr() + y*width + x;
                const int cb = *ptr + threshold;
                const int c_b = *ptr - threshold;
                if(ptr[offset0] > cb)
                  if(ptr[offset5] > cb)
                    if(ptr[offset2] > cb)
                      if(ptr[offset9] > cb)
                        if(ptr[offset1] > cb)
                          if(ptr[offset6] > cb)
                            if(ptr[offset3] > cb)
                              if(ptr[offset4] > cb)
                                goto success_homogeneous;
                              else
                                if(ptr[offset10] > cb)
                                  if(ptr[offset11] > cb)
                                    goto success_structured;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset8] > cb)
                                if(ptr[offset10] > cb)
                                  if(ptr[offset11] > cb)
                                    goto success_structured;
                                  else
                                    if(ptr[offset4] > cb)
                                      if(ptr[offset7] > cb)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset11] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset4] > cb)
                                  goto success_homogeneous;
                                else
                                  if(ptr[offset10] > cb)
                                    goto success_homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                if(ptr[offset8] > cb)
                                  if(ptr[offset10] > cb)
                                    goto success_homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset6] > cb)
                            if(ptr[offset7] > cb)
                              if(ptr[offset8] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset3] > cb)
                                    goto success_structured;
                                  else
                                    if(ptr[offset10] > cb)
                                      goto success_structured;
                                    else
                                      goto homogeneous;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto success_structured;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                      else
                        if(ptr[offset3] > cb)
                          if(ptr[offset4] > cb)
                            if(ptr[offset1] > cb)
                              if(ptr[offset6] > cb)
                                goto success_homogeneous;
                              else
                                if(ptr[offset11] > cb)
                                  goto success_homogeneous;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset7] > cb)
                                  if(ptr[offset8] > cb)
                                    goto success_homogeneous;
                                  else
                                ...

```

----------------------------------------

TITLE: Accessing Total Pixel Count using OpenCV in Python
DESCRIPTION: Shows how to get the total number of pixels in the image (calculated as rows * columns * channels for color images) using the `img.size` attribute provided by the underlying NumPy array.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_4

LANGUAGE: python
CODE:
```
>>> print( img.size )
562248
```

----------------------------------------

TITLE: Enabling Python 3 Wrapper in CMake Configuration
DESCRIPTION: Modify CMake configuration to enable Python 3 wrapper for OpenCV. It requires Python 3 paths and libraries to be specified and includes additional options for numpy and Python executable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_18

LANGUAGE: bash
CODE:
```
PYTHON3_REALPATH=`realpath /usr/bin/python3`
PYTHON3_BASENAME=`basename ${PYTHON3_REALPATH}`
PKG_CONFIG_PATH=/usr/lib/aarch64-linux-gnu/pkgconfig:/usr/share/pkgconfig \
    PKG_CONFIG_LIBDIR=/usr/lib/aarch64-linux-gnu \
    PKG_CONFIG_SYSROOT_DIR=/ \
        cmake -S opencv \
              -B build4-full_arm64 \
              -DCMAKE_TOOLCHAIN_FILE=/home/kmtr/work/opencv/platforms/linux/aarch64-gnu.toolchain.cmake \
              -DOPENCV_EXTRA_MODULES_PATH=opencv_contrib/modules \
              -DPYTHON3_NUMPY_INCLUDE_DIRS="/usr/local/lib/${PYTHON3_BASENAME}/dist-packages/numpy/core/include/" \
              -DPYTHON3_INCLUDE_PATH="/usr/include/${PYTHON3_BASENAME};/usr/include/" \
              -DPYTHON3_LIBRARIES=`find /usr/lib/aarch64-linux-gnu/ -name libpython*.so` \
              -DPYTHON3_EXECUTABLE="/usr/bin/${PYTHON3_BASENAME}" \
              -DPYTHON3_CVPY_SUFFIX=".so" \
              -GNinja
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree Implementation in C++
DESCRIPTION: A portion of the FAST corner detection algorithm's decision tree that examines pixel values at various offset positions around a central point. The algorithm compares each pixel against brightness thresholds (c_b and cb) to determine if a point is a corner feature, using nested conditional statements with early termination paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_33

LANGUAGE: C++
CODE:
```
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
if(ptr[offset11] < c_b)
  if(ptr[offset7] < c_b)
    if(ptr[offset8] < c_b)
      if(ptr[offset9] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset6] < c_b)
            if(ptr[offset5] < c_b)
              if(ptr[offset3] < c_b)
                {} // goto success_homogeneous;
              else
                if(ptr[offset12] < c_b)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset12] < c_b)
                if(ptr[offset13] < c_b)
                  if(ptr[offset14] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset12] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  if(ptr[offset11] > cb)
    if(ptr[offset12] > cb)
      if(ptr[offset13] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset14] > cb)
            if(ptr[offset15] > cb)
              if(ptr[offset1] > cb)
                {} // goto success_homogeneous;
              else
                if(ptr[offset8] > cb)
                  if(ptr[offset9] > cb)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset5] > cb)
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset14] > cb)
                if(ptr[offset15] > cb)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
  if(ptr[offset11] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset9] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset12] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset6] < c_b)
                  if(ptr[offset5] < c_b)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset14] < c_b)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  if(ptr[offset14] < c_b)
                    if(ptr[offset15] < c_b)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
if(ptr[offset2] < c_b)
  if(ptr[offset9] > cb)
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset12] > cb)
            if(ptr[offset13] > cb)
              if(ptr[offset14] > cb)
                if(ptr[offset15] > cb)
                  {} // goto success_homogeneous;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                if(ptr[offset5] > cb)
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
```

----------------------------------------

TITLE: CMake Macro for Finding Specific Source Files
DESCRIPTION: Defines a CMake macro `glob_more_specific_sources` that searches for source files of a specific type (H, CPP, or JAVA) within predefined subdirectories (`cpp/` or `java/`) relative to a given root path. It takes the type (`_type`), root path (`_root`), and an output list variable (`_output`) as arguments, appending the found file paths to the output list. It uses `file(GLOB ...)` for pattern matching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
# UTILITY: glob specific sources and append them to list (type is in H, CPP, JAVA)
macro(glob_more_specific_sources _type _root _output)
  unset(_masks)
  if(${_type} STREQUAL "H")
    set(_masks "${_root}/cpp/*.h" "${_root}/cpp/*.hpp")
  elseif(${_type} STREQUAL "CPP")
    set(_masks "${_root}/cpp/*.cpp")
  elseif(${_type} STREQUAL "JAVA")
    set(_masks "${_root}/java/*.java" "${_root}/java/*.java.in")
  endif()
  if (_masks)
    file(GLOB _result ${_masks})
    list(APPEND ${_output} ${_result})
  else()
    message(WARNING "Bad argument passed to macro: skipped")
  endif()
endmacro()
```

----------------------------------------

TITLE: Checking Out OpenCV 2.4.13 Tag using Git (Shell)
DESCRIPTION: Creates new local branches named `v2.4.13` based on the `2.4.13` tag in both the `opencv` and `opencv_extra` repositories. This step is necessary to isolate and build a specific tagged version (2.4.13) of OpenCV 2.4.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_12

LANGUAGE: Shell
CODE:
```
# Within the opencv directory:
$ git checkout -b v2.4.13 2.4.13
```

LANGUAGE: Shell
CODE:
```
# Within the opencv_extra directory:
$ git checkout -b v2.4.13 2.4.13
```

----------------------------------------

TITLE: Configuring Android QR Detection Example Project in CMake
DESCRIPTION: Sets up an Android project for QR code detection using OpenCV. Defines the project name and configures it with required OpenCV library dependencies, targeting Android SDK version 11.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/qr-detection/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-qr-detection)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Initializing JavaScript Bindings Generator Module in CMake
DESCRIPTION: Sets up the JavaScript bindings generator module, configures paths, and creates necessary directories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/generator/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(MODULE_NAME "js_bindings_generator")
set(OPENCV_MODULE_IS_PART_OF_WORLD FALSE)
ocv_add_module(${MODULE_NAME} INTERNAL)

set(OPENCV_JS_BINDINGS_DIR "${CMAKE_CURRENT_BINARY_DIR}" CACHE INTERNAL "")
file(REMOVE_RECURSE "${OPENCV_JS_BINDINGS_DIR}/gen")
file(MAKE_DIRECTORY "${OPENCV_JS_BINDINGS_DIR}/gen")
file(REMOVE "${OPENCV_DEPHELPER}/gen_opencv_js_source")  # force re-run after CMake
```

----------------------------------------

TITLE: Installing OpenCV System-wide with Make
DESCRIPTION: Command to install OpenCV system-wide using Make, requires root privileges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_18

LANGUAGE: bash
CODE:
```
sudo make install
```

----------------------------------------

TITLE: Checking for libjpeg-turbo Colorspace Extensions at Compile Time in C
DESCRIPTION: Shows how to use the `#ifdef JCS_EXTENSIONS` C preprocessor directive to conditionally compile code based on the availability of libjpeg-turbo's basic colorspace extensions (like JCS_EXT_RGB, JCS_EXT_BGRX). This allows applications to adapt to different builds or versions of the library and ensures compatibility.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/README.md#2025-04-22_snippet_1

LANGUAGE: c
CODE:
```
#ifdef JCS_EXTENSIONS
```

----------------------------------------

TITLE: Calculating Optical Flow with Lucas-Kanade in JavaScript
DESCRIPTION: This snippet demonstrates how to calculate optical flow using Lucas-Kanade method in OpenCV.js. It employs the function cv.calcOpticalFlowPyrLK with multiple parameters to track feature points across video frames. Important prerequisites include the creation of image pyramids and feature points specification. The inputs are two consecutive frames, while the output contains the new positions of tracked points. This method is suitable for sparse optical flow and might not handle large motions well without pyramids.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_video/js_lucas_kanade/js_lucas_kanade.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
cv.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts, status, err, winSize = new cv.Size(21, 21), maxLevel = 3, criteria = new cv.TermCriteria(cv.TermCriteria_COUNT + cv.TermCriteria_EPS, 30, 0.01), flags = 0, minEigThreshold = 1e-4);
```

----------------------------------------

TITLE: Setting Default DNN Backend Option in CMake Cache - CMake
DESCRIPTION: This snippet defines a cached CMake string variable 'OPENCV_DNN_BACKEND_DEFAULT' to control the default backend used by the DNN module, falling back to DNN_BACKEND_OPENCV if the variable is empty. Affects runtime backend selection. No dependencies required; users can change this setting via the CMake interface.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_23

LANGUAGE: CMake
CODE:
```
set(OPENCV_DNN_BACKEND_DEFAULT "" CACHE STRING "Default backend used by the DNN module (DNN_BACKEND_OPENCV if empty)")
```

----------------------------------------

TITLE: Initializing Filter Arguments
DESCRIPTION: Sets up initial parameters for the filter including kernel size and window name. Creates display window for output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
int kernel_size = 3;
Mat dst;
char window_name[] = "filter2D Demo";
namedWindow(window_name, WINDOW_AUTOSIZE);
```

----------------------------------------

TITLE: Initializing and Configuring SVM Parameters for Non-Linear Classification (Java)
DESCRIPTION: Java implementation of setting up SVM parameters for non-linear classification, including kernel type, C value for misclassification penalty, and termination criteria with sufficiently high iteration count.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_6

LANGUAGE: Java
CODE:
```
// Set up SVM's parameters
SVM svm = SVM.create();
svm.setType(SVM.C_SVC);
svm.setKernel(SVM.RBF);
// When C is small, the decision boundary will be smooth
// When C is large, the decision boundary can better classify all training points but may lead to overfitting
svm.setC(0.1);
// Set termination criteria for the optimization
svm.setTermCriteria(new TermCriteria(TermCriteria.MAX_ITER, (int) 1e7, 1e-6));
```

----------------------------------------

TITLE: Converting Integer FourCC to String using Bitwise Operations (C++)
DESCRIPTION: Illustrates converting an integer FourCC codec identifier back into its 4-character string representation using bitwise AND (`&`) and right shift (`>>`) operations. This method manually extracts each byte corresponding to a character and stores them in a character array, adding a null terminator (`0`). Requires the integer FourCC code (`ex`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
char EXT[] = {ex & 0XFF , (ex & 0XFF00) >> 8,(ex & 0XFF0000) >> 16,(ex & 0XFF000000) >> 24, 0};
```

----------------------------------------

TITLE: Building OpenCV from Source using CMake and Make (Shell)
DESCRIPTION: These two shell commands initiate building the OpenCV project either via CMake's build wrapper or directly invoking Make. Dependencies are the successful execution of CMake configuration and appropriate build tools installed on the system. <build-directory> is the folder created during configuration; <build-options> are additional options for the build process. Outputs are compiled binaries and libraries placed in the build directory. Direct use of 'make' requires using Unix-like platforms and pre-generated Makefiles.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/general_install/general_install.markdown#2025-04-22_snippet_2

LANGUAGE: shell
CODE:
```
cmake --build <build-directory> <build-options>
```

LANGUAGE: shell
CODE:
```
make
```

----------------------------------------

TITLE: Configuring OpenCV Android Tutorial Project with CMake
DESCRIPTION: Sets up an Android project for OpenCV tutorial example with conditional dependencies based on Java library build settings. Configures native dependencies, SDK target version, and OpenGL dependencies. Includes project to the main OpenCV Android examples when target exists.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-4-opencl/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-tutorial-4-opencl)

if(BUILD_FAT_JAVA_LIB)
  set(native_deps opencv_java)
else()
  set(native_deps opencv_imgproc)
endif()

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}"
    LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}"
    SDK_TARGET 21 "${ANDROID_SDK_TARGET}"
    NATIVE_DEPS ${native_deps} -lGLESv2 -lEGL
    COPY_LIBS YES
)
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Setting Path for Additional OpenCV Modules in CMake
DESCRIPTION: This CMake snippet initializes a cache path for additional OpenCV modules. These paths can be multiple and are separated by semicolons, allowing for flexible module management during configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: CMake
CODE:
```
set(OPENCV_EXTRA_MODULES_PATH \"\" CACHE PATH \"Where to look for additional OpenCV modules (can be ;-separated list of paths)\")
```

----------------------------------------

TITLE: Modifying Kernel Package in OpenCV G-API
DESCRIPTION: This snippet demonstrates how to remove an inappropriate kernel from the kernel package to address limitations in OpenCV's G-API Fluid backend. The primary change involves excluding the Fluid-based Box filter to fall back on OpenCV's default implementation, thereby overcoming static kernel size constraints. This modification results in enhanced memory performance and fixes app crashing issues.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/porting_anisotropic_image_segmentation/porting_anisotropic_image_segmentation_gapi_fluid.cpp kernel_hotfix
```

----------------------------------------

TITLE: Including OpenCV Header Conditionally in Objective-C++ Precompiled Header
DESCRIPTION: This preprocessor directive checks if the code is being compiled as C++ (`__cplusplus` is defined) and, if so, includes the main OpenCV header file (`opencv2/opencv.hpp`). This is typically added to the project's precompiled header file (`.pch`) to make OpenCV functions available throughout the project when mixing Objective-C and C++, ensuring compatibility.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/hello/hello.markdown#2025-04-22_snippet_0

LANGUAGE: m
CODE:
```
#ifdef __cplusplus
#import <opencv2/opencv.hpp>
#endif
```

----------------------------------------

TITLE: Storing Camera Calibration Results in OpenCV - XML Output File
DESCRIPTION: This snippet illustrates the XML structure used to store the results of a camera calibration operation performed by the OpenCV-based application. The file includes calibration date, images size, the camera matrix and its standard deviation, distortion coefficients and their uncertainties, and the average re-projection error. This output file is typically named by the user (e.g., camParams.xml), must conform to OpenCV's XML storage format, and can be loaded for later processing or reuse. All numeric values are recorded in double-precision where relevant, and the output reflects the confidence and quality measures of the calibration session.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/interactive_calibration/interactive_calibration.markdown#2025-04-22_snippet_1

LANGUAGE: xml
CODE:
```
<?xml version=\"1.0\"?>\n<opencv_storage>\n<calibrationDate>\"Thu 07 Apr 2016 04:23:03 PM MSK\"</calibrationDate>\n<framesCount>21</framesCount>\n<cameraResolution>\n  1280 720</cameraResolution>\n<cameraMatrix type_id=\"opencv-matrix\">\n  <rows>3</rows>\n  <cols>3</cols>\n  <dt>d</dt>\n  <data>\n    1.2519588293098975e+03 0. 6.6684948780852471e+02 0.\n    1.2519588293098975e+03 3.6298123112613683e+02 0. 0. 1.</data></cameraMatrix>\n<cameraMatrix_std_dev type_id=\"opencv-matrix\">\n  <rows>4</rows>\n  <cols>1</cols>\n  <dt>d</dt>\n  <data>\n    0. 1.2887048808572649e+01 2.8536856683866230e+00\n    2.8341737483430314e+00</data></cameraMatrix_std_dev>\n<dist_coeffs type_id=\"opencv-matrix\">\n  <rows>1</rows>\n  <cols>5</cols>\n  <dt>d</dt>\n  <data>\n    1.3569117181595716e-01 -8.2513063822554633e-01 0. 0.\n    1.6412101575010554e+00</data></dist_coeffs>\n<dist_coeffs_std_dev type_id=\"opencv-matrix\">\n  <rows>5</rows>\n  <cols>1</cols>\n  <dt>d</dt>\n  <data>\n    1.5570675523402111e-02 8.7229075437543435e-02 0. 0.\n    1.8382427901856876e-01</data></dist_coeffs_std_dev>\n<avg_reprojection_error>4.2691743074130178e-01</avg_reprojection_error>\n</opencv_storage>
```

----------------------------------------

TITLE: YOLOv10 Model Execution
DESCRIPTION: Shell commands for running YOLOv10 model with specific parameters for resolution and preprocessing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_yolo/dnn_yolo.markdown#2025-04-22_snippet_6

LANGUAGE: sh
CODE:
```
cd opencv_extra/testdata/dnn
python download_models.py yolov10
cd ..
export OPENCV_TEST_DATA_PATH=$(pwd)
cd <build directory of OpenCV>

./bin/example_dnn_yolo_detector --model=onnx/models/yolov10s.onnx --yolo=yolov10 --width=640 --height=480  --scale=0.003921568627 --padvalue=114
```

----------------------------------------

TITLE: Building LLVM on Linux using CMake and Make
DESCRIPTION: This snippet illustrates the steps for configuring and building the LLVM tools on a Linux system using CMake and Make. It requires LLVM source files and CMake installed to perform the build. The code compiles LLVM with assertions enabled and targets the 'X86' architecture.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown#2025-04-22_snippet_0

LANGUAGE: Bash
CODE:
```
cd llvm_root
mkdir build && cd build
cmake -DLLVM_ENABLE_TERMINFO=OFF -DLLVM_TARGETS_TO_BUILD="X86" -DLLVM_ENABLE_ASSERTIONS=ON -DCMAKE_BUILD_TYPE=Release ..
make -j4
```

----------------------------------------

TITLE: Configuring CMake for Windows Embedded with Visual Studio 2013
DESCRIPTION: Command for configuring CMake build system for Windows Embedded using Visual Studio 2013 as generator and specifying the installed SDK. Uses the arm-wince toolchain file to set up cross-compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/wince/readme.md#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013" -A "MySDK WEC2013" -DCMAKE_TOOLCHAIN_FILE:FILEPATH=../platforms/wince/arm-wince.toolchain.cmake
```

----------------------------------------

TITLE: Setting an Environment Variable in Windows Batch Script
DESCRIPTION: This Windows batch script snippet demonstrates how to define an environment variable ('MY_ENV_VARIABLE') and execute an application ('my_app.exe') that may respond to it. Dependencies: none beyond Windows CMD. Parameters: The environment variable name and its desired value. Limitations: Applies to the current command-line session; GUI-based setting is also possible as described.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/env_reference/env_reference.markdown#2025-04-22_snippet_0

LANGUAGE: bat
CODE:
```
set MY_ENV_VARIABLE=true\nC:\\my_app.exe
```

----------------------------------------

TITLE: Registering InterpLayer OpenCV C++
DESCRIPTION: Demonstrates registering a new layer type in OpenCV to import Caffe models with custom layers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_8

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp Register InterpLayer
```

----------------------------------------

TITLE: Enabling s390 DFLTCC Inflate Optimization for ZLIB in CMake
DESCRIPTION: Checks if the DFLTCC inflate optimization is enabled (WITH_DFLTCC_INFLATE) for the s390 architecture. If enabled, it adds the S390_DFLTCC_INFLATE definition and appends the corresponding source file (`dfltcc_inflate.c`) to the ZLIB architecture-specific source list.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_22

LANGUAGE: cmake
CODE:
```
        if(WITH_DFLTCC_INFLATE)
            add_definitions(-DS390_DFLTCC_INFLATE)
            list(APPEND ZLIB_ARCH_SRCS ${ARCHDIR}/dfltcc_inflate.c)
        endif()
```

----------------------------------------

TITLE: Generating OpenJPEG Configuration Headers in CMake
DESCRIPTION: Uses the `configure_file` command to generate `opj_config.h` and `opj_config_private.h` in the build directory (`CMAKE_CURRENT_BINARY_DIR/openjp2`). These files are created from corresponding `.cmake.in` template files, substituting `@VAR@` placeholders with the values of CMake variables determined during the configuration process (e.g., results from header/function checks like `HAVE_STDINT_H`, `OPJ_BIG_ENDIAN`). The `@ONLY` flag ensures only `@VAR@` substitutions occur.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: cmake
CODE:
```
#-----------------------------------------------------------------------------
# opj_config.h generation (2/2)
configure_file(
  ${CMAKE_CURRENT_LIST_DIR}/openjp2/opj_config.h.cmake.in
  ${CMAKE_CURRENT_BINARY_DIR}/openjp2/opj_config.h
  @ONLY
)

configure_file(
  ${CMAKE_CURRENT_LIST_DIR}/openjp2/opj_config_private.h.cmake.in
  ${CMAKE_CURRENT_BINARY_DIR}/openjp2/opj_config_private.h
  @ONLY
)
```

----------------------------------------

TITLE: Enable Compiler Sanitizers in CMake
DESCRIPTION: This script segment adds different compiler sanitizers like Address, Memory, Thread, and Undefined based on the WITH_SANITIZER setting. Each sanitizer corresponds to specific runtime checks for memory and logic errors during debugging.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: CMake
CODE:
```
if(WITH_SANITIZER STREQUAL "Address")
    add_address_sanitizer()
elif(WITH_SANITIZER STREQUAL "Memory")
    add_memory_sanitizer()
elif(WITH_SANITIZER STREQUAL "Thread")
    add_thread_sanitizer()
elif(WITH_SANITIZER STREQUAL "Undefined")
    add_undefined_sanitizer()
endif()
```

----------------------------------------

TITLE: Defining ViewController Interface with Camera (Objective-C)
DESCRIPTION: This code defines the ViewController interface, including IBOutlets for the image view and button, and adds the CvVideoCamera property for handling video input.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/video_processing/video_processing.markdown#2025-04-22_snippet_1

LANGUAGE: Objective-C
CODE:
```
#import <opencv2/videoio/cap_ios.h>
using namespace cv;

@interface ViewController : UIViewController
{
    IBOutlet UIImageView* imageView;
    IBOutlet UIButton* button;
    CvVideoCamera* videoCamera;
}

- (IBAction)actionStart:(id)sender;

@property (nonatomic, retain) CvVideoCamera* videoCamera;

@end
```

----------------------------------------

TITLE: Setting OpenVX HAL Cache Variables
DESCRIPTION: Defines cache variables for OpenVX HAL configuration including version, libraries, headers, and include directories for use in other parts of the build system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openvx/hal/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
set(OPENVX_HAL_FOUND TRUE CACHE INTERNAL "")
set(OPENVX_HAL_VERSION 0.0.1 CACHE INTERNAL "")
set(OPENVX_HAL_LIBRARIES "openvx_hal" CACHE INTERNAL "")
set(OPENVX_HAL_HEADERS "${CMAKE_CURRENT_SOURCE_DIR}/openvx_hal.hpp" CACHE INTERNAL "")
set(OPENVX_HAL_INCLUDE_DIRS "${CMAKE_CURRENT_SOURCE_DIR}" "${OPENCV_3P_OPENVX_DIR}/include" "${OPENVX_INCLUDE_DIR}" CACHE INTERNAL "")
```

----------------------------------------

TITLE: Interactive Image Pyramid Loop in C++
DESCRIPTION: Enters an infinite loop that waits for key presses. Pressing 'i' triggers image upsampling (`pyrUp`), 'o' triggers downsampling (`pyrDown`), and ESC exits the loop. The updated image is displayed after each operation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
    //![loop]
    Mat tmp = src;
    Mat dst = tmp;

    for(;;)
    {
        imshow( window_name, dst );
        char c = (char)waitKey(0);

        if( c == 27 )
        { break; }
        else if( c == 'i' )
        { pyrUp( tmp, dst, Size( tmp.cols*2, tmp.rows*2 ) ); printf("** Zoom In: Image x 2 \n"); }
        else if( c == 'o' )
        { pyrDown( tmp, dst, Size( tmp.cols/2, tmp.rows/2 ) ); printf("** Zoom Out: Image / 2 \n"); }

        tmp = dst;
    }
    //![loop]

    return EXIT_SUCCESS;
}
```

----------------------------------------

TITLE: Conditional Branch Logic for FAST Corner Detection in C++
DESCRIPTION: Complex nested conditional structure that compares pixel values at different offsets against threshold values (cb and c_b) to determine if a point is a corner. The algorithm uses goto statements to jump to success or continue checking when certain conditions are met.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_27

LANGUAGE: C++
CODE:
```
if(ptr[offset10] > cb)
  if(ptr[offset11] > cb)
    goto success_structured;
  else
    goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
  if(ptr[offset9] > cb)
    if(ptr[offset6] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset3] > cb)
            goto success_structured;
          else
            if(ptr[offset10] > cb)
              goto success_structured;
            else
              goto structured;
        else
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    goto structured;
else
  goto structured;
else
  if(ptr[offset7] < c_b)
    if(ptr[offset9] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset5] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                goto success_structured;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset4] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              goto structured;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              if(ptr[offset1] < c_b)
                goto success_structured;
              else
                if(ptr[offset6] < c_b)
                  goto success_structured;
                else
                  goto structured;
            else
              goto structured;
          else
            goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    goto structured;
else
  if(ptr[offset5] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset9] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset8] > cb)
                goto success_structured;
              else
                if(ptr[offset1] > cb)
                  if(ptr[offset2] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                goto structured;
          else
            if(ptr[offset11] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                goto structured;
            else
              goto structured;
        else
          goto structured;
      else
        if(ptr[offset2] > cb)
          if(ptr[offset3] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset1] > cb)
                if(ptr[offset6] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset8] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
    else
      goto structured;
  else
    if(ptr[offset5] < c_b)
      if(ptr[offset7] < c_b)
        if(ptr[offset9] < c_b)
          if(ptr[offset6] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset8] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset1] < c_b)
                    if(ptr[offset2] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
              else
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset11] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
          else
            goto structured;
        else
```

----------------------------------------

TITLE: Implementing Custom Serialization Methods for File I/O (Inside Class) - OpenCV Python
DESCRIPTION: In this Python snippet, custom read and write methods are added to the custom class for manual serialization and deserialization with OpenCV FileStorage. The write method inserts all attributes, while read pulls named values from the node. The functions assume the nodes conform to the written format.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_14

LANGUAGE: Python
CODE:
```
def write(self, fs):\n    fs.startWriteStruct('MyData', cv2.FileNode_MAP)\n    fs.write('A', self.A)\n    fs.write('X', self.X)\n    fs.write('id', self.name)\n    fs.endWriteStruct()\ndef read(self, node):\n    self.A = int(node.getNode('A').real())\n    self.X = float(node.getNode('X').real())\n    self.name = node.getNode('id').string()
```

----------------------------------------

TITLE: Installing Python 3 Dependencies on Target
DESCRIPTION: Install Python 3 minimal and numpy packages on the target system to enable Python 3 wrapper support for OpenCV. It uses apt package manager to handle installations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_22

LANGUAGE: bash
CODE:
```
sudo apt install -y \
    python3-minimal \
    python3-numpy
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Decision Tree in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm. It compares pixel intensities at specific offsets around a central pixel, using a series of nested if-else statements to determine if the pixel is a corner point. The algorithm continues or jumps to specific labels based on these comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_32

LANGUAGE: C++
CODE:
```
continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
if(ptr[offset12] < c_b)
  if(ptr[offset7] < c_b)
    if(ptr[offset8] < c_b)
      if(ptr[offset9] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            if(ptr[offset13] < c_b)
              if(ptr[offset6] < c_b)
                {} // goto success_homogeneous;
              else
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  if(ptr[offset12] > cb)
    if(ptr[offset13] > cb)
      if(ptr[offset14] > cb)
        if(ptr[offset15] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              {} // goto success_homogeneous;
            else
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset8] > cb)
              if(ptr[offset9] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset7] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset9] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
  if(ptr[offset12] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset9] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset6] < c_b)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset15] < c_b)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
if(ptr[offset4] < c_b)
  if(ptr[offset11] > cb)
    if(ptr[offset12] > cb)
      if(ptr[offset13] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset14] > cb)
            if(ptr[offset15] > cb)
              if(ptr[offset1] > cb)
                {} // goto success_homogeneous;
              else
                if(ptr[offset8] > cb)
                  if(ptr[offset9] > cb)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset5] > cb)
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset14] > cb)
                if(ptr[offset15] > cb)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
```

----------------------------------------

TITLE: Configuring OpenMP Plugin for OpenCV Core
DESCRIPTION: CMake configuration script that sets up the OpenMP parallel processing plugin for OpenCV. It establishes minimum CMake version, configures project paths, enables OpenMP support, and creates the plugin target with necessary dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/misc/plugins/parallel_openmp/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.5)
project(opencv_core_parallel_openmp CXX)

get_filename_component(OpenCV_SOURCE_DIR "${CMAKE_CURRENT_LIST_DIR}/../../../../.." ABSOLUTE)
include("${OpenCV_SOURCE_DIR}/cmake/OpenCVPluginStandalone.cmake")

# scan dependencies
set(WITH_OPENMP ON)
include("${OpenCV_SOURCE_DIR}/modules/core/cmake/parallel/init.cmake")

message(STATUS "OpenMP: ${OpenMP_CXX_VERSION}")
ocv_create_plugin(core "opencv_core_parallel_openmp" "ocv.3rdparty.openmp" "OPENMP" "src/parallel/parallel_openmp.cpp")
```

----------------------------------------

TITLE: Checking OpenCV CMake Package Files
DESCRIPTION: Command to check the presence of OpenCV CMake package files in the build directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_17

LANGUAGE: bash
CODE:
```
ls OpenCV*
```

----------------------------------------

TITLE: Setting Up Emscripten LLVM Upstream Backend for SIMD Support - Bash
DESCRIPTION: This series of bash commands updates and activates the latest upstream version of Emscripten SDK, which is required to build OpenCV.js with SIMD optimizations. It uses './emsdk' to update, install, activate, and set up the environment. These steps are prerequisites when building with SIMD support enabled and should be run prior to the build command.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_17

LANGUAGE: bash
CODE:
```
./emsdk update\n./emsdk install latest-upstream\n./emsdk activate latest-upstream\nsource ./emsdk_env.sh
```

----------------------------------------

TITLE: Collecting OpenCV Headers for JavaScript Bindings in CMake
DESCRIPTION: Gathers headers from specified OpenCV modules and filters out unwanted headers based on predefined criteria.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/generator/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(opencv_hdrs "")
foreach(m ${OPENCV_JS_MODULES})
  list(APPEND opencv_hdrs ${OPENCV_MODULE_${m}_HEADERS})
endforeach(m)

# header blacklist
ocv_list_filterout(opencv_hdrs "modules/.*.h$")
ocv_list_filterout(opencv_hdrs "modules/core/.*/cuda")
ocv_list_filterout(opencv_hdrs "modules/core/.*/opencl")
ocv_list_filterout(opencv_hdrs "modules/core/include/opencv2/core/opengl.hpp")
ocv_list_filterout(opencv_hdrs "modules/core/include/opencv2/core/ocl.hpp")
ocv_list_filterout(opencv_hdrs "modules/cuda.*")
ocv_list_filterout(opencv_hdrs "modules/cudev")
ocv_list_filterout(opencv_hdrs "modules/core/.*/hal/")
ocv_list_filterout(opencv_hdrs "modules/.*/detection_based_tracker.hpp") # Conditional compilation
ocv_list_filterout(opencv_hdrs "modules/core/include/opencv2/core/utils/*.private.*")
ocv_list_filterout(opencv_hdrs "modules/core/include/opencv2/core/utils/instrumentation.hpp")
ocv_list_filterout(opencv_hdrs "modules/core/include/opencv2/core/utils/trace*")

ocv_update_file("${CMAKE_CURRENT_BINARY_DIR}/headers.txt" "${opencv_hdrs}")
```

----------------------------------------

TITLE: Installing OpenCV via Homebrew on macOS
DESCRIPTION: This command uses the Homebrew package manager to install a pre-built version of OpenCV on macOS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_9

LANGUAGE: bash
CODE:
```
brew install opencv
```

----------------------------------------

TITLE: Basic Control Flow for Buffered-Image JPEG Decoding in C
DESCRIPTION: Demonstrates the main control flow sequence for buffered-image decoding, including initialization, processing multiple output passes, and cleanup. Uses jpeg*_read_scanlines() functions for different data precision ranges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_53

LANGUAGE: c
CODE:
```
jpeg_create_decompress()
set data source
jpeg_read_header()
set overall decompression parameters
cinfo.buffered_image = TRUE;    /* select buffered-image mode */
jpeg_start_decompress()
for (each output pass) {
    adjust output decompression parameters if required
    jpeg_start_output()         /* start a new output pass */
    for (all scanlines in image) {
        jpeg_read_scanlines()   /* Use jpeg12_read_scanlines() for
                                   9-bit through 12-bit data precision
                                   and jpeg16_read_scanlines() for
                                   13-bit through 16-bit data
                                   precision. */
        display scanlines
    }
    jpeg_finish_output()        /* terminate output pass */
}
jpeg_finish_decompress()
jpeg_destroy_decompress()
```

----------------------------------------

TITLE: SVM Kernel Mapping Function
DESCRIPTION: Mathematical representation of mapping 2D points to 3D space using phi function for kernel transformation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_svm/py_svm_basics/py_svm_basics.markdown#2025-04-22_snippet_1

LANGUAGE: latex
CODE:
```
\phi (p) = (p_{1}^2,p_{2}^2,\sqrt{2} p_1 p_2)\n\phi (q) = (q_{1}^2,q_{2}^2,\sqrt{2} q_1 q_2)
```

----------------------------------------

TITLE: Initial Configuring and Printing Options with CMake
DESCRIPTION: The code demonstrates how to configure OpenCV initially and print all available options using CMake. It includes options to display help messages and advanced settings. The commands require pre-installed CMake and access to the OpenCV source folder.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_0

LANGUAGE: sh
CODE:
```
# initial configuration
cmake ../opencv

# print all options
cmake -L

# print all options with help message
cmake -LH

# print all options including advanced
cmake -LA
```

----------------------------------------

TITLE: Defining the FLANN Module for OpenCV with Python Bindings - CMake
DESCRIPTION: Declares and configures the FLANN module within the OpenCV CMake build system, specifying a dependency on opencv_core and enabling Python wrapper generation with the WRAP python option. Requires the ocv_define_module CMake macro, typically provided by OpenCV's build infrastructure. Accepts the module name, required dependencies, and options for bindings. The input is a set of identifiers; the output is the configuration of the FLANN module within the OpenCV build tree. Applicable only within OpenCV CMake-based builds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/flann/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
ocv_define_module(flann opencv_core WRAP python)
```

----------------------------------------

TITLE: Declaring Variables (Parsing Arguments) for Laplacian Demo in Python
DESCRIPTION: Initializes Python variables for the Laplacian demo by parsing command-line arguments using argparse to get the input image path. Sets default values for kernel size, scale, delta, and output depth (ddepth). Requires argparse and cv2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
#! [variables]
# [variables]
# Declare the variables we are going to use
kernel_size = 3
scale = 1
delta = 0
ddepth = cv.CV_16S
# [variables]
# ! [variables]
```

----------------------------------------

TITLE: Decompressing Partial Scanlines in JPEG Images (C)
DESCRIPTION: This function allows decompression of only a portion of each row in a JPEG image. It must be called after jpeg_start_decompress() and before any calls to jpeg*_read_scanlines() or jpeg*_skip_scanlines(). The function adjusts xoffset to fall on an iMCU boundary and updates width accordingly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_19

LANGUAGE: C
CODE:
```
jpeg_crop_scanline (j_decompress_ptr cinfo, JDIMENSION *xoffset,
                            JDIMENSION *width)
                /* Use jpeg12_crop_scanline() for 12-bit data precision. */
```

----------------------------------------

TITLE: Displaying Help for setup_winrt.bat
DESCRIPTION: Executes the `setup_winrt.bat` script with the `-h` flag to display its available command-line options and usage instructions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_3

LANGUAGE: batch
CODE:
```
setup_winrt.bat -h
```

----------------------------------------

TITLE: FAST Corner Detection Conditional Logic in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm implementation. It uses nested if-else statements to compare pixel values at various offsets to determine if a point is a corner. The algorithm checks surrounding pixels against a threshold and makes decisions based on these comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_13

LANGUAGE: C++
CODE:
```
else
  if(ptr[offset2] < c_b)
    if(ptr[offset9] > cb)
      if(ptr[offset5] > cb)
        if(ptr[offset1] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset11] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset11] > cb)
                      if(ptr[offset10] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset7] > cb)
                if(ptr[offset8] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset4] > cb)
                      goto is_a_corner;
                    else
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset3] > cb)
                      if(ptr[offset4] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset7] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset3] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset3] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset5] < c_b)
              if(ptr[offset1] < c_b)
                if(ptr[offset6] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset7] < c_b)
                    if(ptr[offset8] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset1] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset9] < c_b)
        if(ptr[offset5] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset6] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  goto is_a_corner;
                else
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      if(ptr[offset4] < c_b)
                        if(ptr[offset7] < c_b)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset11] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset8] < c_b)
                    if(ptr[offset10] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset3] < c_b)
                      goto is_a_corner;
                    else
                      if(ptr[offset10] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset10] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset10] < c_b)
```

----------------------------------------

TITLE: CMake Macro for Copying Common Java Test Files
DESCRIPTION: Defines a CMake macro `copy_common_tests` to recursively copy files from a source location (`_src_location`) matching `res/*` or `src/*` patterns to a destination location (`_dst_location`). It uses `add_custom_command` to perform the copy operation only if the source file is newer or doesn't exist at the destination. It also appends both the source and destination file paths to a dependency list variable (`_deps`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
# UTILITY: copy common java test files and add them to _deps
# copy_common_tests(<source-folder> <destination-folder> <variable-to-store-deps>)
macro(copy_common_tests _src_location _dst_location _deps)
  set(_src ${_src_location})
  set(_dst ${_dst_location})
  file(GLOB_RECURSE _files RELATIVE "${_src}" "${_src}/res/*" "${_src}/src/*")
  foreach(f ${_files})
    add_custom_command(
        OUTPUT "${_dst}/${f}"
        COMMAND ${CMAKE_COMMAND} -E copy_if_different "${_src}/${f}" "${_dst}/${f}"
        MAIN_DEPENDENCY "${_src}/${f}"
        COMMENT "Copying ${f}")
    list(APPEND ${_deps} "${_src}/${f}" "${_dst}/${f}")
  endforeach()
  unset(_files)
  unset(_src)
  unset(_dst)
endmacro()
```

----------------------------------------

TITLE: Adding Text to Images with OpenCV in Python
DESCRIPTION: Demonstrates how to add text to an image using the cv.putText() function, specifying font type, scale, color, and other parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
font = cv.FONT_HERSHEY_SIMPLEX
cv.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,cv.LINE_AA)
```

----------------------------------------

TITLE: Defining Advanced Camera Calibration Parameters in OpenCV - XML
DESCRIPTION: This snippet defines an XML configuration structure for advanced camera calibration parameters in OpenCV. It details settings necessary for chAruco pattern generation, frame filtering, solver behavior, and capture constraints. The file should be named (for example) defaultConfig.xml and is intended to be read by the calibration application at startup to override defaults. Users must fill in appropriate values matching their calibration board setup and hardware, and ensure the XML complies with the OpenCV file storage format.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/interactive_calibration/interactive_calibration.markdown#2025-04-22_snippet_0

LANGUAGE: xml
CODE:
```
<?xml version=\"1.0\"?>\n<opencv_storage>\n<charuco_dict>0</charuco_dict>\n<charuco_square_length>200</charuco_square_length>\n<charuco_marker_size>100</charuco_marker_size>\n<calibration_step>1</calibration_step>\n<max_frames_num>30</max_frames_num>\n<min_frames_num>10</min_frames_num>\n<solver_eps>1e-7</solver_eps>\n<solver_max_iters>30</solver_max_iters>\n<fast_solver>0</fast_solver>\n<frame_filter_conv_param>0.1</frame_filter_conv_param>\n<camera_resolution>1280 720</camera_resolution>\n</opencv_storage>
```

----------------------------------------

TITLE: Importing OpenCV Framework in Swift
DESCRIPTION: This snippet demonstrates how to import the OpenCV framework module into a Swift source file to enable usage of OpenCV features. Before use, ensure that the OpenCV framework has been added to your Xcode project and configured correctly for Swift interoperability. Input: none; Output: the OpenCV module is made accessible in the current scope.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/doc/README.md#2025-04-22_snippet_1

LANGUAGE: Swift
CODE:
```
import OpenCV
```

----------------------------------------

TITLE: Classification Test Configuration Class
DESCRIPTION: DataClass defining test configuration parameters including batch size, image dimensions, and data paths for classification evaluation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_9

LANGUAGE: python
CODE:
```
@dataclass
class TestClsConfig:
    batch_size: int = 50
    frame_size: int = 224
    img_root_dir: str = "./ILSVRC2012_img_val"
    # location of image-class matching
    img_cls_file: str = "./val.txt"
    bgr_to_rgb: bool = True
```

----------------------------------------

TITLE: Template Matching Formula: TM_SQDIFF (LaTeX)
DESCRIPTION: Mathematical formula for the Squared Difference (TM_SQDIFF) template matching method used in OpenCV's `matchTemplate` function. R(x,y) is the result, T is the template, and I is the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_1

LANGUAGE: latex
CODE:
```
\f[R(x,y)= \sum _{x',y'} (T(x',y')-I(x+x',y+y'))^2\f]
```

----------------------------------------

TITLE: Defining Custom Target for Android Build in CMake
DESCRIPTION: This CMake command defines a custom target named `${the_module}_android`. This target is added to the `ALL` target, meaning it will be built by default. It depends on the completion of the custom command that builds the AAR, signified by the existence of the `${OPENCV_DEPHELPER}/${the_module}_android` file. It also lists the Android manifest file as a source file associated with this target.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
add_custom_target(${the_module}_android ALL DEPENDS "${OPENCV_DEPHELPER}/${the_module}_android" SOURCES "${__base_dir}/${ANDROID_MANIFEST_FILE}")
```

----------------------------------------

TITLE: Checking Object Detection Help Documentation
DESCRIPTION: Command to display help information for the object detection script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/README.md#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
python object_detection.py opencv_fd -h
```

----------------------------------------

TITLE: Creating cv.Mat from ImageData in JavaScript
DESCRIPTION: Illustrates constructing a cv.Mat object from an ImageData object for further processing with OpenCV.js. This operation assumes the canvas contains 8-bit RGBA images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_image_display/js_image_display.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
let src = cv.matFromImageData(imgData);
```

----------------------------------------

TITLE: Splitting Image into BGR Planes in C++
DESCRIPTION: C++ snippet using OpenCV's `split` function to separate a 3-channel source image (assumed to be in BGR format) into three individual single-channel Mats, stored in a `std::vector<Mat>`. The input is the source image, and the output is the vector of planes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Separate the image in 3 places ( B, G and R )
```

----------------------------------------

TITLE: Converting Color Image to Grayscale using OpenCV in Objective-C
DESCRIPTION: This code snippet shows how to convert a color image (inputMat) to grayscale using OpenCV's cvtColor function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/image_manipulation/image_manipulation.markdown#2025-04-22_snippet_1

LANGUAGE: Objective-C
CODE:
```
cv::Mat greyMat;
cv::cvtColor(inputMat, greyMat, COLOR_BGR2GRAY);
```

----------------------------------------

TITLE: Implementing Structured Pixel Comparison for Feature Detection in C++
DESCRIPTION: This code snippet implements a structured approach to pixel comparison for feature detection. It uses nested if-else statements to compare pixel values at various offsets against thresholds, determining whether to proceed to a 'success_structured' or 'structured' state.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_23

LANGUAGE: C++
CODE:
```
x++;
if(x > xsizeB)
    break;
else
{
    const unsigned char* const ptr = img.ptr() + y*width + x;
    const int cb = *ptr + threshold;
    const int c_b = *ptr - threshold;
    if(ptr[offset0] > cb)
      if(ptr[offset2] > cb)
        if(ptr[offset5] > cb)
          if(ptr[offset9] > cb)
            if(ptr[offset7] > cb)
              if(ptr[offset1] > cb)
                if(ptr[offset6] > cb)
                  if(ptr[offset3] > cb)
                    if(ptr[offset4] > cb)
                      goto success_structured;
                    else
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto success_structured;
                        else
                          goto structured;
                      else
                        goto structured;
                  else
                    if(ptr[offset8] > cb)
                      if(ptr[offset10] > cb)
                        if(ptr[offset4] > cb)
                          goto success_structured;
                        else
                          if(ptr[offset11] > cb)
                            goto success_structured;
                          else
                            goto structured;
                      else
                        goto structured;
                    else
                      goto structured;
                else
                  if(ptr[offset11] > cb)
                    if(ptr[offset3] > cb)
                      if(ptr[offset4] > cb)
                        goto success_structured;
                      else
                        if(ptr[offset10] > cb)
                          goto success_structured;
                        else
                          goto structured;
                    else
                      if(ptr[offset8] > cb)
                        if(ptr[offset10] > cb)
                          goto success_structured;
                        else
                          goto structured;
                      else
                        goto structured;
                  else
                    goto structured;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset4] > cb)
                      if(ptr[offset3] > cb)
                        goto success_structured;
                      else
                        if(ptr[offset10] > cb)
                          goto success_structured;
                        else
                          goto structured;
                    else
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto success_structured;
                        else
                          goto structured;
                      else
                        goto structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset1] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset3] > cb)
                    if(ptr[offset4] > cb)
                      goto success_structured;
                    else
                      if(ptr[offset10] > cb)
                        goto success_structured;
                      else
                        goto structured;
                  else
                    if(ptr[offset8] > cb)
                      if(ptr[offset10] > cb)
                        goto success_structured;
                      else
                        goto structured;
                    else
                      goto structured;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset3] > cb)
                      if(ptr[offset4] > cb)
```

----------------------------------------

TITLE: Main Function of Motion Deblur Filter in C++
DESCRIPTION: Contains the core algorithm for recovering a motion-blurred image using PSF generation, Wiener filter, and frequency domain filtering. It premises the use of OpenCV with robust frequency domain techniques for image restoration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/motion_deblur_filter/motion_deblur_filter.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
@snippet samples/cpp/tutorial_code/ImgProc/motion_deblur_filter/motion_deblur_filter.cpp main
```

----------------------------------------

TITLE: C++11 Lambda for Parallel Convolution in OpenCV
DESCRIPTION: This snippet demonstrates simplifying the parallel convolution implementation using C++11 lambdas. By eliminating the necessity for a separate class, the lambda expression provides a concise approach for leveraging OpenCV's parallel_for_ framework.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_new/how_to_use_OpenCV_parallel_for_new.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp convolution-parallel-cxx11
```

----------------------------------------

TITLE: Optimized GPU Arithmetic using Explicit Functions in C++
DESCRIPTION: Demonstrates the optimized way to perform the arithmetic operation `t1 = 2 * mu1_mu2 + C1` on the GPU. Instead of using overloaded operators, it explicitly calls `gpu::multiply` and `gpu::add`. This avoids the creation of temporary intermediate `GpuMat` objects, reducing memory overhead and potentially improving performance by utilizing in-place operations where possible.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_14

LANGUAGE: cpp
CODE:
```
gpu::multiply(b.mu1_mu2, 2, b.t1); //b.t1 = 2 * b.mu1_mu2 + C1;
gpu::add(b.t1, C1, b.t1);
```

----------------------------------------

TITLE: Importing OpenCV in Python
DESCRIPTION: This snippet shows how to import the OpenCV library in Python and assign it the alias 'cv' for easy access. The alias helps keep the code concise and readable, especially when calling OpenCV's functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import cv2 as cv
```

----------------------------------------

TITLE: Implementing Custom Serialization for File I/O (Outside Class) - OpenCV C++
DESCRIPTION: This C++ snippet defines global read() and write() methods outside the custom class to support OpenCV FileStorage serialization for user-defined types. It sets default values if a node is missing and allows using << and >> operators for file I/O. All members must be assigned by reading the correct node elements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_15

LANGUAGE: C++
CODE:
```
void write(FileStorage& fs, const MyData& data)\n{\n    data.write(fs);\n}\nvoid read(const FileNode& node, MyData& data, const MyData& defaultData = MyData())\n{\n    if(node.empty())\n        data = defaultData;\n    else\n        data.read(node);\n}
```

----------------------------------------

TITLE: Building OpenCV Plugins (Shell)
DESCRIPTION: This multi-line shell script shows the process to configure and build OpenCV plugins (such as TBB parallel backends) using CMake in a plugin subdirectory. It requires compatible versions of the TBB library and the OpenCV build, CMake, and a compiler matching the main build. Environment variables such as TBB_DIR and specific CMake define options (OPENCV_PLUGIN_NAME, OPENCV_PLUGIN_DESTINATION, CMAKE_BUILD_TYPE) must be set accordingly. The <suffix>, <dest-folder>, <config>, and source directory path need to be adjusted for your environment. Plugin binaries will be generated in the current directory and can be loaded dynamically by OpenCV if named correctly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/general_install/general_install.markdown#2025-04-22_snippet_4

LANGUAGE: shell
CODE:
```
# set-up environment for TBB detection, for example:\n#   export TBB_DIR=<dir-with-tbb-cmake-config>\ncmake -G<generator> \\n    -DOPENCV_PLUGIN_NAME=opencv_core_tbb_<suffix> \\n    -DOPENCV_PLUGIN_DESTINATION=<dest-folder> \\n    -DCMAKE_BUILD_TYPE=<config> \\n    <opencv>/modules/core/misc/plugins/parallel_tbb\ncmake --build . --config <config>
```

----------------------------------------

TITLE: Configuring OpenCV Java JAR Build Environment
DESCRIPTION: Sets up directories, file paths, and build variables for the OpenCV Java JAR. Configures source file copying and prepares the build environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jar/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(${the_module}_jar)

set(OPENCV_JAVA_DIR "${CMAKE_CURRENT_BINARY_DIR}/opencv" CACHE INTERNAL "")

file(REMOVE_RECURSE "${OPENCV_JAVA_DIR}")
file(REMOVE "${OPENCV_DEPHELPER}/${the_module}_jar_source_copy")

set(java_src_dir "${OPENCV_JAVA_DIR}/java")
file(MAKE_DIRECTORY "${java_src_dir}")

set(JAR_NAME_WE opencv-${OPENCV_JAVA_LIB_NAME_SUFFIX})
set(JAR_NAME ${JAR_NAME_WE}.jar)
set(OPENCV_JAR_DIR "${OpenCV_BINARY_DIR}/bin/" CACHE INTERNAL "")
set(OPENCV_JAR_FILE "${OPENCV_JAR_DIR}${JAR_NAME}" CACHE INTERNAL "")

ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/java" "${java_src_dir}")

set(depends gen_opencv_java_source "${OPENCV_DEPHELPER}/gen_opencv_java_source")
ocv_copyfiles_add_target(${the_module}_jar_source_copy JAVA_SRC_COPY "Copy Java(JAR) source files" ${depends})
set(depends ${the_module}_jar_source_copy "${OPENCV_DEPHELPER}/${the_module}_jar_source_copy")
```

----------------------------------------

TITLE: Setting Description for OpenCV Module - CMake
DESCRIPTION: Assigns a human-readable description to the OpenCV FLANN module for documentation and configuration purposes. This variable is used internally by the OpenCV CMake build system to provide information about the module to users and maintainers. There are no parameters other than the string; no explicit dependencies beyond standard CMake usage.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/flann/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(the_description "Clustering and Search in Multi-Dimensional Spaces")
```

----------------------------------------

TITLE: Configuring TBB Include Directories and Source Files
DESCRIPTION: Sets up the include directories for TBB and collects the source files for compilation. Filters out specific files that have external dependencies to simplify the build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
ocv_include_directories("${tbb_src_dir}/include"
                        "${tbb_src_dir}/src/"
                        "${tbb_src_dir}/src/rml/include"
                        "${CMAKE_CURRENT_SOURCE_DIR}")

file(GLOB lib_srcs "${tbb_src_dir}/src/tbb/*.cpp")
file(GLOB lib_hdrs "${tbb_src_dir}/src/tbb/*.h")
ocv_list_filterout(lib_srcs "${tbb_src_dir}/src/tbb/tbbbind.cpp")  # hwloc.h requirement
ocv_list_filterout(lib_srcs "${tbb_src_dir}/src/tbb/tbb_bind.cpp")  # hwloc.h requirement 2020.1+
```

----------------------------------------

TITLE: Configuring OpenCV with OpenNI2 Support using CMake
DESCRIPTION: Creates a build directory, navigates into it, and runs CMake to configure the OpenCV build. The '-DWITH_OPENNI2=ON' flag explicitly enables OpenNI2 support, instructing CMake to find the necessary OpenNI libraries and headers (using the environment variables set previously) and include OpenNI-related functionality in the build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
$ mkdir build
$ cd build
$ cmake -DWITH_OPENNI2=ON ..
```

----------------------------------------

TITLE: Building a Minimal OpenCV Debugging Application in C++
DESCRIPTION: This C++ snippet demonstrates a simple command-line program that loads an image and applies the Canny edge detector. It illustrates the use of standard OpenCV headers and objects (cv::Mat), and is meant to be built and debugged with Visual Studio to showcase the Image Watch visual debugger extension. Users must supply an input image filename as a command-line argument, and the program requires an OpenCV installation configured with Visual Studio. The code produces no output files and is intended for in-memory debugging and visualization only.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_image_watch/windows_visual_studio_image_watch.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
// Test application for the Visual Studio Image Watch Debugger extension

#include <iostream>                        // std::cout
#include <opencv2/core/core.hpp>           // cv::Mat
#include <opencv2/imgcodecs/imgcodecs.hpp>     // cv::imread()
#include <opencv2/imgproc/imgproc.hpp>     // cv::Canny()

using namespace std;
using namespace cv;

void help()
{
    cout
        << "----------------------------------------------------" << endl
        << "This is a test program for the Image Watch Debugger " << endl
        << "plug-in for Visual Studio. The program loads an     " << endl
        << "image from a file and runs the Canny edge detector. " << endl
        << "No output is displayed or written to disk."
        << endl
        << "Usage:"                                               << endl
        << "image-watch-demo inputimage"                          << endl
        << "----------------------------------------------------" << endl
        << endl;
}

int main(int argc, char *argv[])
{
    help();

    if (argc != 2)
    {
        cout << "Wrong number of parameters" << endl;
        return -1;
    }

    cout << "Loading input image: " << argv[1] << endl;
    Mat input;
    input = imread(argv[1], IMREAD_COLOR);

    cout << "Detecting edges in input image" << endl;
    Mat edges;
    Canny(input, edges, 10, 100);

    return 0;
}
```

----------------------------------------

TITLE: Configuring PNG Support in CMake
DESCRIPTION: CMake configuration options for enabling PNG support in OpenCV imgcodecs module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/readme.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
WITH_PNG=ON # Enable libpng support
WITH_SPNG=ON # Enable libspng support
```

----------------------------------------

TITLE: Estimating Pose and Drawing Axes on Multiple Images with OpenCV (Python)
DESCRIPTION: Processes a set of chessboard images, locates the chessboard corners, refines them, estimates the object's pose using cv.solvePnP, and projects 3D axis points onto the image plane. It then uses the draw function to overlay axes, displaying each result. Depends on camera calibration data, axis/object points, and previously defined draw function. Inputs are image files matching a pattern, and successful cases may result in saved annotated images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_pose/py_pose.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
for fname in glob.glob('left*.jpg'):\n    img = cv.imread(fname)\n    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n    ret, corners = cv.findChessboardCorners(gray, (7,6),None)\n\n    if ret == True:\n        corners2 = cv.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n\n        # Find the rotation and translation vectors.\n        ret,rvecs, tvecs = cv.solvePnP(objp, corners2, mtx, dist)\n\n        # project 3D points to image plane\n        imgpts, jac = cv.projectPoints(axis, rvecs, tvecs, mtx, dist)\n\n        img = draw(img,corners2,imgpts)\n        cv.imshow('img',img)\n        k = cv.waitKey(0) & 0xFF\n        if k == ord('s'):\n            cv.imwrite(fname[:6]+'.png', img)\n\ncv.destroyAllWindows()
```

----------------------------------------

TITLE: Implementing a Kernel for the OpenCV CPU Backend (OpenCV G-API, C++)
DESCRIPTION: Illustrates a backend-specific implementation of a declared kernel interface for the CPU (OpenCV) plugin. The run() method adapts the interface to work with real data objects (cv::Mat), providing actual functional behavior. This implementation is packaged as part of a kernel package and is invoked during graph execution. Requires prior kernel interface declaration and OpenCV includes; implementation signature must follow backend conventions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/doc/20-kernel-api.markdown#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
// Example kernel implementation for the CPU backend (OpenCV)
struct GCPUFilter2D
{
    static void run(const cv::Mat &in, const cv::Mat &kernel, cv::Point anchor, cv::Mat &out)
    {
        cv::filter2D(in, out, -1, kernel, anchor, 0, cv::BORDER_DEFAULT);
    }
};
// Used when compiling with cv::gapi::kernels<...>()
```

----------------------------------------

TITLE: Outputting std::vector of Points in OpenCV C++
DESCRIPTION: Demonstrates how to output a vector of points directly using the << operator. OpenCV provides built-in support for common container combinations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_18

LANGUAGE: C++
CODE:
```
vector<Point2f> vPoints(20);
for (size_t i = 0; i < vPoints.size(); ++i)
    vPoints[i] = Point2f((float)(i * 5), (float)(i % 7));
cout << "A vector of 2D Points = " << vPoints << endl << endl;
```

----------------------------------------

TITLE: Configuring Leiningen Profile with Localrepo Plugin
DESCRIPTION: This Clojure snippet shows how to configure the Leiningen user profile to include the lein-localrepo plugin, allowing installation of any JAR as a Maven artifact locally. The profiles.clj file is updated to ensure the plugin is accessible to any CLJ project. No additional installation steps are needed as the plugin is downloaded automatically when first used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_1

LANGUAGE: clojure
CODE:
```
{:user {:plugins [[lein-localrepo "0.5.2"]]}}
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Decision Tree in C++
DESCRIPTION: This code snippet shows part of a decision tree implementation for the FAST corner detection algorithm. It compares pixel values at various offsets around a central point to determine if the point represents a corner in an image. The algorithm uses goto statements to branch to either 'is_a_corner' or 'is_not_a_corner' labels based on intensity comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_25

LANGUAGE: C++
CODE:
```
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                  else
                    if(ptr[offset9] < c_b)
                      if(ptr[offset7] > cb)
                        if(ptr[offset1] < c_b)
                          goto is_not_a_corner;
                        else
                          if(ptr[offset1] > cb)
                            if(ptr[offset6] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset3] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                if(ptr[offset3] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset1] < c_b)
                          goto is_not_a_corner;
                        else
                          if(ptr[offset1] > cb)
                            if(ptr[offset6] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset3] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                if(ptr[offset3] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                    else
                      if(ptr[offset7] > cb)
                        if(ptr[offset9] > cb)
                          if(ptr[offset1] < c_b)
                            if(ptr[offset6] < c_b)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset8] > cb)
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset1] > cb)
                              if(ptr[offset6] > cb)
                                if(ptr[offset10] > cb)
                                  if(ptr[offset11] > cb)
                                    if(ptr[offset3] > cb)
                                      goto is_a_corner;
                                    else
                                      if(ptr[offset8] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                if(ptr[offset6] < c_b)
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      if(ptr[offset3] > cb)
                                        goto is_a_corner;
                                      else
                                        if(ptr[offset8] > cb)
                                          goto is_a_corner;
                                        else
                                          goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      if(ptr[offset3] > cb)
                                        goto is_a_corner;
                                      else
                                        if(ptr[offset8] > cb)
                                          goto is_a_corner;
                                        else
                                          goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                            else
                              if(ptr[offset6] < c_b)
                                goto is_not_a_corner;
                              else
                                if(ptr[offset6] > cb)
                                  if(ptr[offset8] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                        else
                          if(ptr[offset1] < c_b)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset1] > cb)
                              if(ptr[offset6] > cb)
                                if(ptr[offset3] > cb)
```

----------------------------------------

TITLE: ARM Architecture Optimization Configuration
DESCRIPTION: Configures NEON optimization settings for ARM architectures, including source files and compiler definitions based on the selected optimization level.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libpng/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(TARGET_ARCH MATCHES "^(ARM|arm|aarch)")
  if(TARGET_ARCH MATCHES "^(ARM64|arm64|aarch64)")
    set(PNG_ARM_NEON_POSSIBLE_VALUES on off)
    set(PNG_ARM_NEON "on"
        CACHE STRING "Enable ARM NEON optimizations: on|off; on is default")
  else()
    set(PNG_ARM_NEON_POSSIBLE_VALUES check on off)
    set(PNG_ARM_NEON "off"
        CACHE STRING "Enable ARM NEON optimizations: check|on|off; off is default")
  endif()
```

----------------------------------------

TITLE: Setting an Environment Variable in Linux Shell Script
DESCRIPTION: This shell script snippet sets 'MY_ENV_VARIABLE' for the current shell session or process. Useful for applications like OpenCV that check environment variables at runtime. Dependencies: Bash or POSIX-compliant shell. Parameters: Variable name and value. Limitations: Only persists for the current process hierarchy, not globally.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/env_reference/env_reference.markdown#2025-04-22_snippet_1

LANGUAGE: sh
CODE:
```
export MY_ENV_VARIABLE=true\n./my_app
```

----------------------------------------

TITLE: Building OpenCV.js on Windows with Docker - Bash/PowerShell
DESCRIPTION: This command runs a Docker container for the Emscripten SDK on Windows, mapping the current PowerShell location into the container and running the build script using emcmake and Python3. It preserves Windows pathing and permissions conventions. Outputs are OpenCV.js build artifacts. Requires Docker installed and PowerShell as shell.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_24

LANGUAGE: bash
CODE:
```
docker run --rm --workdir /src -v "$(get-location):/src" "emscripten/emsdk" emcmake python3 ./platforms/js/build_js.py build_js
```

----------------------------------------

TITLE: Listing G-API Source Files in CMake
DESCRIPTION: Defines a CMake variable `gapi_srcs` containing an explicit list of all C++ source files (`.cpp`) required to build the core G-API functionality, including frontend API, compiler, executor, various backends (CPU, Fluid, OAK, OCL, IE, OV, ONNX, Render, PlaidML), common backend code, serialization, streaming, Python bindings, and utility code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
set(gapi_srcs
    # Front-end part
    src/api/grunarg.cpp
    src/api/gorigin.cpp
    src/api/gmat.cpp
    src/api/garray.cpp
    src/api/gopaque.cpp
    src/api/gscalar.cpp
    src/api/gframe.cpp
    src/api/gkernel.cpp
    src/api/gbackend.cpp
    src/api/gcommon.cpp
    src/api/gproto.cpp
    src/api/gnode.cpp
    src/api/gcall.cpp
    src/api/gcomputation.cpp
    src/api/operators.cpp
    src/api/kernels_core.cpp
    src/api/kernels_imgproc.cpp
    src/api/kernels_video.cpp
    src/api/kernels_nnparsers.cpp
    src/api/kernels_ot.cpp
    src/api/kernels_streaming.cpp
    src/api/kernels_stereo.cpp
    src/api/render.cpp
    src/api/render_ocv.cpp
    src/api/ginfer.cpp
    src/api/media.cpp
    src/api/rmat.cpp

    # Compiler part
    src/compiler/gmodel.cpp
    src/compiler/gmodelbuilder.cpp
    src/compiler/gislandmodel.cpp
    src/compiler/gcompiler.cpp
    src/compiler/gcompiled.cpp
    src/compiler/gstreaming.cpp
    src/compiler/passes/helpers.cpp
    src/compiler/passes/dump_dot.cpp
    src/compiler/passes/islands.cpp
    src/compiler/passes/meta.cpp
    src/compiler/passes/kernels.cpp
    src/compiler/passes/exec.cpp
    src/compiler/passes/transformations.cpp
    src/compiler/passes/pattern_matching.cpp
    src/compiler/passes/perform_substitution.cpp
    src/compiler/passes/streaming.cpp
    src/compiler/passes/intrin.cpp

    # Executor
    src/executor/gabstractexecutor.cpp
    src/executor/gabstractstreamingexecutor.cpp
    src/executor/gexecutor.cpp
    src/executor/gtbbexecutor.cpp
    src/executor/gthreadedexecutor.cpp
    src/executor/gstreamingexecutor.cpp
    src/executor/gasync.cpp
    src/executor/thread_pool.cpp

    # CPU Backend (currently built-in)
    src/backends/cpu/gcpubackend.cpp
    src/backends/cpu/gcpukernel.cpp
    src/backends/cpu/gcpuimgproc.cpp
    src/backends/cpu/gcpustereo.cpp
    src/backends/cpu/gcpuvideo.cpp
    src/backends/cpu/gcpucore.cpp
    src/backends/cpu/gcpuot.cpp
    src/backends/cpu/gnnparsers.cpp

    # Fluid Backend (also built-in, FIXME:move away)
    src/backends/fluid/gfluidbuffer.cpp
    src/backends/fluid/gfluidbackend.cpp
    src/backends/fluid/gfluidimgproc.cpp
    src/backends/fluid/gfluidimgproc_func.dispatch.cpp
    src/backends/fluid/gfluidcore.cpp
    src/backends/fluid/gfluidcore_func.dispatch.cpp

    # OAK Backend (optional)
    src/backends/oak/goak.cpp
    src/backends/oak/goakbackend.cpp
    src/backends/oak/goak_memory_adapters.cpp

    # OCL Backend (currently built-in)
    src/backends/ocl/goclbackend.cpp
    src/backends/ocl/goclkernel.cpp
    src/backends/ocl/goclimgproc.cpp
    src/backends/ocl/goclcore.cpp

    # IE Backend. FIXME: should be included by CMake
    # if and only if IE support is enabled
    src/backends/ie/giebackend.cpp
    src/backends/ie/giebackend/giewrapper.cpp

    # OV Backend. FIXME: should be included by CMake
    # if and only if OV support is enabled
    src/backends/ov/govbackend.cpp

    # ONNX backend
    src/backends/onnx/gonnxbackend.cpp
    src/backends/onnx/dml_ep.cpp
    src/backends/onnx/coreml_ep.cpp

    # Render backend
    src/backends/render/grenderocv.cpp
    src/backends/render/ft_render.cpp

    # PlaidML Backend
    src/backends/plaidml/gplaidmlcore.cpp
    src/backends/plaidml/gplaidmlbackend.cpp

    # Common backend code
    src/backends/common/gmetabackend.cpp
    src/backends/common/gcompoundbackend.cpp
    src/backends/common/gcompoundkernel.cpp

    # Serialization API and routines
    src/api/s11n.cpp
    src/backends/common/serialization.cpp

    # Streaming backend
    src/backends/streaming/gstreamingbackend.cpp

    # Python bridge
    src/backends/ie/bindings_ie.cpp
    src/backends/onnx/bindings_onnx.cpp
    src/backends/ov/bindings_ov.cpp
    src/backends/python/gpythonbackend.cpp

    # Queue Streaming source
    src/streaming/queue_source.cpp

    # OpenVPL Streaming source
    src/streaming/onevpl/source.cpp
    src/streaming/onevpl/source_priv.cpp
    src/streaming/onevpl/file_data_provider.cpp
    src/streaming/onevpl/cfg_params.cpp
    src/streaming/onevpl/cfg_params_parser.cpp
    src/streaming/onevpl/utils.cpp
    src/streaming/onevpl/default.cpp
    src/streaming/onevpl/data_provider_interface_exception.cpp
    src/streaming/onevpl/accelerators/surface/base_frame_adapter.cpp
    src/streaming/onevpl/accelerators/surface/cpu_frame_adapter.cpp
    src/streaming/onevpl/accelerators/surface/dx11_frame_adapter.cpp
    src/streaming/onevpl/accelerators/surface/surface.cpp
    src/streaming/onevpl/accelerators/surface/surface_pool.cpp
    src/streaming/onevpl/accelerators/utils/shared_lock.cpp
    src/streaming/onevpl/accelerators/accel_policy_cpu.cpp
    src/streaming/onevpl/accelerators/accel_policy_dx11.cpp
    src/streaming/onevpl/accelerators/accel_policy_va_api.cpp
    src/streaming/onevpl/accelerators/dx11_alloc_resource.cpp
    src/streaming/onevpl/engine/engine_session.cpp
    src/streaming/onevpl/engine/processing_engine_base.cpp
    src/streaming/onevpl/engine/decode/decode_engine_legacy.cpp
    src/streaming/onevpl/engine/decode/decode_session.cpp
    src/streaming/onevpl/engine/transcode/transcode_engine_legacy.cpp
    src/streaming/onevpl/engine/transcode/transcode_session.cpp
    src/streaming/onevpl/engine/preproc/preproc_engine.cpp
    src/streaming/onevpl/engine/preproc/preproc_session.cpp
    src/streaming/onevpl/engine/preproc/preproc_dispatcher.cpp
    src/streaming/onevpl/engine/preproc_engine_interface.cpp
    src/streaming/onevpl/demux/async_mfp_demux_data_provider.cpp
    src/streaming/onevpl/data_provider_dispatcher.cpp

    src/streaming/onevpl/cfg_param_device_selector.cpp
    src/streaming/onevpl/device_selector_interface.cpp

    # GStreamer Streaming source
    src/streaming/gstreamer/gstreamer_pipeline_facade.cpp
    src/streaming/gstreamer/gstreamerpipeline.cpp
    src/streaming/gstreamer/gstreamersource.cpp
    src/streaming/gstreamer/gstreamer_buffer_utils.cpp
    src/streaming/gstreamer/gstreamer_media_adapter.cpp
    src/streaming/gstreamer/gstreamerenv.cpp

    # Utils (ITT tracing)
    src/utils/itt.cpp
    )
```

----------------------------------------

TITLE: Running OpenCV Installation Script in Git Bash
DESCRIPTION: Command to execute the OpenCV installation script in Git Bash. This starts the build process for OpenCV and OpenCV contrib modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
./installOCV.sh
```

----------------------------------------

TITLE: Setting JPEG Compression Quality (C)
DESCRIPTION: This function constructs JPEG quantization tables for the specified quality setting (0-100 scale). The force_baseline parameter constrains table entries to 1-255 for full JPEG baseline compatibility.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_23

LANGUAGE: C
CODE:
```
jpeg_set_quality (j_compress_ptr cinfo, int quality, boolean force_baseline)
```

----------------------------------------

TITLE: SIFT Feature Matching with Ratio Test in Python
DESCRIPTION: Implements feature matching using SIFT descriptors and Brute-Force matcher with k-nearest neighbors. Applies Lowe's ratio test for better match filtering.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_matcher/py_matcher.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt

img1 = cv.imread('box.png',cv.IMREAD_GRAYSCALE)          # queryImage
img2 = cv.imread('box_in_scene.png',cv.IMREAD_GRAYSCALE) # trainImage

# Initiate SIFT detector
sift = cv.SIFT_create()

# find the keypoints and descriptors with SIFT
kp1, des1 = sift.detectAndCompute(img1,None)
kp2, des2 = sift.detectAndCompute(img2,None)

# BFMatcher with default params
bf = cv.BFMatcher()
matches = bf.knnMatch(des1,des2,k=2)

# Apply ratio test
good = []
for m,n in matches:
    if m.distance < 0.75*n.distance:
        good.append([m])

# cv.drawMatchesKnn expects list of lists as matches.
img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

plt.imshow(img3),plt.show()
```

----------------------------------------

TITLE: Creating and Linking the libtiff Library with CMake
DESCRIPTION: This snippet defines the creation of the libtiff static library with its source files and links it against the required libraries. It configures library properties such as output name and debugging settings, ensuring proper linkage and debugging symbols are available for development.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
add_library(${TIFF_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${lib_srcs})
target_link_libraries(${TIFF_LIBRARY} ${ZLIB_LIBRARIES})

set_target_properties(${TIFF_LIBRARY}
    PROPERTIES
    OUTPUT_NAME "${TIFF_LIBRARY}"
    DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
    COMPILE_PDB_NAME ${TIFF_LIBRARY}
    COMPILE_PDB_NAME_DEBUG "${TIFF_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
    ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
    )
```

----------------------------------------

TITLE: Configuring libjpeg Library Build with CMake - CMake
DESCRIPTION: This snippet sets up the libjpeg static library build in the OpenCV project using CMake. It includes directives to gather all source and header files, apply source filtering based on the platform, configure compilation flags, disable selected warnings, define target properties, and handle installation. Dependencies include OpenCV-specific macros and variables, and a working CMake environment. Inputs are controlled by the OpenCV and CMake build configuration (such as target platform and enabled folders), with outputs being the built static library and its debug symbols. The setup requires that OpenCV and CMake variables (e.g., JPEG_LIBRARY, CMAKE_CURRENT_SOURCE_DIR) are predefined and expects standard CMake toolchain support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
# ----------------------------------------------------------------------------\n#  CMake file for libjpeg. See root CMakeLists.txt\n#\n# ----------------------------------------------------------------------------\nproject(${JPEG_LIBRARY})\nocv_include_directories(${CMAKE_CURRENT_SOURCE_DIR})\nfile(GLOB lib_srcs *.c)\nfile(GLOB lib_hdrs *.h)\nif(ANDROID OR IOS OR APPLE)\n  ocv_list_filterout(lib_srcs jmemansi.c)\nelse()\n  ocv_list_filterout(lib_srcs jmemnobs.c)\nendif()\n# ----------------------------------------------------------------------------------\n#         Define the library target:\n# ----------------------------------------------------------------------------------\nadd_library(${JPEG_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${lib_srcs} ${lib_hdrs})\nif(CV_GCC OR CV_CLANG)\n  set_source_files_properties(jcdctmgr.c PROPERTIES COMPILE_FLAGS "-O1")\nendif()\nocv_warnings_disable(CMAKE_C_FLAGS -Wcast-align -Wshadow -Wunused -Wshift-negative-value -Wimplicit-fallthrough)\nocv_warnings_disable(CMAKE_C_FLAGS -Wunused-parameter) # clang\nocv_warnings_disable(CMAKE_C_FLAGS /wd4013 /wd4244 /wd4267) # vs2005\nset_target_properties(${JPEG_LIBRARY}\n  PROPERTIES OUTPUT_NAME ${JPEG_LIBRARY}\n  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"\n  COMPILE_PDB_NAME ${JPEG_LIBRARY}\n  COMPILE_PDB_NAME_DEBUG "${JPEG_LIBRARY}${OPENCV_DEBUG_POSTFIX}"\n  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}\n  )\nif(ENABLE_SOLUTION_FOLDERS)\n  set_target_properties(${JPEG_LIBRARY} PROPERTIES FOLDER "3rdparty")\nendif()\nif(NOT BUILD_SHARED_LIBS)\n  ocv_install_target(${JPEG_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)\nendif()\nocv_install_3rdparty_licenses(libjpeg README)
```

----------------------------------------

TITLE: Finding All C++ Sample Files in CMake
DESCRIPTION: Uses the `file(GLOB ...)` command to find all files ending with `.cpp` in the current source directory (`CMAKE_CURRENT_SOURCE_DIR`). It stores the list of relative file paths in the `all_samples` variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: cmake
CODE:
```
file(GLOB all_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Algorithm in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm. It compares pixel values at various offsets to determine if a pixel is a corner. The algorithm uses a series of nested conditional statements and goto labels for efficient branching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_20

LANGUAGE: C++
CODE:
```
else
  goto homogeneous;
else
  if(ptr[offset8] < c_b)
    if(ptr[offset10] < c_b)
      goto success_homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        goto success_homogeneous;
      else
        goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset10] < c_b)
    if(ptr[offset11] < c_b)
      if(ptr[offset7] < c_b)
        if(ptr[offset1] < c_b)
          if(ptr[offset3] < c_b)
            goto success_homogeneous;
          else
            if(ptr[offset8] < c_b)
              goto success_homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset8] < c_b)
              goto success_homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset3] < c_b)
            goto success_homogeneous;
          else
            if(ptr[offset8] < c_b)
              goto success_homogeneous;
            else
              goto homogeneous;
        else
          goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  if(ptr[offset9] > cb)
    if(ptr[offset5] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset1] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset11] < c_b)
                  goto success_structured;
                else
                  goto structured;
              else
                goto homogeneous;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset8] > cb)
                  if(ptr[offset11] > cb)
                    if(ptr[offset10] > cb)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset4] > cb)
                    goto success_structured;
                  else
                    if(ptr[offset11] > cb)
                      goto success_structured;
                    else
                      goto structured;
                else
                  if(ptr[offset3] > cb)
                    if(ptr[offset4] > cb)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset8] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset3] > cb)
                  goto success_structured;
                else
                  if(ptr[offset10] > cb)
                    goto success_structured;
                  else
                    goto homogeneous;
              else
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto success_structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto success_structured;
                else
                  goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
    else
      if(ptr[offset3] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset5] < c_b)
            if(ptr[offset7] < c_b)
              if(ptr[offset1] < c_b)
                if(ptr[offset6] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset8] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset1] < c_b)
                if(ptr[offset6] < c_b)
                  goto success_homogeneous;
                else
                  if(ptr[offset11] < c_b)
                    goto success_homogeneous;
                  else
                    goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset1] < c_b)
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          goto homogeneous;
      else
        goto homogeneous;
  else
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        if(ptr[offset5] < c_b)
```

----------------------------------------

TITLE: Verifying Pkg-config for ARMv7 (Bash)
DESCRIPTION: Tests the `pkg-config` setup for the `armhf` (ARMv7) architecture. Similar to the aarch64 check, it sets environment variables to direct `pkg-config` to the appropriate paths for `armhf` libraries and lists all available packages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_12

LANGUAGE: bash
CODE:
```
PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig:/usr/share/pkgconfig \
  PKG_CONFIG_LIBDIR=/usr/lib/arm-linux-gnueabihf \
  PKG_CONFIG_SYSROOT_DIR=/ \
      pkg-config --list-all
```

----------------------------------------

TITLE: Configuring OpenCV Android Camera Calibration Example
DESCRIPTION: CMake configuration that sets up an Android camera calibration example project. It defines the project name, adds Android-specific build settings, sets OpenCV library dependencies, and specifies minimum SDK target of 11.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/camera-calibration/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-camera-calibration)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Processing Camera Frames with Pure OpenCL
DESCRIPTION: C++ code showing how to process camera frames using direct OpenCL calls. This approach uses cl::ImageGL to wrap OpenGL textures and process them without copying data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_10

LANGUAGE: C++
CODE:
```
// process_pure_opencl
```

----------------------------------------

TITLE: Starting JPEG Compression Cycle in C
DESCRIPTION: This snippet demonstrates how to begin a JPEG compression cycle using 'jpeg_start_compress'. This function initializes internal state, allocates working storage, and starts the JPEG datastream header. Passing 'TRUE' ensures a complete JPEG interchange datastream is produced.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_6

LANGUAGE: C
CODE:
```
jpeg_start_compress(&cinfo, TRUE);
```

----------------------------------------

TITLE: Creating Display Window
DESCRIPTION: Creates a window to display the remapping results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/remap/remap.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
namedWindow( "Remap demo", WINDOW_AUTOSIZE );
```

LANGUAGE: Java
CODE:
```
HighGui.namedWindow("Remap demo", HighGui.WINDOW_AUTOSIZE);
```

LANGUAGE: Python
CODE:
```
cv.namedWindow("Remap demo", cv.WINDOW_AUTOSIZE)
```

----------------------------------------

TITLE: Adding Actions Runner Service
DESCRIPTION: Commands to copy and reload the actions-runner service configuration in systemd.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/s390/README.md#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
sudo cp self-hosted-builder/actions-runner.service /etc/systemd/system/
sudo systemctl daemon-reload
```

----------------------------------------

TITLE: Process Contours and Draw Shapes in OpenCV Java
DESCRIPTION: Applies polygonal approximation for contours and draws bounding rectangles and circles using OpenCV in Java.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_12

LANGUAGE: Java
CODE:
```
for (int i = 0; i < contours.size(); i++) {
    MatOfPoint2f contour2f = new MatOfPoint2f(contours.get(i).toArray());
    MatOfPoint2f approxCurve = new MatOfPoint2f();
    Imgproc.approxPolyDP(contour2f, approxCurve, 3, true);
    Rect rect = Imgproc.boundingRect(new MatOfPoint(approxCurve.toArray()));
    Point center = new Point();
    float[] radius = new float[1];
    Imgproc.minEnclosingCircle(approxCurve, center, radius);
}
```

----------------------------------------

TITLE: Initializing cv::Mat Objects with Specific Types and Sizes (C++)
DESCRIPTION: Provides C++ examples for creating OpenCV `cv::Mat` objects. It demonstrates initializing matrices with specified dimensions (rows, columns, or `cv::Size`) and data types using the predefined constants (e.g., `CV_32F`, `CV_64FC2`, `CV_8UC3`). It also shows how to create a single-channel matrix (`grayscale`) with the same size and element depth as an existing multi-channel image (`img`) using `img.size()` and `CV_MAKETYPE`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
    Mat mtx(3, 3, CV_32F); // make a 3x3 floating-point matrix
    Mat cmtx(10, 1, CV_64FC2); // make a 10x1 2-channel floating-point
                               // matrix (10-element complex vector)
    Mat img(Size(1920, 1080), CV_8UC3); // make a 3-channel (color) image
                                        // of 1920 columns and 1080 rows.
    Mat grayscale(img.size(), CV_MAKETYPE(img.depth(), 1)); // make a 1-channel image of
                                                            // the same size and same
                                                            // channel type as img
```

----------------------------------------

TITLE: Generating Configuration Header for OpenCV Data Directories in CMake
DESCRIPTION: This CMake script generates a configuration header file for OpenCV data directories. It checks the provided CMake variables such as CMAKE_INSTALL_PREFIX and OPENCV_OTHER_INSTALL_PATH to create the necessary directories as define statements. The script further handles platform-specific path adjustments and avoids unnecessary file writes by comparing existing content.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
# generate data (samples data) config file
set(OPENCV_DATA_CONFIG_FILE "${OPENCV_CONFIG_FILE_INCLUDE_DIR}/opencv_data_config.hpp")
set(OPENCV_DATA_CONFIG_STR "")

if(CMAKE_INSTALL_PREFIX)
  set(OPENCV_DATA_CONFIG_STR "${OPENCV_DATA_CONFIG_STR}\n#define OPENCV_INSTALL_PREFIX \"${CMAKE_INSTALL_PREFIX}\"\n")
endif()
if(OPENCV_OTHER_INSTALL_PATH)
  set(OPENCV_DATA_CONFIG_STR "${OPENCV_DATA_CONFIG_STR}\n#define OPENCV_DATA_INSTALL_PATH \"${OPENCV_OTHER_INSTALL_PATH}\"\n")
endif()

set(OPENCV_DATA_CONFIG_STR "${OPENCV_DATA_CONFIG_STR}\n#define OPENCV_BUILD_DIR \"${CMAKE_BINARY_DIR}\"\n")

file(RELATIVE_PATH SOURCE_DIR_RELATIVE ${CMAKE_BINARY_DIR} ${CMAKE_SOURCE_DIR})
set(OPENCV_DATA_CONFIG_STR "${OPENCV_DATA_CONFIG_STR}\n#define OPENCV_DATA_BUILD_DIR_SEARCH_PATHS \\\"${SOURCE_DIR_RELATIVE}/\"\n")

if(WIN32)
  file(RELATIVE_PATH INSTALL_DATA_DIR_RELATIVE "${CMAKE_INSTALL_PREFIX}/${OPENCV_BIN_INSTALL_PATH}" "${CMAKE_INSTALL_PREFIX}/${OPENCV_OTHER_INSTALL_PATH}")
else()
  file(RELATIVE_PATH INSTALL_DATA_DIR_RELATIVE "${CMAKE_INSTALL_PREFIX}/${OPENCV_LIB_INSTALL_PATH}" "${CMAKE_INSTALL_PREFIX}/${OPENCV_OTHER_INSTALL_PATH}")
endif()
list(APPEND OPENCV_INSTALL_DATA_DIR_RELATIVE "${INSTALL_DATA_DIR_RELATIVE}")
string(REPLACE ";" ",\\n    \"" OPENCV_INSTALL_DATA_DIR_RELATIVE_STR "\"${OPENCV_INSTALL_DATA_DIR_RELATIVE}\"")
set(OPENCV_DATA_CONFIG_STR "${OPENCV_DATA_CONFIG_STR}\n#define OPENCV_INSTALL_DATA_DIR_RELATIVE ${OPENCV_INSTALL_DATA_DIR_RELATIVE_STR}\n")

if(EXISTS "${OPENCV_DATA_CONFIG_FILE}")
  file(READ "${OPENCV_DATA_CONFIG_FILE}" __content)
endif()
if(NOT OPENCV_DATA_CONFIG_STR STREQUAL "${__content}")
  file(WRITE "${OPENCV_DATA_CONFIG_FILE}" "${OPENCV_DATA_CONFIG_STR}")
endif()

```

----------------------------------------

TITLE: Highgui Plugins Configuration Options in OpenCV
DESCRIPTION: Defines options available since OpenCV 4.5.3 to control building GTK backend as a dynamically loaded plugin for the highgui module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_19

LANGUAGE: markdown
CODE:
```
| Option | Default | Description |
| --------| ------ | ------- |
| `HIGHGUI_ENABLE_PLUGINS` | _ON_ | Enable or disable plugins completely. |
| `HIGHGUI_PLUGIN_LIST` | _empty_ | Comma- or semicolon-separated list of backend names to be compiled as plugins. Supported names are _gtk_, _gtk2_, _gtk3_, and _all_. |
```

----------------------------------------

TITLE: Configuring Basic x86 Features for ZLIB in CMake
DESCRIPTION: Sets up basic configurations for the x86 architecture (BASEARCH_X86_FOUND). It adds the DX86_FEATURES definition and appends common x86 header and source files (for runtime CPU detection if enabled). It also includes a fallback header for MSVC compilers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_24

LANGUAGE: cmake
CODE:
```
    elseif(BASEARCH_X86_FOUND)
        add_definitions(-DX86_FEATURES)
        list(APPEND ZLIB_ARCH_HDRS ${ARCHDIR}/x86_functions.h)
        if(WITH_RUNTIME_CPU_DETECTION)
            list(APPEND ZLIB_ARCH_HDRS ${ARCHDIR}/x86_features.h)
            list(APPEND ZLIB_ARCH_SRCS ${ARCHDIR}/x86_features.c)
        endif()
        if(MSVC)
            list(APPEND ZLIB_ARCH_HDRS fallback_builtins.h)
        endif()
```

----------------------------------------

TITLE: Backprojecting 3D Points to 2D in PnPProblem Using C++
DESCRIPTION: Contains the backproject3DPoint function of the PnPProblem class, projecting 3D world coordinates to 2D image points using the estimated rotation and translation. It outputs a 2D point in the image frame.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_19

LANGUAGE: cpp
CODE:
```
// Backproject a 3D point to 2D using the estimated pose parameters

cv::Point2f PnPProblem::backproject3DPoint(const cv::Point3f &point3d)
{
    // 3D point vector [x y z 1]'
    cv::Mat point3d_vec = cv::Mat(4, 1, CV_64FC1);
    point3d_vec.at<double>(0) = point3d.x;
    point3d_vec.at<double>(1) = point3d.y;
    point3d_vec.at<double>(2) = point3d.z;
    point3d_vec.at<double>(3) = 1;

    // 2D point vector [u v 1]'
    cv::Mat point2d_vec = cv::Mat(4, 1, CV_64FC1);
    point2d_vec = _A_matrix * _P_matrix * point3d_vec;

    // Normalization of [u v]'
    cv::Point2f point2d;
    point2d.x = point2d_vec.at<double>(0) / point2d_vec.at<double>(2);
    point2d.y = point2d_vec.at<double>(1) / point2d_vec.at<double>(2);

    return point2d;
}
```

----------------------------------------

TITLE: Configuring ZLIB-NG Support in CMake
DESCRIPTION: CMake configuration option for using zlib-ng as the zlib implementation in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/readme.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
WITH_ZLIB_NG=ON # Use zlib-ng implementation
```

----------------------------------------

TITLE: Building OpenCV.js Loader with Loader Option - Bash
DESCRIPTION: Builds OpenCV.js along with its optional loader by adding the --build_loader flag. The loader enables WebAssembly feature detection and automated selection of the appropriate OpenCV.js build at runtime. Requires emcmake, Python, and the optional dependency wasm-feature-detect for web usage. Outputs loader.js for web applications.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --build_loader
```

----------------------------------------

TITLE: Creating a New Clojure Project with Leiningen Bash
DESCRIPTION: This Bash command sequence illustrates creating a new Clojure project using Leiningen, with added dependencies for OpenCV. The project.clj file is modified to include OpenCV JARs. Expected output is a new project directory structure with specified dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
lein new simple-sample\ncd simple-sample
```

----------------------------------------

TITLE: Trackbar Callback in OpenCV Python
DESCRIPTION: Sets a trackbar on an OpenCV window and binds a callback function in Python, reacting to trackbar updates. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_16

LANGUAGE: Python
CODE:
```
cv2.createTrackbar("Trackbar", "Source", sliderValue, maxValue, on_trackbar)
```

----------------------------------------

TITLE: Specifying JPEG Color Space and Components in libjpeg (C)
DESCRIPTION: These C fields within the compression parameters structure (`cinfo`) define the color space used within the JPEG file (`jpeg_color_space`, type `J_COLOR_SPACE`) and the corresponding number of color components (`num_components`, type `int`). It is generally recommended to use the `jpeg_set_color_space()` function to set these values rather than modifying them directly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_33

LANGUAGE: C
CODE:
```
J_COLOR_SPACE jpeg_color_space
```

LANGUAGE: C
CODE:
```
int num_components
```

----------------------------------------

TITLE: Configuring Module Builds in OpenCV
DESCRIPTION: Shows how to enable or disable specific OpenCV modules using `cmake` options. This includes disabling a module or building specified modules with automatic dependency inclusion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_7

LANGUAGE: sh
CODE:
```
cmake -DBUILD_opencv_calib3d=OFF ../opencv
```

LANGUAGE: sh
CODE:
```
cmake -DBUILD_LIST=calib3d,videoio,ts ../opencv
```

----------------------------------------

TITLE: Building OpenCV.js with Docker Using Emscripten Version 2.0.10 - Bash
DESCRIPTION: This command runs the OpenCV.js build process inside a Docker container using the emscripten/emsdk:2.0.10 image to ensure compatibility. It mounts the current directory and sets correct user IDs for file permission matching. Recommended if the latest version of emscripten fails to build successfully. Outputs are OpenCV.js build files generated by Python3 and emcmake.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_25

LANGUAGE: bash
CODE:
```
docker run --rm -v $(pwd):/src -u $(id -u):$(id -g) emscripten/emsdk:2.0.10 emcmake python3 ./platforms/js/build_js.py build_js
```

----------------------------------------

TITLE: Alternative OpenNI SDK Environment Initialization Script (>= v2.3.0.86)
DESCRIPTION: A shell script provided as an alternative to `install.sh` for Orbbec OpenNI SDK versions 2.3.0.86 and newer. It checks for root privileges, determines the script's path, installs udev rules for the USB device (if not on Darwin/macOS), and creates an 'OpenNIDevEnvironment' file that exports the OPENNI2_INCLUDE and OPENNI2_REDIST environment variables pointing to the SDK location. This script needs to be run with sudo.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
# Check if user is root/running with sudo
if [ `whoami` != root ]; then
    echo Please run this script with sudo
    exit
fi

ORIG_PATH=`pwd`
cd `dirname $0`
SCRIPT_PATH=`pwd`
cd $ORIG_PATH

if [ "`uname -s`" != "Darwin" ]; then
    # Install UDEV rules for USB device
    cp ${SCRIPT_PATH}/orbbec-usb.rules /etc/udev/rules.d/558-orbbec-usb.rules
    echo "usb rules file install at /etc/udev/rules.d/558-orbbec-usb.rules"
fi

OUT_FILE="$SCRIPT_PATH/OpenNIDevEnvironment"
echo "export OPENNI2_INCLUDE=$SCRIPT_PATH/../sdk/Include" > $OUT_FILE
echo "export OPENNI2_REDIST=$SCRIPT_PATH/../sdk/libs" >> $OUT_FILE
chmod a+r $OUT_FILE
echo "exit"
```

----------------------------------------

TITLE: Setting Image Parameters for JPEG Compression with libjpeg in C
DESCRIPTION: This snippet illustrates how to configure the key image parameters needed before compressing an image with the libjpeg library in C. It sets the image width, height, number of input components (color channels), and is intended for use with a 24-bit RGB image. The example assumes that variables Width and Height are already defined. It is necessary to assign these values to the jpeg_compress_struct before starting the compression process. This configuration determines how the JPEG library interprets the source image data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_4

LANGUAGE: C
CODE:
```
cinfo.image_width = Width;      /* image width and height, in pixels */
cinfo.image_height = Height;
cinfo.input_components = 3;     /* # of color components per pixel */
```

----------------------------------------

TITLE: Storing SIMD Register Data into Memory using OpenCV Intrinsics (C++)
DESCRIPTION: This snippet illustrates how to store the contents of a SIMD register into a memory buffer using OpenCV intrinsics. The v_store function writes the register data (e.g., the first 128 bits / 4 floats) into the destination pointer. The type of 'ptr' must match the register's element type to avoid misinterpretation of stored values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
float ptr[4];
v_store(ptr, reg); // store the first 128 bits(interpreted as 4x32-bit floats) of reg into ptr.
```

----------------------------------------

TITLE: Reading Input Image
DESCRIPTION: Shows how to read the input image for ChArUco detection
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
cv::Mat image;
image = cv::imread(parser.get<cv::String>("image"));
```

----------------------------------------

TITLE: Building OpenCV with MSBuild (Windows) (Batch)
DESCRIPTION: This Batch command uses MSBuild to compile the OpenCV library based on the Visual Studio solution generated by CMake. It specifies the solution file ('OpenCV.sln'), the build target ('Build'), the configuration ('Release'), and verbosity ('m' for minimal). The '/m' flag enables parallel builds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_5

LANGUAGE: bat
CODE:
```
msbuild /m OpenCV.sln /t:Build /p:Configuration=Release /v:m
```

----------------------------------------

TITLE: Image Stitching Using OpenCV in Python
DESCRIPTION: This Python snippet executes image stitching using a homography matrix calculated from two rotating images via OpenCV. Dependencies are OpenCV and NumPy. Input expects image pairs and outputs a panoramic image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_38

LANGUAGE: Python
CODE:
```
import cv2
import numpy as np

def stitch_images(image1, image2, homography):
    # Code to stitch images
    # ...

```

----------------------------------------

TITLE: Installing Ninja Build System on Linux
DESCRIPTION: Command to install Ninja build system on Linux using the package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
sudo apt-get install ninja-build
```

----------------------------------------

TITLE: Sequential Convolution Implementation using OpenCV
DESCRIPTION: This snippet demonstrates a sequential implementation of image convolution using OpenCV. It involves iterating over the image pixels and applying the kernel to compute the convolution. The implementation handles edge cases by adding borders to the source image prior to computation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_new/how_to_use_OpenCV_parallel_for_new.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp convolution-sequential
```

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp convolution-make-borders
```

LANGUAGE: C++
CODE:
```
@snippet how_to_use_OpenCV_parallel_for_new.cpp convolution-kernel-loop
```

----------------------------------------

TITLE: Configuring and Populating the OpenCV World Project (CMake)
DESCRIPTION: This block executes after the initial CMake pass (`NOT OPENCV_INITIAL_PASS`). It disables precompiled headers for the world build, declares the `opencv_world` project, and applies a workaround for a linker issue in MSVC 2015 (VC14) by setting the `/INCREMENTAL:NO` flag. It then iterates through the modules listed in `OPENCV_MODULES_BUILD`, checks if each module is part of the world (`OPENCV_MODULE_${m}_IS_PART_OF_WORLD`), and includes its build configuration using the `include_one_module` function. Status messages indicate the progress. Finally, it sets the `CMAKE_CURRENT_SOURCE_DIR` for the `opencv_world` module itself.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
if(NOT OPENCV_INITIAL_PASS)
  set(ENABLE_PRECOMPILED_HEADERS OFF CACHE INTERNAL "" FORCE)
  project(opencv_world)

  # MSVS 2014 (vc14): LINK : fatal error LNK1210: exceeded internal ILK size limit; link with /INCREMENTAL:NO
  if(MSVC AND MSVC_VERSION EQUAL 1900)
    foreach(flag_var
            CMAKE_EXE_LINKER_FLAGS_DEBUG
            CMAKE_EXE_LINKER_FLAGS_RELWITHDEBINFO
            CMAKE_MODULE_LINKER_FLAGS_DEBUG
            CMAKE_MODULE_LINKER_FLAGS_RELWITHDEBINFO
            CMAKE_SHARED_LINKER_FLAGS_DEBUG
            CMAKE_SHARED_LINKER_FLAGS_RELWITHDEBINFO
    )
      if(${flag_var} MATCHES "/INCREMENTAL")
        string(REGEX REPLACE "/INCREMENTAL[^ ]*" "/INCREMENTAL:NO" ${flag_var} "${${flag_var}}")
      else()
        set(${flag_var} "${${flag_var}} /INCREMENTAL:NO*")
      endif()
    endforeach(flag_var)
  endif()

  message(STATUS "Processing WORLD modules...")
  foreach(m ${OPENCV_MODULES_BUILD})
    set(the_module ${m})
    if(OPENCV_MODULE_${m}_IS_PART_OF_WORLD)
      message(STATUS "    module ${m}...")
      set(CMAKE_CURRENT_SOURCE_DIR "${OPENCV_MODULE_${m}_LOCATION}")
      #add_subdirectory("${OPENCV_MODULE_${m}_LOCATION}" ${CMAKE_CURRENT_BINARY_DIR}/${m})
      include_one_module(${m})
    endif()
  endforeach()
  message(STATUS "Processing WORLD modules... DONE")
  set(CMAKE_CURRENT_SOURCE_DIR "${OPENCV_MODULE_opencv_world_LOCATION}")
endif()
```

----------------------------------------

TITLE: Implementing Pixel Comparison Logic for Feature Detection in C++
DESCRIPTION: This snippet contains a highly nested conditional structure that compares pixel values at different offsets. It's used to detect specific patterns or features in an image, likely part of a corner or edge detection algorithm in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_37

LANGUAGE: C++
CODE:
```
if(ptr[offset4] < c_b)
  if(ptr[offset5] > cb)
    if(ptr[offset12] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset9] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset13] > cb)
                  if(ptr[offset6] > cb)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset14] > cb)
                      if(ptr[offset15] > cb)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
    if(ptr[offset12] < c_b)
      if(ptr[offset13] < c_b)
        if(ptr[offset14] < c_b)
          if(ptr[offset15] < c_b)
            if(ptr[offset1] < c_b)
              if(ptr[offset3] < c_b)
                {} // goto success_homogeneous;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset8] < c_b)
                if(ptr[offset9] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset9] < c_b)
                    if(ptr[offset10] < c_b)
                      if(ptr[offset11] < c_b)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
  if(ptr[offset5] < c_b)
    if(ptr[offset7] > cb)
      if(ptr[offset14] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset9] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset12] > cb)
                  if(ptr[offset13] > cb)
                    if(ptr[offset6] > cb)
                      {} // goto success_homogeneous;
                    else
                      if(ptr[offset15] > cb)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
      if(ptr[offset14] < c_b)
        if(ptr[offset15] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset6] < c_b)
                {} // goto success_homogeneous;
              else
                if(ptr[offset13] < c_b)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset12] < c_b)
                    if(ptr[offset13] < c_b)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset8] < c_b)
              if(ptr[offset9] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    if(ptr[offset12] < c_b)
                      if(ptr[offset13] < c_b)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
    if(ptr[offset7] < c_b)
      if(ptr[offset3] < c_b)
        if(ptr[offset1] < c_b)
          if(ptr[offset6] < c_b)
            if(ptr[offset8] < c_b)
              {} // goto success_homogeneous;
            else
              if(ptr[offset15] < c_b)
                {} // goto success_homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset13] < c_b)
              if(ptr[offset14] < c_b)
                if(ptr[offset15] < c_b)
```

----------------------------------------

TITLE: Documenting Functions in C++ with Doxygen
DESCRIPTION: Provides an example of documenting a C++ function using Doxygen syntax. This includes brief descriptions, parameter documentation, and equations formatted with TeX, assuming familiarity with Doxygen comment conventions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_3

LANGUAGE: c++
CODE:
```
/** @brief Calculates the exponent of every array element.

The function exp calculates the exponent of every element of the input array: 
\f[ \texttt{dst} [I] = e^{ src(I) } \f]

The maximum relative error is about 7e-6 for single-precision input and less than 1e-10 for
double-precision input. Currently, the function converts denormalized values to zeros on output.
Special values (NaN, Inf) are not handled.

@param src input array.
@param dst output array of the same size and type as src.

@sa log , cartToPolar , polarToCart , phase , pow , sqrt , magnitude
*/
CV_EXPORTS_W void exp(InputArray src, OutputArray dst);
```

----------------------------------------

TITLE: Customizing Source File Compile Definitions and API Header Inclusion - Platform-Specific Logic - CMake
DESCRIPTION: Applies a compile definition DEBUG_POSTFIX to the backend_plugin.cpp file if the OPENCV_DEBUG_POSTFIX variable is defined. Removes WinRT and iOS-specific API headers from the list of public headers unless explicitly enabled, and adjusts C++ build flags for certain WinRT modes. This platform-specific logic ensures correct compilation and API exposure depending on build settings and target environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
if(OPENCV_DEBUG_POSTFIX)
  ocv_append_source_file_compile_definitions("${CMAKE_CURRENT_LIST_DIR}/src/backend_plugin.cpp" "DEBUG_POSTFIX=${OPENCV_DEBUG_POSTFIX}")
endif()

# Removing WinRT API headers by default
list(REMOVE_ITEM videoio_ext_hdrs "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cap_winrt.hpp")

# Remove iOS API header by default
list(REMOVE_ITEM videoio_ext_hdrs "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cap_ios.h")

if(DEFINED WINRT AND NOT DEFINED ENABLE_WINRT_MODE_NATIVE)
  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /ZW")
endif()
```

----------------------------------------

TITLE: Configuring Win32UI Backend for HighGUI in CMake
DESCRIPTION: Sets up the Win32UI backend for OpenCV HighGUI on Windows platforms. Handles both plugin and built-in configurations, and adds OpenGL support if available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_15

LANGUAGE: CMake
CODE:
```
if(TARGET ocv.3rdparty.win32ui)
  if("win32ui" IN_LIST HIGHGUI_PLUGIN_LIST OR HIGHGUI_PLUGIN_LIST STREQUAL "all")
    ocv_create_builtin_highgui_plugin(opencv_highgui_win32 ocv.3rdparty.win32ui "window_w32.cpp")
  elseif(NOT OPENCV_HIGHGUI_BUILTIN_BACKEND)
    set(OPENCV_HIGHGUI_BUILTIN_BACKEND "WIN32UI")
    list(APPEND highgui_srcs ${CMAKE_CURRENT_LIST_DIR}/src/window_w32.cpp)
    list(APPEND tgts ocv.3rdparty.win32ui)
    if(HAVE_OPENGL AND OPENGL_LIBRARIES)
      list(APPEND tgts "${OPENGL_LIBRARIES}")
    endif()
  endif()
endif()
```

----------------------------------------

TITLE: Example Directory Structure for -info File Method (Text)
DESCRIPTION: Shows the recommended directory structure when using the `-info <collection_file_name>` argument with `opencv_createsamples`. It demonstrates placing the image files (e.g., `img1.jpg`, `img2.jpg`) within a subdirectory (`img`) relative to the description file (`info.dat`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/traincascade.markdown#2025-04-22_snippet_2

LANGUAGE: text
CODE:
```
/img
  img1.jpg
  img2.jpg
info.dat
```

----------------------------------------

TITLE: Drawing a Filled Circle in Python
DESCRIPTION: Implementation of the MyFilledCircle function that draws a filled circle in OpenCV Python. The function takes the image and center point, and uses the circle() function with a negative thickness value to create a solid filled circle.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_23

LANGUAGE: python
CODE:
```
def MyFilledCircle(img, center):
    cv.circle(img,
               center,
               w//32,
               (0, 0, 255),
               -1,
               cv.LINE_8)
```

----------------------------------------

TITLE: Building OpenCV from Source on macOS
DESCRIPTION: This command builds OpenCV using make, utilizing all available CPU cores for faster compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
make -j$(sysctl -n hw.ncpu)
```

----------------------------------------

TITLE: Configuring Android Project in CMake
DESCRIPTION: Sets up an Android project for the MobileNet object detection example. Configures project dependencies and SDK target version, and adds it to OpenCV Android examples if the target is successfully created.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/mobilenet-objdetect/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Installing Clang Compiler on Linux
DESCRIPTION: Command to install the Clang compiler on Linux using the package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
sudo apt-get install clang
```

----------------------------------------

TITLE: Configuring Doxyfile for OpenCV Tag Linking - Doxygen Configuration
DESCRIPTION: This configuration snippet sets the Doxygen TAGFILES variable to link the local OpenCV tag file to the remote documentation. It enables automatic hyperlinking from entities like cv::Mat referenced in your project to their definitions in the OpenCV documentation. You need to have the opencv.tag file downloaded locally in docs/doxygen-tags/ and Doxygen installed. 'TAGFILES' accepts path and URL pairs; output is extended references in HTML docs. Constraints: the local and URL paths must be accurate.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/cross_referencing/tutorial_cross_referencing.markdown#2025-04-22_snippet_1

LANGUAGE: Doxygen
CODE:
```
TAGFILES = ./docs/doxygen-tags/opencv.tag=http://docs.opencv.org/4.11.0
```

----------------------------------------

TITLE: Enabling libjpeg v7 API/ABI Emulation via CMake Option
DESCRIPTION: Provides the CMake command-line argument `-DWITH_JPEG7=1` used to configure the libjpeg-turbo build process. Setting this option enables emulation of the libjpeg v7 API and ABI, allowing applications compiled against libjpeg v7 to run with libjpeg-turbo without recompilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/README.md#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
-DWITH_JPEG7=1
```

----------------------------------------

TITLE: Setting Linear JPEG Compression Quality (C)
DESCRIPTION: Similar to jpeg_set_quality(), but uses sample tables from the JPEG standard multiplied by a scale factor. Larger scale factors result in lower quality. Useful for conforming to Adobe PostScript DCT conventions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_24

LANGUAGE: C
CODE:
```
jpeg_set_linear_quality (j_compress_ptr cinfo, int scale_factor,
                         boolean force_baseline)
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Decision Tree in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm that evaluates whether a pixel is a corner based on comparisons with its surrounding pixels. It uses conditional branching with goto statements to efficiently navigate the decision tree of pixel intensity comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_28

LANGUAGE: C++
CODE:
```
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset8] < c_b)
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset11] < c_b)
                            if(ptr[offset3] < c_b)
                              if(ptr[offset4] < c_b)
                                goto is_a_corner;
                              else
                                if(ptr[offset10] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset8] < c_b)
                                if(ptr[offset10] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset7] < c_b)
                if(ptr[offset2] > cb)
                  if(ptr[offset1] > cb)
                    if(ptr[offset6] > cb)
                      goto is_not_a_corner;
                    else
                      if(ptr[offset6] < c_b)
                        if(ptr[offset8] < c_b)
                          if(ptr[offset4] < c_b)
                            if(ptr[offset3] < c_b)
                              goto is_a_corner;
                            else
                              if(ptr[offset10] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset10] < c_b)
                              if(ptr[offset11] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset1] < c_b)
                      if(ptr[offset6] > cb)
                        if(ptr[offset8] < c_b)
                          if(ptr[offset10] < c_b)
                            if(ptr[offset11] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        if(ptr[offset6] < c_b)
                          if(ptr[offset8] < c_b)
                            if(ptr[offset4] < c_b)
                              if(ptr[offset3] < c_b)
                                goto is_a_corner;
                              else
                                if(ptr[offset10] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          if(ptr[offset8] < c_b)
                            if(ptr[offset10] < c_b)
                              if(ptr[offset11] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                    else
                      if(ptr[offset6] > cb)
                        goto is_not_a_corner;
                      else
                        if(ptr[offset6] < c_b)
                          if(ptr[offset8] < c_b)
                            if(ptr[offset4] < c_b)
                              if(ptr[offset3] < c_b)
                                goto is_a_corner;
                              else
                                if(ptr[offset10] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                else
                  if(ptr[offset2] < c_b)
                    if(ptr[offset1] > cb)
                      if(ptr[offset6] > cb)
                        goto is_not_a_corner;
                      else
                        if(ptr[offset6] < c_b)
                          if(ptr[offset8] < c_b)
                            if(ptr[offset4] < c_b)
                              if(ptr[offset3] < c_b)
                                goto is_a_corner;
                              else
                                if(ptr[offset10] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset1] < c_b)
                        if(ptr[offset6] > cb)
                          if(ptr[offset11] < c_b)
                            if(ptr[offset3] < c_b)
                              if(ptr[offset4] < c_b)
                                goto is_a_corner;
                              else
                                if(ptr[offset10] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset8] < c_b)
                                if(ptr[offset10] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          if(ptr[offset6] < c_b)
                            if(ptr[offset3] < c_b)
                              if(ptr[offset4] < c_b)
                                goto is_a_corner;
                              else
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset8] < c_b)
```

----------------------------------------

TITLE: FFmpeg Configuration Option in OpenCV
DESCRIPTION: Defines the WITH_FFMPEG build option for integrating with the FFmpeg library for video decoding and encoding. This enables support for various video formats through required components including avcodec, avformat, avutil, and swscale.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_11

LANGUAGE: markdown
CODE:
```
`WITH_FFMPEG` (default: _ON_)
```

----------------------------------------

TITLE: Running OpenCV Semihosting Examples with QEMU
DESCRIPTION: These commands demonstrate how to execute the compiled OpenCV semihosting example applications (`example_semihosting_histogram` and `example_semihosting_norm`) using the QEMU AArch64 emulator (`qemu-aarch64`). This allows testing the semihosting binaries in a Linux userspace environment. Assumes the binaries are located in the `./bin/` directory relative to where the command is run and that `qemu-aarch64` is installed and available in the system's PATH.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/semihosting/README.md#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
    qemu-aarch64 ./bin/example_semihosting_histogram
    qemu-aarch64 ./bin/example_semihosting_norm
```

----------------------------------------

TITLE: Configuring CMake for OpenCV HAL in CMake
DESCRIPTION: This snippet sets up a CMake project to build a shared library for the OpenCV HAL using the CMake build system. It sets the CMake minimum version, project name, and library details. The snippet also configures include directories and copies specific header files and configuration files to the build directory. Dependencies include OpenCV source directory and standard CMake utilities. Key outputs are the configuration file and library artifacts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/hal/c_hal/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.5 FATAL_ERROR)

set(PROJECT_NAME "c_hal")
set(HAL_LIB_NAME "c_hal")

add_library(${HAL_LIB_NAME} impl.c)
set_target_properties(${HAL_LIB_NAME} PROPERTIES POSITION_INDEPENDENT_CODE TRUE)
set(OPENCV_SRC_DIR "${CMAKE_CURRENT_SOURCE_DIR}/../../..")
target_include_directories(${HAL_LIB_NAME} PUBLIC ${CMAKE_CURRENT_SOURCE_DIR} ${OPENCV_SRC_DIR}/modules/core/include)

set(OpenCV_HAL_FOUND TRUE)
set(OpenCV_HAL_VERSION 0.0.1)
set(OpenCV_HAL_LIBRARIES ${CMAKE_CURRENT_BINARY_DIR}/lib${HAL_LIB_NAME}.a)
set(OpenCV_HAL_HEADERS "impl.h")
set(OpenCV_HAL_INCLUDE_DIRS ${CMAKE_CURRENT_LIST_DIR})

configure_file("impl.h" "${CMAKE_BINARY_DIR}/impl.h" COPYONLY)
configure_file("config.cmake" "${CMAKE_BINARY_DIR}/OpenCV_HALConfig.cmake")
```

----------------------------------------

TITLE: Sourcing OpenNI Environment Variables
DESCRIPTION: Executes the 'OpenNIDevEnvironment' script provided by the Orbbec OpenNI SDK. This script sets environment variables (like OPENNI2_INCLUDE and OPENNI2_REDIST) necessary for development tools and OpenCV's build system to find the OpenNI headers and libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
$ source OpenNIDevEnvironment
```

----------------------------------------

TITLE: Setting up zlib Source Files and Build Targets
DESCRIPTION: Configures source files, headers, and build targets for zlib library. Supports both static and shared library builds with conditional compilation of additional features like GZFILE operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_36

LANGUAGE: cmake
CODE:
```
set(ZLIB_PUBLIC_HDRS
    ${CMAKE_CURRENT_BINARY_DIR}/zconf${SUFFIX}.h
    ${CMAKE_CURRENT_BINARY_DIR}/zlib_name_mangling${SUFFIX}.h
    ${CMAKE_CURRENT_BINARY_DIR}/zlib${SUFFIX}.h
)
set(ZLIB_PRIVATE_HDRS
    adler32_p.h
    chunkset_tpl.h
    compare256_rle.h
    arch_functions.h
    crc32_braid_p.h
    crc32_braid_comb_p.h
    crc32_braid_tbl.h
    deflate.h
    deflate_p.h
    functable.h
    inffast_tpl.h
    inffixed_tbl.h
    inflate.h
    inflate_p.h
    inftrees.h
    insert_string_tpl.h
    match_tpl.h
    trees.h
    trees_emit.h
    trees_tbl.h
    zbuild.h
    zendian.h
    zutil.h
)
```

----------------------------------------

TITLE: Generating Colored Segmentation Mask from Predictions
DESCRIPTION: This Python snippet post-processes the raw segmentation prediction (a 2D array of class IDs, `segm_mask`) to create a visually interpretable colored mask. It uses a predefined list or dictionary `colors` (mapping class IDs to BGR or RGB color tuples, likely loaded from PASCAL VOC info) to map each predicted class ID to its corresponding color. The resulting flat list of colors is reshaped into a 3-channel image (`processed_mask`) matching the mask's height and width. This mask is then resized using nearest-neighbor interpolation (`cv2.INTER_NEAREST`) to match the original input image dimensions (`img_width`, `img_height`) and converted to `uint8` format. Finally, `cv2.cvtColor` might be used to ensure the color format (e.g., BGR to RGB) is consistent, for instance, with PASCAL VOC color definitions. Requires `numpy` and `cv2` (OpenCV).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_9

LANGUAGE: python
CODE:
```
# convert mask values into PASCAL VOC colors
processed_mask = np.stack([colors[color_id] for color_id in segm_mask.flatten()])

# reshape mask into 3-channel image
processed_mask = processed_mask.reshape(mask_height, mask_width, 3)
processed_mask = cv2.resize(processed_mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST).astype(
    np.uint8)

# convert colored mask from BGR to RGB for compatibility with PASCAL VOC colors
processed_mask = cv2.cvtColor(processed_mask, cv2.COLOR_BGR2RGB)
```

----------------------------------------

TITLE: Configuring OpenJPEG Threading Support
DESCRIPTION: Sets up threading configuration for OpenJPEG, including platform-specific mutex implementations and thread library detection. Handles Windows and POSIX thread support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/openjp2/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
option(OPJ_USE_THREAD "Build with thread/mutex support " ON)
if(NOT OPJ_USE_THREAD)
  add_definitions(-DMUTEX_stub)
endif()

find_package(Threads QUIET)

if(OPJ_USE_THREAD AND WIN32 AND NOT Threads_FOUND )
  add_definitions(-DMUTEX_win32)
  set(Threads_FOUND YES)
endif()

if(OPJ_USE_THREAD AND Threads_FOUND AND CMAKE_USE_WIN32_THREADS_INIT)
  add_definitions(-DMUTEX_win32)
endif()

if(OPJ_USE_THREAD AND Threads_FOUND AND CMAKE_USE_PTHREADS_INIT )
  add_definitions(-DMUTEX_pthread)
endif()
```

----------------------------------------

TITLE: Checking Python Version in gdb
DESCRIPTION: This snippet checks the Python version bundled with gdb. It requires gdb to be active and a shell session open within gdb. The script prints the Python version info, which is crucial for compatibility checks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_gdb_pretty_printer/linux_gdb_pretty_printer.markdown#2025-04-22_snippet_0

LANGUAGE: Shell
CODE:
```
python
import sys
print(sys.version_info)
end
```

----------------------------------------

TITLE: Adjusting MSVC Compiler Flags for Standalone Build in CMake
DESCRIPTION: Modifies C/C++ compiler and linker flags specifically for the MSVC compiler when building samples standalone. If build hardening isn't enabled, it suppresses CRT secure warnings. If linking against a static OpenCV library (`NOT OpenCV_SHARED`), it changes the C runtime library linkage from dynamic (/MD, /MDd) to static (/MT, /MTd) in standard CMake flag variables and adjusts linker flags to ignore conflicting default libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: cmake
CODE:
```
if(MSVC)
  if(NOT ENABLE_BUILD_HARDENING)
    add_definitions(-D_CRT_SECURE_NO_WARNINGS)
  endif()

  if(NOT OpenCV_SHARED)
    foreach(flag_var
            CMAKE_C_FLAGS CMAKE_C_FLAGS_DEBUG CMAKE_C_FLAGS_RELEASE
            CMAKE_C_FLAGS_MINSIZEREL CMAKE_C_FLAGS_RELWITHDEBINFO
            CMAKE_CXX_FLAGS CMAKE_CXX_FLAGS_DEBUG CMAKE_CXX_FLAGS_RELEASE
            CMAKE_CXX_FLAGS_MINSIZEREL CMAKE_CXX_FLAGS_RELWITHDEBINFO)
      if(${flag_var} MATCHES "/MD")
        string(REGEX REPLACE "/MD" "/MT" ${flag_var} "${${flag_var}}")
      endif()
      if(${flag_var} MATCHES "/MDd")
        string(REGEX REPLACE "/MDd" "/MTd" ${flag_var} "${${flag_var}}")
      endif()
    endforeach(flag_var)

    set(CMAKE_EXE_LINKER_FLAGS "${CMAKE_EXE_LINKER_FLAGS} /NODEFAULTLIB:atlthunk.lib /NODEFAULTLIB:msvcrt.lib /NODEFAULTLIB:msvcrtd.lib")
    if(NOT BUILD_WITH_STATIC_CRT)
      set(CMAKE_EXE_LINKER_FLAGS_DEBUG "${CMAKE_EXE_LINKER_FLAGS_DEBUG} /NODEFAULTLIB:libcmt.lib")
      set(CMAKE_EXE_LINKER_FLAGS_RELEASE "${CMAKE_EXE_LINKER_FLAGS_RELEASE} /NODEFAULTLIB:libcmtd.lib")
    endif()
  endif()
endif()
```

----------------------------------------

TITLE: Generating Asymmetric Circle Grid Pattern using Python Script (Shell)
DESCRIPTION: Uses the 'gen_pattern.py' script to create an asymmetric circle grid pattern ('acircles') saved as 'acircleboard.svg'. It specifies 7 rows, 5 columns, a square size of 10mm, and a radius rate of 2 (meaning radius = square_size / 2 * radius_rate = 10mm), resulting in less spacing between circles compared to the symmetric type. Requires Python and the 'gen_pattern.py' script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_pattern/camera_calibration_pattern.markdown#2025-04-22_snippet_2

LANGUAGE: shell
CODE:
```
python gen_pattern.py -o acircleboard.svg --rows 7 --columns 5 --type acircles --square_size 10 --radius_rate 2
```

----------------------------------------

TITLE: Downloading OpenCV Source Using wget
DESCRIPTION: Commands to download and extract OpenCV source code using wget and unzip.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_9

LANGUAGE: bash
CODE:
```
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
unzip opencv.zip
```

----------------------------------------

TITLE: Creating Destination Images and Mapping Matrices
DESCRIPTION: Initializes destination image and mapping matrices for x and y coordinates that will be used in the remapping process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/remap/remap.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
Mat dst, map_x, map_y;
dst.create( src.size(), src.type() );
map_x.create( src.size(), CV_32FC1 );
map_y.create( src.size(), CV_32FC1 );
```

LANGUAGE: Java
CODE:
```
Mat dst = new Mat();
Mat map_x = new Mat();
Mat map_y = new Mat();
dst.create(src.size(), src.type());
map_x.create(src.size(), CvType.CV_32FC1);
map_y.create(src.size(), CvType.CV_32FC1);
```

LANGUAGE: Python
CODE:
```
dst = np.zeros(src.shape, dtype=src.dtype)
map_x = np.zeros((src.shape[0], src.shape[1]), dtype=np.float32)
map_y = np.zeros((src.shape[0], src.shape[1]), dtype=np.float32)
```

----------------------------------------

TITLE: Configuring OpenCV.js Loader in CMake
DESCRIPTION: Sets up a custom command to copy the loader.js file to the output directory, which is used for loading OpenCV.js in web environments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
set(opencv_loader_js_bin_dir "${EXECUTABLE_OUTPUT_PATH}")
set(loader_dir ${CMAKE_CURRENT_SOURCE_DIR}/src)

set(opencv_loader_js_file_deps "")

file(MAKE_DIRECTORY "${opencv_loader_js_bin_dir}")

add_custom_command(
        TARGET ${PROJECT_NAME} POST_BUILD
        COMMAND ${CMAKE_COMMAND} -E copy
                ${loader_dir}/loader.js
                ${opencv_loader_js_bin_dir}/loader.js)
list(APPEND opencv_loader_js_file_deps "${loader_dir}/loader.js" "${opencv_loader_js_bin_dir}/loader.js")

add_custom_target(${PROJECT_NAME}_loader ALL
                  DEPENDS ${OCV_JS_PATH} ${opencv_loader_js_file_deps})

add_custom_target(opencv_test_js ALL DEPENDS opencv_js_test opencv_js_perf opencv_js_loader)
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Logic in C++
DESCRIPTION: This code snippet implements the core logic of the FAST corner detection algorithm. It compares pixel values at various offsets to determine if a point is a corner. The algorithm uses goto statements to efficiently navigate through different conditions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_31

LANGUAGE: C++
CODE:
```
else
  if(ptr[offset1] < c_b)
    if(ptr[offset6] > cb)
      if(ptr[offset8] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        if(ptr[offset8] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset8] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
  else
    if(ptr[offset6] > cb)
      goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        if(ptr[offset8] < c_b)
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset7] > cb)
    if(ptr[offset9] < c_b)
      if(ptr[offset1] > cb)
        if(ptr[offset6] < c_b)
          goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset1] < c_b)
          if(ptr[offset6] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset8] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset8] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
    else
      if(ptr[offset9] > cb)
        if(ptr[offset1] < c_b)
          if(ptr[offset6] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset3] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset6] < c_b)
              goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset3] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset8] > cb)
                      if(ptr[offset10] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset8] > cb)
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset8] > cb)
                  if(ptr[offset4] > cb)
                    if(ptr[offset3] > cb)
                      goto is_a_corner;
                    else
                      if(ptr[offset10] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
      else
        if(ptr[offset1] > cb)
          if(ptr[offset6] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset6] < c_b)
              goto is_not_a_corner;
            else
```

----------------------------------------

TITLE: Setting Default JPEG Compression Parameters (C)
DESCRIPTION: This function sets all JPEG parameters to reasonable defaults based on the input image's color space. It's recommended to call this function before setting any specific parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_20

LANGUAGE: C
CODE:
```
jpeg_set_defaults (j_compress_ptr cinfo)
```

----------------------------------------

TITLE: Listing OpenCV GUI Tutorials in Markdown
DESCRIPTION: This snippet lists various GUI-related tutorials for OpenCV using Markdown syntax. Each list item includes a reference to a specific tutorial page and a brief description of its content.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_table_of_contents_gui.markdown#2025-04-22_snippet_1

LANGUAGE: Markdown
CODE:
```
-   @ref tutorial_display_image

    Learn to load an
    image, display it, and save it back

-   @subpage tutorial_py_video_display

    Learn to play videos,
    capture videos from a camera, and write videos

-   @subpage tutorial_py_drawing_functions

    Learn to draw lines,
    rectangles, ellipses, circles, etc with OpenCV

-   @subpage tutorial_py_mouse_handling

    Draw stuff with your
    mouse

-   @subpage tutorial_py_trackbar

    Create trackbar to
    control certain parameters
```

----------------------------------------

TITLE: Conditionally Including cudacodec Module in CMake
DESCRIPTION: Checks if the `opencv_cudacodec` module is available (`HAVE_opencv_cudacodec` is true). If it is, it uses `ocv_include_modules_recurse` to include its headers and settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: cmake
CODE:
```
if(HAVE_opencv_cudacodec)
  ocv_include_modules_recurse(opencv_cudacodec)
endif()
```

----------------------------------------

TITLE: XML Configuration for Camera Calibration Input Images
DESCRIPTION: This XML snippet shows the structure of a configuration file used to specify input images for camera calibration in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_12

LANGUAGE: xml
CODE:
```
<?xml version="1.0"?>
<opencv_storage>
<images>
images/CameraCalibration/VID5/xx1.jpg
images/CameraCalibration/VID5/xx2.jpg
images/CameraCalibration/VID5/xx3.jpg
images/CameraCalibration/VID5/xx4.jpg
images/CameraCalibration/VID5/xx5.jpg
images/CameraCalibration/VID5/xx6.jpg
images/CameraCalibration/VID5/xx7.jpg
images/CameraCalibration/VID5/xx8.jpg
</images>
</opencv_storage>
```

----------------------------------------

TITLE: Loading Camera Calibration Results with OpenCV (Python)
DESCRIPTION: This snippet loads previously computed camera calibration data from an .npz file, retrieving the camera matrix and distortion coefficients needed for subsequent pose estimation calculations. It uses NumPy to load data, expects 'mtx' and 'dist' arrays to be present, and is required as a dependency for all the following pose estimation computations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_pose/py_pose.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np\nimport cv2 as cv\nglob\n\n# Load previously saved data\nwith np.load('B.npz') as X:\n    mtx, dist, _, _ = [X[i] for i in ('mtx','dist','rvecs','tvecs')]
```

----------------------------------------

TITLE: Finding Shortest Distance with Point Polygon Test in OpenCV in JavaScript
DESCRIPTION: This JavaScript code snippet uses the OpenCV function cv.pointPolygonTest to determine the shortest distance from a given point to the closest edge of a contour. It accepts a contour, a point, and a boolean to determine if the distance should be measured. If measureDist is true, the function returns the signed distance, while measureDist false only checks point-in-contour status.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contours_more_functions/js_contours_more_functions.markdown#2025-04-22_snippet_1

LANGUAGE: JavaScript
CODE:
```
let dist = cv.pointPolygonTest(cnt, new cv.Point(50, 50), true);
```

----------------------------------------

TITLE: Conditionally Setting WinRT Compilation Flags in CMake
DESCRIPTION: Checks if the `WINRT` variable is defined and `ENABLE_WINRT_MODE_NATIVE` is not defined. If these conditions are met (indicating a non-native WinRT build, likely C++/CX), it appends the `/ZW` flag to the C++ compiler flags (`CMAKE_CXX_FLAGS`) to enable Windows Runtime language extensions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
if(DEFINED WINRT AND NOT DEFINED ENABLE_WINRT_MODE_NATIVE)
  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /ZW")
endif()
```

----------------------------------------

TITLE: Installing Prerequisites
DESCRIPTION: Command to install Podman container management tool using DNF package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/s390/README.md#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
sudo dnf install podman
```

----------------------------------------

TITLE: Splitting and Merging Matrix Channels in OpenCV JavaScript
DESCRIPTION: These snippets show cv.split, which decomposes a multi-channel array into its constituent channels (arrays), and cv.merge, which combines multiple arrays into a single multi-channel matrix. They facilitate manipulating individual frequency or spatial channels during image processing. Inputs include the source matrix/vector and output destination(s). Dependencies: OpenCV.js; arrays involved must have compatible size and depth.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_transforms/js_fourier_transform/js_fourier_transform.markdown#2025-04-22_snippet_4

LANGUAGE: JavaScript
CODE:
```
cv.split (m, mv)
```

LANGUAGE: JavaScript
CODE:
```
cv.merge (mv, dst)
```

----------------------------------------

TITLE: Building OpenCV Framework Excluding Specific Module in Bash
DESCRIPTION: Command to build the OpenCV framework for iOS with extra modules, excluding a specific module (e.g., optflow).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/ios_install/ios_install.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
cd ~/<my_working_directory>
python opencv/platforms/ios/build_framework.py ios --contrib opencv_contrib --without optflow
```

----------------------------------------

TITLE: Example CMake Output Verifying OpenNI2 Support
DESCRIPTION: Shows a snippet of typical CMake configuration output for OpenCV. The line 'OpenNI2:                     YES (2.3.0)' confirms that CMake successfully detected the OpenNI2 SDK (version 2.3.0 in this example) and that OpenCV will be built with support for it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_5

LANGUAGE: text
CODE:
```
--   Video I/O:
--     DC1394:                      YES (2.2.6)
--     FFMPEG:                      YES
--       avcodec:                   YES (58.91.100)
--       avformat:                  YES (58.45.100)
--       avutil:                    YES (56.51.100)
--       swscale:                   YES (5.7.100)
--       avresample:                NO
--     GStreamer:                   YES (1.18.1)
--     OpenNI2:                     YES (2.3.0)
--     v4l/v4l2:                    YES (linux/videodev2.h)
```

----------------------------------------

TITLE: Adding Dispatched Source Files for Architecture Optimization - CMake
DESCRIPTION: This snippet triggers inclusion of the \"undistort\" source with architecture-specific optimizations (SSE2, AVX2) in the build. It relies on OpenCV's custom macro \"ocv_add_dispatched_file\" and aids in conditional compilation for performance. The function expects source file and one or more target architectures as parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/calib3d/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
ocv_add_dispatched_file(undistort SSE2 AVX2)
```

----------------------------------------

TITLE: Configuring Installation Rules for libjasper in CMake
DESCRIPTION: This snippet sets up installation rules for the libjasper library and its associated license files within the OpenCV project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjasper/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${JASPER_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(jasper LICENSE README copyright)
```

----------------------------------------

TITLE: Generating Doxygen Configuration Files from Templates in CMake
DESCRIPTION: Uses the `configure_file` command to generate the final `DoxygenLayout.xml`, `Doxyfile`, and `root.markdown` files in the build directory (`CMAKE_CURRENT_BINARY_DIR`). It uses the template files specified by `OPENCV_DOCS_DOXYGEN_LAYOUT`, `OPENCV_DOCS_DOXYFILE_IN`, and `root.markdown.in`, substituting variables marked with `@VAR@` (due to `@ONLY`) with their current CMake values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_15

LANGUAGE: cmake
CODE:
```
# writing file
configure_file("${OPENCV_DOCS_DOXYGEN_LAYOUT}" DoxygenLayout.xml @ONLY)
configure_file("${OPENCV_DOCS_DOXYFILE_IN}" ${doxyfile} @ONLY)
configure_file(root.markdown.in ${rootfile} @ONLY)
```

----------------------------------------

TITLE: Configuring OpenCV JavaScript Module in CMake
DESCRIPTION: Sets up the OpenCV JavaScript module, including dependencies, compiler flags, and build targets. It checks for Emscripten and Python, configures the module, and sets up compilation and linking flags for Emscripten.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(OPENCV_INITIAL_PASS)
  add_subdirectory(generator)
endif()

if(NOT BUILD_opencv_js)
  return()
endif()

set(the_description "The JavaScript(JS) bindings")

set(OPENCV_JS "opencv.js")
set(JS_HELPER "${CMAKE_CURRENT_SOURCE_DIR}/src/helpers.js")

find_path(EMSCRIPTEN_INCLUDE_DIR
          emscripten/bind.h
          PATHS
            ENV EMSCRIPTEN_ROOT
          PATH_SUFFIXES system/include include
          DOC "Location of Emscripten SDK")

if(NOT EMSCRIPTEN_INCLUDE_DIR OR NOT PYTHON_DEFAULT_AVAILABLE)
  set(DISABLE_MSG "Module 'js' disabled because the following dependencies are not found:")
  if(NOT EMSCRIPTEN_INCLUDE_DIR)
    set(DISABLE_MSG "${DISABLE_MSG} Emscripten")
  endif()
  if(NOT PYTHON_DEFAULT_AVAILABLE)
    set(DISABLE_MSG "${DISABLE_MSG} Python")
  endif()
  message(STATUS ${DISABLE_MSG})
  ocv_module_disable(js)
endif()

ocv_add_module(js BINDINGS PRIVATE_REQUIRED opencv_js_bindings_generator)

ocv_module_include_directories(${EMSCRIPTEN_INCLUDE_DIR})

add_definitions("-std=c++11")

set(deps ${OPENCV_MODULE_${the_module}_DEPS})
list(REMOVE_ITEM deps opencv_js_bindings_generator)
link_libraries(${deps})

set(bindings_cpp "${OPENCV_JS_BINDINGS_DIR}/gen/bindings.cpp")
set_source_files_properties(${bindings_cpp} PROPERTIES GENERATED TRUE)

OCV_OPTION(BUILD_WASM_INTRIN_TESTS "Build WASM intrin tests" OFF )
if(BUILD_WASM_INTRIN_TESTS)
  add_definitions(-DTEST_WASM_INTRIN)
  ocv_module_include_directories("${CMAKE_CURRENT_SOURCE_DIR}/../ts/include")
  ocv_module_include_directories("${CMAKE_CURRENT_SOURCE_DIR}/../imgcodecs/include")
  ocv_module_include_directories("${CMAKE_CURRENT_SOURCE_DIR}/../videoio/include")
  ocv_module_include_directories("${CMAKE_CURRENT_SOURCE_DIR}/../highgui/include")
  ocv_add_executable(${the_module} ${bindings_cpp} "${CMAKE_CURRENT_SOURCE_DIR}/../ts/src/ts_gtest.cpp")
else()
  ocv_add_executable(${the_module} ${bindings_cpp})
endif()

add_dependencies(${the_module} gen_opencv_js_source)

set(COMPILE_FLAGS "")
if(NOT CMAKE_CXX_COMPILER_ID MATCHES "MSVC")
    set(COMPILE_FLAGS "${COMPILE_FLAGS} -Wno-missing-prototypes")
endif()
if(COMPILE_FLAGS)
    set_target_properties(${the_module} PROPERTIES COMPILE_FLAGS ${COMPILE_FLAGS})
endif()

set(EMSCRIPTEN_LINK_FLAGS "${EMSCRIPTEN_LINK_FLAGS} -s TOTAL_MEMORY=128MB -s WASM_MEM_MAX=1GB -s ALLOW_MEMORY_GROWTH=1")
set(EMSCRIPTEN_LINK_FLAGS "${EMSCRIPTEN_LINK_FLAGS} -s MODULARIZE=1")
set(EMSCRIPTEN_LINK_FLAGS "${EMSCRIPTEN_LINK_FLAGS} -s EXPORT_NAME=\"'cv'\" -s DEMANGLE_SUPPORT=1")
set(EMSCRIPTEN_LINK_FLAGS "${EMSCRIPTEN_LINK_FLAGS} -s FORCE_FILESYSTEM=1 --use-preload-plugins --bind --post-js ${JS_HELPER} ${COMPILE_FLAGS}")
set_target_properties(${the_module} PROPERTIES LINK_FLAGS "${EMSCRIPTEN_LINK_FLAGS}")
```

----------------------------------------

TITLE: Downloading Dependencies for OpenCV
DESCRIPTION: This snippet configures automatic downloading of dependencies during the OpenCV build, offering alternatives for setting cache locations and proxy settings. It also highlights the use of helper scripts for failed downloads.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_8

LANGUAGE: sh
CODE:
```
export OPENCV_DOWNLOAD_PATH=/tmp/opencv-cache
cmake ../opencv
# or
cmake -DOPENCV_DOWNLOAD_PATH=/tmp/opencv-cache ../opencv
```

LANGUAGE: sh
CODE:
```
export http_proxy=<proxy-host>:<port>
export https_proxy=<proxy-host>:<port>
```

----------------------------------------

TITLE: Configuring OpenCV Project with CMake
DESCRIPTION: Sets up a CMake project for OpenCV, including package finding, version checking, and linking configuration. Defines an executable target and links it with OpenCV libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/example_cmake/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
# cmake needs this line
cmake_minimum_required(VERSION 3.5)

# Define project name
project(opencv_example_project)

# Find OpenCV, you may need to set OpenCV_DIR variable
# to the absolute path to the directory containing OpenCVConfig.cmake file
# via the command line or GUI
find_package(OpenCV REQUIRED)

# If the package has been found, several variables will
# be set, you can find the full list with descriptions
# in the OpenCVConfig.cmake file.
# Print some message showing some of them
message(STATUS "OpenCV library status:")
message(STATUS "    config: ${OpenCV_DIR}")
message(STATUS "    version: ${OpenCV_VERSION}")
message(STATUS "    libraries: ${OpenCV_LIBS}")
message(STATUS "    include path: ${OpenCV_INCLUDE_DIRS}")

# Declare the executable target built from your sources
add_executable(opencv_example example.cpp)

# Link your application with OpenCV libraries
target_link_libraries(opencv_example PRIVATE ${OpenCV_LIBS})
```

----------------------------------------

TITLE: Configuring x86 AVX2 Optimizations for ZLIB in CMake
DESCRIPTION: Checks if AVX2 optimization is enabled (WITH_AVX2), if intrinsics are available (HAVE_AVX2_INTRIN), and if SSE4.2 is also enabled. If supported, it adds the DX86_AVX2 definition, appends multiple AVX2-specific source files (for slide_hash, chunkset, compare256, adler32), adds feature information for each, and sets compile flags (AVX2FLAG, NOLTOFLAG). Otherwise, it disables AVX2 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_30

LANGUAGE: cmake
CODE:
```
        if(WITH_AVX2)
            check_avx2_intrinsics()
            if(HAVE_AVX2_INTRIN AND WITH_SSE42)
                add_definitions(-DX86_AVX2)
                set(AVX2_SRCS ${ARCHDIR}/slide_hash_avx2.c)
                add_feature_info(AVX2_SLIDEHASH 1 "Support AVX2 optimized slide_hash, using \"${AVX2FLAG}\"")
                list(APPEND AVX2_SRCS ${ARCHDIR}/chunkset_avx2.c)
                add_feature_info(AVX2_CHUNKSET 1 "Support AVX2 optimized chunkset, using \"${AVX2FLAG}\"")
                list(APPEND AVX2_SRCS ${ARCHDIR}/compare256_avx2.c)
                add_feature_info(AVX2_COMPARE256 1 "Support AVX2 optimized compare256, using \"${AVX2FLAG}\"")
                list(APPEND AVX2_SRCS ${ARCHDIR}/adler32_avx2.c)
                add_feature_info(AVX2_ADLER32 1 "Support AVX2-accelerated adler32, using \"${AVX2FLAG}\"")
                list(APPEND ZLIB_ARCH_SRCS ${AVX2_SRCS})
                set_property(SOURCE ${AVX2_SRCS} PROPERTY COMPILE_FLAGS "${AVX2FLAG} ${NOLTOFLAG}")
            else()
                set(WITH_AVX2 OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Drawing Probabilistic Hough Line Segments in OpenCV (Java)
DESCRIPTION: This Java code draws line segments from HoughLinesP on the result image. For each row in the Mat, it plots a line between the segment endpoints using Imgproc.line. Needs a non-empty linesP Mat and output Mat. Requires Java OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_16

LANGUAGE: Java
CODE:
```
for (int i = 0; i < linesP.rows(); i++) {\n    double[] l = linesP.get(i, 0);\n    Imgproc.line(color_dst, new Point(l[0], l[1]), new Point(l[2], l[3]), new Scalar(0,255,0), 3, Imgproc.LINE_AA);\n}\n
```

----------------------------------------

TITLE: Configuring OpenCV CMake Build for NVIDIA Drive PX 2
DESCRIPTION: CMake configuration options for building OpenCV with CUDA support on the NVIDIA Drive PX 2 platform. Enables Python 2 bindings, CUDA 8.0, and other optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_python2=ON \
    -DBUILD_opencv_python3=OFF \
    -DENABLE_NEON=ON \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0 \
    -DCUDA_ARCH_BIN=6.2 \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=OFF \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Testing Python Code with Pylint using Make in Shell
DESCRIPTION: This shell command runs pylint to perform a static analysis on Python code within OpenCV. Requires pylint to be installed through the package manager or via pip.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_2

LANGUAGE: sh
CODE:
```
make check_pylint
```

LANGUAGE: sh
CODE:
```
pip install pylint
```

----------------------------------------

TITLE: Creating Image for Histogram Display in Java
DESCRIPTION: Java snippet creating a blank image (`histImage`) for histogram visualization. It defines width (`histW`) and height (`histH`), calculates the width for each bin (`binW`), and initializes a 3-channel (`CvType.CV_8UC3`) Mat of the specified size with all pixels set to zero (black).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_22

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Draw the histograms for B, G and R
```

----------------------------------------

TITLE: Setting OpenCV Library Directory in Visual Studio
DESCRIPTION: Adds the OpenCV library directory to the project's additional library directories using an environment variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
$(OPENCV_DIR)\lib
```

----------------------------------------

TITLE: Reproducing OpenCV Model Conversion with Python
DESCRIPTION: This command executes the model conversion pipeline in test mode with default image preprocessing using OpenCV and the DNN model runner.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_15

LANGUAGE: shell
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.segmentation.py_to_py_segm --model_name fcnresnet50 --test True --default_img_preprocess True --evaluate False
```

----------------------------------------

TITLE: Processing Source Lists and Setting Include Directories for OpenCV World (CMake)
DESCRIPTION: Calls two custom OpenCV CMake functions. `ocv_glob_module_sources` takes the previously aggregated `headers_list` and `sources_list` as input, likely performing final processing, globbing, or validation on these file lists. `ocv_module_include_directories` sets up the necessary include paths required to compile the `opencv_world` module, ensuring headers from all included sub-modules are findable by the compiler.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
ocv_glob_module_sources(HEADERS ${headers_list} SOURCES ${sources_list})

ocv_module_include_directories()
```

----------------------------------------

TITLE: Setting Halide as Preferable Backend in OpenCV DNN
DESCRIPTION: This snippet shows the command to set Halide as the preferred backend for the OpenCV DNN module. This step is critical for integrating Halide in the deep learning processing pipeline.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
net.setPreferableBackend(DNN_BACKEND_HALIDE);
```

----------------------------------------

TITLE: Configuring OpenCV.js Test Files in CMake
DESCRIPTION: Sets up custom commands and targets for copying and preparing test files for OpenCV.js, including test data and performance test files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
set(opencv_test_js_bin_dir "${EXECUTABLE_OUTPUT_PATH}")
set(test_dir ${CMAKE_CURRENT_SOURCE_DIR}/test)

set(opencv_test_js_file_deps "")

file(MAKE_DIRECTORY "${opencv_test_js_bin_dir}")

file(GLOB_RECURSE test_files RELATIVE "${test_dir}" "${test_dir}/*")
foreach(f ${test_files})
  add_custom_command(OUTPUT "${opencv_test_js_bin_dir}/${f}"
                     COMMAND ${CMAKE_COMMAND} -E copy_if_different "${test_dir}/${f}" "${opencv_test_js_bin_dir}/${f}"
                     DEPENDS "${test_dir}/${f}"
                     COMMENT "Copying ${f}"
                    )
  list(APPEND opencv_test_js_file_deps "${test_dir}/${f}" "${opencv_test_js_bin_dir}/${f}")
endforeach()

set(test_data "haarcascade_frontalface_default.xml")
set(test_data_path "${PROJECT_SOURCE_DIR}/../../data/haarcascades/${test_data}")

add_custom_command(OUTPUT "${opencv_test_js_bin_dir}/${test_data}"
                   COMMAND ${CMAKE_COMMAND} -E copy_if_different "${test_data_path}" "${opencv_test_js_bin_dir}/${test_data}"
                   DEPENDS "${test_data_path}"
                   COMMENT "Copying ${test_data}"
                  )
list(APPEND opencv_test_js_file_deps "${test_data_path}" "${opencv_test_js_bin_dir}/${test_data}")

add_custom_target(${PROJECT_NAME}_test
                  DEPENDS ${OCV_JS_PATH} ${opencv_test_js_file_deps})
```

----------------------------------------

TITLE: Implementing Corner Detection Logic in C++
DESCRIPTION: This snippet contains a series of nested conditional statements that compare pixel values at different offsets to determine if a point is a corner. It uses goto statements for efficient branching and appears to be part of a larger corner detection algorithm.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_22

LANGUAGE: C++
CODE:
```
goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset3] > cb)
          goto is_a_corner;
        else
          if(ptr[offset8] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset3] > cb)
          goto is_a_corner;
        else
          if(ptr[offset8] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    goto is_not_a_corner;
  else
    if(ptr[offset6] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset1] < c_b)
    if(ptr[offset6] < c_b)
      goto is_not_a_corner;
    else
      if(ptr[offset6] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset1] > cb)
      if(ptr[offset6] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset8] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          if(ptr[offset8] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        goto is_not_a_corner;
      else
        if(ptr[offset6] > cb)
          if(ptr[offset8] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
else
  if(ptr[offset2] < c_b)
    goto is_not_a_corner;
  else
    if(ptr[offset2] > cb)
      if(ptr[offset1] < c_b)
        goto is_not_a_corner;
      else
        if(ptr[offset1] > cb)
          if(ptr[offset6] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset3] > cb)
                  goto is_a_corner;
                else
                  if(ptr[offset8] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset3] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset8] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset3] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset8] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset2] < c_b)
    if(ptr[offset7] > cb)
      goto is_not_a_corner;
    else
      if(ptr[offset7] < c_b)
        if(ptr[offset1] < c_b)
          if(ptr[offset6] > cb)
            goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset6] > cb)
              goto is_not_a_corner;
            else
              if(ptr[offset6] < c_b)
```

----------------------------------------

TITLE: OpenVX C++ Image Class Interface Example
DESCRIPTION: Shows the interface definition for the Image class in the OpenVX C++ wrapper, demonstrating the static factory methods for creating different types of image objects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openvx/README.md#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
class Image
{
    static Image create(vx_context context, vx_uint32 width, vx_uint32 height, vx_df_image format);
    static Image createVirtual(vx_graph graph, vx_uint32 width = 0, vx_uint32 height = 0, vx_df_image format = VX_DF_IMAGE_VIRT);
    // ...
}
```

----------------------------------------

TITLE: Building OpenCV with Contrib Repository in Shell
DESCRIPTION: Command line option to include the OpenCV contrib repository when building OpenCV using CMake. The contrib repository contains experimental and non-free algorithms that are not part of the main OpenCV repository.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_0

LANGUAGE: sh
CODE:
```
-DOPENCV_EXTRA_MODULES_PATH=<path-to-opencv_contrib>/modules
```

----------------------------------------

TITLE: Creating OpenCV Java Library Target in CMake
DESCRIPTION: Adds the OpenCV Java library target with appropriate sources and dependencies. Handles different configurations for fat Java library builds and platform-specific settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jni/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
set(__type MODULE)
if(BUILD_FAT_JAVA_LIB)
  set(__type SHARED) # samples link to libopencv_java
elseif(APPLE)
  set(CMAKE_SHARED_MODULE_SUFFIX ".dylib")  # Java is not able to load .so files
endif()
ocv_add_library(${the_module} ${__type}
    ${handwritten_h_sources} ${handwritten_cpp_sources} ${generated_cpp_sources}
    ${copied_files}
)
add_dependencies(${the_module} gen_opencv_java_source)

ocv_target_include_directories(${the_module} "${CMAKE_CURRENT_SOURCE_DIR}/../generator/src/cpp")
ocv_target_include_directories(${the_module} "${OPENCV_JAVA_BINDINGS_DIR}/gen/cpp")
ocv_target_include_modules(${the_module} ${OPENCV_MODULE_${the_module}_DEPS})
if(NOT ANDROID)
  ocv_target_include_directories(${the_module} SYSTEM ${JNI_INCLUDE_DIRS})
endif()
```

----------------------------------------

TITLE: Setting Histogram Value Range in Java
DESCRIPTION: Java snippet defining the range of pixel values for the histogram. A `MatOfFloat` object named `histRange` is created and initialized with the values 0f and 256f, specifying the lower (inclusive) and upper (exclusive) bounds for the histogram bins.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_13

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Set the ranges ( for B,G,R) )
```

----------------------------------------

TITLE: Blending Two Images with OpenCV.js Based on Range Input - JavaScript
DESCRIPTION: This code blends two images using OpenCV.js based on the value of a trackbar (input range) and displays the result in a canvas. It retrieves the current value, computes blending weights (alpha and beta), reads images from canvases, blends them using cv.addWeighted, and displays the result. All created Mat objects are properly deleted to avoid memory leaks. Dependencies: OpenCV.js, HTML canvas elements with specific IDs, input range and text elements. Parameters: trackbar and weightValue element IDs. Outputs: Displays blended image on a canvas.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_trackbar/js_trackbar.markdown#2025-04-22_snippet_4

LANGUAGE: JavaScript
CODE:
```
let weightValue = document.getElementById('weightValue');
let trackbar = document.getElementById('trackbar');
weightValue.setAttribute('value', trackbar.value);
let alpha = trackbar.value/trackbar.max;
let beta = ( 1.0 - alpha );
let src1 = cv.imread('canvasInput1');
let src2 = cv.imread('canvasInput2');
let dst = new cv.Mat();
cv.addWeighted( src1, alpha, src2, beta, 0.0, dst, -1);
cv.imshow('canvasOutput', dst);
dst.delete();
src1.delete();
src2.delete();
```

----------------------------------------

TITLE: Loading an Image using OpenCV in C++
DESCRIPTION: Loads an image from a file specified by a command-line argument using the `imread` function. It checks if the image was loaded successfully and exits if it fails.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/pyramids/pyramids.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
/**
 * @function main
 */
int main( int argc, char** argv )
{
    /// General instructions
    printf( "\n Zoom In-Out demo \n " );
    printf( "------------------\n" );
    printf( " * [i] -> Zoom in \n" );
    printf( " * [o] -> Zoom out \n" );
    printf( " * [ESC] -> Close program \n\n" );

    //![load]
    CommandLineParser parser( argc, argv, "{@input | ../data/chicky_512.png | input image}" );
    Mat src = imread( samples::findFile( parser.get<String>( "@input" ) ) );

    // Check if image is loaded fine
    if( src.empty() ){
        printf(" Error opening image\n");
        printf(" Program Arguments: [image_name -- default ../data/chicky_512.png] \n");
        return EXIT_FAILURE;
    }
    //![load]
```

----------------------------------------

TITLE: Initializing Output Images in OpenCV (C++/Java/Python)
DESCRIPTION: Creates empty `Mat` objects (or NumPy arrays in Python) with the same size and type as the binary image (`bw`). These will store the results of the morphological operations for horizontal and vertical line detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/morph_lines_detection/morph_lines_detection.md#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
//![init]
// Create the images that will use to extract the horizontal and vertical lines
Mat horizontal = bw.clone();
Mat vertical = bw.clone();
//![init]
```

LANGUAGE: java
CODE:
```
//![init]
// Create the images that will use to extract the horizontal and vertical lines
Mat horizontal = bw.clone();
Mat vertical = bw.clone();
//![init]
```

LANGUAGE: python
CODE:
```
#![init]
# Create the images that will use to extract the horizontal and vertical lines
horizontal = np.copy(bw)
vertical = np.copy(bw)
#![init]
```

----------------------------------------

TITLE: Calculating Back Projection with OpenCV in C++
DESCRIPTION: The C++ sample demonstrates loading an image, converting it to HSV, extracting the Hue channel, allowing user selection of bin sizes, and calculating both the histogram and its back projection using OpenCV. Dependencies include OpenCV C++, and the code requires user-provided images as input. Outputs include displayed windows for the original image, histogram, and back projection; key adjustable parameters are the number of bins for the histogram. The code uses cv::mixChannels, cv::calcHist, and cv::calcBackProject, with a trackbar to trigger updates.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/imgproc.hpp>\n#include <opencv2/highgui.hpp>\n\nusing namespace cv;\n\nint main(int argc, char** argv)\n{\n    CommandLineParser parser(argc, argv, \n        \"{@input | | input image}\");\n    Mat src = imread(samples::findFile(parser.get<String>(\"@input\")), IMREAD_COLOR);\n    if (src.empty())\n    {\n        printf(\"Could not open or find the image\n\");\n        return -1;\n    }\n    // ... rest of code\n}\n
```

LANGUAGE: C++
CODE:
```
// Convert to HSV\nMat hsv;\ncvtColor(src, hsv, COLOR_BGR2HSV);\n
```

LANGUAGE: C++
CODE:
```
// Extract only the Hue channel\nMat hue;\nint ch[] = {0, 0};\nhue.create(hsv.size(), hsv.depth());\nmixChannels(&hsv, 1, &hue, 1, ch, 1);\n
```

LANGUAGE: C++
CODE:
```
// Create Trackbar for bins\nint bins = 30;\ncreateTrackbar(\"Histogram Bins\", \"Source image\", &bins, 180, Hist_and_Backproj);\n
```

LANGUAGE: C++
CODE:
```
// Show the image and wait for exit\nimshow(\"Source image\", src);\nwaitKey();\n
```

LANGUAGE: C++
CODE:
```
// Initialize histogram parameters in callback\nvoid Hist_and_Backproj(int, void*)\n{\n    int histSize = MAX(bins, 2);\n    float hue_range[] = {0, 180};\n    const float* ranges = {hue_range};\n    // ... hist and backproj\n}\n
```

LANGUAGE: C++
CODE:
```
// Calculate histogram and normalize\ncalcHist(&hue, 1, 0, Mat(), hist, 1, &histSize, &ranges, true, false);\nnormalize(hist, hist, 0, 255, NORM_MINMAX, -1, Mat());\n
```

LANGUAGE: C++
CODE:
```
// Backprojection\ncalcBackProject(&hue, 1, 0, hist, backproj, &ranges, 1, true);\n
```

----------------------------------------

TITLE: Drawing Ellipse with OpenCV in Python
DESCRIPTION: Draws a half ellipse at the center of the image using the cv.ellipse() function, demonstrating various parameters like axes lengths and angles.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
cv.ellipse(img,(256,256),(100,50),0,0,180,255,-1)
```

----------------------------------------

TITLE: Creating Display Window in Java
DESCRIPTION: This Java snippet uses `HighGui.namedWindow` to create a display window titled with the value of `WINDOW_NAME`. The trackbar will be added to this window.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_4

LANGUAGE: java
CODE:
```
//![window]
// Create window
HighGui.namedWindow(WINDOW_NAME, HighGui.WINDOW_AUTOSIZE);
//![window]
```

----------------------------------------

TITLE: Calculating Convexity Defects with OpenCV in JavaScript
DESCRIPTION: The purpose of this OpenCV function is to detect convexity defects in a given contour relative to its convex hull. The function cv.convexityDefects requires the indices of contour points that form the convex hull, and it outputs a vector describing the defects. A typical defect is provided as a four-element tuple denoting start index, end index, the farthest point from the hull, and depth. Prerequisite: convex hull must be computed with returnPoints set to False.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contours_more_functions/js_contours_more_functions.markdown#2025-04-22_snippet_0



----------------------------------------

TITLE: Checking and Modifying OpenCV Optimizations in Python
DESCRIPTION: Explains how to check whether OpenCV is using optimized code (e.g., with SSE2, AVX) via cv.useOptimized(), and how to enable or disable these optimizations using cv.setUseOptimized(). Shows the effect of this on the performance of cv.medianBlur using IPython's %timeit after enabling/disabling optimization. Dependencies are cv2, IPython (for %timeit), and an image. Inputs: OpenCV image array. Outputs: performance difference between optimized and unoptimized computation. IPython shell required for magic commands.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_optimization/py_optimization.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
# check if optimization is enabled
In [5]: cv.useOptimized()
Out[5]: True

In [6]: %timeit res = cv.medianBlur(img,49)
10 loops, best of 3: 34.9 ms per loop

# Disable it
In [7]: cv.setUseOptimized(False)

In [8]: cv.useOptimized()
Out[8]: False

In [9]: %timeit res = cv.medianBlur(img,49)
10 loops, best of 3: 64.1 ms per loop
```

----------------------------------------

TITLE: Calculating PSNR on GPU (Basic) in C++
DESCRIPTION: Defines a C++ function `getPSNR_GPU` that calculates the PSNR between two images using basic OpenCV GPU functions. It uploads the input `Mat` objects (`I1`, `I2`) to `GpuMat` objects (`gI1`, `gI2`) and then calls a GPU-accelerated `psnr` function. This represents a direct port from CPU to GPU without specific optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-basics-similarity/gpu_basics_similarity.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
//![getpsnrcuda]
double getPSNR_GPU(const Mat& I1, const Mat& I2)
{
    gpu::GpuMat gI1, gI2;
    gI1.upload(I1);
    gI2.upload(I2);

    return psnr(gI1, gI2);
}
//![getpsnrcuda]
```

----------------------------------------

TITLE: Drawing a Filled Circle in C++
DESCRIPTION: Implementation of the MyFilledCircle function that draws a filled circle in OpenCV C++. The function takes the image and center point, and uses the circle() function with a negative thickness value to create a solid filled circle.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_21

LANGUAGE: cpp
CODE:
```
void MyFilledCircle( Mat img, Point center )
{
  circle( img,
      center,
      w/32,
      Scalar( 0, 0, 255 ),
      FILLED,
      LINE_8 );
}
```

----------------------------------------

TITLE: Filtering and Copying Values Greater Than Zero using Streams
DESCRIPTION: Demonstrates using Thrust's count_if and copy_if with a stream to find and copy only positive values from a source matrix to a destination matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_8

LANGUAGE: CUDA
CODE:
```
// Count number of elements greater than 0
int num_greater = thrust::count_if(
    thrust::system::cuda::par.on(StreamAccessor::getStream(stream)),
    d_random_ptr,
    d_random_ptr + d_random.rows * d_random.cols,
    is_greater()
);

// Allocate space for the results
cv::cuda::GpuMat d_result(num_greater, 1, CV_32FC1);
thrust::device_ptr<float> d_result_ptr((float*)d_result.data);

// Copy values greater than 0 to result
thrust::copy_if(
    thrust::system::cuda::par.on(StreamAccessor::getStream(stream)),
    d_random_ptr,
    d_random_ptr + d_random.rows * d_random.cols,
    d_result_ptr,
    is_greater()
);

// Download results to CPU
cv::Mat h_result(d_result);
std::cout << "Found " << num_greater << " values greater than 0" << std::endl;
std::cout << "First 5 values: " << std::endl;
for(int i = 0; i < std::min(5, num_greater); i++)
{
    std::cout << h_result.at<float>(i) << std::endl;
}
```

----------------------------------------

TITLE: Corner Detection Conditional Logic in C++
DESCRIPTION: Complex nested conditional structure that evaluates pixel values using pointer arithmetic to determine corner points. The code compares intensity values at different offsets against threshold values 'cb' and 'c_b' to classify pixels as corners or non-corners.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_21

LANGUAGE: cpp
CODE:
```
goto is_not_a_corner;
else
  if(ptr[offset1] > cb)
    if(ptr[offset6] > cb)
      if(ptr[offset10] > cb)
        if(ptr[offset11] > cb)
          if(ptr[offset3] > cb)
            goto is_a_corner;
          else
            if(ptr[offset8] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            if(ptr[offset3] > cb)
              goto is_a_corner;
            else
              if(ptr[offset8] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            if(ptr[offset3] > cb)
              goto is_a_corner;
            else
              if(ptr[offset8] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset2] < c_b)
    if(ptr[offset1] < c_b)
      if(ptr[offset6] > cb)
        goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
```

----------------------------------------

TITLE: Configuring Wayland Backend for HighGUI in CMake
DESCRIPTION: Configures the Wayland backend for OpenCV HighGUI when WITH_WAYLAND is enabled. Sets up Wayland protocol generation, includes necessary libraries and dependencies, and adds EGL support if available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: CMake
CODE:
```
if(WITH_WAYLAND AND HAVE_WAYLAND)
  set(OPENCV_HIGHGUI_BUILTIN_BACKEND "Wayland")
  add_definitions(-DHAVE_WAYLAND)

  set(CMAKE_INCLUDE_CURRENT_DIR ON)

  if (HAVE_WAYLAND_PROTOCOLS)
      ocv_wayland_generate(
            ${WAYLAND_PROTOCOLS_BASE}/stable/xdg-shell/xdg-shell.xml
            xdg-shell-client-protocol)
  endif()

  list(APPEND highgui_srcs
    ${CMAKE_CURRENT_LIST_DIR}/src/window_wayland.cpp
    ${WAYLAND_PROTOCOL_SOURCES}
  )
  list(APPEND HIGHGUI_LIBRARIES "${WAYLAND_CLIENT_LINK_LIBRARIES};${WAYLAND_CURSOR_LINK_LIBRARIES};${XKBCOMMON_LINK_LIBRARIES}")

  if(HAVE_WAYLAND_EGL)
    if(WAYLAND_EGL_LIBRARIES)
      list(APPEND HIGHGUI_LIBRARIES "${WAYLAND_EGL_LIBRARIES}")
    endif()
  endif()

  ocv_module_include_directories(${WAYLAND_CLIENT_INCLUDE_DIRS} ${XKBCOMMON_INCLUDE_DIRS})

```

----------------------------------------

TITLE: Setting Up Environment Variable for WebNN
DESCRIPTION: This code sets the environment variable `WEBNN_NATIVE_DIR` to the output directory of the WebNN build. This configuration is necessary to enable the native DNN backend in OpenCV for WebNN integration. PATH_TO_WebNN should be replaced with the actual path to the output directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/src/webnn/README.md#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
export WEBNN_NATIVE_DIR=${PATH_TO_WebNN}
```

----------------------------------------

TITLE: Configuring Additional HTML Files for Doxygen in CMake
DESCRIPTION: Appends paths to specific files (icons, images, JavaScript utility files) to the `CMAKE_DOXYGEN_HTML_FILES` list. These files will be copied by Doxygen to the HTML output directory. Finally, it formats this list into a newline-separated string suitable for the Doxyfile configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: cmake
CODE:
```
list(APPEND CMAKE_DOXYGEN_HTML_FILES "${CMAKE_CURRENT_SOURCE_DIR}/opencv.ico")
list(APPEND CMAKE_DOXYGEN_HTML_FILES "${CMAKE_CURRENT_SOURCE_DIR}/pattern.png")
list(APPEND CMAKE_DOXYGEN_HTML_FILES "${CMAKE_CURRENT_SOURCE_DIR}/acircles_pattern.png")
list(APPEND CMAKE_DOXYGEN_HTML_FILES "${CMAKE_CURRENT_SOURCE_DIR}/bodybg.png")
# list(APPEND CMAKE_DOXYGEN_HTML_FILES "${CMAKE_CURRENT_SOURCE_DIR}/mymath.sty")
list(APPEND CMAKE_DOXYGEN_HTML_FILES "${CMAKE_CURRENT_SOURCE_DIR}/tutorial-utils.js")
string(REPLACE ";" " \\\n" CMAKE_DOXYGEN_HTML_FILES "${CMAKE_DOXYGEN_HTML_FILES}")
```

----------------------------------------

TITLE: Setting Deep Neural Network Module Description - CMake
DESCRIPTION: This statement sets the project-level description for the DNN module. Useful for documentation and for integration with CMake system features. The variable 'the_description' is set to a string describing the module's functionality. No dependencies or parameters are required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(the_description "Deep neural network module. It allows to load models from different frameworks and to make forward pass")
```

----------------------------------------

TITLE: Generating OpenCV for Windows Store 8.0 ARM using CMake
DESCRIPTION: Invokes CMake directly using the Visual Studio 2013 ARM generator to create project files for OpenCV targeting Windows Store 8.0 on the ARM architecture. Specifies the system name (WindowsStore) and older system version (8.0).
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_12

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013 ARM" -DCMAKE_SYSTEM_NAME=WindowsStore -DCMAKE_SYSTEM_VERSION=8.0 <path-to-source>
```

----------------------------------------

TITLE: Configuring JNI OpenCV Build Environment - CMake
DESCRIPTION: This CMake script snippet sets up the project for building a JNI native library with OpenCV dependencies for Android. It handles selecting OpenCV components based on whether the SDK or AAR (Maven) source is used, and sets appropriate CMake cache variables and project names. Prerequisites include a properly installed OpenCV package, and optionally, defined OPENCV_FROM_SDK and OPENCV_VERSION_MAJOR variables. Inputs: environment variables; Outputs: target configuration and selected OpenCV components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-4-opencl/jni/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.6)

set(target JNIpart)
project(${target} CXX)

if (OPENCV_FROM_SDK)
  message(STATUS "Using OpenCV from local SDK")
  set(ANDROID_OPENCV_COMPONENTS "opencv_java" CACHE STRING "")
else()
  message(STATUS "Using OpenCV from AAR (Maven repo)")
  set(ANDROID_OPENCV_COMPONENTS "OpenCV::opencv_java${OPENCV_VERSION_MAJOR}" CACHE STRING "")
endif()

message(STATUS "ANDROID_ABI=${ANDROID_ABI}")
find_package(OpenCV REQUIRED COMPONENTS ${ANDROID_OPENCV_COMPONENTS})
find_package(OpenCL QUIET)

```

----------------------------------------

TITLE: Building and Installing OpenCV with CMake
DESCRIPTION: Build OpenCV using CMake within the specified build directory and install it by copying compiled artifacts to the install folder. Requires prior configuration with CMake and the Ninja build system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_19

LANGUAGE: bash
CODE:
```
cmake --build   build4-full_arm64
sudo cmake --install build4-full_arm64
```

----------------------------------------

TITLE: Defining OpenCV Stitching Module in CMake
DESCRIPTION: Defines the stitching module with its required and optional dependencies. This includes core OpenCV modules, CUDA-related modules, and additional dependencies. It also specifies Python wrapping.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/stitching/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
ocv_define_module(stitching opencv_imgproc opencv_features2d opencv_calib3d opencv_flann
                  OPTIONAL opencv_cudaarithm opencv_cudawarping opencv_cudafeatures2d opencv_cudalegacy opencv_cudaimgproc ${STITCHING_CONTRIB_DEPS}
                  WRAP python)
```

----------------------------------------

TITLE: Checking for unistd.h Header in Zlib CMake Configuration
DESCRIPTION: Checks for the presence of the unistd.h header file on non-MSVC platforms. This is used to determine system capabilities for Zlib compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
if(NOT MSVC)
  check_include_file(unistd.h Z_HAVE_UNISTD_H)
endif()
```

----------------------------------------

TITLE: Generating zconf.h Configuration File
DESCRIPTION: Macro to generate zconf.h configuration file from template, replacing specific preprocessor directives with CMake variables for platform-specific configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_35

LANGUAGE: cmake
CODE:
```
macro(generate_cmakein input output)
    file(REMOVE ${output})
    file(STRINGS ${input} _lines)
    foreach(_line IN LISTS _lines)
        string(REGEX REPLACE "#ifdef HAVE_UNISTD_H.*" "@ZCONF_UNISTD_LINE@" _line "${_line}")
        string(REGEX REPLACE "#ifdef NEED_PTRDIFF_T.*" "@ZCONF_PTRDIFF_LINE@" _line "${_line}")
        if(NEED_PTRDIFF_T)
            string(REGEX REPLACE "typedef PTRDIFF_TYPE" "typedef @PTRDIFF_TYPE@" _line "${_line}")
        endif()
        file(APPEND ${output} "${_line}\n")
    endforeach()
endmacro(generate_cmakein)
```

----------------------------------------

TITLE: OpenCV Apps Registration
DESCRIPTION: Registers specific OpenCV applications to be built using the ocv_add_app macro.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
ocv_add_app(annotation)
ocv_add_app(visualisation)
ocv_add_app(interactive-calibration)
ocv_add_app(version)
ocv_add_app(model-diagnostics)
```

----------------------------------------

TITLE: Adding OpenCV Python Path to PYTHONPATH Environment Variable (Shell)
DESCRIPTION: Command to append the directory containing the installed OpenCV Python module (`/usr/local/lib/python2.7/site-packages`) to the `PYTHONPATH` environment variable. This allows the Python interpreter to find the `cv2` module. It's recommended to add this line to a shell configuration file like `~/.bashrc` for persistence across sessions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_17

LANGUAGE: sh
CODE:
```
export PYTHONPATH=$PYTHONPATH:/usr/local/lib/python2.7/site-packages
```

----------------------------------------

TITLE: Configuring JavaScript Assets for OpenCV
DESCRIPTION: Configures JavaScript assets by either using built opencv.js or a specified location, and sets up Haar cascade files for face and eye detection tutorials.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_19

LANGUAGE: cmake
CODE:
```
if(BUILD_opencv_js)
    set(ocv_js_dir "${CMAKE_BINARY_DIR}/bin")
    set(ocv_js "opencv.js")
    list(APPEND js_assets "${ocv_js_dir}/${ocv_js}")
  elseif(DEFINED OPENCV_JS_LOCATION)
    list(APPEND js_assets "${OPENCV_JS_LOCATION}")
  endif()

  # copy haar cascade files
  set(haar_cascade_files "")
  set(data_harrcascades_path "${OpenCV_SOURCE_DIR}/data/haarcascades/")
  list(APPEND js_tutorials_assets_deps "${data_harrcascades_path}/haarcascade_frontalface_default.xml" "${data_harrcascades_path}/haarcascade_eye.xml")
  list(APPEND js_assets "${data_harrcascades_path}/haarcascade_frontalface_default.xml" "${data_harrcascades_path}/haarcascade_eye.xml")
```

----------------------------------------

TITLE: Setting Minimum Inliers via Command Line Argument (Bash/Shell)
DESCRIPTION: Provides an example command-line usage for running the C++ tutorial executable (`cpp-tutorial-pnp_detection`). It demonstrates how to override the default minimum number of inliers required for the Kalman Filter update step by passing the `--inliers=20` argument. This value would likely be parsed by the C++ application and used to initialize or update the `minInliersKalman` variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_28

LANGUAGE: bash
CODE:
```
./cpp-tutorial-pnp_detection --inliers=20
```

----------------------------------------

TITLE: Building OpenCV Framework for iOS in Bash
DESCRIPTION: Command to build the OpenCV framework for iOS using the provided Python script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/ios_install/ios_install.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
cd ~/<my_working_directory>
python opencv/platforms/ios/build_framework.py ios
```

----------------------------------------

TITLE: Adjusting CPU Optimization Levels in OpenCV
DESCRIPTION: Enables configuring CPU optimization levels and instruction set selection. Provides options for SSE3 by default, with advanced options for enabling, disabling, or adjusting various optimization settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_9

LANGUAGE: sh
CODE:
```
cmake -DCPU_BASELINE=AVX2 ../opencv
```

LANGUAGE: sh
CODE:
```
cmake -DCPU_DISPATCH=AVX,AVX2 ../opencv
```

LANGUAGE: sh
CODE:
```
cmake -DCPU_DISPATCH= ../opencv
```

LANGUAGE: sh
CODE:
```
# disable universal intrinsics
cmake -DCV_ENABLE_INTRINSICS=OFF ../opencv
# disable all possible built-in optimizations
cmake -DCV_DISABLE_OPTIMIZATION=ON ../opencv
```

----------------------------------------

TITLE: Defining Source and Header File Collections for DNN Module - CMake
DESCRIPTION: Uses CMake 'file(GLOB_RECURSE ...)' to gather all source files (*.cpp), internal headers (*.hpp, *.h), and sets up the plugin source list. Applies filters to exclude backend and importer source code not intended for the default build. Inputs: Directory paths and file patterns; outputs: file lists for DNN module compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_21

LANGUAGE: CMake
CODE:
```
file(GLOB_RECURSE dnn_srcs
     "${CMAKE_CURRENT_LIST_DIR}/src/*.cpp"
)
file(GLOB_RECURSE dnn_int_hdrs
     "${CMAKE_CURRENT_LIST_DIR}/src/*.hpp"
     "${CMAKE_CURRENT_LIST_DIR}/src/*.h"
)
set(dnn_plugin_srcs ${dnn_srcs} ${dnn_int_hdrs})
ocv_list_filterout_ex(dnn_plugin_srcs
    "/src/dnn.cpp$|/src/dnn_utils.cpp$|/src/dnn_read.cpp$|/src/registry.cpp$|/src/backend.cpp$"
    # importers
    "/src/(caffe|darknet|onnx|tensorflow|torch)/"
    # executors
    "/src/(cuda|cuda4dnn|ocl4dnn|vkcom|webnn)/"
)
```

----------------------------------------

TITLE: Corner Detection Conditional Logic Implementation in C++
DESCRIPTION: Complex nested conditional logic for checking pixel values against thresholds in different offsets. Uses goto statements for control flow between different detection scenarios (structured and homogeneous).
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_28

LANGUAGE: C++
CODE:
```
if(ptr[offset2] < c_b)
  if(ptr[offset3] < c_b)
    if(ptr[offset4] < c_b)
      if(ptr[offset1] < c_b)
        if(ptr[offset6] < c_b)
          goto success_structured;
        else
          goto structured;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset8] < c_b)
            goto success_structured;
          else
            goto structured;
        else
          goto structured;
    else
      goto structured;
  else
    goto structured;
else
  goto structured;
```

----------------------------------------

TITLE: Defining and Using a Macro to Check for Header Files in CMake
DESCRIPTION: Includes the `CheckIncludeFile` CMake module and defines a macro `ensure_file_include` to check for the existence of specified C header files. The macro takes the filename, a variable to store the result (e.g., `HAVE_STRING_H`), and a mandatory status (YES/NO). It prints informative messages based on whether the file is found and if it's mandatory. Subsequently, it uses this macro to check for several standard C headers required by OpenJPEG.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
#-----------------------------------------------------------------------------
# opj_config.h generation (1/2)

# Check if some include files are provided by the system
# These files are mandatory, so if they are not provided OpenJPEG library can't be built
include(CheckIncludeFile)
macro(ensure_file_include INCLUDE_FILENAME VARIABLE_NAME MANDATORY_STATUS)
  check_include_file(${INCLUDE_FILENAME} ${VARIABLE_NAME})
  if(NOT ${VARIABLE_NAME})
    if(${MANDATORY_STATUS})
      message(STATUS "The file '${INCLUDE_FILENAME}' is mandatory for OpenJPEG build, but not found on your system")
      return()
    else()
      message(STATUS "The file '${INCLUDE_FILENAME}' is optional for OpenJPEG build and not found on your system." 
              " Internal implementation will be used.")
    endif()
  endif()
endmacro()

ensure_file_include("string.h"   HAVE_STRING_H YES)
ensure_file_include("memory.h"   HAVE_MEMORY_H YES)
ensure_file_include("stdlib.h"   HAVE_STDLIB_H YES)
ensure_file_include("stdio.h"    HAVE_STDIO_H  YES)
ensure_file_include("math.h"     HAVE_MATH_H   YES)
ensure_file_include("float.h"    HAVE_FLOAT_H  YES)
ensure_file_include("time.h"     HAVE_TIME_H   YES)
ensure_file_include("stdarg.h"   HAVE_STDARG_H YES)
ensure_file_include("ctype.h"    HAVE_CTYPE_H  YES)
ensure_file_include("assert.h"   HAVE_ASSERT_H YES)

# For the following files, we provide an alternative, they are not mandatory
ensure_file_include("stdint.h"   OPJ_HAVE_STDINT_H   NO)
ensure_file_include("inttypes.h" OPJ_HAVE_INTTYPES_H NO)
```

----------------------------------------

TITLE: Creating Build Directory for OpenCV
DESCRIPTION: Commands to create and enter the build directory for OpenCV compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_11

LANGUAGE: bash
CODE:
```
mkdir -p build && cd build
```

----------------------------------------

TITLE: Creating Project Directory for SBT Sample (Bash)
DESCRIPTION: This sequence of Bash commands navigates to a chosen location outside the OpenCV source directory and creates a new directory named 'JavaSample' to house the SBT-based Java project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_10

LANGUAGE: bash
CODE:
```
cd <somewhere outside opencv>
mkdir JavaSample
```

----------------------------------------

TITLE: Formatting Image-Annotation Pair List (Plaintext)
DESCRIPTION: Illustrates the required format for a text file listing pairs of image file paths and their corresponding annotation XML file paths. This file serves as input for Caffe's data creation scripts (`create_data.sh`, `create_annoset.py`) to build the LMDB database.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/face_detector/how_to_train_face_detector.txt#2025-04-22_snippet_2

LANGUAGE: plaintext
CODE:
```
images_val/0.jpg annotations_val/0.jpg.xml
```

----------------------------------------

TITLE: Declaring an Empty cv::Mat Variable for Edge Detection in C++
DESCRIPTION: This snippet shows the declaration of an empty cv::Mat object intended to store the results of Canny edge detection. It highlights where to set a Visual Studio breakpoint for using the Image Watch extension and serves as a key step in the image processing workflow. No input parameters are needed for this statement, but the variable is later populated using an OpenCV function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_image_watch/windows_visual_studio_image_watch.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
Mat edges;
```

----------------------------------------

TITLE: Estimating Homography using OpenCV's findHomography - Java
DESCRIPTION: The code demonstrates calling OpenCV Java’s findHomography method to estimate a projective transformation between two chessboard images. Both input and output are Mat objects containing the matched points and resulting 3x3 matrix, respectively. RANSAC or other methods may be selected for robustness.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_13

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/features2D/Homography/PerspectiveCorrection.java estimate-homography
```

----------------------------------------

TITLE: Installing Zlib Library for Static Builds in CMake
DESCRIPTION: Installs the Zlib library for static builds as part of the OpenCV modules. This ensures the static library is available to users of the OpenCV project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: CMake
CODE:
```
if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${ZLIB_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev)
endif()
```

----------------------------------------

TITLE: Draw Final Matches and Output in OpenCV using Python
DESCRIPTION: Python snippet to visualize and save the result of matched keypoints using OpenCV, including outputting match statistics.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_17

LANGUAGE: Python
CODE:
```
samples/python/tutorial_code/features2D/akaze_matching/AKAZE_match.py draw final matches
```

----------------------------------------

TITLE: FAST Corner Detection Structured Pattern Checking in C++
DESCRIPTION: Implementation of the structured pattern checking in FAST corner detection algorithm. This section increments the x-coordinate and tests pixel values against threshold values to determine if the current pixel is a corner point by examining its surrounding pixels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_10

LANGUAGE: C++
CODE:
```
structured:
{
  x++;
  if(x > xsizeB)
      break;
  else
  {
      const unsigned char* const ptr = img.ptr() + y*width + x;
      const int cb = *ptr + threshold;
      const int c_b = *ptr - threshold;
      if(ptr[offset0] > cb)
        if(ptr[offset5] > cb)
          if(ptr[offset2] > cb)
            if(ptr[offset9] > cb)
              if(ptr[offset1] > cb)
                if(ptr[offset6] > cb)
                  if(ptr[offset3] > cb)
                    if(ptr[offset4] > cb)
                      goto success_structured;
                    else
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto success_structured;
                        else
                          goto structured;
                      else
                        goto structured;
                  else
                    if(ptr[offset8] > cb)
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto success_structured;
                        else
                          if(ptr[offset4] > cb)
                            if(ptr[offset7] > cb)
                              goto success_structured;
                            else
                              goto structured;
                          else
                            goto structured;
                      else
                        goto structured;
                    else
                      goto structured;
                else
                  if(ptr[offset11] > cb)
                    if(ptr[offset3] > cb)
                      if(ptr[offset4] > cb)
                        goto success_structured;
                      else
                        if(ptr[offset10] > cb)
                          goto success_structured;
                        else
                          goto structured;
                    else
                      if(ptr[offset8] > cb)
                        if(ptr[offset10] > cb)
                          goto success_structured;
                        else
                          goto structured;
                      else
                        goto structured;
                  else
                    goto structured;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset7] > cb)
                    if(ptr[offset8] > cb)
                      if(ptr[offset4] > cb)
                        if(ptr[offset3] > cb)
                          goto success_structured;
                        else
                          if(ptr[offset10] > cb)
                            goto success_structured;
                          else
                            goto structured;
                      else
                        if(ptr[offset10] > cb)
                          if(ptr[offset11] > cb)
                            goto success_structured;
                          else
                            goto structured;
                        else
                          goto structured;
                    else
                      goto structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset1] > cb)
                    if(ptr[offset6] > cb)
                      goto success_structured;
                    else
                      if(ptr[offset11] > cb)
                        goto success_structured;
                      else
                        goto structured;
                  else
                    if(ptr[offset6] > cb)
                      if(ptr[offset7] > cb)
                        if(ptr[offset8] > cb)
                          goto success_structured;
                        else
                          goto structured;
                      else
                        goto structured;
                    else
                      goto structured;
                else
                  goto structured;
              else
                goto structured;
          else
            if(ptr[offset9] > cb)
              if(ptr[offset7] > cb)
                if(ptr[offset8] > cb)
                  if(ptr[offset1] > cb)
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        goto success_structured;
                      else
                        if(ptr[offset6] > cb)
                          if(ptr[offset4] > cb)
                            goto success_structured;
                          else
                            goto structured;
                        else
                          goto structured;
                    else
                      if(ptr[offset6] > cb)
                        if(ptr[offset3] > cb)
                          if(ptr[offset4] > cb)
                            goto success_structured;
                          else
                            goto structured;
                        else
```

----------------------------------------

TITLE: Configuring libjasper Project in CMake for OpenCV
DESCRIPTION: This snippet sets up the project for libjasper library and adds definitions to exclude support for various image formats.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjasper/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(${JASPER_LIBRARY})

add_definitions(-DEXCLUDE_MIF_SUPPORT -DEXCLUDE_PNM_SUPPORT -DEXCLUDE_BMP_SUPPORT -DEXCLUDE_RAS_SUPPORT  -DEXCLUDE_JPG_SUPPORT -DEXCLUDE_PGX_SUPPORT)

ocv_include_directories(${CMAKE_CURRENT_SOURCE_DIR})

file(GLOB lib_srcs *.c)
file(GLOB lib_hdrs *.h)
file(GLOB lib_ext_hdrs jasper/*.h)
```

----------------------------------------

TITLE: Marking and Including Code Snippets from Files - Doxygen Snippet
DESCRIPTION: Explains marking code regions in a source file for later inclusion in documentation with @snippet. Code is bracketed by '//! [label]' and later referenced by filename and label. This allows targeted inclusion of only relevant portions. Inputs are code region delimiters and snippet command; output is extracted code region in documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_12

LANGUAGE: cpp
CODE:
```
//! [var_init]
int a = 0;
//! [var_init]
```

LANGUAGE: markdown
CODE:
```
@snippet samples/cpp/test.cpp var_init
```

----------------------------------------

TITLE: GCC Compiler-Specific Configuration
DESCRIPTION: Configures GCC-specific compiler flags for performance optimization, including visibility settings and inline parameters. Includes version-specific compiler flag adjustments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/carotene/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(CMAKE_COMPILER_IS_GNUCC)
    set(CMAKE_CXX_FLAGS "-fvisibility=hidden ${CMAKE_CXX_FLAGS}")

    # allow more inlines - these parameters improve performance for:
    # - matchTemplate about 5-10%
    # - goodFeaturesToTrack 10-20%
    # - cornerHarris 30% for some cases
    if(CMAKE_CXX_COMPILER_VERSION VERSION_LESS "10.0.0")
        set_source_files_properties(${carotene_sources} COMPILE_FLAGS "--param ipcp-unit-growth=100000 --param inline-unit-growth=100000 --param large-stack-frame-growth=5000")
    else()
        set_source_files_properties(${carotene_sources} COMPILE_FLAGS "--param ipa-cp-unit-growth=100000 --param inline-unit-growth=100000 --param large-stack-frame-growth=5000")
    endif()
endif()
```

----------------------------------------

TITLE: Setting Target Properties for the OpenJPEG Library in CMake
DESCRIPTION: Configures properties for the OpenJPEG library target (identified by `${OPENJPEG_LIBRARY_NAME}`, which is `libopenjp2`). It sets the output name, applies the standard OpenCV debug postfix (`OPENCV_DEBUG_POSTFIX`) to debug builds, defines PDB (Program Database) names for debugging symbols on Windows, and specifies the output directory for the built library artifacts using the `3P_LIBRARY_OUTPUT_PATH` variable (likely defined in the parent OpenCV CMake configuration).
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: cmake
CODE:
```
set_target_properties(${OPENJPEG_LIBRARY_NAME}
  PROPERTIES
    OUTPUT_NAME              ${OPENJPEG_LIBRARY_NAME}
    DEBUG_POSTFIX            "${OPENCV_DEBUG_POSTFIX}"
    COMPILE_PDB_NAME         ${OPENJPEG_LIBRARY_NAME}
    COMPILE_PDB_NAME_DEBUG   "${OPENJPEG_LIBRARY_NAME}${OPENCV_DEBUG_POSTFIX}"
    ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
)
```

----------------------------------------

TITLE: Including CUDA Include Directories in CMake
DESCRIPTION: Conditionally adds the CUDA include directories specified by the `CUDA_INCLUDE_DIRS` variable to the build configuration using `ocv_include_directories` if CUDA support is available (`HAVE_CUDA` is true).
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: cmake
CODE:
```
if(HAVE_CUDA)
  ocv_include_directories(${CUDA_INCLUDE_DIRS})
endif()
```

----------------------------------------

TITLE: Setting OpenCV Include Directory in Visual Studio
DESCRIPTION: Adds the OpenCV include directory to the project's additional include directories using an environment variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
$(OPENCV_DIR)\..\..\include
```

----------------------------------------

TITLE: Disabling Specific C++ Warnings in CMake
DESCRIPTION: Checks if the custom `ocv_warnings_disable` command exists. If it does, it calls the command to disable specific C++ warnings (`-Wsuggest-override`, `-Winconsistent-missing-override`) for the C++ compiler flags (`CMAKE_CXX_FLAGS`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
if(COMMAND ocv_warnings_disable)
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wsuggest-override -Winconsistent-missing-override)
endif()
```

----------------------------------------

TITLE: Setting Up Project and Recursively Including Dependencies for TAPI Samples - CMake
DESCRIPTION: Configures the project under the name tapi_samples and uses ocv_include_modules_recurse to include all modules needed by the TAPI samples. It also dynamically discovers all .cpp files in the current directory and prepares them for sample build. The configuration relies on the earlier definition of OPENCV_TAPI_SAMPLES_REQUIRED_DEPS to include appropriate modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/tapi/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
project(tapi_samples)
ocv_include_modules_recurse(${OPENCV_TAPI_SAMPLES_REQUIRED_DEPS})
file(GLOB all_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
```

----------------------------------------

TITLE: Configuration options for building OpenCV as shared libraries
DESCRIPTION: Additional CMake configuration parameters needed to build OpenCV as shared libraries instead of static libraries. Enables shared libraries and zlib dependency.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/wince/readme.md#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
-DBUILD_SHARED_LIBS=ON `
-DBUILD_ZLIB=ON
```

----------------------------------------

TITLE: Platform-Specific TBB Library Configuration
DESCRIPTION: Configures platform-specific settings for the TBB library. For Windows, this creates the DLL export definition file, while for Unix platforms it links against system libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: CMake
CODE:
```
if (WIN32)
  if (ARM)
    set(platform_macro /D_M_ARM=1)
  endif()

  add_custom_command(TARGET tbb
                     PRE_BUILD
                     COMMAND ${CMAKE_C_COMPILER} /nologo /TC /EP ${tbb_src_dir}\\src\\tbb\\win32-tbb-export.def /DTBB_NO_LEGACY=1 /D_CRT_SECURE_NO_DEPRECATE /D__TBB_BUILD=1 ${platform_macro} /I${tbb_src_dir}\\src /I${tbb_src_dir}\\include > "${tbb_src_dir}\\src\\tbb\\tbb.def"
                     WORKING_DIRECTORY ${tbb_src_dir}\\src\\tbb
                     COMMENT "Generating tbb.def file" VERBATIM
                    )

  set(CMAKE_SHARED_LINKER_FLAGS "${CMAKE_SHARED_LINKER_FLAGS} /DEF:${tbb_src_dir}/src/tbb/tbb.def /DLL /MAP /fixed:no /INCREMENTAL:NO")
else()
  target_link_libraries(tbb c m dl)
endif()
```

----------------------------------------

TITLE: Disabling RVV Support in OpenCV RISC-V Build
DESCRIPTION: This CMake option disables RVV (RISC-V Vector Extension) support when building OpenCV for RISC-V targets that do not support it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/riscv/README.md#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
-D WITH_RVV=OFF
```

----------------------------------------

TITLE: Allocating/Resizing Output Mat using create() in OpenCV in Java
DESCRIPTION: Allocates or reinitializes a Mat in Java with create, matching size and type of input Mat. Ensures that output Mat is ready for operation results. Input is the output Mat, target rows, cols, and type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_26

LANGUAGE: Java
CODE:
```
output.create(input.rows(), input.cols(), input.type());
```

----------------------------------------

TITLE: Waiting for User Input to Exit OpenCV Application
DESCRIPTION: Code to keep the application window open until the user presses a key, allowing them to view the images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
waitKey(0);
```

LANGUAGE: Java
CODE:
```
waitKey(0);
```

LANGUAGE: Python
CODE:
```
cv.waitKey(0)
```

----------------------------------------

TITLE: Generating Linearly Separable Training Data for SVM (C++)
DESCRIPTION: Generates training data that is linearly separable using random points from two classes with different probability density functions. This creates the first part of the dataset needed for demonstrating SVMs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
// Set up the linearly separable part of the training data
int labels[2] = {1, -1};
Mat trainData(2 * NTRAINING_SAMPLES, 2, CV_32FC1);
Mat trainLabels(2 * NTRAINING_SAMPLES, 1, CV_32SC1);
RNG rng(100); // Random value generation class

// Generate training samples
for(int i = 0; i < 2; ++i)
{
    Mat trainClass = trainData.rowRange(i * NTRAINING_SAMPLES, (i + 1) * NTRAINING_SAMPLES);
    // The x coordinate of the points is in [0, 0.4 * WIDTH] or [0.6 * WIDTH, WIDTH]
    // The y coordinate of the points is in [0, 0.4 * HEIGHT] or [0.6 * HEIGHT, HEIGHT]
    Mat center = trainClass.colRange(0, 1);
    if (i == 0)
    {
        center = center * 0.2f + 0.2f;
    }
    else
    {
        center = center * 0.2f + 0.6f;
    }
    rng.fill(trainClass.colRange(1, 2), RNG::UNIFORM, Scalar(0), Scalar(1));

    // Set the labels of the classes. They are integers from the set {1, -1}
    trainLabels.rowRange(i * NTRAINING_SAMPLES, (i + 1) * NTRAINING_SAMPLES)
        .setTo(Scalar(labels[i]));
}
```

----------------------------------------

TITLE: AVFoundation Configuration Option in OpenCV
DESCRIPTION: Defines the WITH_AVFOUNDATION build option for Apple platforms to enable the AVFoundation framework for camera frame capture and video encoding/decoding.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_15

LANGUAGE: markdown
CODE:
```
`WITH_AVFOUNDATION` (Apple; default: _ON_)
```

----------------------------------------

TITLE: Building Halide on Windows using CMake and MSBuild
DESCRIPTION: This snippet provides instructions for building the Halide project on Windows, using CMake and MSBuild in a Visual Studio environment. This process excludes building tests, apps, and tutorials.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_halide/dnn_halide.markdown#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
cd halide_root
mkdir build && cd build
cmake.exe -DLLVM_DIR=\\path-to-llvm-install\\lib\\cmake\\llvm -DLLVM_VERSION=40 -DWITH_TESTS=OFF -DWITH_APPS=OFF -DWITH_TUTORIALS=OFF -DCMAKE_BUILD_TYPE=Release -G "Visual Studio 14 Win64" ..
MSBuild.exe /m:4 /t:Build /p:Configuration=Release .\\ALL_BUILD.vcxproj
```

----------------------------------------

TITLE: Writing and Reading OpenCV Mat Objects to XML/YAML/JSON - OpenCV C++
DESCRIPTION: These snippets show how to write and read Mat objects (matrices/images) to XML/YAML/JSON files using OpenCV's FileStorage in C++. Writing is performed with the << operator and reading with the >> operator or [] operator. Requires OpenCV and a properly created cv::Mat object. This can handle matrices of any supported type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
Mat mat = Mat::eye(3, 3, CV_64F);\nfs << "matrix" << mat;\n\nfs["matrix"] >> mat;
```

----------------------------------------

TITLE: Gathering Source Files and Metadata for Doxygen from OpenCV Modules in CMake
DESCRIPTION: Initializes lists to store paths for include files, documentation, BibTeX files, samples, tutorials, and HAL interfaces. It iterates through main and extra OpenCV modules, checks against a blacklist, and appends relevant file/directory paths to the corresponding lists. It conditionally excludes CUDA-related headers, gathers sample and tutorial files, generates a markdown file listing contrib tutorials, collects HAL replacement headers and BibTeX files, and builds lists of main and extra module references for Doxygen.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
# gathering headers
set(paths_include)
set(paths_doc)
set(paths_bib)
set(paths_sample)
set(paths_tutorial)
set(paths_hal_interface)
set(refs_main)
set(refs_extra)
set(deps)
foreach(m ${OPENCV_MODULES_MAIN} ${OPENCV_MODULES_EXTRA})
  set(the_module "${m}")
  if(NOT the_module MATCHES "^opencv_")
    set(the_module "opencv_${m}")
  endif()
  list(FIND blacklist ${m} _pos)
  if(NOT EXISTS "${OPENCV_MODULE_${the_module}_LOCATION}/include"
      AND NOT EXISTS "${OPENCV_MODULE_${the_module}_LOCATION}/doc"
  )
    set(_pos -2)  # blacklist
  endif()
  if(${_pos} EQUAL -1)
    list(APPEND CMAKE_DOXYGEN_ENABLED_SECTIONS "HAVE_opencv_${m}")
    # include folder
    set(header_dir "${OPENCV_MODULE_opencv_${m}_LOCATION}/include")
    if(EXISTS "${header_dir}")
      list(APPEND paths_include "${header_dir}")
      list(APPEND deps ${header_dir})
      if(OPENCV_DOCS_EXCLUDE_CUDA)
        if(EXISTS "${OPENCV_MODULE_opencv_${m}_LOCATION}/include/opencv2/${m}/cuda")
          list(APPEND CMAKE_DOXYGEN_EXCLUDE_LIST "${OPENCV_MODULE_opencv_${m}_LOCATION}/include/opencv2/${m}/cuda")
        endif()
        file(GLOB list_cuda_files "${OPENCV_MODULE_opencv_${m}_LOCATION}/include/opencv2/${m}/*cuda*.hpp")
        if(list_cuda_files)
          list(APPEND CMAKE_DOXYGEN_EXCLUDE_LIST ${list_cuda_files})
        endif()
      endif()
    endif()
    # doc folder
    set(docs_dir "${OPENCV_MODULE_opencv_${m}_LOCATION}/doc")
    if(EXISTS "${docs_dir}")
      list(APPEND paths_doc "${docs_dir}")
      list(APPEND deps ${docs_dir})
    endif()
    # sample folder
    set(sample_dir "${OPENCV_MODULE_opencv_${m}_LOCATION}/samples")
    if(EXISTS "${sample_dir}")
      list(APPEND paths_sample "${sample_dir}")
      list(APPEND deps ${sample_dir})
    endif()
    # tutorial folder
    set(tutorial_dir "${OPENCV_MODULE_opencv_${m}_LOCATION}/tutorials")
    if(EXISTS "${tutorial_dir}")
      list(APPEND paths_tutorial "${tutorial_dir}")
      list(APPEND deps ${tutorial_dir})

      # tutorial reference entry
      file(GLOB tutorials RELATIVE "${OPENCV_MODULE_opencv_${m}_LOCATION}" "${tutorial_dir}/*.markdown")
      foreach (t ${tutorials})
        if (NOT DEFINED CMAKE_DOXYGEN_TUTORIAL_CONTRIB_ROOT)
          set(CMAKE_DOXYGEN_TUTORIAL_CONTRIB_ROOT "- @ref tutorial_contrib_root")
          set(tutorial_contrib_root "${CMAKE_CURRENT_BINARY_DIR}/contrib_tutorials.markdown")
          file(WRITE "${tutorial_contrib_root}"
            "Tutorials for contrib modules {#tutorial_contrib_root}\n"
            "=============================\n")
        endif()
        file(STRINGS "${OPENCV_MODULE_opencv_${m}_LOCATION}/${t}" tutorial_id LIMIT_COUNT 1 REGEX ".*{#[^}]+}")
        string(REGEX REPLACE ".*{#([^}]+)}" "\\1" tutorial_id "${tutorial_id}")
        file(APPEND "${tutorial_contrib_root}" "- ${m}. @subpage ${tutorial_id}\n")
      endforeach()
    endif()
    # HAL replacement file
    set(replacement_header "${OPENCV_MODULE_opencv_${m}_LOCATION}/src/hal_replacement.hpp")
    if(EXISTS "${replacement_header}")
      list(APPEND paths_hal_interface "${replacement_header}")
    endif()

    # BiBTeX file
    set(bib_file "${docs_dir}/${m}.bib")
    if(EXISTS "${bib_file}")
      set(paths_bib "${paths_bib} ${bib_file}")
      list(APPEND deps ${bib_file})
    endif()
    # Reference entry
    set(one_ref "\t- ${m}. @ref ${m}\n")
    list(FIND OPENCV_MODULES_EXTRA ${m} _pos)
    if(${_pos} EQUAL -1)
      set(refs_main "${refs_main}${one_ref}")
    else()
      set(refs_extra "${refs_extra}${one_ref}")
    endif()
  endif()
endforeach()
```

----------------------------------------

TITLE: Setting Compile Definitions and Module-Specific Configuration (CMake)
DESCRIPTION: Adds a private compile definition `OPENCV_MODULE_IS_PART_OF_WORLD=1` to the `opencv_world` target using `ocv_target_compile_definitions`. This definition allows source code to conditionally compile sections specific to the world build. It then conditionally calls `ocv_imgcodecs_configure_target()` and `ocv_highgui_configure_target()` if the respective modules (`opencv_imgcodecs`, `opencv_highgui`) are being built and included in the `opencv_world` target, enabling module-specific post-creation configuration steps.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
ocv_target_compile_definitions(${the_module} PRIVATE OPENCV_MODULE_IS_PART_OF_WORLD=1)

if(BUILD_opencv_imgcodecs AND OPENCV_MODULE_opencv_imgcodecs_IS_PART_OF_WORLD)
  ocv_imgcodecs_configure_target()
endif()
if(BUILD_opencv_highgui AND OPENCV_MODULE_opencv_highgui_IS_PART_OF_WORLD)
  ocv_highgui_configure_target()
endif()
```

----------------------------------------

TITLE: Displaying OpenCL, ONNX, and CANN Integration Status in OpenCV Build
DESCRIPTION: Checks and displays the status of OpenCL, ONNX, and CANN integrations, showing specific features, include paths, and library information when available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_27

LANGUAGE: cmake
CODE:
```
if(WITH_OPENCL OR HAVE_OPENCL)
  ocv_build_features_string(opencl_features
    IF HAVE_OPENCL_SVM THEN "SVM"
    IF HAVE_CLAMDFFT THEN "AMDFFT"
    IF HAVE_CLAMDBLAS THEN "AMDBLAS"
    IF HAVE_OPENCL_D3D11_NV THEN "NVD3D11"
    IF HAVE_VA_INTEL THEN "INTELVA"
    ELSE "no extra features")
  status("")
  status("  OpenCL:"     HAVE_OPENCL   THEN   "YES (${opencl_features})" ELSE "NO")
  if(HAVE_OPENCL)
    status("    Include path:"  OPENCL_INCLUDE_DIRS THEN "${OPENCL_INCLUDE_DIRS}" ELSE "NO")
    status("    Link libraries:"       OPENCL_LIBRARIES THEN "${OPENCL_LIBRARIES}" ELSE "Dynamic load")
  endif()
endif()

if(WITH_ONNX OR HAVE_ONNX)
  status("")
  status("  ONNX:"     HAVE_ONNX THEN "YES" ELSE "NO")
  if(HAVE_ONNX)
    status("    Include path:"  ONNX_INCLUDE_DIR THEN "${ONNX_INCLUDE_DIR}" ELSE "NO")
    status("    Link libraries:" ONNX_LIBRARIES THEN "${ONNX_LIBRARIES}" ELSE "NO")
  endif()
endif()

if(WITH_CANN)
  status("")
  status("  CANN:"    HAVE_CANN THEN "YES" ELSE "NO")
  if(HAVE_CANN)
    status("    Include path"     CANN_INCLUDE_DIRS THEN "${CANN_INCLUDE_DIRS}" ELSE "NO")
    status("    Link libraries:"  CANN_LIBRARIES    THEN "${CANN_LIBRARIES}"    ELSE "NO")
  endif()
endif()
```

----------------------------------------

TITLE: CMake Hook for OpenCV Compiler and Linker Options
DESCRIPTION: This snippet configures post-build and post-compiler hooks. It includes configurations for Python and CUDA support and sets compiler and linker options based on the environment, such as not using certain features on iOS or XROS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: CMake
CODE:
```
ocv_cmake_hook(POST_CMAKE_BUILD_OPTIONS)

# --- Python Support ---
if(NOT IOS AND NOT XROS)
  include(cmake/OpenCVDetectPython.cmake)
endif()

include(cmake/OpenCVCompilerOptions.cmake)

ocv_cmake_hook(POST_COMPILER_OPTIONS)

# --- CUDA Support ---
if(ENABLE_CUDA_FIRST_CLASS_LANGUAGE)
  if(CMAKE_VERSION VERSION_LESS 3.18)
    message(WARNING \"CUDA: First class language only supported for CMake versions >= 3.18, falling back to FindCUDA!\")
    set(ENABLE_CUDA_FIRST_CLASS_LANGUAGE OFF CACHE BOOL \"Enable CUDA as a first class language, if enabled dependant projects will need to use CMake >= 3.18\" FORCE)
  else()

    # Check CUDA_PATH if supplied
    if(UNIX AND CUDA_PATH AND NOT ENV{CUDA_PATH})
      set(ENV{CUDA_PATH} ${CUDA_PATH})
    elseif(WIN32 AND CUDA_PATH)
      set(ENV{PATH} \"${CUDA_PATH}\\bin\;$ENV{PATH}\")
    endif()
    include(CheckLanguage)
    check_language(CUDA)

    # Fallback to checking default locations
    if(NOT CMAKE_CUDA_COMPILER)
      # Checking windows default search...[truncated]
```

----------------------------------------

TITLE: Configuration options for headless WEC2013 build
DESCRIPTION: Comprehensive set of CMake configuration options for building OpenCV for headless WEC2013 environments. Disables various modules and features to reduce dependencies and resource requirements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/wince/readme.md#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
-DBUILD_EXAMPLES=OFF `
-DBUILD_opencv_apps=OFF `
-DBUILD_opencv_calib3d=OFF `
-DBUILD_opencv_highgui=OFF `
-DBUILD_opencv_features2d=OFF `
-DBUILD_opencv_flann=OFF `
-DBUILD_opencv_ml=OFF `
-DBUILD_opencv_objdetect=OFF `
-DBUILD_opencv_photo=OFF `
-DBUILD_opencv_shape=OFF `
-DBUILD_opencv_stitching=OFF `
-DBUILD_opencv_superres=OFF `
-DBUILD_opencv_ts=OFF `
-DBUILD_opencv_video=OFF `
-DBUILD_opencv_videoio=OFF `
-DBUILD_opencv_videostab=OFF `
-DBUILD_opencv_dnn=OFF `
-DBUILD_opencv_java=OFF `
-DBUILD_opencv_python2=OFF `
-DBUILD_opencv_python3=OFF `
-DBUILD_opencv_java_bindings_generator=OFF `
-DBUILD_opencv_python_bindings_generator=OFF `
-DBUILD_TIFF=OFF `
-DCV_TRACE=OFF `
-DWITH_OPENCL=OFF `
-DHAVE_OPENCL=OFF `
-DWITH_QT=OFF `
-DWITH_GTK=OFF `
-DWITH_QUIRC=OFF `
-DWITH_JASPER=OFF `
-DWITH_WEBP=OFF `
-DWITH_PROTOBUF=OFF `
-DBUILD_SHARED_LIBS=OFF `
-DWITH_OPENEXR=OFF `
-DWITH_TIFF=OFF `
```

----------------------------------------

TITLE: Invoking Error Handlers in JPEG Library (C Macros)
DESCRIPTION: Describes the C macros used within the JPEG library or application code to trigger the error handling mechanism. `ERREXITn(...)` is used for fatal errors, `WARNMSn(...)` for warnings about corrupt data, and `TRACEMSn(...)` for trace/informational messages. These macros store the message code and any printf-style parameters into the `cinfo->err` struct before calling `error_exit` or `emit_message`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_48

LANGUAGE: c
CODE:
```
ERREXITn(...)
WARNMSn(...)
TRACEMSn(...)
```

----------------------------------------

TITLE: Enabling Soft-Float Compilation Flag with CMake - Bash
DESCRIPTION: Configures the OpenCV cross-compilation process with the SOFTFP flag enabled, which instructs the compiler to use software floating-point. Requires all CMake configuration prerequisites, and is intended for platforms where hardware floating-point is not supported. Adjust optional parameters as needed to suit platform constraints.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/arm_crosscompile_with_cmake.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
cmake [<some optional parameters>] -DSOFTFP=ON -DCMAKE_TOOLCHAIN_FILE=<path to the OpenCV source directory>/platforms/linux/arm-gnueabi.toolchain.cmake <path to the OpenCV source directory>
```

----------------------------------------

TITLE: Defining the Progress Monitoring Structure in libjpeg (C)
DESCRIPTION: Defines the `jpeg_progress_mgr` structure in C, used to manage progress reporting in libjpeg. The library updates the fields (`pass_counter`, `pass_limit`, `completed_passes`, `total_passes`) which can be accessed within a user-defined callback function pointed to by `cinfo->progress->progress_monitor`. This allows applications to track the progress of compression or decompression operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_65

LANGUAGE: c
CODE:
```
struct jpeg_progress_mgr {
  void (*progress_monitor) (j_common_ptr cinfo);

  long pass_counter;      /* work units completed in this pass */
  long pass_limit;        /* total number of work units in this pass */
  int completed_passes;   /* passes completed so far */
  int total_passes;       /* total number of passes expected */
};
```

----------------------------------------

TITLE: Referencing Entities with @ref - Doxygen/Markdown
DESCRIPTION: Shows explicit, named, implicit, and disabled references using the doxygen @ref command. Proper usage generates documentation links to classes, pages, or anchors. No dependencies except doxygen processing. Input is entity name or alias; output is hyperlink in documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_7

LANGUAGE: markdown
CODE:
```
Explicit reference: @ref MyClass
Explicit named reference: @ref example_page "Example page"
Implicit reference: cv::abc::MyClass1 or just MyClass1
Disable implicit reference: %MyClass1
```

----------------------------------------

TITLE: Library Target Configuration
DESCRIPTION: Defines the library targets and their compilation settings, including platform-specific definitions and NEON support configuration. Creates both object and static library targets.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/carotene/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
add_library(carotene_objs OBJECT EXCLUDE_FROM_ALL
  ${carotene_headers}
  ${carotene_sources}
)

if(NOT CAROTENE_NS STREQUAL "carotene")
    target_compile_definitions(carotene_objs PUBLIC "-DCAROTENE_NS=${CAROTENE_NS}")
endif()

if(WITH_NEON)
    target_compile_definitions(carotene_objs PRIVATE "-DWITH_NEON")
endif()

if(MINGW)
    target_compile_definitions(carotene_objs PRIVATE "-D_USE_MATH_DEFINES=1")
endif()

# we add dummy file to fix XCode build
add_library(carotene STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} "$<TARGET_OBJECTS:carotene_objs>" "${CAROTENE_SOURCE_DIR}/dummy.cpp")
```

----------------------------------------

TITLE: Disabling Specific Compiler Warnings in CMake for OpenJPEG
DESCRIPTION: Uses the OpenCV macro `ocv_warnings_disable` to suppress specific compiler warnings (related to implicit conversions, unused variables, missing prototypes/declarations, and documentation) that might arise during the compilation of the OpenJPEG C code, ensuring a cleaner build output within the OpenCV environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
ocv_warnings_disable(CMAKE_C_FLAGS
    -Wimplicit-const-int-float-conversion  # clang
    -Wunused-but-set-variable # clang15
    -Wmissing-prototypes # clang, function opj_t1_ht_decode_cblk
    -Wmissing-declarations # gcc, function opj_t1_ht_decode_cblk
    -Wdocumentation # clang
)
```

----------------------------------------

TITLE: Adding CUDA Preprocessor Definition in CMake
DESCRIPTION: Conditionally adds the preprocessor definition `-DHAVE_CUDA=1` to the compiler flags if either the `HAVE_CUDA` or `CUDA_FOUND` CMake variable is true, indicating that CUDA support is available and configured.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
if(HAVE_CUDA OR CUDA_FOUND)
  add_definitions(-DHAVE_CUDA=1)
endif()
```

----------------------------------------

TITLE: Cloning OpenCV Repository Using Git
DESCRIPTION: Command to clone the OpenCV repository using Git, including all branches and commit history.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_10

LANGUAGE: bash
CODE:
```
git clone https://github.com/opencv/opencv.git
```

----------------------------------------

TITLE: Adding UMD Wrapper for OpenCV.js in CMake
DESCRIPTION: Sets up a custom command to create a UMD (Universal Module Definition) wrapper for the OpenCV.js file, allowing it to be used in various JavaScript environments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(MODULE_JS_PATH "${OpenCV_BINARY_DIR}/bin/${the_module}.js")
set(OCV_JS_PATH "${OpenCV_BINARY_DIR}/bin/${OPENCV_JS}")

add_custom_command(
   OUTPUT ${OCV_JS_PATH}
   COMMAND ${PYTHON_DEFAULT_EXECUTABLE} "${CMAKE_CURRENT_SOURCE_DIR}/src/make_umd.py" ${MODULE_JS_PATH} "${OCV_JS_PATH}"
   DEPENDS ${the_module}
   DEPENDS "${CMAKE_CURRENT_SOURCE_DIR}/src/make_umd.py")

add_custom_target(${OPENCV_JS} ALL
                  DEPENDS ${OCV_JS_PATH}
                  DEPENDS ${the_module})
```

----------------------------------------

TITLE: Setting Default Backend and Finalizing OpenCV HighGUI Module in CMake
DESCRIPTION: Sets a default backend if none was selected, displays status information, handles include and library directories, and finalizes the module configuration with necessary target properties, compiler options, and test setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_17

LANGUAGE: CMake
CODE:
```
if(NOT OPENCV_HIGHGUI_BUILTIN_BACKEND)
  set(OPENCV_HIGHGUI_BUILTIN_BACKEND "NONE")
endif()
message(STATUS "highgui: using builtin backend: ${OPENCV_HIGHGUI_BUILTIN_BACKEND}")
set(OPENCV_HIGHGUI_BUILTIN_BACKEND "${OPENCV_HIGHGUI_BUILTIN_BACKEND}" PARENT_SCOPE)  # informational

if(TRUE)
  # these variables are set by 'ocv_append_build_options(HIGHGUI ...)'
  foreach(P ${HIGHGUI_INCLUDE_DIRS})
    ocv_include_directories(${P})
  endforeach()

  foreach(P ${HIGHGUI_LIBRARY_DIRS})
    link_directories(${P})
  endforeach()
endif()

if(tgts STREQUAL "PRIVATE")
  set(tgts "")
endif()

ocv_install_used_external_targets(${tgts})

source_group("Src" FILES ${highgui_srcs} ${highgui_hdrs})
source_group("Include" FILES ${highgui_ext_hdrs})
ocv_set_module_sources(HEADERS ${highgui_ext_hdrs} SOURCES ${highgui_srcs} ${highgui_hdrs})
ocv_module_include_directories()

ocv_create_module(${HIGHGUI_LIBRARIES})

macro(ocv_highgui_configure_target)
if(APPLE)
  add_apple_compiler_options(${the_module})
endif()

if(MSVC AND NOT BUILD_SHARED_LIBS AND BUILD_WITH_STATIC_CRT)
  set_target_properties(${the_module} PROPERTIES LINK_FLAGS "/NODEFAULTLIB:atlthunk.lib /NODEFAULTLIB:atlsd.lib /NODEFAULTLIB:libcmt.lib /DEBUG")
endif()

ocv_warnings_disable(CMAKE_CXX_FLAGS -Wno-deprecated-declarations)
endmacro()

if(NOT BUILD_opencv_world)
  ocv_highgui_configure_target()
endif()

ocv_add_accuracy_tests(${tgts})
#ocv_add_perf_tests(${tgts})

if(HIGHGUI_ENABLE_PLUGINS)
```

----------------------------------------

TITLE: Disabling Unused Function Warning for GCC/Clang in CMake
DESCRIPTION: Checks if the compiler is GCC (`CV_GCC`) or Clang (`CV_CLANG`) and if noisy warnings are not enabled (`ENABLE_NOISY_WARNINGS` is false). If both conditions are true, it appends the `-Wno-unused-function` flag to the C compiler flags (`CMAKE_C_FLAGS`) to suppress warnings about unused functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: cmake
CODE:
```
if((CV_GCC OR CV_CLANG) AND NOT ENABLE_NOISY_WARNINGS)
  set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -Wno-unused-function")
endif()
```

----------------------------------------

TITLE: Downloading and Validating TBB Source Code
DESCRIPTION: Downloads the TBB source code from GitHub using the ocv_download function. Verifies the download with MD5 hash check and determines the source directory structure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(tbb_src_dir "${OpenCV_BINARY_DIR}/3rdparty/tbb")
ocv_download(FILENAME ${OPENCV_TBB_FILENAME}
             HASH ${OPENCV_TBB_RELEASE_MD5}
             URL
               "${OPENCV_TBB_URL}"
               "$ENV{OPENCV_TBB_URL}"
               "https://github.com/oneapi-src/oneTBB/archive/refs/tags/"
             DESTINATION_DIR ${tbb_src_dir}
             ID TBB
             STATUS res
             UNPACK RELATIVE_URL)
if(NOT res)
  return()
endif()
if(OPENCV_TBB_SUBDIR)
  # use current value
  ocv_assert(EXISTS "${tbb_src_dir}/${OPENCV_TBB_SUBDIR}")
elseif(EXISTS "${tbb_src_dir}/oneTBB-${OPENCV_TBB_RELEASE_}")
  set(OPENCV_TBB_SUBDIR "oneTBB-${OPENCV_TBB_RELEASE_}")
elseif(EXISTS "${tbb_src_dir}/tbb-${OPENCV_TBB_RELEASE_}")
  set(OPENCV_TBB_SUBDIR "oneTBB-${OPENCV_TBB_RELEASE_}")
else()
  message(FATAL_ERROR "TBB: Can't configure TBB. Specify OPENCV_TBB_SUBDIR through command-line.")
endif()
set(tbb_src_dir "${tbb_src_dir}/${OPENCV_TBB_SUBDIR}")
```

----------------------------------------

TITLE: Setting Source Files and Conditional Compilation for libtiff
DESCRIPTION: This snippet lists the source and header files for the libtiff library and conditionally includes platform-specific files. On Windows platforms, it includes tif_win32.c; otherwise, it includes tif_unix.c. This ensures that the build process includes the correct implementation based on the operating system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
set(lib_srcs
    tif_aux.c
    tif_close.c
    tif_codec.c
    tif_color.c
    tif_compress.c
    tif_dir.c
    tif_dirinfo.c
    tif_dirread.c
    tif_dirwrite.c
    tif_dumpmode.c
    tif_error.c
    tif_extension.c
    tif_fax3.c
    tif_fax3sm.c
    tif_flush.c
    tif_getimage.c
    tif_hash_set.c
    tif_jbig.c
    tif_jpeg_12.c
    tif_jpeg.c
    tif_luv.c
    tif_lzma.c
    tif_lzw.c
    tif_next.c
    tif_ojpeg.c
    tif_open.c
    tif_packbits.c
    tif_pixarlog.c
    tif_predict.c
    tif_print.c
    tif_read.c
    tif_strip.c
    tif_swab.c
    tif_thunder.c
    tif_tile.c
    tif_version.c
    tif_warning.c
    tif_webp.c
    tif_write.c
    tif_zip.c
    tif_zstd.c
    tif_stream.cxx
    t4.h
    tif_dir.h
    tif_fax3.h
    tif_hash_set.h
    tif_predict.h
    tiff.h
    tiffio.h
    tiffiop.h
    "${CMAKE_CURRENT_BINARY_DIR}/tiffvers.h"
    uvcode.h
    tiffio.hxx
    "${CMAKE_CURRENT_BINARY_DIR}/tif_config.h"
    "${CMAKE_CURRENT_BINARY_DIR}/tiffconf.h"
    )

if(WIN32 AND NOT WINRT)
  list(APPEND lib_srcs tif_win32.c)
else()
  list(APPEND lib_srcs tif_unix.c)
endif()
```

----------------------------------------

TITLE: Opening Video Files with OpenCV VideoCapture in C++
DESCRIPTION: Shows how to initialize `cv::VideoCapture` objects using command-line arguments (`argv`) for video file paths. It demonstrates two methods: passing the path directly to the constructor and using the `open()` method after construction. Requires `<string>` and `<opencv2/videoio.hpp>` headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
const string sourceReference = argv[1],sourceCompareWith = argv[2];

VideoCapture captRefrnc(sourceReference);
// or
VideoCapture captUndTst;
captUndTst.open(sourceCompareWith);
```

----------------------------------------

TITLE: Running ResNet-50 Evaluation Example
DESCRIPTION: Specific command example for evaluating PyTorch ResNet-50 model using the DNN model runner.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_10

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.classification.py_to_py_cls --model_name resnet50
```

----------------------------------------

TITLE: Outputting std::vector via cv::Mat in OpenCV C++
DESCRIPTION: Shows how to convert and output a std::vector through cv::Mat. This demonstrates the interoperability between STL containers and OpenCV data structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_17

LANGUAGE: C++
CODE:
```
vector<float> v;
v.push_back((float)CV_PI);
v.push_back(2);
v.push_back(3.01f);
cout << "Vector of floats via Mat = " << Mat(v) << endl << endl;
```

----------------------------------------

TITLE: OpenGL Configuration Option in OpenCV
DESCRIPTION: Defines the WITH_OPENGL build option which enables OpenGL integration for hardware-accelerated window drawing with GTK, WIN32 and Qt backends, plus basic OpenGL interoperability.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_18

LANGUAGE: markdown
CODE:
```
`WITH_OPENGL` (default: _OFF_)
```

----------------------------------------

TITLE: Executing PaddlePaddle ResNet50 Demo Script (Shell)
DESCRIPTION: Runs the Python script `paddle_resnet50.py`. This script is expected to handle exporting the PaddlePaddle ResNet50 model to ONNX, loading it using `cv2.dnn.readNetFromONNX`, preprocessing an image, and performing inference.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/dnn_model_runner/dnn_conversion/paddlepaddle/README.md#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
python paddle_resnet50.py
```

----------------------------------------

TITLE: Verifying System Libraries and Options in CMake for OpenCV
DESCRIPTION: This section of the CMake configuration manages detection and verification of system libraries and options, such as pkg-config availability and certain symbolic checks, ensuring dependencies are correctly configured for OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: CMake
CODE:
```
if(UNIX OR MINGW)
  if(NOT APPLE_FRAMEWORK OR OPENCV_ENABLE_PKG_CONFIG)
    if(CMAKE_CROSSCOMPILING AND NOT DEFINED ENV{PKG_CONFIG_LIBDIR} AND NOT DEFINED ENV{PKG_CONFIG_SYSROOT_DIR}
...
  # Ensure that libpthread is not listed as one of the libraries to pass to the linker.
  if (OPENCV_DISABLE_THREAD_SUPPORT)
    list(REMOVE_ITEM OPENCV_LINKER_LIBS pthread)
  endif()

  if(OPENCV_ENABLE_MEMALIGN)
    CHECK_SYMBOL_EXISTS(posix_memalign stdlib.h HAVE_POSIX_MEMALIGN)
    CHECK_INCLUDE_FILE(malloc.h HAVE_MALLOC_H)
    if(HAVE_MALLOC_H)
      CHECK_SYMBOL_EXISTS(memalign malloc.h HAVE_MEMALIGN)
    endif()
    # TODO:
    # - std::aligned_alloc() C++17 / C11
  endif()

  CHECK_SYMBOL_EXISTS(getauxval sys/auxv.h HAVE_GETAUXVAL)
  CHECK_SYMBOL_EXISTS(elf_aux_info sys/auxv.h HAVE_ELF_AUX_INFO)
el... [truncated]
```

----------------------------------------

TITLE: Configuring OpenVX HAL Static Library
DESCRIPTION: Creates and configures the OpenVX HAL static library with source files, include directories, and link dependencies. Sets output directory and optional installation rules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openvx/hal/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
add_library(openvx_hal STATIC openvx_hal.cpp openvx_hal.hpp ${OPENCV_3P_OPENVX_DIR}/include/ivx.hpp ${OPENCV_3P_OPENVX_DIR}/include/ivx_lib_debug.hpp)
target_include_directories(openvx_hal PUBLIC
  ${CMAKE_CURRENT_SOURCE_DIR}
  ${OPENCV_3P_OPENVX_DIR}/include
  ${CMAKE_SOURCE_DIR}/modules/core/include
  ${CMAKE_SOURCE_DIR}/modules/imgproc/include
  ${CMAKE_SOURCE_DIR}/modules/features2d/include
  ${OPENVX_INCLUDE_DIR})
target_link_libraries(openvx_hal PUBLIC ${OPENVX_LIBRARIES})
set_target_properties(openvx_hal PROPERTIES ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH})
if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(openvx_hal EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev)
endif()
```

----------------------------------------

TITLE: OpenCV App Addition Macro
DESCRIPTION: Defines a macro for conditionally adding OpenCV application subdirectories based on BUILD_APPS_LIST configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
macro(ocv_add_app directory)
  if(DEFINED BUILD_APPS_LIST)
    list(FIND BUILD_APPS_LIST ${directory} _index)
    if (${_index} GREATER -1)
      add_subdirectory(${directory})
    else()
      message(STATUS "Skip OpenCV app: ${directory}")
    endif()
  else()
    add_subdirectory(${directory})
  endif()
endmacro()
```

----------------------------------------

TITLE: Creating Directory Structure in Git Bash for OpenCV Build
DESCRIPTION: Commands to create a directory structure in Git Bash for building OpenCV. This snippet creates a directory at C:/lib and navigates to it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
mkdir /c/lib
cd /c/lib
```

----------------------------------------

TITLE: Configuring and Exporting slow_hal Module - CMake
DESCRIPTION: This CMake script initializes the build environment for the 'slow_hal' library within the larger OpenCV project. It sets up the project and library names, creates a static or shared library from source, configures position-independent code, and specifies the necessary include directories (including core OpenCV headers). Various variables are exported so other modules can detect and use the HAL implementation, and 'configure_file' ensures key headers and configuration scripts are copied to the appropriate binary locations for consumption by other components. Prerequisites include CMake 3.5+ and the expected directory structure under the OpenCV source tree.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/hal/slow_hal/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.5 FATAL_ERROR)

set(PROJECT_NAME "slow_hal")
set(HAL_LIB_NAME "slow_hal")

add_library(${HAL_LIB_NAME} impl.cpp)
set_target_properties(${HAL_LIB_NAME} PROPERTIES POSITION_INDEPENDENT_CODE TRUE)
set(OPENCV_SRC_DIR "${CMAKE_CURRENT_SOURCE_DIR}/../../..")
target_include_directories(${HAL_LIB_NAME} PUBLIC ${CMAKE_CURRENT_SOURCE_DIR} ${OPENCV_SRC_DIR}/modules/core/include)

set(OpenCV_HAL_FOUND TRUE)
set(OpenCV_HAL_VERSION 0.0.1)
set(OpenCV_HAL_LIBRARIES ${CMAKE_CURRENT_BINARY_DIR}/lib${HAL_LIB_NAME}.a)
set(OpenCV_HAL_HEADERS "impl.hpp")
set(OpenCV_HAL_INCLUDE_DIRS ${CMAKE_CURRENT_LIST_DIR})

configure_file("impl.hpp" "${CMAKE_BINARY_DIR}/impl.hpp" COPYONLY)
configure_file("config.cmake" "${CMAKE_BINARY_DIR}/OpenCV_HALConfig.cmake")

```

----------------------------------------

TITLE: Loading a Fixed AC Huffman Table in C using libjpeg
DESCRIPTION: Shows how to load a predefined AC Huffman table into a specific slot (`n`) within the libjpeg decompression context (`cinfo`). It allocates memory using `jpeg_alloc_huff_table` if needed, then populates the `bits` array (code counts per length) and the `huffval` array (symbols in code-length order) from user-provided `counts` and `symbols` arrays. This is necessary when decoding abbreviated JPEGs lacking embedded Huffman tables.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_60

LANGUAGE: c
CODE:
```
if (cinfo.ac_huff_tbl_ptrs[n] == NULL)
  cinfo.ac_huff_tbl_ptrs[n] = jpeg_alloc_huff_table((j_common_ptr) &cinfo);
huff_ptr = cinfo.ac_huff_tbl_ptrs[n];       /* huff_ptr is JHUFF_TBL* */
for (i = 1; i <= 16; i++) {
  /* counts[i] is number of Huffman codes of length i bits, i=1..16 */
  huff_ptr->bits[i] = counts[i];
}
for (i = 0; i < 256; i++) {
  /* symbols[] is the list of Huffman symbols, in code-length order */
  huff_ptr->huffval[i] = symbols[i];
}
```

----------------------------------------

TITLE: Performing Point Polygon Test with OpenCV in C++
DESCRIPTION: This C++ code demonstrates how to use the cv::pointPolygonTest function in OpenCV to test the presence of a point relative to a polygon. Dependencies include OpenCV 3.0 or above. The input consists of a contour (polygon) and a test point; the function returns a value indicating whether the point is inside, outside, or on the contour. The code handles visualization using OpenCV windows and requires linking against the OpenCV library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/point_polygon_test/point_polygon_test.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include <opencv2/opencv.hpp>\n\nusing namespace cv;\nusing namespace std;\n\nint main(int, char**)\n{\n    // Define a polygon (contour)\n    vector<Point> contour;\n    contour.push_back(Point(100, 100));\n    contour.push_back(Point(200, 100));\n    contour.push_back(Point(200, 200));\n    contour.push_back(Point(100, 200));\n\n    // Define test points\n    Point testPoint1(150, 150); // Should be inside\n    Point testPoint2(250, 150); // Should be outside\n\n    // Test pointPolygonTest\n    double result1 = pointPolygonTest(contour, testPoint1, false);\n    double result2 = pointPolygonTest(contour, testPoint2, false);\n\n    cout << "Test Point 1 (" << testPoint1 << "): " << result1 << endl;\n    cout << "Test Point 2 (" << testPoint2 << "): " << result2 << endl;\n\n    // Visualization: draw contour and points\n    Mat img = Mat::zeros(300, 300, CV_8UC3);\n    polylines(img, contour, true, Scalar(255,255,255), 2);\n    circle(img, testPoint1, 5, Scalar(0,255,0), -1);\n    circle(img, testPoint2, 5, Scalar(0,0,255), -1);\n    imshow("Point Polygon Test", img);\n    waitKey(0);\n    return 0;\n}\n
```

----------------------------------------

TITLE: JPEG Processing Function Declarations
DESCRIPTION: Core JPEG processing function declarations used for managing buffered-image mode operations and scan processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_57

LANGUAGE: c
CODE:
```
jpeg_finish_output()
jpeg_start_output()
jpeg_consume_input()
jpeg_start_decompress()
jpeg_finish_decompress()
jpeg_new_colormap()
```

----------------------------------------

TITLE: Corner Detection Conditional Logic in OpenCV
DESCRIPTION: Complex nested conditional statements that compare pixel values against thresholds (c_b and cb) to determine if a point qualifies as a corner. Uses multiple offset positions to analyze surrounding pixels and jumps to either 'is_a_corner' or 'is_not_a_corner' based on the comparison results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_19

LANGUAGE: C++
CODE:
```
if(ptr[offset2] < c_b)
    goto is_not_a_corner;
else
    if(ptr[offset2] > cb)
      if(ptr[offset1] < c_b)
        goto is_not_a_corner;
      else
        if(ptr[offset1] > cb)
          if(ptr[offset6] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
```

----------------------------------------

TITLE: Versioning and Configuration Files Generation
DESCRIPTION: This snippet sets the version number for libtiff and processes configuration templates using CMake's configure_file command to generate header files required for the build. The tif_config.h, tiffconf.h, and tiffvers.h files are crucial for defining platform-specific and version-specific configurations during the build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
set(LIBTIFF_MAJOR_VERSION "4")
set(LIBTIFF_MINOR_VERSION "6")
set(LIBTIFF_MICRO_VERSION "0")
set(LIBTIFF_VERSION "${LIBTIFF_MAJOR_VERSION}.${LIBTIFF_MINOR_VERSION}.${LIBTIFF_MICRO_VERSION}")
file(READ "RELEASE-DATE" LIBTIFF_RELEASE_DATE content)

set(TIFF_MAX_DIR_COUNT "1048576")

configure_file("${CMAKE_CURRENT_SOURCE_DIR}/tif_config.h.cmake.in"
               "${CMAKE_CURRENT_BINARY_DIR}/tif_config.h"
               @ONLY)
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/tiffconf.h.cmake.in"
               "${CMAKE_CURRENT_BINARY_DIR}/tiffconf.h"
               @ONLY)
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/tiffvers.h.cmake.in"
               "${CMAKE_CURRENT_BINARY_DIR}/tiffvers.h"
               @ONLY)
```

----------------------------------------

TITLE: Configuring Android Project Build Capability in OpenCV CMake
DESCRIPTION: Checks if the necessary tools and versions are available to build Android projects. Sets a flag indicating whether Android projects can be built.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_14

LANGUAGE: CMake
CODE:
```
if(ANDROID AND ANDROID_EXECUTABLE AND ANT_EXECUTABLE AND (ANT_VERSION VERSION_GREATER 1.7) AND (ANDROID_TOOLS_Pkg_Revision GREATER 13))
  SET(CAN_BUILD_ANDROID_PROJECTS TRUE)
else()
  SET(CAN_BUILD_ANDROID_PROJECTS FALSE)
endif()
```

----------------------------------------

TITLE: Implementing Custom Serialization Methods for File I/O (Inside Class) - OpenCV C++
DESCRIPTION: This snippet adds methods for custom serialization within a C++ class to enable seamless integration with OpenCV's FileStorage. Implementations include writing and reading each member variable. These methods must match the serialization protocol of OpenCV and handle default values for missing fields.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_13

LANGUAGE: C++
CODE:
```
void write(FileStorage& fs) const\n{\n    fs << "{" << "A" << A << "X" << X << "id" << id << "}";\n}\nvoid read(const FileNode& node)\n{\n    A = (int)node["A"];\n    X = (double)node["X"];\n    id = (string)node["id"];\n}
```

----------------------------------------

TITLE: Conditional Debug Module and Module Definition in CMake
DESCRIPTION: This snippet includes a conditional definition for including a debug module when DEBUG_opencv_features2d is set. It defines the features2d module with dependencies on opencv_imgproc and optional dependencies like opencv_flann. The module is set up to be capable of being wrapped for various languages such as Java, Objective-C, Python, and JavaScript.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(debug_modules \"\")\nif(DEBUG_opencv_features2d)\n  list(APPEND debug_modules opencv_highgui)\nendif()\nocv_define_module(features2d opencv_imgproc ${debug_modules} OPTIONAL opencv_flann WRAP java objc python js)
```

----------------------------------------

TITLE: Initializing JPEG Decompression Object in C
DESCRIPTION: This snippet focuses on creating and initializing a JPEG decompression object. It involves setting up error handling and is similar to initializing a compression object. The key function is 'jpeg_create_decompress' for decompression processes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_11

LANGUAGE: C
CODE:
```
struct jpeg_decompress_struct cinfo;
struct jpeg_error_mgr jerr;
cinfo.err = jpeg_std_error(&jerr);
jpeg_create_decompress(&cinfo);
```

----------------------------------------

TITLE: Setting OpenJPEG Shared Library SOVERSION in CMake
DESCRIPTION: Determines the shared object version (SOVERSION) for the OpenJPEG library. It defaults to 7 based on the OpenJPEG team's versioning scheme but allows overriding via the `OPENJPEG_SOVERSION` CMake variable during configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
# Because autotools does not support X.Y notation for SOVERSION, we have to use
# two numbering, one for the openjpeg version and one for openjpeg soversion
# version | soversion
#   1.0   |  0
#   1.1   |  1
#   1.2   |  2
#   1.3   |  3
#   1.4   |  4
#   1.5   |  5
#   1.5.1 |  5
#   2.0   |  6
#   2.0.1 |  6
#   2.1   |  7
#   2.1.1 |  7
#   2.1.2 |  7
#   2.2.0 |  7
#   2.3.0 |  7
#   2.3.1 |  7
#   2.4.0 |  7
#   2.5.0 |  7
# above is the recommendation by the OPJ team. If you really need to override this default,
# you can specify your own OPENJPEG_SOVERSION at cmake configuration time:
# cmake -DOPENJPEG_SOVERSION:STRING=42 /path/to/openjpeg
if(NOT OPENJPEG_SOVERSION)
  set(OPENJPEG_SOVERSION 7)
endif()
```

----------------------------------------

TITLE: Configuring Threading and Compiler-Specific Options for TBB
DESCRIPTION: Sets up threading and compiler-specific options for TBB based on the build environment. Includes special handling for GCC, Clang, and pthread support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
if(HAVE_PTHREAD)
  add_definitions(-DUSE_PTHREAD) #required for Unix
endif()

if(CV_GCC)
  add_definitions(-DTBB_USE_GCC_BUILTINS=1) #required for ARM GCC
  if(NOT CMAKE_CXX_COMPILER_VERSION LESS 6.0)
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -flifetime-dse=1") # workaround for GCC 6.x
  endif()
endif()

if(ANDROID_COMPILER_IS_CLANG)
  add_definitions(-D__TBB_GCC_BUILTIN_ATOMICS_PRESENT=1)
endif()
```

----------------------------------------

TITLE: Configuring OpenCV 2.4 Build for DRIVE PX 2 using CMake (Shell)
DESCRIPTION: Runs CMake to configure the OpenCV 2.4 build specifically for the NVIDIA DRIVE PX 2 platform (Vibrante V4L). It sets build type to Release, enables CUDA 8.0 for architecture 6.2, enables Python 2 bindings (`BUILD_opencv_python`), TBB, and FFMPEG, while disabling several other optional dependencies (PNG, TIFF, Jasper, ZLIB, Java, nonfree modules, OpenCL, OpenMP, GStreamer, VTK, 1394, OpenEXR) and specifying the test data path. Assumes execution from a build directory sibling to `opencv` and `opencv_extra`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_14

LANGUAGE: Shell
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_nonfree=OFF \
    -DBUILD_opencv_python=ON \
    -DENABLE_NEON=ON \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0 \
    -DCUDA_ARCH_BIN=6.2 \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=ON \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Setting Solution Folder for Zlib in CMake
DESCRIPTION: Places the Zlib library in the "3rdparty" solution folder if solution folders are enabled. This helps organize the project structure in IDEs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: CMake
CODE:
```
if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${ZLIB_LIBRARY} PROPERTIES FOLDER "3rdparty")
endif()
```

----------------------------------------

TITLE: Conditionally Defining Highgui Module with Dependencies and Wrappers in CMake
DESCRIPTION: Defines the 'highgui' module using the custom `ocv_add_module` function. It specifies `opencv_imgproc` as a required dependency and `opencv_imgcodecs` and `opencv_videoio` as optional dependencies. Crucially, it conditionally includes Java wrappers (`WRAP java`) only when not building for Android. Python wrappers (`WRAP python`) are included for both Android and other platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(ANDROID)
  ocv_add_module(highgui opencv_imgproc OPTIONAL opencv_imgcodecs opencv_videoio WRAP python)
else()
  ocv_add_module(highgui opencv_imgproc OPTIONAL opencv_imgcodecs opencv_videoio WRAP python java)
endif()
```

----------------------------------------

TITLE: Installing AArch64 Python 3 Development Library (Bash)
DESCRIPTION: Installs the Python 3 development library (`libpython3-dev`) specifically for the `arm64` architecture onto the host system. This is required if building the OpenCV Python 3 wrapper for the `arm64` target.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_14

LANGUAGE: bash
CODE:
```
sudo apt install -y \
    libpython3-dev:arm64
```

----------------------------------------

TITLE: Configuring JPEG Support in CMake
DESCRIPTION: CMake configuration options for enabling JPEG support in OpenCV imgcodecs module. Includes options for choosing between libjpeg-turbo and standard libjpeg, as well as SIMD optimization controls.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/readme.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
WITH_JPEG=ON # Enable JPEG support
BUILD_JPEG=ON # Use libjpeg-turbo by default
BUILD_JPEG_TURBO_DISABLE=ON # Force using libjpeg instead
ENABLE_LIBJPEG_TURBO_SIMD=ON # Control SIMD instructions
```

----------------------------------------

TITLE: Configuring RVV HAL Internal Variables with CMake - CMake
DESCRIPTION: This snippet initializes and caches variables that control integration of the RVV (RISC-V Vector) Hardware Abstraction Layer into OpenCV. It requires ${MIN_VER_CMAKE} to be defined and the build to use CMake, but has no external dependencies. Key parameters set include minimum CMake version, the HAL library name, version string, library targets, header file, and include directories. No parameters are externally exposed; all values are set as internal cache entries to facilitate subsequent build steps within the CMake system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/hal_rvv/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION ${MIN_VER_CMAKE} FATAL_ERROR)

set(HAL_LIB_NAME "")

set(RVV_HAL_FOUND TRUE CACHE INTERNAL "")
set(RVV_HAL_VERSION "0.0.1" CACHE INTERNAL "")
set(RVV_HAL_LIBRARIES ${HAL_LIB_NAME} CACHE INTERNAL "")
set(RVV_HAL_HEADERS "hal_rvv.hpp" CACHE INTERNAL "")
set(RVV_HAL_INCLUDE_DIRS "${CMAKE_CURRENT_SOURCE_DIR}" "${CMAKE_SOURCE_DIR}/modules/imgproc/include" CACHE INTERNAL "")
```

----------------------------------------

TITLE: Camera Frame Transformation Matrix Equation
DESCRIPTION: Mathematical equation showing how 3D points are transformed from world coordinates to camera coordinates using rotation and translation components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/calib3d/doc/solvePnP.markdown#2025-04-22_snippet_1

LANGUAGE: Mathematical Notation
CODE:
```
\begin{bmatrix}
X_c \\
Y_c \\
Z_c \\
1
\end{bmatrix} =
\hspace{0.2em} ^{c}\bf{T}_w
\begin{bmatrix}
X_{w} \\
Y_{w} \\
Z_{w} \\
1
\end{bmatrix}
```

----------------------------------------

TITLE: Enabling OpenCL Compiler Definitions if Available - CMake
DESCRIPTION: If both OPENCV_DNN_OPENCL and HAVE_OPENCL are true, this sets a compile definition (CV_OCL4DNN=1) for the DNN module, enabling code paths specific to OpenCL. The snippet checks variables and applies definitions to target. No parameters beyond variable checks and setting compile definitions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: CMake
CODE:
```
if(OPENCV_DNN_OPENCL AND HAVE_OPENCL)
  ocv_target_compile_definitions(${the_module} PRIVATE "CV_OCL4DNN=1")
endif()
```

----------------------------------------

TITLE: Ensuring Doxygen HTML Output Directory Exists in CMake
DESCRIPTION: Uses the `file(MAKE_DIRECTORY ...)` command to create the specified HTML output directory (`${CMAKE_CURRENT_BINARY_DIR}/doxygen/html`) if it does not already exist. This prevents errors later when Doxygen tries to write output files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_17

LANGUAGE: cmake
CODE:
```
# make sure the build directory exists
file(MAKE_DIRECTORY "${opencv_tutorial_html_dir}")
```

----------------------------------------

TITLE: Verifying Pkg-config for AArch64 Freetype/Harfbuzz (Bash)
DESCRIPTION: Uses `pkg-config` with the appropriate environment variables set for `aarch64` to retrieve the compiler and linker flags needed for using the Freetype2 and HarfBuzz libraries installed for the `arm64` architecture. Successful output confirms `pkg-config` can find these libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_15

LANGUAGE: bash
CODE:
```
PKG_CONFIG_PATH=/usr/lib/aarch64-linux-gnu/pkgconfig:/usr/share/pkgconfig \
    PKG_CONFIG_LIBDIR=/usr/lib/aarch64-linux-gnu \
    PKG_CONFIG_SYSROOT_DIR=/ \
       pkg-config freetype2 harfbuzz --cflags --libs
-I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/harfbuzz -I/usr/include/glib-2.0 -I/usr/lib/aarch64-linux-gnu/glib-2.0/include -L/usr/lib/aarch64-linux-gnu -lfreetype -lharfbuzz
```

----------------------------------------

TITLE: Running OpenCV.js Performance Tests with Node.js - Shell
DESCRIPTION: This shell script sequence changes to the 'bin/perf' directory, installs dependencies with npm, and invokes the performance test JavaScript script for 'threshold' with a custom test parameter filter. It requires a built OpenCV.js with performance tests and Node.js/npm. The '--test_param_filter' argument controls which test is run. Outputs are benchmark results displayed in the terminal.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_22

LANGUAGE: sh
CODE:
```
cd bin/perf\nnpm install\nnode perf_threshold.js --test_param_filter="(1920x1080, CV_8UC1, THRESH_BINARY)"
```

----------------------------------------

TITLE: Text Recognition on Public Datasets Using Bash
DESCRIPTION: These bash commands are used to perform text recognition on publicly available datasets as test cases. It involves models stored in ONNX format and requires the OpenCV executables to be pre-built. The commands take paths to models and evaluation data as inputs, along with flags for execution options. Results appearing on the connected display or adjustments in verbosity level might be considered constraints.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_9

LANGUAGE: bash
CODE:
```
example_dnn_scene_text_recognition -mp=path/to/crnn.onnx -e=true -edp=path/to/evaluation_data_rec -vp=/path/to/alphabet_36.txt -rgb=0
example_dnn_scene_text_recognition -mp=path/to/crnn_cs.onnx -e=true -edp=path/to/evaluation_data_rec -vp=/path/to/alphabet_94.txt -rgb=1
```

----------------------------------------

TITLE: Displaying Intel IPP Status in OpenCV Build
DESCRIPTION: Checks and displays the status of Intel Integrated Performance Primitives (IPP) integration, including version information, root directory, linking method, and the presence of IPP Image Wrappers (IW).
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_22

LANGUAGE: cmake
CODE:
```
if(WITH_IPP AND HAVE_IPP)
  status("    Intel IPP:" "${IPP_VERSION_STR} [${IPP_VERSION_MAJOR}.${IPP_VERSION_MINOR}.${IPP_VERSION_BUILD}]")
  status("           at:" "${IPP_ROOT_DIR}")
  if(NOT HAVE_IPP_ICV)
    status("       linked:" BUILD_WITH_DYNAMIC_IPP THEN "dynamic" ELSE "static")
  endif()
  if(HAVE_IPP_IW)
    if(BUILD_IPP_IW)
      status("    Intel IPP IW:" "sources (${IW_VERSION_MAJOR}.${IW_VERSION_MINOR}.${IW_VERSION_UPDATE})")
    else()
      status("    Intel IPP IW:" "binaries (${IW_VERSION_MAJOR}.${IW_VERSION_MINOR}.${IW_VERSION_UPDATE})")
    endif()
    status("              at:" "${IPP_IW_PATH}")
  else()
    status("    Intel IPP IW:"   NO)
  endif()
endif()
```

----------------------------------------

TITLE: Configuring s390 CRC32-VX Optimization for ZLIB in CMake
DESCRIPTION: Checks if CRC32 Vector Extension (VX) optimization is enabled (WITH_CRC32_VX) for s390 and verifies VGFMA intrinsics support (HAVE_VGFMA_INTRIN). If supported, it adds the S390_CRC32_VX definition, appends the `crc32-vx.c` source file, and sets specific compile flags (VGFMAFLAG, NOLTOFLAG) for that file. Otherwise, it disables the feature.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_23

LANGUAGE: cmake
CODE:
```
        if(WITH_CRC32_VX)
            check_vgfma_intrinsics()
            if(HAVE_VGFMA_INTRIN)
                add_definitions(-DS390_CRC32_VX)
                set(CRC32_VX_SRCS ${ARCHDIR}/crc32-vx.c)
                list(APPEND ZLIB_ARCH_SRCS ${CRC32_VX_SRCS})
                set_property(SOURCE ${CRC32_VX_SRCS} PROPERTY COMPILE_FLAGS "${VGFMAFLAG} ${NOLTOFLAG}")
            else()
                set(WITH_CRC32_VX OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Doxygen Documentation Generation Setup
DESCRIPTION: Configures Doxygen documentation generation target with dependencies on JavaScript assets and other required files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_21

LANGUAGE: cmake
CODE:
```
add_custom_target(
    doxygen_cpp
    COMMAND ${DOXYGEN_EXECUTABLE} ${doxyfile}
    DEPENDS ${doxyfile} ${rootfile} ${bibfile} ${deps} ${js_tutorials_assets_deps}
    COMMENT "Generate Doxygen documentation"
  )
```

----------------------------------------

TITLE: Displaying OpenVINO and Inference Engine Status in OpenCV Build
DESCRIPTION: Complex conditional section that checks for OpenVINO or Inference Engine integration, displaying version information, library paths, and include directories when available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_24

LANGUAGE: cmake
CODE:
```
if(HAVE_OPENVINO
    OR (WITH_OPENVINO AND NOT WITH_INF_ENGINE AND NOT INF_ENGINE_TARGET)
)
  status("    OpenVINO:" TARGET openvino::runtime THEN "YES (${OpenVINO_VERSION})" ELSE "NO")
else()
  if(WITH_INF_ENGINE OR INF_ENGINE_TARGET)
    if(INF_ENGINE_TARGET)
      list(GET INF_ENGINE_TARGET 0 ie_target)
      set(__msg "YES (${INF_ENGINE_RELEASE} / ${INF_ENGINE_VERSION})")
      ocv_get_imported_target(ie_target "${ie_target}")
      get_target_property(_lib ${ie_target} IMPORTED_LOCATION)
      get_target_property(_lib_imp_rel ${ie_target} IMPORTED_IMPLIB_RELEASE)
      get_target_property(_lib_imp_dbg ${ie_target} IMPORTED_IMPLIB_DEBUG)
      get_target_property(_lib_rel ${ie_target} IMPORTED_LOCATION_RELEASE)
      get_target_property(_lib_dbg ${ie_target} IMPORTED_LOCATION_DEBUG)
      ocv_build_features_string(_lib
        IF _lib THEN "${_lib}"
        IF _lib_imp_rel AND _lib_imp_dbg THEN "${_lib_imp_rel} / ${_lib_imp_dbg}"
        IF _lib_rel AND _lib_dbg THEN "${_lib_rel} / ${_lib_dbg}"
        IF _lib_rel  THEN "${_lib_rel}"
        IF _lib_dbg  THEN "${_lib_dbg}"
        ELSE "unknown"
      )
      get_target_property(_inc ${ie_target} INTERFACE_INCLUDE_DIRECTORIES)
      status("    Inference Engine:" "${__msg}")
      status("        * libs:" "${_lib}")
      status("        * includes:" "${_inc}")
    else()
      status("    Inference Engine:"     "NO")
    endif()
  endif()
  if(WITH_NGRAPH OR HAVE_NGRAPH)
    if(HAVE_NGRAPH)
      ocv_get_imported_target(__target ngraph::ngraph)
      set(__msg "YES (${ngraph_VERSION})")
      get_target_property(_lib ${__target} IMPORTED_LOCATION)
      get_target_property(_lib_imp_rel ${__target} IMPORTED_IMPLIB_RELEASE)
      get_target_property(_lib_imp_dbg ${__target} IMPORTED_IMPLIB_DEBUG)
      get_target_property(_lib_rel ${__target} IMPORTED_LOCATION_RELEASE)
      get_target_property(_lib_dbg ${__target} IMPORTED_LOCATION_DEBUG)
      ocv_build_features_string(_lib
        IF _lib THEN "${_lib}"
        IF _lib_imp_rel AND _lib_imp_dbg THEN "${_lib_imp_rel} / ${_lib_imp_dbg}"
        IF _lib_rel AND _lib_dbg THEN "${_lib_rel} / ${_lib_dbg}"
        IF _lib_rel  THEN "${_lib_rel}"
        IF _lib_dbg  THEN "${_lib_dbg}"
        ELSE "unknown"
      )
      get_target_property(_inc ${__target} INTERFACE_INCLUDE_DIRECTORIES)
      status("    nGraph:" "${__msg}")
      status("        * libs:" "${_lib}")
      status("        * includes:" "${_inc}")
    else()
      status("    nGraph:"     "NO")
    endif()
  endif()
endif()
```

----------------------------------------

TITLE: Location of Existing FastCV Libraries in eSDK Sysroot (Path)
DESCRIPTION: This file path points to the directory within the Qualcomm eSDK sysroot where pre-existing FastCV libraries are typically located. If the FastCV library is updated (e.g., downloaded or built by the OpenCV build process), the new libraries found in the build output directory should replace the ones in this location to ensure the target system uses the updated version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_6

LANGUAGE: text
CODE:
```
<ESDK_PATH>\qcom-wayland_sdk\tmp\sysroots\qcs6490-rb3gen2-vision-kit\usr\lib
```

----------------------------------------

TITLE: Applying Input Image Smoothing in libjpeg (C)
DESCRIPTION: A C integer field within the compression parameters structure (`cinfo`). If set to a non-zero value (1 to 100), the input image data is smoothed before compression. A value of 1 corresponds to minimal smoothing, while 100 represents maximum smoothing. The default value is zero, meaning no smoothing is applied.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_37

LANGUAGE: C
CODE:
```
int smoothing_factor
```

----------------------------------------

TITLE: Bitwise Operations with Vector Registers in C++
DESCRIPTION: Shows bitwise shift and AND operations on vector registers containing integer values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_5

LANGUAGE: C++
CODE:
```
v_int32 as;                              // {a1, ..., an}
v_int32 al = as << 2;                    // {a1 << 2, ..., an << 2}
v_int32 bl = as >> 2;                    // {a1 >> 2, ..., an >> 2}

v_int32 a, b;
v_int32 a_and_b = a & b;                 // {a1 & b1, ..., an & bn}
```

----------------------------------------

TITLE: Tonemapping HDR Image using OpenCV Python
DESCRIPTION: Maps a 32-bit float HDR image to the range [0..1] using a gamma value. This requires clipping out-of-bound values to prevent overflow when processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_hdr/py_hdr.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
# Tonemap HDR image
tonemap1 = cv.createTonemap(gamma=2.2)
res_debevec = tonemap1.process(hdr_debevec.copy())
```

----------------------------------------

TITLE: Accessing Image Data Type using OpenCV in Python
DESCRIPTION: Demonstrates how to retrieve the data type of the image elements (e.g., `uint8` for standard 8-bit images) using the `img.dtype` attribute. Checking the `dtype` is crucial for debugging as many OpenCV-Python errors stem from invalid data types.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.markdown#2025-04-22_snippet_5

LANGUAGE: python
CODE:
```
>>> print( img.dtype )
uint8
```

----------------------------------------

TITLE: Android GLSurfaceView Implementation for Camera Preview
DESCRIPTION: Java code for GLSurfaceView implementation including surface callbacks and camera handling. This class handles the camera preview rendering using OpenGL ES.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
    @Override
    public void onSurfaceChanged(GL10 gl, int surfaceWidth, int surfaceHeight) {
        Log.i(LOGTAG, "onSurfaceChanged("+surfaceWidth+"x"+surfaceHeight+")");
        NativeGLRenderer.changeSize(surfaceWidth, surfaceHeight);
        setCameraPreviewSize(surfaceWidth, surfaceHeight);
    }

    @Override
    public void onSurfaceCreated(GL10 gl, EGLConfig config) {
        Log.i(LOGTAG, "onSurfaceCreated");
        String strGLVersion = GLES20.glGetString(GLES20.GL_VERSION);
        if (strGLVersion != null)
            Log.i(LOGTAG, "OpenGL ES version: " + strGLVersion);

        int hTex = NativeGLRenderer.initGL();
        mSTex = new SurfaceTexture(hTex);
        mSTex.setOnFrameAvailableListener(this);
        openCamera();
        mGLInit = true;
    }
```

----------------------------------------

TITLE: Generating SSD MobileNetV1 Text Graph (.pbtxt) with Script - Console
DESCRIPTION: Executes the 'tf_text_graph_ssd.py' script to create a .pbtxt text graph from the TensorFlow frozen graph and the model config. Essential for enabling OpenCV to interpret TensorFlow SSD detection models. Accepts input, config, and output paths as parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_5

LANGUAGE: console
CODE:
```
python tf_text_graph_ssd.py --input ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb --config ssd_mobilenet_v1_coco_2017_11_17/ssd_mobilenet_v1_coco.config --output ssd_mobilenet_v1_coco_2017_11_17.pbtxt
```

----------------------------------------

TITLE: Displaying 32F Image by Conversion to 8U for imshow with OpenCV in Java
DESCRIPTION: In Java OpenCV, converts a float Mat to 8-bit before display, using convertTo. Native imshow not available; display via workaround. Automatic scaling may be required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_44

LANGUAGE: Java
CODE:
```
Mat img8u = new Mat();\nimg.convertTo(img8u, CvType.CV_8U, 255.0);\n// display img8u using Java GUI or save to file
```

----------------------------------------

TITLE: Output Shape Computation for Custom Layer OpenCV C++
DESCRIPTION: Determine output blob shapes based on input forms, allowing additional memory requests using \'internals\'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp MyLayer::getMemoryShapes
```

----------------------------------------

TITLE: Getting Back Projection in Java with OpenCV
DESCRIPTION: This snippet demonstrates how to calculate the back projection of an image using OpenCV in Java. It uses the calcBackProject method with previously calculated histogram and image data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_3

LANGUAGE: Java
CODE:
```
Imgproc.calcBackProject(Arrays.asList(hue), channels, hist, backproj, ranges, 1);
```

----------------------------------------

TITLE: Custom Operation for Converting Face Detection to ROI Array
DESCRIPTION: Declaration of a custom G-API operation that processes the face detection network output into an array of face rectangles (ROIs).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
// ROI type definition
using Contour = std::vector<cv::Point>;

// Custom operation to parse SSD detection results
G_API_OP(ParseSSD, <cv::GArray<cv::Rect>(cv::GMat, cv::Size, float, bool)>, "custom.fd_postproc") {
    static cv::GArrayDesc outMeta(const cv::GMatDesc&, const cv::Size&, float, bool) {
        return cv::empty_array_desc();
    }
};
```

----------------------------------------

TITLE: TensorFlow Frozen Graph Reading
DESCRIPTION: Demonstrates loading a TensorFlow frozen model graph into a tf.Graph object which can then be used for inference. It requires the TensorFlow library and an available graph file. Inputs include the path to the frozen graph file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
# init deeplab model graph
model_graph = tf.Graph()

# obtain
with tf.io.gfile.GFile(frozen_graph_path, 'rb') as graph_file:
    tf_model_graph = GraphDef()
tf_model_graph.ParseFromString(graph_file.read())

with model_graph.as_default():
    tf.import_graph_def(tf_model_graph, name='')
```

----------------------------------------

TITLE: Generating Non-Linearly Separable Training Data for SVM (C++)
DESCRIPTION: Creates overlapping training data that is non-linearly separable by introducing random points that cross class boundaries. This second part of the dataset demonstrates the need for non-linear SVM techniques.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/non_linear_svms.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
// Set up the non-linearly separable part of the training data
float FRAC_LINEAR_SEP = 0.9f; // Fraction of the training samples which will be linearly separable
int trainingSamplesToAdd = 2 * NTRAINING_SAMPLES * (1 - FRAC_LINEAR_SEP);
Mat extraTrainData(trainingSamplesToAdd, 2, CV_32FC1);
Mat extraTrainLabels(trainingSamplesToAdd, 1, CV_32SC1);
RNG rng2(100);

// Generate extra non-linearly separable points
for(int i = 0; i < trainingSamplesToAdd; i++)
{
    int clsIdx = i % 2;
    float x = rng2.uniform(0.0f, 1.0f);
    float y = rng2.uniform(0.0f, 1.0f);
    extraTrainData.at<float>(i, 0) = x;
    extraTrainData.at<float>(i, 1) = y;
    extraTrainLabels.at<int>(i, 0) = labels[clsIdx];
}

// Merge all the training data
Mat completeTrainData;
vconcat(trainData, extraTrainData, completeTrainData);
Mat completeTrainLabels;
vconcat(trainLabels, extraTrainLabels, completeTrainLabels);
```

----------------------------------------

TITLE: Configuring DNN Module Build and Tests
DESCRIPTION: Main CMake configuration for OpenCV DNN module including source compilation, test configuration, and optional backend support. Sets up module sources, dependencies, and testing parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_24

LANGUAGE: cmake
CODE:
```
ocv_append_source_file_compile_definitions("${CMAKE_CURRENT_LIST_DIR}/src/dnn_params.cpp" "OPENCV_DNN_BACKEND_DEFAULT=${OPENCV_DNN_BACKEND_DEFAULT}")

ocv_install_used_external_targets(${libs} ${dnn_runtime_libs})

ocv_glob_module_sources(${sources_options} SOURCES ${fw_srcs} ${webnn_srcs})
ocv_create_module(${libs} ${dnn_runtime_libs})
ocv_add_samples()
ocv_add_accuracy_tests(${dnn_runtime_libs})

if(NOT BUILD_PROTOBUF)
  if(TARGET opencv_test_dnn)
    ocv_target_compile_definitions(opencv_test_dnn PRIVATE "OPENCV_DNN_EXTERNAL_PROTOBUF=1")
  endif()
endif()

set(perf_path "${CMAKE_CURRENT_LIST_DIR}/perf")
file(GLOB_RECURSE perf_srcs "${perf_path}/*.cpp")
file(GLOB_RECURSE perf_hdrs "${perf_path}/*.hpp" "${perf_path}/*.h")
ocv_add_perf_tests(${dnn_runtime_libs}
    FILES test_common "${CMAKE_CURRENT_LIST_DIR}/test/test_common.hpp" "${CMAKE_CURRENT_LIST_DIR}/test/test_common.impl.hpp"
    FILES Src ${perf_srcs}
    FILES Include ${perf_hdrs}
)

ocv_option(OPENCV_DNN_PERF_CAFFE "Add performance tests of Caffe framework" OFF)
ocv_option(OPENCV_DNN_PERF_CLCAFFE "Add performance tests of clCaffe framework" OFF)
if(BUILD_PERF_TESTS)
  if (OPENCV_DNN_PERF_CAFFE
      OR ${the_module}_PERF_CAFFE  # compatibility for deprecated option
  )
    find_package(Caffe QUIET)
    if (Caffe_FOUND)
      ocv_target_compile_definitions(opencv_perf_dnn PRIVATE "HAVE_CAFFE=1")
      ocv_target_link_libraries(opencv_perf_dnn caffe)
    endif()
  elseif(OPENCV_DNN_PERF_CLCAFFE
         OR ${the_module}_PERF_CAFFE  # compatibility for deprecated option
  )
    find_package(Caffe QUIET)
    if (Caffe_FOUND)
      ocv_target_compile_definitions(opencv_perf_dnn PRIVATE "HAVE_CLCAFFE=1")
      ocv_target_link_libraries(opencv_perf_dnn caffe)
    endif()
  endif()
endif()

if(DNN_ENABLE_PLUGINS)
  ocv_target_compile_definitions(${the_module} PRIVATE ENABLE_PLUGINS)
  if(TARGET opencv_test_dnn)
    ocv_target_compile_definitions(opencv_test_dnn PRIVATE ENABLE_PLUGINS)
  endif()
  if(OPENCV_DEBUG_POSTFIX)
    ocv_append_source_file_compile_definitions("${CMAKE_CURRENT_LIST_DIR}/src/backend.cpp" "DEBUG_POSTFIX=${OPENCV_DEBUG_POSTFIX}")
  endif()
endif()

ocv_option(OPENCV_TEST_DNN_OPENVINO "Build test with OpenVINO code" (TARGET ocv.3rdparty.openvino))
if(TARGET ocv.3rdparty.openvino AND OPENCV_TEST_DNN_OPENVINO)
  if(TARGET opencv_test_dnn)
    ocv_target_link_libraries(opencv_test_dnn ocv.3rdparty.openvino)
  endif()
endif()

ocv_option(OPENCV_TEST_DNN_CANN "Build test with CANN" (TARGET ocv.3rdparty.cann))
if(TARGET ocv.3rdparty.cann AND OPENCV_TEST_DNN_CANN)
  if(TARGET opencv_test_dnn)
    ocv_target_link_libraries(opencv_test_dnn ocv.3rdparty.cann)
  endif()
endif()

ocv_option(OPENCV_TEST_DNN_TIMVX "Build test with TIM-VX" (HAVE_TIMVX))
if(OPENCV_TEST_DNN_TIMVX)
  if(TARGET opencv_test_dnn)
    ocv_target_compile_definitions(opencv_test_dnn PRIVATE "HAVE_TIMVX=1")
  endif()
endif()

ocv_option(OPENCV_TEST_DNN_TFLITE "Build test with TFLite" (OPENCV_DNN_TFLITE))
if(OPENCV_TEST_DNN_TFLITE)
  if(TARGET opencv_test_dnn)
    ocv_target_compile_definitions(opencv_test_dnn PRIVATE "OPENCV_TEST_DNN_TFLITE=1")
  endif()
  if(TARGET opencv_perf_dnn)
    ocv_target_compile_definitions(opencv_perf_dnn PRIVATE "OPENCV_TEST_DNN_TFLITE=1")
  endif()
endif()
```

----------------------------------------

TITLE: Configuring OpenCV Application Build with CMake
DESCRIPTION: This code snippet uses CMake commands to specify the source files and OpenCV modules required for building an application named \'opencv_createsamples\'. The \'file(GLOB SRCS *.cpp)\' command collects all C++ source files in the directory, and \'ocv_add_application\' links necessary OpenCV modules such as opencv_core, opencv_imgproc, opencv_objdetect, etc. Prerequisites include having CMake and OpenCV installed. Inputs include the source files, and outputs involve a configured build setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/createsamples/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
file(GLOB SRCS *.cpp)
ocv_add_application(opencv_createsamples
    MODULES opencv_core opencv_imgproc opencv_objdetect opencv_imgcodecs opencv_highgui opencv_calib3d opencv_features2d opencv_videoio
    SRCS ${SRCS})
```

----------------------------------------

TITLE: Handling Non-Existent Files in Python with OpenCV
DESCRIPTION: Shows how to handle attempts to read from non-existent files in Python using OpenCV, which initializes the data structure with default values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_20

LANGUAGE: python
CODE:
```
python/tutorial_code/core/file_input_output/file_input_output.py nonexist
```

----------------------------------------

TITLE: Terminating Custom Destination Manager in JPEG Library (C)
DESCRIPTION: Defines the `term_destination` function signature, a required method for a custom `jpeg_destination_mgr`. This function is called by `jpeg_finish_compress()` after all compressed data has been generated. Its responsibility is to flush any remaining data from the output buffer. The amount of data remaining can be determined from `next_output_byte` and the known buffer start/size, or by calculating `total_buffer_size - free_in_buffer`. This method is *not* called by `jpeg_abort()` or `jpeg_destroy()`; cleanup during aborts must be handled separately.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_52

LANGUAGE: c
CODE:
```
term_destination (j_compress_ptr cinfo)
```

----------------------------------------

TITLE: Configuring libspng CMake Project
DESCRIPTION: Core CMake configuration for building libspng library. Sets up project variables, includes directories, and defines source files. Configures the library with ZLIB dependency and appropriate compiler definitions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libspng/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
project(${SPNG_LIBRARY})

set(CURR_INCLUDE_DIR "${CMAKE_CURRENT_LIST_DIR}")
set_property(GLOBAL PROPERTY SPNG_INCLUDE_DIR ${CURR_INCLUDE_DIR})
ocv_include_directories(${ZLIB_INCLUDE_DIRS})

file(GLOB_RECURSE spng_headers RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "*.h")
file(GLOB_RECURSE spng_sources RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "*.c")

message(STATUS "libspng will be used as PNG codec")
```

----------------------------------------

TITLE: Building Qt for OpenCV
DESCRIPTION: Command to build Qt using nmake after configuration
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
nmake
```

----------------------------------------

TITLE: Defining Custom Build Target for Android Examples in CMake
DESCRIPTION: Creates a custom target named `opencv_android_examples`. This target acts as an aggregate or placeholder, likely used to group or trigger the build of all the included Android sample projects. It doesn't produce an output file itself but can depend on other targets defined within the subdirectories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
add_custom_target(opencv_android_examples)
```

----------------------------------------

TITLE: Creating the G-API Module Target and Linking Dependencies in CMake
DESCRIPTION: Finalizes the G-API module definition using `ocv_create_module()`, which creates the actual build target (library). It then links the created module target (`${the_module}`, typically `opencv_gapi`) against its essential private dependency 'ade'. It conditionally links against the OpenVINO target (`ocv.3rdparty.openvino`) if available and enabled via `OPENCV_GAPI_WITH_OPENVINO`, and against TBB (`tbb`) if `HAVE_TBB` is true.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: cmake
CODE:
```
ocv_create_module()

ocv_target_link_libraries(${the_module} PRIVATE ade)

if(TARGET ocv.3rdparty.openvino AND OPENCV_GAPI_WITH_OPENVINO)
  ocv_target_link_libraries(${the_module} PRIVATE ocv.3rdparty.openvino)
  ocv_install_used_external_targets(ocv.3rdparty.openvino)
endif()

if(HAVE_TBB)
  ocv_target_link_libraries(${the_module} PRIVATE tbb)
endif()
```

----------------------------------------

TITLE: Executing PaddleSeg Portrait Segmentation Demo Script (Shell)
DESCRIPTION: Runs the Python script `paddle_humanseg.py`. This script loads the previously converted ONNX model (`humanseg_hrnet18_tiny.onnx`) using `cv2.dnn.readNetFromONNX`, preprocesses an input image, performs inference for segmentation, postprocesses the output, and saves the visualized result.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/dnn_model_runner/dnn_conversion/paddlepaddle/README.md#2025-04-22_snippet_4

LANGUAGE: shell
CODE:
```
python paddle_humanseg.py
```

----------------------------------------

TITLE: Including Common Python Configuration in CMake
DESCRIPTION: Includes a shared CMake file (common.cmake) with common configuration settings for Python bindings. After including the shared configuration, it unsets module-specific variables to avoid affecting other modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/python3/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
include(../common.cmake)

unset(MODULE_NAME)
unset(MODULE_INSTALL_SUBDIR)
```

----------------------------------------

TITLE: Configuring KleidiCV HAL Build Settings
DESCRIPTION: Sets up the KleidiCV HAL project with specific compiler options and includes required dependencies. Handles SME2 option configuration and suppresses specific compiler warnings for unused functions and old-style casts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/kleidicv/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
project(kleidicv_hal)

if(HAVE_KLEIDICV)
  option(KLEIDICV_ENABLE_SME2 "" OFF) # not compatible with some CLang versions in NDK
  include("${KLEIDICV_SOURCE_PATH}/adapters/opencv/CMakeLists.txt")
  # HACK to suppress adapters/opencv/kleidicv_hal.cpp:343:12: warning: unused function 'from_opencv' [-Wunused-function]
  target_compile_options( kleidicv_hal PRIVATE
      $<TARGET_PROPERTY:kleidicv,COMPILE_OPTIONS>
      "-Wno-old-style-cast" "-Wno-unused-function"
  )
endif()
```

----------------------------------------

TITLE: Drawing a Line in Python
DESCRIPTION: Implementation of the MyLine function that draws a line between two points in OpenCV Python. The function takes the image, start and end points, and uses the line() function with specified color, thickness, and line type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_17

LANGUAGE: python
CODE:
```
def MyLine(img, start, end):
    thickness = 2
    lineType = cv.LINE_8

    cv.line(img,
             start,
             end,
             (0, 0, 0),
             thickness,
             lineType)
```

----------------------------------------

TITLE: Initializing Variables for JavaScript Tutorial Assets in CMake
DESCRIPTION: Sets CMake variables defining the target HTML directory for Doxygen output (`opencv_tutorial_html_dir`), the source directory containing JavaScript tutorial assets (`js_tutorials_assets_dir`), and initializes an empty list for potential dependencies (`js_tutorials_assets_deps`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_16

LANGUAGE: cmake
CODE:
```
# js tutorial assets
set(opencv_tutorial_html_dir "${CMAKE_CURRENT_BINARY_DIR}/doxygen/html")
set(js_tutorials_assets_dir "${CMAKE_CURRENT_SOURCE_DIR}/js_tutorials/js_assets")
set(js_tutorials_assets_deps "")
```

----------------------------------------

TITLE: Installation Paths Configuration for OpenNI and PrimeSensor
DESCRIPTION: Default installation paths for OpenNI libraries and PrimeSensor Module on different operating systems.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/kinect_openni.markdown#2025-04-22_snippet_0

LANGUAGE: text
CODE:
```
OpenNI:
    Linux & MacOSX:
        Libs into: /usr/lib
        Includes into: /usr/include/ni
    Windows:
        Libs into: c:/Program Files/OpenNI/Lib
        Includes into: c:/Program Files/OpenNI/Include
PrimeSensor Module:
    Linux & MacOSX:
        Bins into: /usr/bin
    Windows:
        Bins into: c:/Program Files/Prime Sense/Sensor/Bin
```

----------------------------------------

TITLE: Installing DNN Sample Source Files in CMake
DESCRIPTION: Installs DNN example source files including CPP, HPP, and CMakeLists files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
ocv_install_example_src(dnn *.cpp *.hpp CMakeLists.txt)
```

----------------------------------------

TITLE: FAST Corner Detection Homogeneous Pattern Checking in C++
DESCRIPTION: Implementation of the homogeneous pattern checking portion of the FAST corner detection algorithm. The code uses nested conditionals to compare pixel values at various offsets against a threshold to determine if a pixel is a corner point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
else
  goto homogeneous;
else
  goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset5] < c_b)
    if(ptr[offset9] < c_b)
      if(ptr[offset6] < c_b)
        if(ptr[offset7] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset8] < c_b)
                goto success_homogeneous;
              else
                if(ptr[offset1] < c_b)
                  if(ptr[offset2] < c_b)
                    goto success_homogeneous;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset11] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          goto homogeneous;
      else
        goto homogeneous;
    else
      if(ptr[offset2] < c_b)
        if(ptr[offset3] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset7] < c_b)
              if(ptr[offset1] < c_b)
                if(ptr[offset6] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset8] < c_b)
                    goto success_homogeneous;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
      else
        goto homogeneous;
  else
    goto homogeneous;
}
}
```

----------------------------------------

TITLE: Defining Required Dependencies for CUDA Samples in CMake
DESCRIPTION: Sets a CMake variable `OPENCV_CUDA_SAMPLES_REQUIRED_DEPS` containing a list of OpenCV modules required to build the CUDA samples. This variable is used later for dependency checking and linking.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
set(OPENCV_CUDA_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_flann
  opencv_imgproc
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui
  opencv_ml
  opencv_video
  opencv_objdetect
  opencv_features2d
  opencv_calib3d
  opencv_superres
  opencv_cudaarithm
  opencv_cudafilters
  opencv_cudawarping
  opencv_cudaimgproc
  opencv_cudafeatures2d
  opencv_cudaoptflow
  opencv_cudabgsegm
  opencv_cudastereo
  opencv_cudaobjdetect)
```

----------------------------------------

TITLE: Installing Third-party Licenses in CMake
DESCRIPTION: This snippet installs third-party licenses associated with the module. It specifically mentions the MSCR component and its corresponding license file path. This ensures compliance with third-party software licenses in the OpenCV project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
ocv_install_3rdparty_licenses(mscr \"${CMAKE_CURRENT_SOURCE_DIR}/3rdparty/mscr/chi_table_LICENSE.txt\")
```

----------------------------------------

TITLE: Installing Build Tools and Cross-Compilers (Bash)
DESCRIPTION: Updates the package list and installs essential packages required for building software and cross-compiling. This includes `git`, `cmake`, `pkgconf`, `build-essential`, the optional `ninja-build` for faster compilation, and toolchains for armhf (ARMv7) and arm64 (AArch64) targets.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
sudo apt update -y
sudo apt install -y \
    git \
    cmake \
    pkgconf \
    build-essential \
    ninja-build \
    crossbuild-essential-armhf \
    crossbuild-essential-arm64
```

----------------------------------------

TITLE: Configuring Windows RT Features in CMake for OpenCV
DESCRIPTION: This snippet handles Windows RT-specific configurations for OpenCV. It checks for Windows RT support and reports relevant information about the build environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_20

LANGUAGE: CMake
CODE:
```
if(WIN32)
status("")
status("  Windows RT support:" WINRT THEN YES ELSE NO)
  if(WINRT)
    status("    Building for Microsoft platform: " ${CMAKE_SYSTEM_NAME})
    status("    Building for architectures: " ${CMAKE_VS_EFFECTIVE_PLATFORMS})
    status("    Building for version: " ${CMAKE_SYSTEM_VERSION})
    if (DEFINED ENABLE_WINRT_MODE_NATIVE)
      status("    Building for C++ without CX extensions")
    endif()
  endif()
endif(WIN32)
```

----------------------------------------

TITLE: Adjusting Compiler Flags for TBB Compatibility
DESCRIPTION: Filters out compiler flags that are not handled properly by the TBB code. Removes visibility settings and certain warning flags that could cause build issues.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: CMake
CODE:
```
# filter out flags that are not handled well by the TBB code
foreach(var CMAKE_CXX_FLAGS CMAKE_CXX_FLAGS_RELEASE CMAKE_CXX_FLAGS_DEBUG)
  string(REPLACE "-Werror=non-virtual-dtor" "" ${var} "${${var}}")
  string(REPLACE "-fvisibility=hidden" "" ${var} "${${var}}")
  string(REPLACE "-fvisibility-inlines-hidden" "" ${var} "${${var}}")
endforeach()
```

----------------------------------------

TITLE: Corner Detection Conditional Logic in C++
DESCRIPTION: Implements pixel intensity comparison logic for corner detection using multiple offsets. The code evaluates various pixel positions relative to a central point to determine if the location qualifies as a corner based on intensity thresholds cb and c_b.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_34

LANGUAGE: c++
CODE:
```
if(ptr[offset6] > cb)
  if(ptr[offset3] < c_b)
    if(ptr[offset4] < c_b)
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset6] < c_b)
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
```

----------------------------------------

TITLE: Adding Toggle Buttons for Multi-Language Examples - Doxygen Toggle Markup
DESCRIPTION: Shows the pattern for adding toggle buttons in doxygen-based documentation for displaying alternative code or text blocks (e.g., for C++, Java, Python). Inputs are labeled toggle blocks wrapping content; outputs are tabbed interface in rendered documentation. No dependencies beyond doxygen configuration. Key parameters include button type/name.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_13

LANGUAGE: markdown
CODE:
```
@add_toggle{Button Name}

  text / code / doxygen commands

@end_toggle
```

----------------------------------------

TITLE: Defining a Typed Kernel Interface with G_TYPED_KERNEL (OpenCV G-API, C++)
DESCRIPTION: Declares a new G-API kernel interface using the G_TYPED_KERNEL macro, specifying the kernel name, function signature, and a string identifier. This macro generates a type for graph pipeline construction and facilitates future backend-specific implementations. Requires OpenCV G-API, and must include a definition of outMeta() to propagate metadata within the pipeline. Inputs and outputs are specified using G-API dynamic types and standard C++ types, as required by the macro signature.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/doc/20-kernel-api.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#define G_TYPED_KERNEL(KernelName, Signature, Id)
// Macro expands to kernel interface type declaration
// Usage example in doc:
G_TYPED_KERNEL(Filter2D, <cv::GMat(cv::GMat, cv::Mat, cv::Point)>, "org.opencv.filter2d");
// where
//   - Filter2D        : Kernel interface name
//   - cv::GMat        : Return type (G-API dynamic type)
//   - cv::GMat, ...   : Argument types
//   - "org.opencv.filter2d" : String ID for internal use
```

----------------------------------------

TITLE: Estimating Diamond Marker Pose as ChArUco Board (C++)
DESCRIPTION: This snippet highlights an alternative approach to pose estimation, treating the detected diamond marker as a small ChArUco board using OpenCV's routines. With the four corners and known square size, the diamond is processed as a mini board for pose computation. This approach makes use of the aruco/charuco pose estimation functions, leveraging existing ChArUco infrastructure. Requires OpenCV aruco & charuco modules, and accurate detection/calibration data. The output is the 3D pose of the diamond marker relative to the camera.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_diamond_detection/charuco_diamond_detection.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
// Pose estimation as ChArUco board
cv::Ptr<cv::aruco::CharucoBoard> diamondBoard = cv::aruco::CharucoBoard::create(/*specify board parameters*/);
cv::Vec3d rvec, tvec;
bool valid = cv::aruco::estimatePoseCharucoBoard(
    diamondCorners[0], // or proper detected corners
    diamondIds[0],
    diamondBoard,
    cameraMatrix,
    distCoeffs,
    rvec,
    tvec
);
if (valid) {
    cv::aruco::drawAxis(image, cameraMatrix, distCoeffs, rvec, tvec, squareLength * 0.5);
}
```

----------------------------------------

TITLE: Linking regex Library for QNX in OpenCV ts Module
DESCRIPTION: Checks for the availability of the regex library on QNX systems and links it to the ts module if found.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ts/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
if(CMAKE_SYSTEM_NAME STREQUAL "QNX")
  include(CheckLibraryExists)
  CHECK_LIBRARY_EXISTS(regex regexec "" HAVE_REGEX_LIBRARY)
  if(HAVE_REGEX_LIBRARY)
    ocv_target_link_libraries(${the_module} PUBLIC regex)
  endif()
endif()
```

----------------------------------------

TITLE: Check Compiler Support for Built-in Functions in CMake
DESCRIPTION: These code snippets test whether the compiler supports various __builtin functions like __builtin_ctz and __builtin_assume_aligned. When available, these are defined as macros for further use during optimized code generation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: CMake
CODE:
```
#
# Check for __attribute__((aligned(x))) support in the compiler
#
check_c_source_compiles(
    "int main(void) {
        __attribute__((aligned(8))) int test = 0;
        (void)test;
        return 0;
    }"
    HAVE_ATTRIBUTE_ALIGNED FAIL_REGEX "aligned")
if(HAVE_ATTRIBUTE_ALIGNED)
    add_definitions(-DHAVE_ATTRIBUTE_ALIGNED)
endif()

#
# Check for __builtin_assume_aligned(x,n) support in the compiler
#
check_c_source_compiles(
    "char *test(char *buffer) {
        char *abuffer = __builtin_assume_aligned(buffer,64);
        return abuffer;
    }
    int main() {
        return 0;
    }"
    HAVE_BUILTIN_ASSUME_ALIGNED)
if(HAVE_BUILTIN_ASSUME_ALIGNED)
    add_definitions(-DHAVE_BUILTIN_ASSUME_ALIGNED)
endif()

#
# check for __builtin_ctz() support in the compiler
#
check_c_source_compiles(
    "int main(void) {
        unsigned int zero = 0;
        long test = __builtin_ctz(zero);
        (void)test;
        return 0;
    }"
    HAVE_BUILTIN_CTZ
)
if(HAVE_BUILTIN_CTZ)
    add_definitions(-DHAVE_BUILTIN_CTZ)
endif()

#
# check for __builtin_ctzll() support in the compiler
#
check_c_source_compiles(
    "int main(void) {
        unsigned int zero = 0;
        long test = __builtin_ctzll(zero);
        (void)test;
        return 0;
    }"
    HAVE_BUILTIN_CTZLL
)
if(HAVE_BUILTIN_CTZLL)
    add_definitions(-DHAVE_BUILTIN_CTZLL)
endif()
```

----------------------------------------

TITLE: Including Common CMake Configuration File
DESCRIPTION: This line includes another CMake file named `common.cmake` located in the same directory as the current `CMakeLists.txt` file (`CMAKE_CURRENT_SOURCE_DIR`). This is used to import shared settings, functions, or macros common to different parts of the Java module build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
include(${CMAKE_CURRENT_SOURCE_DIR}/common.cmake)
```

----------------------------------------

TITLE: Installing Media and GUI Dependencies
DESCRIPTION: Commands to install dependencies for GUI features, camera support, and media handling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev
sudo apt-get install libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev
```

----------------------------------------

TITLE: Loading a Fixed Quantization Table in C using libjpeg
DESCRIPTION: Demonstrates how to load a predefined quantization table into a specific slot (`n`) within the libjpeg decompression context (`cinfo`). It allocates memory for the table if necessary using `jpeg_alloc_quant_table` and then copies the 64 quantization values from a source array (`Qtable`) into the `quantval` member of the `JQUANT_TBL` structure. This is typically used when preparing to decode an abbreviated JPEG image that relies on external tables.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_59

LANGUAGE: c
CODE:
```
if (cinfo.quant_tbl_ptrs[n] == NULL)
  cinfo.quant_tbl_ptrs[n] = jpeg_alloc_quant_table((j_common_ptr) &cinfo);
quant_ptr = cinfo.quant_tbl_ptrs[n];        /* quant_ptr is JQUANT_TBL* */
for (i = 0; i < 64; i++) {
  /* Qtable[] is desired quantization table, in natural array order */
  quant_ptr->quantval[i] = Qtable[i];
}
```

----------------------------------------

TITLE: Finding Highgui External Header Files using Glob in CMake
DESCRIPTION: Uses the `file(GLOB ...)` command to find all files matching the patterns `*.hpp` and `*.h` within specific include directories related to the highgui module (`include/opencv2/`, `include/opencv2/${name}/`). The results are stored in the `highgui_ext_hdrs` variable, likely used for installation or packaging.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: cmake
CODE:
```
file(GLOB highgui_ext_hdrs
     "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/*.hpp"
     "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/*.hpp"
     "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/*.h")
```

----------------------------------------

TITLE: Initializing Matrix for Blurred Image with OpenCV in Clojure
DESCRIPTION: Creates a new Mat object with the same dimensions and element type as the original image. This will hold the result after applying image processing functions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_23

LANGUAGE: Clojure
CODE:
```
user=> (def blurred (Mat. 512 512 CvType/CV_8UC3))
#'user/blurred
user=>
```

----------------------------------------

TITLE: Configuring x86 SSSE3 Optimizations for ZLIB in CMake
DESCRIPTION: Checks if SSSE3 optimization is enabled (WITH_SSSE3), if intrinsics are available (HAVE_SSSE3_INTRIN), and if SSE2 is also enabled. If all conditions are met, it adds the DX86_SSSE3 definition, appends SSSE3-specific source files (for adler32 and chunkset) to ZLIB_ARCH_SRCS, adds feature information, and sets specific compile flags (SSSE3FLAG, NOLTOFLAG) for these files. Otherwise, it disables SSSE3 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_27

LANGUAGE: cmake
CODE:
```
        if(WITH_SSSE3)
            check_ssse3_intrinsics()
            if(HAVE_SSSE3_INTRIN AND WITH_SSE2)
                add_definitions(-DX86_SSSE3)
                set(SSSE3_SRCS ${ARCHDIR}/adler32_ssse3.c ${ARCHDIR}/chunkset_ssse3.c)
                add_feature_info(SSSE3_ADLER32 1 "Support SSSE3-accelerated adler32, using \"${SSSE3FLAG}\"")
                list(APPEND ZLIB_ARCH_SRCS ${SSSE3_SRCS})
                set_property(SOURCE ${SSSE3_SRCS} PROPERTY COMPILE_FLAGS "${SSSE3FLAG} ${NOLTOFLAG}")
            else()
                set(WITH_SSSE3 OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Helper Function for File Existence Checking
DESCRIPTION: Implements a utility function that appends files to a list only if they exist on the filesystem. Provides warnings for missing files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/protobuf/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
function(append_if_exist OUTPUT_LIST)
    set(${OUTPUT_LIST})
    foreach(fil ${ARGN})
        if(EXISTS ${fil})
            list(APPEND ${OUTPUT_LIST} "${fil}")
        else()
            message(WARNING "file missing: ${fil}")
        endif()
    endforeach()
    set(${OUTPUT_LIST} ${${OUTPUT_LIST}} PARENT_SCOPE)
endfunction()
```

----------------------------------------

TITLE: Including Sample Utilities for Standalone Build in CMake
DESCRIPTION: Includes the `samples_utils.cmake` file within the standalone build context. This script might contain different logic or rely on the found OpenCV package compared to the version used during the integrated build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
include("${CMAKE_CURRENT_LIST_DIR}/samples_utils.cmake")
```

----------------------------------------

TITLE: Conditional Configuration of Python Modules in OpenCV
DESCRIPTION: This CMake script configures the Python support modules during the OpenCV build process. It checks for specific conditions such as the build being for Android or a particular framework and accordingly enables or disables Python 2 and 3 modules. The script requires CMake version 3.5 or higher and manages dependencies by including directories for bindings and tests.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
# ----------------------------------------------------------------------------
#  CMake file for python support
# ----------------------------------------------------------------------------
if(DEFINED OPENCV_INITIAL_PASS)  # OpenCV build

if(ANDROID OR APPLE_FRAMEWORK OR WINRT)
  ocv_module_disable_(python2)
  ocv_module_disable_(python3)
  return()
elseif(BUILD_opencv_world OR (WIN32 AND CMAKE_BUILD_TYPE STREQUAL "Debug"))
  if(NOT DEFINED BUILD_opencv_python2)
    set(__disable_python2 ON)
  endif()
  if(NOT DEFINED BUILD_opencv_python3)
    set(__disable_python3 ON)
  endif()
endif()

add_subdirectory(bindings)

add_subdirectory(test)

if(__disable_python2)
  ocv_module_disable_(python2)
endif()
if(__disable_python3)
  ocv_module_disable_(python3)
endif()
if(__disable_python2 AND __disable_python3)
  return()
endif()

add_subdirectory(python2)
add_subdirectory(python3)

else()  # standalone build

cmake_minimum_required(VERSION 3.5)
project(OpenCVPython CXX C)
include("./standalone.cmake")

endif()
```

----------------------------------------

TITLE: Setting Up Carotene CMake Project
DESCRIPTION: Initializes the CMake project for Carotene and configures basic project variables and directories. Sets up namespace configuration and includes required directories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/carotene/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION ${MIN_VER_CMAKE} FATAL_ERROR)

project(Carotene)

set(CAROTENE_NS "carotene" CACHE STRING "Namespace for Carotene definitions")

set(CAROTENE_INCLUDE_DIR include)
set(CAROTENE_SOURCE_DIR src)

file(GLOB_RECURSE carotene_headers RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "${CAROTENE_INCLUDE_DIR}/*.hpp")
file(GLOB_RECURSE carotene_sources RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "${CAROTENE_SOURCE_DIR}/*.cpp"
                                                                        "${CAROTENE_SOURCE_DIR}/*.hpp")

include_directories(${CAROTENE_INCLUDE_DIR})
```

----------------------------------------

TITLE: Testing Python 3 OpenCV Wrapper
DESCRIPTION: Run a Python script to check if the OpenCV Python 3 wrapper is correctly installed by printing OpenCV's build information.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_28

LANGUAGE: bash
CODE:
```
python3 -c "import cv2; print(cv2.getBuildInformation())"
```

----------------------------------------

TITLE: Pixel Corner Detection Logic in C++
DESCRIPTION: Complex nested conditional logic for determining if a pixel represents a corner by comparing intensity values with neighboring pixels using pointer arithmetic. The code uses goto statements to branch between 'is_a_corner' and 'is_not_a_corner' labels based on multiple threshold comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_35

LANGUAGE: C++
CODE:
```
                                    goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                else
                  if(ptr[offset7] > cb)
                    if(ptr[offset9] < c_b)
                      goto is_not_a_corner;
                    else
                      if(ptr[offset9] > cb)
                        if(ptr[offset1] > cb)
                          if(ptr[offset6] < c_b)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset8] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset3] > cb)
                                    goto is_a_corner;
                                  else
                                    if(ptr[offset10] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset1] < c_b)
                            if(ptr[offset6] < c_b)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset8] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset3] > cb)
                                      goto is_a_corner;
                                    else
                                      if(ptr[offset10] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                  else
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset6] < c_b)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset8] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset3] > cb)
                                      goto is_a_corner;
                                    else
                                      if(ptr[offset10] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                  else
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset9] < c_b)
                      if(ptr[offset7] < c_b)
                        if(ptr[offset1] > cb)
                          if(ptr[offset6] > cb)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] < c_b)
                              if(ptr[offset8] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset1] < c_b)
                            if(ptr[offset6] > cb)
                              if(ptr[offset8] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset8] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                if(ptr[offset8] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] < c_b)
                                if(ptr[offset8] < c_b)
                                  if(ptr[offset10] < c_b)
                                    if(ptr[offset11] < c_b)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
            else
              if(ptr[offset2] > cb)
                if(ptr[offset7] < c_b)
                  if(ptr[offset9] > cb)
                    goto is_not_a_corner;
                  else
                    if(ptr[offset9] < c_b)
                      if(ptr[offset1] > cb)
                        if(ptr[offset6] > cb)
                          goto is_not_a_corner;
                        else
                          if(ptr[offset6] < c_b)
                            if(ptr[offset8] < c_b)
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset1] < c_b)
                          if(ptr[offset6] > cb)
                            if(ptr[offset8] < c_b)
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            if(ptr[offset6] < c_b)
                              if(ptr[offset8] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto is_a_corner;
```

----------------------------------------

TITLE: Compiler Optimization Flags Configuration
DESCRIPTION: Sets up various compiler optimization flags based on the platform and compiler version, particularly for GCC and Clang.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/carotene/hal/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(CV_GCC OR CV_CLANG)
  if(X86 OR ARMEABI_V6 OR (MIPS AND ANDROID_COMPILER_VERSION VERSION_LESS "4.6"))
    list(APPEND TEGRA_COMPILER_FLAGS -fweb -fwrapv -frename-registers -fsched-stalled-insns-dep=100 -fsched-stalled-insns=2)
  elseif(CV_CLANG)
    list(APPEND TEGRA_COMPILER_FLAGS -fwrapv)
  else()
    list(APPEND TEGRA_COMPILER_FLAGS -fweb -fwrapv -frename-registers -fsched2-use-superblocks -fsched2-use-traces
                                     -fsched-stalled-insns-dep=100 -fsched-stalled-insns=2)
  endif()
```

----------------------------------------

TITLE: Configuring OpenCV Build Options in CMake
DESCRIPTION: This snippet defines various CMake options for fine-tuning the OpenCV build process. It includes options for enabling ccache, precompiled headers, profiling, and other compiler-specific optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: CMake
CODE:
```
OCV_OPTION(ENABLE_CCACHE              "Use ccache"                                               (UNIX AND (CMAKE_GENERATOR MATCHES "Makefile" OR CMAKE_GENERATOR MATCHES "Ninja" OR CMAKE_GENERATOR MATCHES "Xcode")) )
OCV_OPTION(ENABLE_PRECOMPILED_HEADERS "Use precompiled headers"                                  MSVC IF (MSVC OR (NOT IOS AND NOT XROS AND NOT CMAKE_CROSSCOMPILING) ) )
OCV_OPTION(ENABLE_DELAYLOAD           "Enable delayed loading of OpenCV DLLs"                    OFF VISIBLE_IF MSVC AND BUILD_SHARED_LIBS)
OCV_OPTION(ENABLE_SOLUTION_FOLDERS    "Solution folder in Visual Studio or in other IDEs"        (MSVC_IDE OR CMAKE_GENERATOR MATCHES Xcode) )
OCV_OPTION(ENABLE_PROFILING           "Enable profiling in the GCC compiler (Add flags: -g -pg)" OFF  IF CV_GCC )
OCV_OPTION(ENABLE_COVERAGE            "Enable coverage collection with  GCov"                    OFF  IF CV_GCC )
OCV_OPTION(OPENCV_ENABLE_MEMORY_SANITIZER "Better support for memory/address sanitizers"         OFF)
OCV_OPTION(ENABLE_OMIT_FRAME_POINTER  "Enable -fomit-frame-pointer for GCC"                      ON   IF CV_GCC )
OCV_OPTION(ENABLE_POWERPC             "Enable PowerPC for GCC"                                   ON   IF (CV_GCC AND CMAKE_SYSTEM_PROCESSOR MATCHES powerpc.*) )
OCV_OPTION(ENABLE_FAST_MATH           "Enable compiler options for fast math optimizations on FP computations (not recommended)" OFF)
OCV_OPTION(ENABLE_NOISY_WARNINGS      "Show all warnings even if they are too noisy"             OFF )
OCV_OPTION(OPENCV_WARNINGS_ARE_ERRORS "Treat warnings as errors"                                 OFF )
OCV_OPTION(ANDROID_EXAMPLES_WITH_LIBS "Build binaries of Android examples with native libraries" OFF  IF ANDROID )
OCV_OPTION(ENABLE_IMPL_COLLECTION     "Collect implementation data on function call"             OFF )
OCV_OPTION(ENABLE_INSTRUMENTATION     "Instrument functions to collect calls trace and performance" OFF )
OCV_OPTION(ENABLE_GNU_STL_DEBUG       "Enable GNU STL Debug mode (defines _GLIBCXX_DEBUG)"       OFF IF CV_GCC )
OCV_OPTION(ENABLE_BUILD_HARDENING     "Enable hardening of the resulting binaries (against security attacks, detects memory corruption, etc)" OFF)
OCV_OPTION(ENABLE_LTO                 "Enable Link Time Optimization" OFF IF CV_GCC OR MSVC)
OCV_OPTION(ENABLE_THIN_LTO            "Enable Thin LTO" OFF IF CV_CLANG)
OCV_OPTION(GENERATE_ABI_DESCRIPTOR    "Generate XML file for abi_compliance_checker tool" OFF IF UNIX)
OCV_OPTION(OPENCV_GENERATE_PKGCONFIG  "Generate .pc file for pkg-config build tool (deprecated)" OFF)
OCV_OPTION(CV_ENABLE_INTRINSICS       "Use intrinsic-based optimized code" ON )
OCV_OPTION(CV_DISABLE_OPTIMIZATION    "Disable explicit optimized code (dispatched code/intrinsics/loop unrolling/etc)" OFF )
OCV_OPTION(CV_TRACE                   "Enable OpenCV code trace" ON)
OCV_OPTION(OPENCV_GENERATE_SETUPVARS  "Generate setup_vars* scripts" ON IF (NOT ANDROID AND NOT APPLE_FRAMEWORK) )
OCV_OPTION(ENABLE_CONFIG_VERIFICATION "Fail build if actual configuration doesn't match requested (WITH_XXX != HAVE_XXX)" OFF)
OCV_OPTION(OPENCV_ENABLE_MEMALIGN     "Enable posix_memalign or memalign usage" ON)
OCV_OPTION(OPENCV_DISABLE_FILESYSTEM_SUPPORT "Disable filesystem support" OFF)
OCV_OPTION(OPENCV_DISABLE_THREAD_SUPPORT "Build the library without multi-threaded code." OFF)
OCV_OPTION(OPENCV_DISABLE_ENV_SUPPORT "Disable environment variables access (getenv)" (CMAKE_SYSTEM_NAME MATCHES "Windows(CE|Phone|Store)"))
OCV_OPTION(OPENCV_SEMIHOSTING         "Build the library for semihosting target (Arm). See https://developer.arm.com/documentation/100863/latest." OFF)
OCV_OPTION(ENABLE_CUDA_FIRST_CLASS_LANGUAGE "Enable CUDA as a first class language, if enabled dependant projects will need to use CMake >= 3.18" OFF
  VISIBLE_IF (WITH_CUDA AND NOT CMAKE_VERSION VERSION_LESS 3.18)
  VERIFY HAVE_CUDA)

OCV_OPTION(ENABLE_PYLINT              "Add target with Pylint checks"                            (BUILD_DOCS OR BUILD_EXAMPLES) IF (NOT CMAKE_CROSSCOMPILING AND NOT APPLE_FRAMEWORK) )
OCV_OPTION(ENABLE_FLAKE8              "Add target with Python flake8 checker"                    (BUILD_DOCS OR BUILD_EXAMPLES) IF (NOT CMAKE_CROSSCOMPILING AND NOT APPLE_FRAMEWORK) )
```

----------------------------------------

TITLE: Disabling Python3 Module When Dependencies Are Missing in CMake
DESCRIPTION: Checks if required Python3 include path and NumPy include directories are available. If not, it disables the Python3 module from being built with OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/python3/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(NOT PYTHON3_INCLUDE_PATH OR NOT PYTHON3_NUMPY_INCLUDE_DIRS)
  ocv_module_disable(python3)
endif()
```

----------------------------------------

TITLE: Cloning OpenCV Repository
DESCRIPTION: Installs Git and clones the OpenCV repository from GitHub.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_6

LANGUAGE: shell
CODE:
```
yum install git
git clone https://github.com/opencv/opencv.git
```

----------------------------------------

TITLE: Building Docker Image for OpenCV.js Documentation - Bash
DESCRIPTION: This bash command builds a Docker image named "opencv-js-doc" from the local Dockerfile, which includes Doxygen and is based on emscripten/emsdk:2.0.10. Requires the Dockerfile present in the current directory. Produces a reusable Docker image for subsequent documentation builds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_28

LANGUAGE: bash
CODE:
```
docker build . -t opencv-js-doc
```

----------------------------------------

TITLE: Defining and Checking Required Dependencies for TAPI Samples - CMake
DESCRIPTION: Defines the required OpenCV modules for TAPI samples in a variable and then checks their availability using ocv_check_dependencies. Ensures each sample is only built if all required modules (like opencv_core, opencv_imgproc, etc.) are present. Key parameter is OPENCV_TAPI_SAMPLES_REQUIRED_DEPS, which must contain all module names needed for TAPI sample functionality.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/tapi/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(OPENCV_TAPI_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_video
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui
  opencv_objdetect
  opencv_features2d
  opencv_calib3d
  opencv_flann)
ocv_check_dependencies(${OPENCV_TAPI_SAMPLES_REQUIRED_DEPS})
```

----------------------------------------

TITLE: Setting OpenVX Directory and Including HAL Subdirectory in CMake
DESCRIPTION: This CMake code snippet executes if the preceding check determines that OpenVX is available (`HAVE_OPENVX` is true). It sets the CMake variable `OPENCV_3P_OPENVX_DIR` to the path of the current source directory (`CMAKE_CURRENT_SOURCE_DIR`). Then, it uses `add_subdirectory(hal)` to include the `hal` subdirectory, instructing CMake to process the `CMakeLists.txt` within that directory, which is necessary for building the OpenVX Hardware Abstraction Layer.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openvx/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
set(OPENCV_3P_OPENVX_DIR ${CMAKE_CURRENT_SOURCE_DIR})
add_subdirectory(hal)
```

----------------------------------------

TITLE: CMake Configuration Output for OpenCV Cross-Compilation
DESCRIPTION: This snippet shows the CMake configuration output for cross-compiling OpenCV. It confirms the host system as Linux x86_64, the target system as Linux arm, and shows that FFmpeg is available. The output also includes version information and enabled features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_30

LANGUAGE: cmake
CODE:
```
-- General configuration for OpenCV 4.8.0-dev =====================================
--   Version control:               408730b
--
--   Extra modules:
--     Location (extra):            /home/kmtr/work/opencv_contrib/modules
--     Version control (extra):     faa5468
--
--   Platform:
--     Timestamp:                   2023-12-02T03:39:58Z
--     Host:                        Linux 6.5.0-13-generic x86_64
--     Target:                      Linux 1 arm
--     CMake:                       3.27.4
--     CMake generator:             Ninja
--     CMake build tool:            /usr/bin/ninja
--     Configuration:               Release
--
--   CPU/HW features:
--     Baseline:                    NEON
--       requested:                 DETECT
--       required:                  NEON
--       disabled:                  VFPV3
--
--   C/C++:
--     Built as dynamic libs?:      YES
--     C++ standard:                11
--     C++ Compiler:                /usr/bin/arm-linux-gnueabihf-g++  (ver 13.2.0)

:
:

--
--   Video I/O:
--     DC1394:                      NO
--     FFMPEG:                      YES
--       avcodec:                   YES (60.3.100)
--       avformat:                  YES (60.3.100)
--       avutil:                    YES (58.2.100)
--       swscale:                   YES (7.1.100)
--       avresample:                NO
--     GStreamer:                   NO
--     v4l/v4l2:                    YES (linux/videodev2.h)
--
```

----------------------------------------

TITLE: Defining Custom Target for OpenCV Java Bindings Generation in CMake
DESCRIPTION: Creates a CMake custom target named `gen_opencv_java_source`. This target serves as a build system entity that depends on the output files generated by the previously defined custom command (`java_generated_files`). It lists the main Python generator script (`gen_java.py`) and the JSON configuration file (`gen_java.json`) as sources, which helps integrate the generation process into IDEs and build system dependency tracking.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/generator/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
add_custom_target(gen_opencv_java_source DEPENDS ${java_generated_files}
    SOURCES "${JAVA_SOURCE_DIR}/generator/gen_java.py"
            "${CMAKE_CURRENT_BINARY_DIR}/gen_java.json"
)
```

----------------------------------------

TITLE: Configuring Interactive SVG Option for Doxygen in CMake
DESCRIPTION: Sets a CMake cache variable `OPENCV_DOCS_INTERACTIVE_SVG` (defaulting to 'NO') to control the `INTERACTIVE_SVG` option in Doxygen, specifically addressing compatibility issues with certain Doxygen versions. It also sets the corresponding internal variable `CMAKECONFIG_INTERACTIVE_SVG` for the Doxyfile template.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: cmake
CODE:
```
# Doxygen 1.8.16 fix: https://github.com/doxygen/doxygen/pull/6870
# NO is needed here: https://github.com/opencv/opencv/pull/16039
set(OPENCV_DOCS_INTERACTIVE_SVG "NO" CACHE BOOL "Doxygen/INTERACTIVE_SVG value")
set(CMAKECONFIG_INTERACTIVE_SVG "${OPENCV_DOCS_INTERACTIVE_SVG}")
```

----------------------------------------

TITLE: Initializing AGAST Pixel Offsets in OpenCV (C++)
DESCRIPTION: Defines the makeAgastOffsets function, which sets up offset tables for different AGAST detector variants (OAST_9_16, AGAST_7_12d, AGAST_7_12s, and AGAST_5_8). The function takes a destination pixel array, row stride, and detector type, filling the offsets for use in AGAST corner evaluation. This depends on OpenCV infrastructure (constants/enumerations) and ensures that only supported types are processed; CV_Assert is used for sanity checks. The output is a 16-length pixel array with relative offsets for neighborhood sampling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include "agast_score.hpp"

#ifdef _MSC_VER
#pragma warning( disable : 4127 )
#endif

namespace cv
{

void makeAgastOffsets(int pixel[16], int rowStride, int type)
{
    static const int offsets16[][2] =
    {
        {-3,  0}, {-3, -1}, {-2, -2}, {-1, -3}, {0, -3}, { 1, -3}, { 2, -2}, { 3, -1},
        { 3,  0}, { 3,  1}, { 2,  2}, { 1,  3}, {0,  3}, {-1,  3}, {-2,  2}, {-3,  1}
    };

    static const int offsets12d[][2] =
    {
        {-3,  0}, {-2, -1}, {-1, -2}, {0, -3}, { 1, -2}, { 2, -1},
        { 3,  0}, { 2,  1}, { 1,  2}, {0,  3}, {-1,  2}, {-2,  1}
    };

    static const int offsets12s[][2] =
    {
        {-2,  0}, {-2, -1}, {-1, -2}, {0, -2}, { 1, -2}, { 2, -1},
        { 2,  0}, { 2,  1}, { 1,  2}, {0,  2}, {-1,  2}, {-2,  1}
    };

    static const int offsets8[][2] =
    {
        {-1,  0}, {-1, -1}, {0, -1}, { 1, -1},
        { 1,  0}, { 1,  1}, {0,  1}, {-1,  1}
    };

    const int (*offsets)[2] = type == AgastFeatureDetector::OAST_9_16 ? offsets16 :
                              type == AgastFeatureDetector::AGAST_7_12d ? offsets12d :
                              type == AgastFeatureDetector::AGAST_7_12s ? offsets12s :
                              type == AgastFeatureDetector::AGAST_5_8 ? offsets8  : 0;

    CV_Assert(pixel && offsets);

    int k = 0;
    for( ; k < 16; k++ )
        pixel[k] = offsets[k][0] + offsets[k][1] * rowStride;
}

```

----------------------------------------

TITLE: Running OpenCV Tests
DESCRIPTION: Command to run the basic OpenCV tests using make.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_9

LANGUAGE: bash
CODE:
```
$ make test
```

----------------------------------------

TITLE: Visualizing Raw and Estimated Poses in C++ (OpenCV)
DESCRIPTION: This C++ snippet demonstrates drawing the results of pose estimation onto an image (`frame_vis`) using OpenCV (Step X, optional visualization). It calls a helper function `drawObjectMesh` twice: once to render a 3D mesh based on the raw PnP result (`pnp_detection`, drawn in green) and once for the Kalman-filtered estimate (`pnp_detection_est`, drawn in yellow). It then computes the 2D image projections of 3D coordinate axes endpoints using `backproject3DPoint` based on the estimated pose and draws these axes using `draw3DCoordinateAxes`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_27

LANGUAGE: cpp
CODE:
```
// -- Step X: Draw pose

drawObjectMesh(frame_vis, &mesh, &pnp_detection, green);                // draw current pose
drawObjectMesh(frame_vis, &mesh, &pnp_detection_est, yellow);           // draw estimated pose

double l = 5;
std::vector<cv::Point2f> pose_points2d;
pose_points2d.push_back(pnp_detection_est.backproject3DPoint(cv::Point3f(0,0,0)));    // axis center
pose_points2d.push_back(pnp_detection_est.backproject3DPoint(cv::Point3f(l,0,0)));    // axis x
pose_points2d.push_back(pnp_detection_est.backproject3DPoint(cv::Point3f(0,l,0)));    // axis y
pose_points2d.push_back(pnp_detection_est.backproject3DPoint(cv::Point3f(0,0,l)));    // axis z
draw3DCoordinateAxes(frame_vis, pose_points2d);                                       // draw axes
```

----------------------------------------

TITLE: Implementing CvVideoCameraDelegate Protocol (Objective-C++)
DESCRIPTION: This code demonstrates how to implement the CvVideoCameraDelegate protocol, which is necessary for processing video frames. It includes a basic image processing example that inverts the colors of the frame.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/video_processing/video_processing.markdown#2025-04-22_snippet_3

LANGUAGE: Objective-C++
CODE:
```
#pragma mark - Protocol CvVideoCameraDelegate

#ifdef __cplusplus
- (void)processImage:(Mat&)image;
{
    // Do some OpenCV stuff with the image
    Mat image_copy;
    cvtColor(image, image_copy, COLOR_BGR2GRAY);

    // invert image
    bitwise_not(image_copy, image_copy);

    //Convert BGR to BGRA (three channel to four channel)
    Mat bgr;
    cvtColor(image_copy, bgr, COLOR_GRAY2BGR);

    cvtColor(bgr, image, COLOR_BGR2BGRA);
}
#endif
```

----------------------------------------

TITLE: Executing Custom OCR Model using OpenCV DNN from the Command Line - Bash
DESCRIPTION: This snippet demonstrates how to start the OpenCV-based text detection and recognition pipeline using command-line arguments. The text_detection tool requires specifying the path to both the text detection and text recognition models (typically in ONNX format). The '-m' flag denotes the detection model, while '-ocr' indicates the OCR (recognition) model. No installation is documented here, but it presumes 'text_detection' is either in your PATH or runnable from the current directory, and compatible model files are available. The expected input is a live or provided image stream, and the output will be recognized text printed or displayed depending on the implementation. Ensure OpenCV's DNN module and any dependencies required by the tool are installed. This command may require additional arguments for input/output configuration depending on your use case.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_OCR/dnn_OCR.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
$ text_detection -m=[path_to_text_detect_model] -ocr=[path_to_text_recognition_model]
```

----------------------------------------

TITLE: Checking for Aligned Memory Allocation Functions in CMake
DESCRIPTION: Checks for the availability of various functions used for allocating aligned memory blocks. It first checks for `malloc.h` using `check_include_files`. Then, using `check_symbol_exists`, it checks for `_aligned_malloc` (MSVC), `posix_memalign` (POSIX), and `memalign` (obsolete) within their respective headers. Notably, the check for `posix_memalign` temporarily sets `CMAKE_REQUIRED_DEFINITIONS` to ensure the correct POSIX feature test macros are defined during the check.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: cmake
CODE:
```
# Allocating Aligned Memory Blocks
include(CheckIncludeFiles)
check_include_files(malloc.h OPJ_HAVE_MALLOC_H)
include(CheckSymbolExists)
# _aligned_alloc https://msdn.microsoft.com/en-us/library/8z34s9c6.aspx
check_symbol_exists(_aligned_malloc malloc.h OPJ_HAVE__ALIGNED_MALLOC)
# posix_memalign (needs _POSIX_C_SOURCE >= 200112L on Linux)
set(_prev_CMAKE_REQUIRED_DEFINITIONS ${CMAKE_REQUIRED_DEFINITIONS})
set(CMAKE_REQUIRED_DEFINITIONS -D_POSIX_C_SOURCE=200112L)
check_symbol_exists(posix_memalign stdlib.h OPJ_HAVE_POSIX_MEMALIGN)
set(CMAKE_REQUIRED_DEFINITIONS ${_prev_CMAKE_REQUIRED_DEFINITIONS})
unset(_prev_CMAKE_REQUIRED_DEFINITIONS)
# memalign (obsolete)
check_symbol_exists(memalign malloc.h OPJ_HAVE_MEMALIGN)
```

----------------------------------------

TITLE: Declaring and Dispatching Optimized Source Files in OpenCV with CMake
DESCRIPTION: These CMake commands register a set of source files (such as 'accum', 'bilateral_filter', etc.) to be compiled with support for specific CPU instruction set extensions (e.g., SSE2, SSE4_1, AVX2, AVX512_SKX). This pattern enables the OpenCV imgproc module to use the most optimized code path available for an end-user's hardware, providing performance improvements at runtime. Each call to 'ocv_add_dispatched_file' maps a logical operation module to its corresponding platform-specific implementations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/imgproc/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
ocv_add_dispatched_file(accum SSE4_1 AVX AVX2)
ocv_add_dispatched_file(bilateral_filter SSE2 AVX2)
ocv_add_dispatched_file(box_filter SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(filter SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(color_hsv SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(color_rgb SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(color_yuv SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(median_blur SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(morph SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(smooth SSE2 SSE4_1 AVX2)
ocv_add_dispatched_file(sumpixels SSE2 AVX2 AVX512_SKX)
```

----------------------------------------

TITLE: Creating Build Directory
DESCRIPTION: Commands to create and navigate to build directory for OpenCV compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
mkdir build
cd build
```

----------------------------------------

TITLE: Documentation Dependencies and Installation Setup
DESCRIPTION: Sets up dependencies between different documentation targets and configures installation of the generated documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_24

LANGUAGE: cmake
CODE:
```
add_dependencies(doxygen doxygen_cpp)

  if(TARGET doxygen_python)
    add_dependencies(doxygen doxygen_python)
  endif()

  if(TARGET doxygen_javadoc)
    add_dependencies(doxygen_cpp doxygen_javadoc)
  endif()

  add_dependencies(opencv_docs doxygen)

  install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/doxygen/html
    DESTINATION "${OPENCV_DOC_INSTALL_PATH}"
    COMPONENT "docs" OPTIONAL
    ${compatible_MESSAGE_NEVER}
  )
```

----------------------------------------

TITLE: Installing Python Dependencies
DESCRIPTION: Commands to install Python-specific dependencies for both Python 2 and 3.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
sudo apt-get install python-dev python-numpy
sudo apt-get install python3-dev python3-numpy
```

----------------------------------------

TITLE: Configuring libtiff Build and Feature Detection - CMake - CMake
DESCRIPTION: This code configures the libtiff build for the OpenCV project via CMake. It sets up checks for availability of header files, function existence, type sizes, library linkage, and endianness detection to ensure portability across platforms. Key options for enabling or disabling algorithm support, dependency integration (e.g., JPEG, ZLIB), and platform-specific build settings are provided, with resulting flags and preprocessor definitions passed down to the compilation stage. Typical inputs involve system and toolchain characteristics; outputs are cached build options, optionally including detected header/functions, enabled features, and compiler definitions. Prerequisites: a working CMake installation and any libraries to be linked (JPEG, ZLIB, etc.).
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
# ----------------------------------------------------------------------------\n#  CMake file for libtiff. See root CMakeLists.txt\n#\n# ----------------------------------------------------------------------------\nproject(${TIFF_LIBRARY})\n\ninclude(CheckCSourceCompiles)\ninclude(CheckFunctionExists)\ninclude(CheckIncludeFile)\ninclude(CheckTypeSize)\n\n\n# Find libm, if available\nfind_library(M_LIBRARY m)\n\ncheck_include_file(assert.h    HAVE_ASSERT_H)\nif(NOT MSVC)\n  check_include_file(dlfcn.h     HAVE_DLFCN_H)\nendif()\ncheck_include_file(fcntl.h     HAVE_FCNTL_H)\ncheck_include_file(inttypes.h  HAVE_INTTYPES_H)\ncheck_include_file(io.h        HAVE_IO_H)\ncheck_include_file(limits.h    HAVE_LIMITS_H)\ncheck_include_file(malloc.h    HAVE_MALLOC_H)\ncheck_include_file(memory.h    HAVE_MEMORY_H)\ncheck_include_file(search.h    HAVE_SEARCH_H)\ncheck_include_file(stdint.h    HAVE_STDINT_H)\ncheck_include_file(string.h    HAVE_STRING_H)\nif(NOT MSVC)\n  check_include_file(strings.h   HAVE_STRINGS_H)\n  check_include_file(sys/time.h  HAVE_SYS_TIME_H)\nendif()\ncheck_include_file(sys/types.h HAVE_SYS_TYPES_H)\nif(NOT MSVC)\n  check_include_file(unistd.h    HAVE_UNISTD_H)\nendif()\n\n# Inspired from /usr/share/autoconf/autoconf/c.m4\nforeach(inline_keyword "inline" "__inline__" "__inline")\n  if(NOT DEFINED C_INLINE)\n    set(CMAKE_REQUIRED_DEFINITIONS_SAVE ${CMAKE_REQUIRED_DEFINITIONS})\n    set(CMAKE_REQUIRED_DEFINITIONS ${CMAKE_REQUIRED_DEFINITIONS}\n        "-Dinline=${inline_keyword}")\n    check_c_source_compiles("\n        typedef int foo_t;\n        static inline foo_t static_foo() {return 0;}\n        foo_t foo(){return 0;}\n        int main(int argc, char *argv[]) {return 0;}"\n      C_HAS_${inline_keyword})\n    set(CMAKE_REQUIRED_DEFINITIONS ${CMAKE_REQUIRED_DEFINITIONS_SAVE})\n    if(C_HAS_${inline_keyword})\n      set(C_INLINE TRUE)\n      set(INLINE_KEYWORD "${inline_keyword}")\n    endif()\n endif()\nendforeach()\nif(NOT DEFINED C_INLINE)\n  set(INLINE_KEYWORD)\nendif()\n\n\n# Check type sizes\n# NOTE: Could be replaced with C99 <stdint.h>\ncheck_type_size("signed short" SIZEOF_SIGNED_SHORT)\ncheck_type_size("unsigned short" SIZEOF_UNSIGNED_SHORT)\ncheck_type_size("signed int" SIZEOF_SIGNED_INT)\ncheck_type_size("unsigned int" SIZEOF_UNSIGNED_INT)\ncheck_type_size("signed long" SIZEOF_SIGNED_LONG)\ncheck_type_size("unsigned long" SIZEOF_UNSIGNED_LONG)\ncheck_type_size("signed long long" SIZEOF_SIGNED_LONG_LONG)\ncheck_type_size("unsigned long long" SIZEOF_UNSIGNED_LONG_LONG)\ncheck_type_size("unsigned char *" SIZEOF_UNSIGNED_CHAR_P)\n\nset(CMAKE_EXTRA_INCLUDE_FILES_SAVE ${CMAKE_EXTRA_INCLUDE_FILES})\nset(CMAKE_EXTRA_INCLUDE_FILES ${CMAKE_EXTRA_INCLUDE_FILES} "stddef.h")\ncheck_type_size("size_t" SIZEOF_SIZE_T)\ncheck_type_size("ptrdiff_t" SIZEOF_PTRDIFF_T)\nset(CMAKE_EXTRA_INCLUDE_FILES ${CMAKE_EXTRA_INCLUDE_FILES_SAVE})\n\nset(TIFF_INT8_T "signed char")\nset(TIFF_UINT8_T "unsigned char")\n\nset(TIFF_INT16_T "signed short")\nset(TIFF_UINT16_T "unsigned short")\n\nif(SIZEOF_SIGNED_INT EQUAL 4)\n  set(TIFF_INT32_T "signed int")\n  set(TIFF_INT32_FORMAT "%d")\nelseif(SIZEOF_SIGNED_LONG EQUAL 4)\n  set(TIFF_INT32_T "signed long")\n  set(TIFF_INT32_FORMAT "%ld")\nendif()\n\nif(SIZEOF_UNSIGNED_INT EQUAL 4)\n  set(TIFF_UINT32_T "unsigned int")\n  set(TIFF_UINT32_FORMAT "%u")\nelseif(SIZEOF_UNSIGNED_LONG EQUAL 4)\n  set(TIFF_UINT32_T "unsigned long")\n  set(TIFF_UINT32_FORMAT "%lu")\nendif()\n\nif(SIZEOF_SIGNED_LONG EQUAL 8)\n  set(TIFF_INT64_T "signed long")\n  set(TIFF_INT64_FORMAT "%ld")\nelseif(SIZEOF_SIGNED_LONG_LONG EQUAL 8)\n  set(TIFF_INT64_T "signed long long")\n  if(MINGW)\n    set(TIFF_INT64_FORMAT "%I64d")\n  else()\n    set(TIFF_INT64_FORMAT "%lld")\n  endif()\nendif()\n\nif(SIZEOF_UNSIGNED_LONG EQUAL 8)\n  set(TIFF_UINT64_T "unsigned long")\n  set(TIFF_UINT64_FORMAT "%lu")\nelseif(SIZEOF_UNSIGNED_LONG_LONG EQUAL 8)\n  set(TIFF_UINT64_T "unsigned long long")\n  if(MINGW)\n    set(TIFF_UINT64_FORMAT "%I64u")\n  else()\n    set(TIFF_UINT64_FORMAT "%llu")\n  endif()\nendif()\n\nif(SIZEOF_UNSIGNED_INT EQUAL SIZEOF_SIZE_T)\n  set(TIFF_SIZE_T "uint32_t")\n  set(TIFF_SIZE_FORMAT "%u")\n  set(TIFF_SSIZE_T "int32_t")\n  set(TIFF_SSIZE_FORMAT "%d")\nelseif(SIZEOF_UNSIGNED_LONG EQUAL SIZEOF_SIZE_T)\n  set(TIFF_SIZE_T "uint64_t")\n  set(TIFF_SIZE_FORMAT "%lu")\n  set(TIFF_SSIZE_T "int64_t")\n  set(TIFF_SSIZE_FORMAT "%ld")\nelseif(SIZEOF_UNSIGNED_LONG_LONG EQUAL SIZEOF_SIZE_T)\n  set(TIFF_SIZE_T "uint64_t")\n  if(MINGW)\n    set(TIFF_SIZE_FORMAT "%I64u")\n    set(TIFF_SSIZE_FORMAT "%I64d")\n  else()\n    set(TIFF_SIZE_FORMAT "%llu")\n    set(TIFF_SSIZE_FORMAT "%lld")\n  endif()\nendif()\n\nif(SIZEOF_SIGNED_INT EQUAL SIZEOF_UNSIGNED_CHAR_P)\nelseif(SIZEOF_SIGNED_LONG EQUAL SIZEOF_UNSIGNED_CHAR_P)\nelseif(SIZEOF_SIGNED_LONG_LONG EQUAL SIZEOF_UNSIGNED_CHAR_P)\n  set(TIFF_SSIZE_T "signed long long")\n  if(MINGW)\n  else()\n  endif()\nendif()\n\nif(NOT SIZEOF_PTRDIFF_T)\n  set(TIFF_PTRDIFF_T "${TIFF_SSIZE_T}")\n  set(TIFF_PTRDIFF_FORMAT "${SSIZE_FORMAT}")\nelse()\n  set(TIFF_PTRDIFF_T "ptrdiff_t")\n  set(TIFF_PTRDIFF_FORMAT "%ld")\nendif()\n\n# Nonstandard int types\nif(NOT MSVC)\n  check_type_size(INT8 int8)\n  set(HAVE_INT8 ${INT8})\n  check_type_size(INT16 int16)\n  set(HAVE_INT16 ${INT16})\n  check_type_size(INT32 int32)\n  set(HAVE_INT32 ${INT32})\nendif()\n\n# Check functions\nif(NOT MSVC)\n   set(CMAKE_REQUIRED_LIBRARIES_SAVE ${CMAKE_REQUIRED_LIBRARIES})\n  set(CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES} ${M_LIBRARY})\n  check_function_exists(floor HAVE_FLOOR)\n  check_function_exists(pow   HAVE_POW)\n  check_function_exists(sqrt  HAVE_SQRT)\n  set(CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES_SAVE})\nendif()\n\nif(NOT MSVC)\n  check_function_exists(isascii    HAVE_ISASCII)\n  check_function_exists(memset     HAVE_MEMSET)\n  check_function_exists(mmap       HAVE_MMAP)\n  check_function_exists(getopt     HAVE_GETOPT)\nendif()\ncheck_function_exists(memmove    HAVE_MEMMOVE)\ncheck_function_exists(setmode    HAVE_SETMODE)\ncheck_function_exists(strcasecmp HAVE_STRCASECMP)\ncheck_function_exists(strchr     HAVE_STRCHR)\ncheck_function_exists(strrchr    HAVE_STRRCHR)\ncheck_function_exists(strstr     HAVE_STRSTR)\ncheck_function_exists(strtol     HAVE_STRTOL)\ncheck_function_exists(strtol     HAVE_STRTOUL)\ncheck_function_exists(strtoull   HAVE_STRTOULL)\ncheck_function_exists(lfind      HAVE_LFIND)\n\n# CPU bit order\nset(fillorder FILLORDER_MSB2LSB)\nif(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES "i.*86.*" OR\n   CMAKE_HOST_SYSTEM_PROCESSOR MATCHES "amd64.*" OR\n   # AMD64 on Windows\n   CMAKE_HOST_SYSTEM_PROCESSOR MATCHES "AMD64" OR\n   CMAKE_HOST_SYSTEM_PROCESSOR MATCHES "x86_64.*")\n  set(fillorder FILLORDER_LSB2MSB)\nendif()\nset(HOST_FILLORDER ${fillorder} CACHE STRING "Native CPU bit order")\nmark_as_advanced(HOST_FILLORDER)\n\n# CPU endianness\ninclude(TestBigEndian)\ntest_big_endian(bigendian)\nif(bigendian)\n  set(bigendian ON)\nelse()\n  set(bigendian OFF)\nendif()\nset(HOST_BIG_ENDIAN ${bigendian} CACHE STRING "Native CPU bit order")\nmark_as_advanced(HOST_BIG_ENDIAN)\nif(HOST_BIG_ENDIAN)\n  set(HOST_BIG_ENDIAN 1)\nelse()\n  set(HOST_BIG_ENDIAN 0)\nendif()\nif(HOST_BIG_ENDIAN)\n  add_definitions(-DWORDS_BIGENDIAN)\nendif()\n\n# IEEE floating point\nset(HAVE_IEEEFP 1 CACHE STRING "IEEE floating point is available")\nmark_as_advanced(HAVE_IEEEFP)\n\n# Large file support\nif(UNIX OR MINGW)\n  if(ANDROID AND (ANDROID_NATIVE_API_LEVEL LESS 21) AND CV_GCC)\n    # Android NDK build problem: 'mmap' issue with GCC and API<21\n  else()\n    # This might not catch every possibility catered for by\n    # AC_SYS_LARGEFILE.\n    add_definitions(-D_FILE_OFFSET_BITS=64)\n    set(FILE_OFFSET_BITS 64)\n  endif()\nendif()\n\n# Documentation install directory (default to cmake project docdir)\nset(LIBTIFF_DOCDIR "${CMAKE_INSTALL_FULL_DOCDIR}")\n\n# Options to enable and disable internal codecs\n\noption(ccitt "support for CCITT Group 3 & 4 algorithms" ON)\nset(CCITT_SUPPORT ${ccitt})\n\noption(packbits "support for Macintosh PackBits algorithm" ON)\nset(PACKBITS_SUPPORT ${packbits})\n\noption(lzw "support for LZW algorithm" ON)\nset(LZW_SUPPORT ${lzw})\n\noption(thunder "support for ThunderScan 4-bit RLE algorithm" ON)\nset(THUNDER_SUPPORT ${thunder})\n\noption(next "support for NeXT 2-bit RLE algorithm" ON)\nset(NEXT_SUPPORT ${next})\n\noption(logluv "support for LogLuv high dynamic range algorithm" ON)\nset(LOGLUV_SUPPORT ${logluv})\n\n# Option for Microsoft Document Imaging\noption(mdi "support for Microsoft Document Imaging" ON)\nset(MDI_SUPPORT ${mdi})\n\n# ZLIB\nset(ZLIB_SUPPORT 0)\nif(ZLIB_LIBRARY)\n  set(ZLIB_SUPPORT 1)\nendif()\nset(ZIP_SUPPORT ${ZLIB_SUPPORT})\n\nset(PIXARLOG_SUPPORT FALSE)\n\n# JPEG\nset(JPEG_SUPPORT FALSE)\nif(HAVE_JPEG)\n  set(JPEG_SUPPORT TRUE)\n  if(TARGET ${JPEG_LIBRARY} AND DEFINED ${JPEG_LIBRARY}_BINARY_DIR)\n    include_directories("${${JPEG_LIBRARY}_BINARY_DIR}")\n  endif()\n  include_directories(${JPEG_INCLUDE_DIR})\nendif()\n\noption(old-jpeg "support for Old JPEG compression (read-only)" OFF)  # OpenCV: changed to OFF\nset(OJPEG_SUPPORT FALSE)\nif(JPEG_SUPPORT AND old-jpeg)\n  set(OJPEG_SUPPORT TRUE)\nendif()\n\n# OpenCV: turned off\nset(JBIG_SUPPORT 0)\nset(LZMA_SUPPORT 0)  # OpenCV: turned off\nset(JPEG12_FOUND FALSE)  # OpenCV: turned off\nset(STRIPCHOP_DEFAULT)\nset(STRIP_SIZE_DEFAULT 8192)\n\n# Win32 IO\nset(win32_io FALSE)\nif(WIN32 AND NOT WINRT)\n  set(win32_io TRUE)\nendif()\nset(USE_WIN32_FILEIO ${win32_io} CACHE BOOL "Use win32 IO system (Microsoft Windows only)")\nif(USE_WIN32_FILEIO)\n  set(USE_WIN32_FILEIO TRUE)\nelse()\n  set(USE_WIN32_FILEIO FALSE)\nendif()\n\n# Orthogonal features\n\n# OpenCV: turned ON\nset(SUBIFD_SUPPORT 1)\nset(DEFAULT_EXTRASAMPLE_AS_ALPHA 1)\nset(CHECK_JPEG_YCBCR_SUBSAMPLING 1)\n\nif(JPEG_INCLUDE_DIR)\n  list(APPEND TIFF_INCLUDES ${JPEG_INCLUDE_DIR})\nendif()\nif(JPEG12_INCLUDE_DIR)\n  list(APPEND TIFF_INCLUDES ${JPEG12_INCLUDE_DIR})\nendif()\nif(JBIG_INCLUDE_DIR)\n  list(APPEND TIFF_INCLUDES ${JBIG_INCLUDE_DIR})\nendif()\nif(LIBLZMA_INCLUDE_DIRS)\n  list(APPEND TIFF_INCLUDES ${LIBLZMA_INCLUDE_DIRS})\nendif()\n
```

----------------------------------------

TITLE: Defining Macro for Objective-C Bindings Generation Target in CMake
DESCRIPTION: Creates a macro that defines custom commands and targets for generating Objective-C bindings for a specific platform. This macro sets up the directories, Python command arguments, and dependencies for the generator script execution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/generator/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
set(objc_generated_targets "")

macro(ocv_add_objc_generated_target TARGET)
  set(objc_${TARGET}_generated_output_dependecy "${OPENCV_DEPHELPER}/gen_opencv_objc_source_${TARGET}")
  file(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/${TARGET}")
  add_custom_command(
      OUTPUT ${objc_generated_files} "${objc_${TARGET}_generated_output_dependecy}"
      COMMAND ${PYTHON_DEFAULT_EXECUTABLE} "${OBJC_SOURCE_DIR}/generator/gen_objc.py"
              -p "${OBJC_SOURCE_DIR}/../python/src2/gen2.py"
              -c "${CONFIG_FILE}"
              -t "${TARGET}"
              -f "${OPENCV_OBJC_FRAMEWORK_NAME}"
      COMMAND ${CMAKE_COMMAND} -E touch "${objc_${TARGET}_generated_output_dependecy}"
      WORKING_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/${TARGET}"
      DEPENDS "${OpenCV_SOURCE_DIR}/modules/objc/generator/gen_objc.py"
              "${OpenCV_SOURCE_DIR}/modules/python/src2/gen2.py"
              "${OpenCV_SOURCE_DIR}/modules/python/src2/hdr_parser.py"
              # don't, result of file(WRITE): "${CMAKE_CURRENT_BINARY_DIR}/gen_objc.json"
              ${deps}
              # not allowed (file(WRITE) result): "${CONFIG_FILE}"
      COMMENT "Generate files for Objective-C bindings (${TARGET})"
  )
  add_custom_target(gen_opencv_objc_source_${TARGET}
      # excluded from all: ALL
      DEPENDS ${objc_generated_files} ${objc_${TARGET}_generated_output_dependecy}
      SOURCES "${OBJC_SOURCE_DIR}/generator/gen_objc.py"
              "${OBJC_SOURCE_DIR}/generator/templates/cmakelists.template"
              "${CMAKE_CURRENT_BINARY_DIR}/gen_objc.json"
  )
  list(APPEND objc_generated_targets gen_opencv_objc_source_${TARGET})
endmacro()
```

----------------------------------------

TITLE: Generating Documentation using Make in Shell
DESCRIPTION: This shell command compiles the Doxygen documentation for OpenCV. It assumes a certain directory structure and successful CMake configuration. Produces documentation files viewable in a web browser.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_1

LANGUAGE: sh
CODE:
```
make doxygen
```

----------------------------------------

TITLE: Declaring VideoIO Module and Source/Header Files - OpenCV CMake Macros - CMake
DESCRIPTION: Adds and configures the videoio module within OpenCV, specifying dependencies (imgproc, imgcodecs) and language wrappers (java, objc, python). Lists main source and header files for compilation, and gathers additional headers matching patterns for inclusion. Notably uses ocv_add_module macro and CMake file globbing, relying on OpenCV CMake utilities.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
ocv_add_module(videoio opencv_imgproc opencv_imgcodecs WRAP java objc python)

set(videoio_hdrs ${CMAKE_CURRENT_LIST_DIR}/src/precomp.hpp)

set(videoio_srcs
  "${CMAKE_CURRENT_LIST_DIR}/src/videoio_registry.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/videoio_c.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/cap.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/cap_images.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/cap_mjpeg_encoder.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/cap_mjpeg_decoder.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/backend_plugin.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/backend_static.cpp"
  "${CMAKE_CURRENT_LIST_DIR}/src/container_avi.cpp")

file(GLOB videoio_ext_hdrs
  "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/*.hpp"
  "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/*.hpp"
  "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/*.h"
  "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/legacy/*.h")
```

----------------------------------------

TITLE: Configuring Intel ITT API Library for OpenCV in CMake
DESCRIPTION: Complete CMake configuration for building the Intel ITT API library within OpenCV. It sets up the library name, source files, include paths, platform-specific dependencies, and installation rules. The configuration also extracts the API version and disables specific compiler warnings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ittnotify/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(NOT ITT_LIBRARY)
  set(ITT_LIBRARY "ittnotify")
endif()
project(${ITT_LIBRARY} C)

if(NOT WIN32)
  include(CheckLibraryExists)
  if(COMMAND CHECK_LIBRARY_EXISTS)
    CHECK_LIBRARY_EXISTS(dl dlerror "" HAVE_DL_LIBRARY)
  endif()
endif()

ocv_warnings_disable(CMAKE_C_FLAGS -Wimplicit-fallthrough)

ocv_include_directories("${CMAKE_CURRENT_SOURCE_DIR}/include")
set(ITT_INCLUDE_DIRECTORY "${CMAKE_CURRENT_SOURCE_DIR}/include")

set(ITT_PUBLIC_HDRS
    include/ittnotify.h
    include/jitprofiling.h
    include/libittnotify.h
)
set(ITT_PRIVATE_HDRS
    src/ittnotify/disable_warnings.h
    src/ittnotify/ittnotify_config.h
    src/ittnotify/ittnotify_static.h
    src/ittnotify/ittnotify_types.h
)
set(ITT_SRCS
    src/ittnotify/ittnotify_static.c
    src/ittnotify/jitprofiling.c
)

add_library(${ITT_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${ITT_SRCS} ${ITT_PUBLIC_HDRS} ${ITT_PRIVATE_HDRS})

file(STRINGS "src/ittnotify/ittnotify_config.h" API_VERSION_NUM REGEX "#define\[ \t\]+API_VERSION_NUM[ \t]+([0-9\.]+)")
if(API_VERSION_NUM MATCHES "#define\[ \t\]+API_VERSION_NUM[ \t]+([0-9\.]*)")
  set(ITTNOTIFY_VERSION "${CMAKE_MATCH_1}"  CACHE INTERNAL "" FORCE)
endif()

if(NOT WIN32)
  if(HAVE_DL_LIBRARY)
    target_link_libraries(${ITT_LIBRARY} dl)
  endif()
endif()

set_target_properties(${ITT_LIBRARY} PROPERTIES
        OUTPUT_NAME ${ITT_LIBRARY}
        DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
        COMPILE_PDB_NAME ${ITT_LIBRARY}
        COMPILE_PDB_NAME_DEBUG "${ITT_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
        ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
    )

ocv_warnings_disable(CMAKE_C_FLAGS -Wundef -Wsign-compare)
ocv_warnings_disable(CMAKE_C_FLAGS -Wstrict-prototypes) # clang15

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${ITT_LIBRARY} PROPERTIES FOLDER "3rdparty")
endif()

if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${ITT_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(ittnotify src/ittnotify/BSD-3-Clause.txt src/ittnotify/GPL-2.0-only.txt)
```

----------------------------------------

TITLE: Accessing Image Properties with OpenCV.js - JavaScript
DESCRIPTION: Demonstrates loading an image into a cv.Mat and printing its width, height, size, depth, channel count, and type. Requires OpenCV.js to be loaded and an input element (e.g., canvas with id \"canvasInput\"). Useful for debugging and validation of image data before further manipulation. Outputs image properties to the console.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
let src = cv.imread("canvasInput");
console.log('image width: ' + src.cols + '\n' +
            'image height: ' + src.rows + '\n' +
            'image size: ' + src.size().width + '*' + src.size().height + '\n' +
            'image depth: ' + src.depth() + '\n' +
            'image channels ' + src.channels() + '\n' +
            'image type: ' + src.type() + '\n');
```

----------------------------------------

TITLE: Setting OpenEXR and IlmBase Version Information
DESCRIPTION: This snippet defines version information for both OpenEXR and IlmBase libraries. It sets major, minor, and patch versions as well as version strings and API version identifiers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(ILMBASE_VERSION_MAJOR "2")
set(ILMBASE_VERSION_MINOR "3")
set(ILMBASE_VERSION_PATCH "0")

set(ILMBASE_VERSION "${ILMBASE_VERSION_MAJOR}.${ILMBASE_VERSION_MINOR}.${ILMBASE_VERSION_PATCH}")
set(ILMBASE_VERSION_API ${ILMBASE_VERSION_MAJOR}_${ILMBASE_VERSION_MINOR})

set(OPENEXR_VERSION_MAJOR "2")
set(OPENEXR_VERSION_MINOR "3")
set(OPENEXR_VERSION_PATCH "0")

set(OPENEXR_VERSION "${OPENEXR_VERSION_MAJOR}.${OPENEXR_VERSION_MINOR}.${OPENEXR_VERSION_PATCH}")
set(OPENEXR_VERSION_API ${OPENEXR_VERSION_MAJOR}_${OPENEXR_VERSION_MINOR})

set(OPENEXR_VERSION "${OPENEXR_VERSION}" PARENT_SCOPE)
```

----------------------------------------

TITLE: Assigning Entities to a Documentation Group - Doxygen Group Markup
DESCRIPTION: Demonstrates assigning functions, classes, or whole blocks to doxygen-defined groups using @ingroup or @addtogroup, which facilitates structured module documentation. Inputs are entity or block and group marker; output is those entities listed in the specified group in documentation navigation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_16

LANGUAGE: cpp
CODE:
```
/** @brief Example function
    @ingroup mymodule
*/
or
/**
@addtogroup mymodule_experimental
@{
*/
... several functions, classes or enumerations here
/**
@}
*/
```

----------------------------------------

TITLE: Defining HAVE_THREADS Macro based on System Support (OpenCV Build) in CMake
DESCRIPTION: Checks if threading support is available (via `Threads::Threads` target, `HAVE_PTHREAD`, MSVC, or Apple) and if example threads are not disabled (`OPENCV_EXAMPLES_DISABLE_THREADS`). If conditions are met, it adds the `-DHAVE_THREADS=1` preprocessor definition for use in C/C++ source files. This applies when building as part of OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
if((TARGET Threads::Threads OR HAVE_PTHREAD OR MSVC OR APPLE) AND NOT OPENCV_EXAMPLES_DISABLE_THREADS)
  add_definitions(-DHAVE_THREADS=1)
endif()
```

----------------------------------------

TITLE: Configuring and Building OpenCV OpenVX C++ Sample Targets using CMake
DESCRIPTION: This CMake code block defines the project name as 'openvx_samples'. It includes required OpenCV modules recursively using `ocv_include_modules_recurse` based on the previously defined dependency list. It adds preprocessor definitions `-DIVX_USE_OPENCV` and `-DIVX_HIDE_INFO_WARNINGS` for compiling the samples. It finds all `.cpp` files recursively using `file(GLOB_RECURSE)` and stores them in `cpp_samples`. Finally, it iterates through each found sample file, defines a build target for it using `ocv_define_sample` (associating it with 'openvx'), and links the target against necessary OpenCV libraries (`OPENCV_LINKER_LIBS`) and the required modules using `ocv_target_link_libraries`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/openvx/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
project(openvx_samples)
ocv_include_modules_recurse(${OPENCV_OPENVX_SAMPLE_REQUIRED_DEPS})
add_definitions(-DIVX_USE_OPENCV)
add_definitions(-DIVX_HIDE_INFO_WARNINGS)
file(GLOB_RECURSE cpp_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
foreach(sample_filename ${cpp_samples})
  ocv_define_sample(tgt ${sample_filename} openvx)
  ocv_target_link_libraries(${tgt} PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_OPENVX_SAMPLE_REQUIRED_DEPS})
endforeach()
```

----------------------------------------

TITLE: Cloning and Preparing OpenCV Repositories (Git, Shell)
DESCRIPTION: This shell script demonstrates how to clone the OpenCV, opencv_contrib, and opencv_extra repositories from GitHub and optionally check out specific version tags for compatibility. It requires Git to be installed and available in the command line environment. The script handles acquiring main and optional repositories, ensuring that correct tags are used for all components. Parameters such as <some-tag> and <same-tag-as-opencv> must be set to the desired release tag values. Output will be local directories containing the repository code at the specified tags.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/general_install/general_install.markdown#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
git clone https://github.com/opencv/opencv\ngit -C opencv checkout <some-tag>\n\n# optionally\ngit clone https://github.com/opencv/opencv_contrib\ngit -C opencv_contrib checkout <same-tag-as-opencv>\n\n# optionally\ngit clone https://github.com/opencv/opencv_extra\ngit -C opencv_extra checkout <same-tag-as-opencv>
```

----------------------------------------

TITLE: Gathering and Filtering JavaScript Tutorial Assets in CMake
DESCRIPTION: Recursively finds all files within the JavaScript tutorial assets directory (`js_tutorials_assets_dir`) using `file(GLOB_RECURSE ...)` and stores them in the `js_assets` list. It then filters out any ESLint configuration files (`.eslintrc.json`) using a custom function `ocv_list_filterout`. Finally, it appends the path to a specific MP4 video file required for a calibration tutorial.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_18

LANGUAGE: cmake
CODE:
```
# gather and copy specific files for js tutorials
file(GLOB_RECURSE js_assets "${js_tutorials_assets_dir}/*")
ocv_list_filterout(js_assets "\\.eslintrc.json")
list(APPEND js_assets "${OpenCV_SOURCE_DIR}/samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/Data/box.mp4")
```

----------------------------------------

TITLE: ARM CPU Feature Detection
DESCRIPTION: Checks for ARM-specific CPU features like CRC32 and NEON using compiler tests
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_18

LANGUAGE: c
CODE:
```
#include <sys/auxv.h>
int main() {
    return (getauxval(AT_HWCAP) & HWCAP_CRC32);
}
```

LANGUAGE: c
CODE:
```
#include <sys/auxv.h>
int main() {
    return (getauxval(AT_HWCAP2) & HWCAP2_CRC32);
}
```

LANGUAGE: c
CODE:
```
#include <sys/auxv.h>
#include <asm/hwcap.h>
int main() {
    return (getauxval(AT_HWCAP2) & HWCAP2_CRC32);
}
```

----------------------------------------

TITLE: Closing Namespace in C++
DESCRIPTION: This code snippet closes the CV namespace, indicating the end of the OpenCV-related code block.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_48

LANGUAGE: C++
CODE:
```
} // END NAMESPACE CV

```

----------------------------------------

TITLE: Validating Matches and Estimating Homography with OpenCV (Python)
DESCRIPTION: This snippet checks if enough good matches exist (with a minimum count). If so, it extracts matched point coordinates from each image, computes the perspective homography using RANSAC to handle outliers, transforms the reference object's corners, and draws the detected region on the scene image. If not enough matches exist, it reports a failure. Dependencies: Output from previous SIFT/FLANN matching, OpenCV, and NumPy. Inputs are the good match list, keypoints, and images. Outputs either the drawn polygon or a missing match message. At least four inlier matches are required to estimate homography reliably.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_feature_homography/py_feature_homography.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
if len(good)>MIN_MATCH_COUNT:\n    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n\n    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n    matchesMask = mask.ravel().tolist()\n\n    h,w = img1.shape\n    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n    dst = cv.perspectiveTransform(pts,M)\n\n    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n\nelse:\n    print( "Not enough matches are found - {}/{}".format(len(good), MIN_MATCH_COUNT) )\n    matchesMask = None
```

----------------------------------------

TITLE: Automatic Memory Management in OpenCV C++
DESCRIPTION: This snippet illustrates the automatic memory management in OpenCV using `cv::Mat`. It demonstrates reference counting, where data is shared between structures like `Mat`, and the use of `clone` for creating separate copies. Includes the creation and release of matrices and changes to reference counters when copying or releasing data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/intro.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
    // create a big 8Mb matrix
    Mat A(1000, 1000, CV_64F);

    // create another header for the same matrix;
    // this is an instant operation, regardless of the matrix size.
    Mat B = A;
    // create another header for the 3-rd row of A; no data is copied either
    Mat C = B.row(3);
    // now create a separate copy of the matrix
    Mat D = B.clone();
    // copy the 5-th row of B to C, that is, copy the 5-th row of A
    // to the 3-rd row of A.
    B.row(5).copyTo(C);
    // now let A and D share the data; after that the modified version
    // of A is still referenced by B and C.
    A = D;
    // now make B an empty matrix (which references no memory buffers),
    // but the modified version of A will still be referenced by C,
    // despite that C is just a single row of the original A
    B.release();

    // finally, make a full copy of C. As a result, the big modified
    // matrix will be deallocated, since it is not referenced by anyone
    C = C.clone();
```

----------------------------------------

TITLE: Defining JPEG DCT Coefficient Data Structures in C
DESCRIPTION: Defines C typedefs for handling Discrete Cosine Transform (DCT) coefficients within the libjpeg library. `JCOEF` represents a single 16-bit signed integer coefficient. `JBLOCK` defines an 8x8 block (DCTSIZE2 = 64) of coefficients. `JBLOCKROW` is a pointer to a row of 8x8 blocks. `JBLOCKARRAY` points to an array of block rows. `JBLOCKIMAGE` points to an array of component block arrays. Coefficients are typically stored quantized and in natural order within these structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/structure.txt#2025-04-22_snippet_3

LANGUAGE: c
CODE:
```
    typedef short JCOEF;                a 16-bit signed integer
    typedef JCOEF JBLOCK[DCTSIZE2];     an 8x8 block of coefficients
    typedef JBLOCK *JBLOCKROW;          ptr to one horizontal row of 8x8 blocks
    typedef JBLOCKROW *JBLOCKARRAY;     ptr to a list of such rows
    typedef JBLOCKARRAY *JBLOCKIMAGE;   ptr to a list of color component arrays
```

----------------------------------------

TITLE: Applying Morphological Transformations (Opening, Closing, etc.) - OpenCV.js - JavaScript
DESCRIPTION: This snippet introduces the cv.morphologyEx() function in OpenCV.js, which generalizes morphological operations such as opening, closing, gradient, top hat, and black hat using a specified operation code (op). Key parameters are src (input image), dst (output image), op (operation type from cv.MorphTypes), kernel, anchor, iterations, borderType, and borderValue. Images may have variable depth and channel counts. The function allows succinct execution of combined morphological operations as needed for different applications.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_morphological_ops/js_morphological_ops.markdown#2025-04-22_snippet_2

LANGUAGE: JavaScript
CODE:
```
cv.morphologyEx(src, dst, op, kernel, anchor = new cv.Point(-1, -1), iterations = 1, borderType = cv.BORDER_CONSTANT, borderValue = cv.morphologyDefaultBorderValue())
```

----------------------------------------

TITLE: Image Smoothing Using Gaussian Filter in C++
DESCRIPTION: Shows the application of Gaussian blurring with cv.GaussianBlur(), which smooths images using a Gaussian kernel. It's effective for reducing image noise and detail. Requires OpenCV with parameters for the source image, destination, kernel size, and sigma values for the kernel. Suitable for various image depths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_filtering/js_filtering.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
cv::GaussianBlur(src, dst, cv::Size(ksize, ksize), sigmaX, sigmaY, cv::BORDER_DEFAULT);
```

----------------------------------------

TITLE: Parsing and Validating Plugin List with Conditional Warnings - VideoIO Plugin System - CMake
DESCRIPTION: Parses the VIDEOIO_PLUGIN_LIST to support both comma- and semicolon-separated values, lowercases the plugin names, and disables the list if plugin usage is globally disabled. Issues a warning if the list is set while plugins are disabled, ensuring that configuration inconsistencies are caught early in the build. No external dependencies are required; key inputs include user- or preset variables VIDEOIO_PLUGIN_LIST and VIDEOIO_ENABLE_PLUGINS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
string(REPLACE "," ";" VIDEOIO_PLUGIN_LIST "${VIDEOIO_PLUGIN_LIST}")  # support comma-separated list (,) too
string(TOLOWER "${VIDEOIO_PLUGIN_LIST}" VIDEOIO_PLUGIN_LIST)
if(NOT VIDEOIO_ENABLE_PLUGINS)
  if(VIDEOIO_PLUGIN_LIST)
    message(WARNING "VideoIO: plugins are disabled through VIDEOIO_ENABLE_PLUGINS, so VIDEOIO_PLUGIN_LIST='${VIDEOIO_PLUGIN_LIST}' is ignored")
    set(VIDEOIO_PLUGIN_LIST "")
  endif()
else()
  # Make virtual opencv_videoio_plugins target
  if(NOT TARGET opencv_videoio_plugins)
    add_custom_target(opencv_videoio_plugins ALL)
  endif()
endif()
```

----------------------------------------

TITLE: Writing and Reading ICC Profiles with libjpeg - C
DESCRIPTION: Provides the function signatures for writing and reading ICC device profiles in JPEG images using libjpeg. These functions are agnostic to ICC data internals, and focus only on embedding or extracting binary profile data at the correct position within the JPEG marker stream. Usage requires a properly initialized compressor or decompressor context, and functions must be called in strict sequence during JPEG write/read workflows.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_62

LANGUAGE: c
CODE:
```
void jpeg_write_icc_profile (j_compress_ptr cinfo,
                                     const JOCTET *icc_data_ptr,
                                     unsigned int icc_data_len);
boolean jpeg_read_icc_profile (j_decompress_ptr cinfo,
                               JOCTET **icc_data_ptr,
                               unsigned int *icc_data_len);
```

----------------------------------------

TITLE: Including Android Sample Project Subdirectories in CMake
DESCRIPTION: Adds multiple subdirectories to the CMake build process using the `add_subdirectory` command. Each listed directory (e.g., '15-puzzle', 'face-detection', 'tutorial-1-camerapreview') is expected to contain its own `CMakeLists.txt` file defining an individual Android sample project. CMake processes the `CMakeLists.txt` file in each subdirectory, integrating its targets and build rules into the main project build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
add_subdirectory(15-puzzle)
add_subdirectory(face-detection)
add_subdirectory(qr-detection)
add_subdirectory(image-manipulations)
add_subdirectory(camera-calibration)
add_subdirectory(color-blob-detection)
add_subdirectory(mobilenet-objdetect)
add_subdirectory(video-recorder)
add_subdirectory(tutorial-1-camerapreview)
add_subdirectory(tutorial-2-mixedprocessing)
add_subdirectory(tutorial-3-cameracontrol)
add_subdirectory(tutorial-4-opencl)
```

----------------------------------------

TITLE: Calculating Equivalent Diameter using OpenCV.js
DESCRIPTION: Calculates the equivalent diameter of a contour, which is the diameter of a circle having the same area as the contour. Requires a contour (`cnt`). Uses `cv.contourArea` to get the area and applies the formula sqrt(4 * area / PI).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_properties/js_contour_properties.markdown#2025-04-22_snippet_3

LANGUAGE: javascript
CODE:
```
let area = cv.contourArea(cnt, false);
let equiDiameter = Math.sqrt(4 * area / Math.PI);
```

----------------------------------------

TITLE: Waiting for User Exit in C++ OpenCV Program
DESCRIPTION: Code snippet demonstrating how to wait for a user to press a key to exit an OpenCV application in C++. This is typically used at the end of image processing applications to keep the result window open until the user is ready to close it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_21

LANGUAGE: cpp
CODE:
```
// Wait until user exit program by pressing a key
waitKey(0);
```

----------------------------------------

TITLE: Initializing TBB Project and Version Configuration in CMake
DESCRIPTION: Sets up the TBB project, defines version information and download paths. Includes a check to prevent using BUILD_TBB on non-ARM Windows platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(tbb CXX)

if (WIN32 AND NOT ARM)
  message(FATAL_ERROR "BUILD_TBB option supports Windows on ARM only!\nUse regular official TBB build instead of the BUILD_TBB option!")
endif()

ocv_update(OPENCV_TBB_RELEASE "v2022.1.0")
ocv_update(OPENCV_TBB_RELEASE_MD5 "cce28e6cb1ceae14a93848990c98cb6b")
ocv_update(OPENCV_TBB_FILENAME "${OPENCV_TBB_RELEASE}.tar.gz")
string(REGEX REPLACE "^v" "" OPENCV_TBB_RELEASE_ "${OPENCV_TBB_RELEASE}")
#ocv_update(OPENCV_TBB_SUBDIR ...)
```

----------------------------------------

TITLE: Configuring Compiler Definitions and Warnings for Protobuf
DESCRIPTION: Sets up compiler-specific definitions and disables various warnings based on the compiler being used (MSVC, GCC, ICC). Includes special handling for threading and platform-specific issues.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/protobuf/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(HAVE_PTHREAD)
  add_definitions(-DHAVE_PTHREAD=1)
endif()

if(MSVC)
  add_definitions( -D_CRT_SECURE_NO_WARNINGS=1 )
  ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4244 /wd4267 /wd4018 /wd4355 /wd4800 /wd4251 /wd4996 /wd4146)
else()
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wno-deprecated -Wmissing-prototypes -Wmissing-declarations -Wshadow)
endif()
```

----------------------------------------

TITLE: Defining calib3d Module with Dependencies and Language Wrappers - CMake
DESCRIPTION: This snippet defines the calib3d module using OpenCV's ocv_define_module macro. It specifies dependencies such as opencv_imgproc, opencv_features2d, opencv_flann, and conditionally includes debug modules. It also enables wrappers for Java, Objective-C, Python, and JavaScript. Prerequisite: Supporting CMake macros must be included.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/calib3d/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
ocv_define_module(calib3d opencv_imgproc opencv_features2d opencv_flann ${debug_modules}
    WRAP java objc python js
)
```

----------------------------------------

TITLE: Updating and Including OpenCV Configurations in CMake
DESCRIPTION: This snippet sets the OPENCV_CONFIG_FILE_INCLUDE_DIR to store platform-dependent cvconfig.h files and includes these directories in the CMake processing path. It is crucial for CMake to locate platform-specific configuration headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: CMake
CODE:
```
ocv_update(OPENCV_CONFIG_FILE_INCLUDE_DIR \"${CMAKE_BINARY_DIR}/\" CACHE PATH \"Where to create the platform-dependant cvconfig.h\")
ocv_include_directories(${OPENCV_CONFIG_FILE_INCLUDE_DIR})
```

----------------------------------------

TITLE: Brute-Force Matching with OpenCV in Java
DESCRIPTION: Java snippet using OpenCV's brute-force matcher to match descriptors between images and implementing 2-nearest neighbor matching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java 2-nn matching
```

----------------------------------------

TITLE: Implementing Nested Conditional Checks for Image Feature Detection in C++
DESCRIPTION: This code snippet contains a series of nested if-else statements comparing pixel values at different offsets. It's part of a larger algorithm, likely for corner or feature detection in images. The code uses goto-like structures through comments for control flow.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_34

LANGUAGE: C++
CODE:
```
if(ptr[offset9] < c_b)
  if(ptr[offset7] < c_b)
    if(ptr[offset8] < c_b)
      if(ptr[offset6] < c_b)
        if(ptr[offset5] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset1] < c_b)
                {} // goto success_homogeneous;
              else
                if(ptr[offset10] < c_b)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  if(ptr[offset12] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              if(ptr[offset12] < c_b)
                if(ptr[offset13] < c_b)
                  if(ptr[offset14] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
      else
        if(ptr[offset10] < c_b)
          if(ptr[offset11] < c_b)
            if(ptr[offset12] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  if(ptr[offset9] > cb)
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset12] > cb)
            if(ptr[offset13] > cb)
              if(ptr[offset14] > cb)
                if(ptr[offset15] > cb)
                  {} // goto success_homogeneous;
                else
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                if(ptr[offset5] > cb)
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset4] > cb)
                if(ptr[offset5] > cb)
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset5] > cb)
                  if(ptr[offset6] > cb)
                    if(ptr[offset7] > cb)

```

----------------------------------------

TITLE: Pixel Comparison Decision Tree for Feature Detection in C++
DESCRIPTION: A decision tree implementation that compares pixel values at various offsets against threshold values (cb and c_b) to determine if a pixel represents a corner or feature point. The algorithm uses goto statements to branch between 'homogeneous', 'structured', and 'success' states based on pixel intensity patterns.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_18

LANGUAGE: cpp
CODE:
```
if(ptr[offset11] > cb)
  goto success_homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset6] > cb)
    if(ptr[offset8] > cb)
      goto success_homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  if(ptr[offset1] > cb)
    if(ptr[offset6] > cb)
      goto success_homogeneous;
    else
      if(ptr[offset11] > cb)
        goto success_homogeneous;
      else
        goto homogeneous;
  else
    goto homogeneous;
else
  goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset9] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset5] < c_b)
        if(ptr[offset1] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset3] > cb)
                if(ptr[offset11] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                goto homogeneous;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset11] < c_b)
                    if(ptr[offset10] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset4] < c_b)
                    goto success_structured;
                  else
                    if(ptr[offset11] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                else
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        if(ptr[offset1] > cb)
          if(ptr[offset3] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  goto success_structured;
                else
                  goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
    else
      if(ptr[offset1] > cb)
        if(ptr[offset3] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                goto success_homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
      else
        goto homogeneous;
  else
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset7] > cb)
            if(ptr[offset1] > cb)
              if(ptr[offset3] > cb)
                goto success_homogeneous;
              else
                if(ptr[offset8] > cb)
                  goto success_homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset8] > cb)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset1] > cb)
              if(ptr[offset3] > cb)
                goto success_homogeneous;
              else
                if(ptr[offset8] > cb)
                  goto success_homogeneous;
                else
                  goto homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                goto success_homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        goto homogeneous;
    else
      goto homogeneous;
else
  if(ptr[offset7] > cb)
    if(ptr[offset9] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset5] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                goto success_homogeneous;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset4] > cb)
                    goto success_structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset3] > cb)
```

----------------------------------------

TITLE: Initializing Android Activity with OpenGL-enabled Camera Preview - Java
DESCRIPTION: This Java class defines a minimal Android Activity to set up a camera preview using an OpenGL surface view. It initializes the interface in landscape mode, disables the title bar, sets the view to full screen, and manages the surface view's lifecycle in onCreate, onPause, and onResume. Prerequisites are basic Android development setup and a corresponding GLSurfaceView implementation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_5

LANGUAGE: java
CODE:
```
public class Tutorial4Activity extends Activity {\n\n    private MyGLSurfaceView mView;\n\n    @Override\n    public void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        requestWindowFeature(Window.FEATURE_NO_TITLE);\n        getWindow().setFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN,\n                WindowManager.LayoutParams.FLAG_FULLSCREEN);\n        getWindow().setFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON,\n                WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);\n        setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);\n\n        mView = new MyGLSurfaceView(this);\n        setContentView(mView);\n    }\n\n    @Override\n    protected void onPause() {\n        mView.onPause();\n        super.onPause();\n    }\n\n    @Override\n    protected void onResume() {\n        super.onResume();\n        mView.onResume();\n    }\n}
```

----------------------------------------

TITLE: Enabling Lossless JPEG Compression with libjpeg in C
DESCRIPTION: This C function enables lossless JPEG compression mode within the libjpeg library. It requires the compression structure pointer `cinfo`, a predictor selection value (integer 1-7) which determines the DPCM predictor used, and a point transform value (integer 0 to {precision}-1). A point transform of 0 ensures mathematically lossless compression, while non-zero values introduce a form of lossy quantization. Lossless mode disables many standard JPEG features like DCT, quality selection, and color space conversion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_29

LANGUAGE: C
CODE:
```
jpeg_enable_lossless (j_compress_ptr cinfo, int predictor_selection_value,
                      int point_transform)
```

----------------------------------------

TITLE: Configuring Android-specific Settings in CMake for OpenCV
DESCRIPTION: This snippet handles Android-specific configurations for OpenCV, including NDK, SDK, and toolchain settings. It checks for Android build environment and reports relevant information.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_19

LANGUAGE: CMake
CODE:
```
if(ANDROID)
  status("")
  if(DEFINED ANDROID_NDK_REVISION)
    set(__msg "${ANDROID_NDK} (ver ${ANDROID_NDK_REVISION})")
  else()
    set(__msg "location: ${ANDROID_NDK}")
  endif()
  status("  Android NDK: " ${__msg})
  status("    Android ABI:" ${ANDROID_ABI})
  if(BUILD_WITH_STANDALONE_TOOLCHAIN)
    status("    NDK toolchain:" "standalone: ${ANDROID_STANDALONE_TOOLCHAIN}")
  elseif(BUILD_WITH_ANDROID_NDK OR DEFINED ANDROID_TOOLCHAIN_NAME)
    status("    NDK toolchain:" "${ANDROID_TOOLCHAIN_NAME}")
  endif()
  status("    STL type:" ${ANDROID_STL})
  status("    Native API level:" ${ANDROID_NATIVE_API_LEVEL})

  if(BUILD_ANDROID_PROJECTS)
    status("  Android SDK: " "${ANDROID_SDK} (tools: ${ANDROID_SDK_TOOLS_VERSION} build tools: ${ANDROID_SDK_BUILD_TOOLS_VERSION})")
    if(ANDROID_EXECUTABLE)
      status("    android tool:"  "${ANDROID_EXECUTABLE}")
    endif()
  else()
    status("  Android SDK: " "not used, projects are not built")
  endif()
  if(DEFINED ANDROID_SDK_COMPATIBLE_TARGET)
    status("    SDK target:" "${ANDROID_SDK_COMPATIBLE_TARGET}")
  endif()
  if(DEFINED ANDROID_PROJECTS_BUILD_TYPE)
    if(ANDROID_PROJECTS_BUILD_TYPE STREQUAL "ANT")
      status("    Projects build scripts:" "Ant/Eclipse compatible")
    elseif(ANDROID_PROJECTS_BUILD_TYPE STREQUAL "ANT")
      status("    Projects build scripts:" "Gradle")
    endif()
  endif()
endif()
```

----------------------------------------

TITLE: Camera Calibration Matrix Values
DESCRIPTION: 3x3 camera calibration matrix containing focal lengths (fx, fy), principal point (cx, cy) and skew. Used for mapping 3D world points to 2D image points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/data/essential_mat_data.txt#2025-04-22_snippet_0

LANGUAGE: text
CODE:
```
651.4462353114224 0 376.27522319223914
0 653.7348054191838 280.1106539526218
0 0 1
```

----------------------------------------

TITLE: Building OpenCV using Make
DESCRIPTION: Executes the 'make' command within the OpenCV build directory. This command starts the compilation and linking process based on the configuration generated by CMake in the previous step, ultimately building the OpenCV libraries with the enabled OpenNI2 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
$ make
```

----------------------------------------

TITLE: Configuring Whitelist for JavaScript Bindings Generation in CMake
DESCRIPTION: Sets up the whitelist file for JavaScript bindings generation, either from an environment variable or by generating it from module-specific whitelist files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/generator/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
if(DEFINED ENV{OPENCV_JS_WHITELIST})
  set(OPENCV_JS_WHITELIST_FILE "$ENV{OPENCV_JS_WHITELIST}")
  message(STATUS "Use white list from environment ${OPENCV_JS_WHITELIST_FILE}")
else()
  #generate white list from modules/<module_name>/misc/js/whitelist.json
  set(OPENCV_JS_WHITELIST_FILE "${CMAKE_CURRENT_BINARY_DIR}/whitelist.json")
  foreach(m in ${OPENCV_JS_MODULES})
    set(js_whitelist "${OPENCV_MODULE_${m}_LOCATION}/misc/js/gen_dict.json")
    if (EXISTS "${js_whitelist}")
      file(READ "${js_whitelist}" whitelist_content)
      list(APPEND OPENCV_JS_WHITELIST_CONTENT  "\"${m}\": ${whitelist_content}")
    endif()
  endforeach(m)
  string(REPLACE ";" ", \n" OPENCV_JS_WHITELIST_CONTENT_STRING "${OPENCV_JS_WHITELIST_CONTENT}")
  set(OPENCV_JS_WHITELIST_CONTENT_STRING "{\n${OPENCV_JS_WHITELIST_CONTENT_STRING}}\n")
  ocv_update_file("${OPENCV_JS_WHITELIST_FILE}" "${OPENCV_JS_WHITELIST_CONTENT_STRING}")
  message(STATUS "Use autogenerated whitelist ${OPENCV_JS_WHITELIST_FILE}")
endif()
```

----------------------------------------

TITLE: Installing libspng Library
DESCRIPTION: Configures installation settings for the libspng library. Handles solution folder organization, library installation paths, and license file installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libspng/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
if(ENABLE_SOLUTION_FOLDERS)
    set_target_properties(${SPNG_LIBRARY} PROPERTIES FOLDER "3rdparty")
endif()

if(NOT BUILD_SHARED_LIBS)
    ocv_install_target(${SPNG_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(${SPNG_LIBRARY} LICENSE)
```

----------------------------------------

TITLE: Implementing Keypoint Detection and Storage Logic in AGAST Algorithm
DESCRIPTION: This code snippet handles keypoint memory allocation and storage after corner detection. It dynamically adjusts the reserved memory based on the number of expected corners and creates new KeyPoint objects for detected corners.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_41

LANGUAGE: C++
CODE:
```
if(total == nExpectedCorners)
{
    if(nExpectedCorners == 0)
    {
        nExpectedCorners = 512;
        keypoints.reserve(nExpectedCorners);
    }
    else
    {
        nExpectedCorners *= 2;
        keypoints.reserve(nExpectedCorners);
    }
}
keypoints.push_back(KeyPoint(Point2f((float)x, (float)y), 1.0f));
total++;
```

----------------------------------------

TITLE: Specifying Code Block Language with @code{.xml} - Doxygen XML Markup
DESCRIPTION: Shows how to mark a code block as XML in documentation using the @code{.xml} directive, enabling tailored syntax highlighting. No additional dependencies. Input is XML snippet; output is syntax-highlighted code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_10

LANGUAGE: xml
CODE:
```
@code{.xml}
@endcode
```

----------------------------------------

TITLE: Computing Projective Homography Matrix from Euclidean Homography - C++
DESCRIPTION: This snippet constructs a projective homography matrix from the plane-to-plane Euclidean homography and camera intrinsics using matrix multiplication. Requires the previously computed homography and calibrated camera intrinsic matrix. Output is a projective matrix used for image warping across views.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_24

LANGUAGE: cpp
CODE:
```
@snippet homography_from_camera_displacement.cpp compute-homography
```

----------------------------------------

TITLE: Listing Android Devices with adb - Command Line (bash)
DESCRIPTION: This sequence demonstrates the use of the 'adb devices' command to enumerate connected Android devices from the command line. It is useful for verifying whether a device is properly recognized by the development environment and ready for debugging, deployment, or further interaction. No additional dependencies are required except the Android SDK platform-tools package.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_dev_intro.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
savuor@rostislav-laptop:~/Android/Sdk/platform-tools$ ./adb devices
List of devices attached
R58MB40Q3VP     device

savuor@rostislav-laptop:~/Android/Sdk/platform-tools$
```

----------------------------------------

TITLE: Executing Caffe Training Process via Shell
DESCRIPTION: Provides the shell commands to initiate the Caffe SSD model training. It first creates directories for snapshots and logs, then executes the Caffe training tool, specifying the solver configuration file (`solver.prototxt`), the GPU to use (GPU 0), and redirecting both standard output and error streams to a log file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/face_detector/how_to_train_face_detector.txt#2025-04-22_snippet_3

LANGUAGE: shell
CODE:
```
mkdir -p snapshot
mkdir -p log
/path_for_caffe_build_dir/tools/caffe train -solver="solver.prototxt" -gpu 0  2>&1 | tee -a log/log.log
```

----------------------------------------

TITLE: Handling Negative Slopes in Image Gradients with OpenCV Python
DESCRIPTION: This snippet demonstrates the importance of data type handling when working with gradient operators. It shows how using cv.CV_8U directly can result in losing edge information (negative transitions), while using cv.CV_64F with absolute value conversion preserves all edges.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_gradients/py_gradients.markdown#2025-04-22_snippet_1

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('box.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"

# Output dtype = cv.CV_8U
sobelx8u = cv.Sobel(img,cv.CV_8U,1,0,ksize=5)

# Output dtype = cv.CV_64F. Then take its absolute and convert to cv.CV_8U
sobelx64f = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)
abs_sobel64f = np.absolute(sobelx64f)
sobel_8u = np.uint8(abs_sobel64f)

plt.subplot(1,3,1),plt.imshow(img,cmap = 'gray')
plt.title('Original'), plt.xticks([]), plt.yticks([])
plt.subplot(1,3,2),plt.imshow(sobelx8u,cmap = 'gray')
plt.title('Sobel CV_8U'), plt.xticks([]), plt.yticks([])
plt.subplot(1,3,3),plt.imshow(sobel_8u,cmap = 'gray')
plt.title('Sobel abs(CV_64F)'), plt.xticks([]), plt.yticks([])

plt.show()
```

----------------------------------------

TITLE: Manipulating Matrices in Clojure Using OpenCV
DESCRIPTION: Closely follows the OpenCV Java tutorial, demonstrating matrix creation, element setting, and data output in Clojure. This showcases translating typical Java code constructs into Clojure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_18

LANGUAGE: clojure
CODE:
```
user=> (def m (Mat. 5 10 CvType/CV_8UC1 (Scalar. 0 0)))
#'user/m
user=> (def mr1 (.row m 1))
#'user/mr1
user=> (.setTo mr1 (Scalar. 1 0))
#<Mat Mat [ 1*10*CV_8UC1, isCont=true, isSubmat=true, nativeObj=0x7fc9dac49880, dataAddr=0x7fc9d9c98d5a ]>
user=> (def mc5 (.col m 5))
#'user/mc5
user=> (.setTo mc5 (Scalar. 5 0))
#<Mat Mat [ 5*1*CV_8UC1, isCont=false, isSubmat=true, nativeObj=0x7fc9d9c995a0, dataAddr=0x7fc9d9c98d55 ]>
user=> (println (.dump m))
[0, 0, 0, 0, 0, 5, 0, 0, 0, 0;
  1, 1, 1, 1, 1, 5, 1, 1, 1, 1;
  0, 0, 0, 0, 0, 5, 0, 0, 0, 0;
  0, 0, 0, 0, 0, 5, 0, 0, 0, 0;
  0, 0, 0, 0, 0, 5, 0, 0, 0, 0]
nil
```

----------------------------------------

TITLE: Configuring Build Structure with CMake for OpenCV - CMake
DESCRIPTION: This CMake script sets project build variables (such as a semihosting suffix and a raw pixel include path) and organizes the build process by including subdirectories that correspond to different OpenCV modules (headers, histogram, and normalization). It requires CMake and expects an existing directory structure for the specified subdirectories. Inputs include project-specific paths and variable definitions, and the outputs are the configured CMake build directories with their respective CMakeLists. Limitations include being meaningful only within the context of the OpenCV build system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/semihosting/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
# This file is part of OpenCV project.
# It is subject to the license terms in the LICENSE file found in the top-level directory
# of this distribution and at http://opencv.org/license.html

set(SEMIHOSTING_SUFFIX semihosting)

add_subdirectory(include)
set(RAW_PIXEL_INCLUDE ${CMAKE_CURRENT_BINARY_DIR}/include)
add_subdirectory(histogram)
add_subdirectory(norm)
```

----------------------------------------

TITLE: Configuring OpenCL Support Option for DNN Module - CMake
DESCRIPTION: Defines the CMake option OPENCV_DNN_OPENCL to enable or disable OpenCL support for accelerated computing in the DNN module. It is set based on whether HAVE_OPENCL is available and if the platform is not Apple. Key parameters: option name, help text, and logical condition. No immediate outputs, but downstream build logic will check this variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: CMake
CODE:
```
ocv_option(OPENCV_DNN_OPENCL "Build with OpenCL support" HAVE_OPENCL AND NOT APPLE)
```

----------------------------------------

TITLE: Test Module Configuration Class
DESCRIPTION: DataClass defining test module configuration including paths, image preprocessing parameters, and model settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_12

LANGUAGE: python
CODE:
```
@dataclass
class TestClsModuleConfig:
    cls_test_data_dir: str = "../data"
    test_module_name: str = "classification"
    test_module_path: str = "classification.py"
    input_img: str = os.path.join(cls_test_data_dir, "squirrel_cls.jpg")
    model: str = ""

    frame_height: str = str(TestClsConfig.frame_size)
    frame_width: str = str(TestClsConfig.frame_size)
    scale: str = "1.0"
    mean: List[str] = field(default_factory=lambda: ["0.0", "0.0", "0.0"])
    std: List[str] = field(default_factory=list)
    crop: str = "False"
    rgb: str = "True"
    rsz_height: str = ""
    rsz_width: str = ""
    classes: str = os.path.join(cls_test_data_dir, "dnn", "classification_classes_ILSVRC2012.txt")
```

----------------------------------------

TITLE: Including Optional Tutorial Subdirectories
DESCRIPTION: This part of the script adds tutorial and example subdirectories conditionally. It ensures that specific version requirements are met before including subdirectories for parallel backend examples or individual CMake examples. This modular approach helps manage optional content in the OpenCV sample setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
include("tutorial_code/calib3d/real_time_pose_estimation/CMakeLists.txt" OPTIONAL)

# Standalone samples only
if(OpenCV_FOUND AND NOT CMAKE_VERSION VERSION_LESS "3.1")
  add_subdirectory("example_cmake")
endif()
if(OpenCV_FOUND AND NOT CMAKE_VERSION VERSION_LESS "3.9"
    AND NOT OPENCV_EXAMPLES_SKIP_PARALLEL_BACKEND
)
  add_subdirectory("tutorial_code/core/parallel_backend")
endif()
```

----------------------------------------

TITLE: Calculating Mean Color/Intensity within Contour Mask in OpenCV Python
DESCRIPTION: This snippet calculates the mean color (for a color image) or mean intensity (for a grayscale image) within the region defined by a mask. It utilizes the `cv.mean` function, applying it to the input image (`im`) and considering only the pixels specified by the `mask`. Requires the input image `im` and a pre-computed `mask` image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_properties/py_contour_properties.markdown#2025-04-22_snippet_7

LANGUAGE: python
CODE:
```
mean_val = cv.mean(im,mask = mask)
```

----------------------------------------

TITLE: JPEG Compression Operation Structure in C
DESCRIPTION: Basic outline of a JPEG compression operation showing the typical sequence of function calls required for compressing an image using the IJG JPEG library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_0

LANGUAGE: C
CODE:
```
Allocate and initialize a JPEG compression object
Specify the destination for the compressed data (eg, a file)
Set parameters for compression, including image size & colorspace
jpeg_start_compress(...);
while (scan lines remain to be written)
        jpeg_write_scanlines(...);  /* Use jpeg12_write_scanlines() for
                                       9-bit through 12-bit data
                                       precision and
                                       jpeg16_write_scanlines() for
                                       13-bit through 16-bit data
                                       precision. */
jpeg_finish_compress(...);
Release the JPEG compression object
```

----------------------------------------

TITLE: Configuring x86 AVX512VNNI Optimizations for ZLIB in CMake
DESCRIPTION: Checks if AVX512VNNI optimization is enabled (WITH_AVX512VNNI), if intrinsics are available (HAVE_AVX512VNNI_INTRIN), and if AVX2 is also enabled. If supported, it adds the DX86_AVX512VNNI definition, adds feature information for AVX512VNNI adler32 support, appends the specific source file, and sets compile flags (AVX512VNNIFLAG, NOLTOFLAG). Otherwise, it disables AVX512VNNI support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_32

LANGUAGE: cmake
CODE:
```
        if(WITH_AVX512VNNI)
            check_avx512vnni_intrinsics()
            if(HAVE_AVX512VNNI_INTRIN AND WITH_AVX2)
                add_definitions(-DX86_AVX512VNNI)
                add_feature_info(AVX512VNNI_ADLER32 1 "Support AVX512VNNI adler32, using \"${AVX512VNNIFLAG}\"")
                list(APPEND AVX512VNNI_SRCS ${ARCHDIR}/adler32_avx512_vnni.c)
                list(APPEND ZLIB_ARCH_SRCS ${AVX512VNNI_SRCS})
                set_property(SOURCE ${AVX512VNNI_SRCS} PROPERTY COMPILE_FLAGS "${AVX512VNNIFLAG} ${NOLTOFLAG}")
            else()
                set(WITH_AVX512VNNI OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Configuring Android CPU Features Library Build in CMake
DESCRIPTION: Complete CMake configuration for building the Android CPU Features library. Sets up include directories, creates static library target, configures output paths and installation rules. Uses conditional logic to handle Android-specific setup and shared library builds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/cpufeatures/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(NOT ANDROID)
  message("cpufeatures is ANDROID project")
endif()

ocv_update(OPENCV_CPUFEATURES_TARGET_NAME libcpufeatures)

set(CPUFEATURES_ROOT "${CMAKE_CURRENT_SOURCE_DIR}" CACHE PATH "Android cpufeatures project sources (for example, <android-ndk>/sources/android/cpufeatures)")

set(CPUFEATURES_INCLUDE_DIRS ${CPUFEATURES_ROOT} CACHE INTERNAL "")
set(CPUFEATURES_LIBRARIES "${OPENCV_CPUFEATURES_TARGET_NAME}" CACHE INTERNAL "")

if(NOT DEFINED CPUFEATURES_SOURCES)
  set(CPUFEATURES_SOURCES ${CPUFEATURES_ROOT}/cpu-features.c ${CPUFEATURES_ROOT}/cpu-features.h)
endif()

include_directories(${CPUFEATURES_INCLUDE_DIRS})
add_library(${OPENCV_CPUFEATURES_TARGET_NAME} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${CPUFEATURES_SOURCES})

set_target_properties(${OPENCV_CPUFEATURES_TARGET_NAME}
  PROPERTIES OUTPUT_NAME cpufeatures
  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
  COMPILE_PDB_NAME cpufeatures
  COMPILE_PDB_NAME_DEBUG "cpufeatures${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
)

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${OPENCV_CPUFEATURES_TARGET_NAME} PROPERTIES FOLDER "3rdparty")
endif()

if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${OPENCV_CPUFEATURES_TARGET_NAME} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(cpufeatures LICENSE README.md)
```

----------------------------------------

TITLE: Automated Sample Target Definition and Linking for OpenCV TAPI - CMake
DESCRIPTION: Iterates over all TAPI sample source files, defining build targets via ocv_define_sample and linking required OpenCV libraries. Ensures each sample is set up as a separate build target and properly linked with both OpenCV's global linker libraries and the specific dependencies defined for TAPI. This step automates boilerplate target setup for each example in the samples directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/tapi/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
foreach(sample_filename ${all_samples})
  ocv_define_sample(tgt ${sample_filename} tapi)
  ocv_target_link_libraries(${tgt} PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_TAPI_SAMPLES_REQUIRED_DEPS})
endforeach()
```

----------------------------------------

TITLE: Third-Party Build Configuration Options
DESCRIPTION: Defines build options for various third-party libraries including zlib, libtiff, OpenJPEG, and others. Configures conditional builds based on platform and user preferences.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
OCV_OPTION(OPENCV_FORCE_3RDPARTY_BUILD   "Force using 3rdparty code from source" OFF)
OCV_OPTION(BUILD_ZLIB               "Build zlib from source"             (WIN32 OR APPLE OR OPENCV_FORCE_3RDPARTY_BUILD) )
OCV_OPTION(BUILD_TIFF               "Build libtiff from source"          (WIN32 OR ANDROID OR APPLE OR OPENCV_FORCE_3RDPARTY_BUILD) )
OCV_OPTION(BUILD_OPENJPEG           "Build OpenJPEG from source"         (WIN32 OR ANDROID OR APPLE OR OPENCV_FORCE_3RDPARTY_BUILD) )
OCV_OPTION(BUILD_JASPER             "Build libjasper from source"        (WIN32 OR ANDROID OR APPLE OR OPENCV_FORCE_3RDPARTY_BUILD) )
OCV_OPTION(BUILD_JPEG               "Build libjpeg from source"          (WIN32 OR ANDROID OR APPLE OR OPENCV_FORCE_3RDPARTY_BUILD) )
OCV_OPTION(BUILD_PNG                "Build libpng from source"           (WIN32 OR ANDROID OR APPLE OR OPENCV_FORCE_3RDPARTY_BUILD) )
```

----------------------------------------

TITLE: Default Input Preprocessing Configuration for MobileNet (Python)
DESCRIPTION: Provides an example dictionary configuring default image preprocessing for MobileNet in the test pipeline, specifying mean subtraction, scale normalization, crop options, and color format. This block is typically found in default_preprocess_config.py and is a required dependency for standardized testing. Key-value pairs in tf_input_blob are referenced by the pipeline during preprocessing. Inputs must match preprocessing needs of the model; outputs affect how images are prepared for inference.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/tf_cls_model_conversion_tutorial.md#2025-04-22_snippet_6

LANGUAGE: python
CODE:
```
tf_input_blob = {
    "mean": ["127.5", "127.5", "127.5"],
    "scale": str(1 / 127.5),
    "std": [],
    "crop": "True",
    "rgb": "True"
}
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree in C++
DESCRIPTION: Complex nested conditional structure for comparing pixel intensities against threshold values in the FAST corner detection algorithm. Uses goto statements for control flow between success and structured cases based on pixel intensity comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_24

LANGUAGE: C++
CODE:
```
                                    goto success_structured;
                                  else
                                    goto structured;
                                else
                                  goto structured;
                              else
                                goto structured;
                          else
                            goto structured;
                      else
                        if(ptr[offset3] > cb)
                          if(ptr[offset4] > cb)
                            if(ptr[offset7] > cb)
                              if(ptr[offset1] > cb)
                                if(ptr[offset6] > cb)
                                  goto success_structured;
                                else
                                  if(ptr[offset11] > cb)
                                    goto success_structured;
                                  else
                                    goto structured;
                              else
                                if(ptr[offset6] > cb)
                                  if(ptr[offset8] > cb)
                                    goto success_structured;
                                  else
                                    goto structured;
                                else
                                  goto structured;
                            else
                              if(ptr[offset1] > cb)
                                if(ptr[offset6] > cb)
                                  goto success_structured;
                                else
                                  if(ptr[offset11] > cb)
                                    goto success_structured;
                                  else
                                    goto structured;
                              else
                                goto structured;
                          else
                            goto structured;
                        else
                          goto structured;
                    else
                      if(ptr[offset7] < c_b)
                        if(ptr[offset9] < c_b)
                          if(ptr[offset5] < c_b)
                            if(ptr[offset1] > cb)
                              if(ptr[offset4] > cb)
                                if(ptr[offset10] > cb)
                                  if(ptr[offset3] > cb)
                                    if(ptr[offset11] > cb)
                                      goto success_structured;
                                    else
                                      goto structured;
                                  else
                                    goto structured;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset8] < c_b)
                                      if(ptr[offset11] < c_b)
                                        if(ptr[offset10] < c_b)
                                          goto success_structured;
                                        else
                                          goto structured;
                                      else
                                        goto structured;
                                    else
                                      goto structured;
                                  else
                                    goto structured;
                              else
                                if(ptr[offset6] < c_b)
                                  if(ptr[offset8] < c_b)
                                    if(ptr[offset10] < c_b)
                                      if(ptr[offset4] < c_b)
                                        goto success_structured;
                                      else
                                        if(ptr[offset11] < c_b)
                                          goto success_structured;
                                        else
                                          goto structured;
                                    else
                                      if(ptr[offset3] < c_b)
                                        if(ptr[offset4] < c_b)
                                          goto success_structured;
                                        else
                                          goto structured;
                                      else
                                        goto structured;
                                  else
                                    goto structured;
                                else
                                  goto structured;
```

----------------------------------------

TITLE: Initializing Custom Destination Manager in JPEG Library (C)
DESCRIPTION: Defines the `init_destination` function signature, a required method for a custom `jpeg_destination_mgr`. This function is called by `jpeg_start_compress()` before any compressed data is written. Its purpose is to perform any necessary setup for the destination manager and initialize the `next_output_byte` and `free_in_buffer` fields. `free_in_buffer` must be set to a positive value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_50

LANGUAGE: c
CODE:
```
init_destination (j_compress_ptr cinfo)
```

----------------------------------------

TITLE: Configuring IPP IW Library Build in CMake
DESCRIPTION: Sets up the IPP IW library project, including source files, include directories, and compiler definitions. It also configures platform-specific compiler flags and defines the library target with appropriate properties.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ippicv/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(${IPP_IW_LIBRARY})

ocv_include_directories(${IPP_INCLUDE_DIRS} ${IPP_IW_PATH}/include)
add_definitions(-DIW_BUILD)
if(HAVE_IPP_ICV)
  add_definitions(-DICV_BASE)
endif()

file(GLOB lib_srcs ${IPP_IW_PATH}/src/*.c ${IPP_IW_PATH}/src/*.cpp)
file(GLOB lib_hdrs ${IPP_IW_PATH}/include/*.h ${IPP_IW_PATH}/include/iw/*.h ${IPP_IW_PATH}/include/iw++/*.hpp)

add_library(${IPP_IW_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${lib_srcs} ${lib_hdrs})

if(UNIX)
  if(CV_GCC OR CV_CLANG OR CV_ICC)
    set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -Wno-unused-function -Wno-missing-braces -Wno-missing-field-initializers")
  endif()
  if(CV_CLANG)
    set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -Wno-self-assign -Wno-strict-prototypes")
  endif()
endif()

set_target_properties(${IPP_IW_LIBRARY}
  PROPERTIES OUTPUT_NAME ${IPP_IW_LIBRARY}
  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
  COMPILE_PDB_NAME ${IPP_IW_LIBRARY}
  COMPILE_PDB_NAME_DEBUG "${IPP_IW_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
  )

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${IPP_IW_LIBRARY} PROPERTIES FOLDER "3rdparty")
endif()

if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${IPP_IW_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()
```

----------------------------------------

TITLE: Defining 16-Bit JPEG Pixel Sample Data Structures in C
DESCRIPTION: Defines C typedefs for handling 16-bit pixel sample data within the libjpeg library. `J16SAMPLE` represents a single unsigned 16-bit pixel component (0-65535), typically implemented as `unsigned short`. `J16SAMPROW` is a pointer to a row of `J16SAMPLE` values. `J16SAMPARRAY` points to an array of rows. `J16SAMPIMAGE` points to an array of component arrays. This maintains the consistent pointer-per-row design for different bit depths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/structure.txt#2025-04-22_snippet_2

LANGUAGE: c
CODE:
```
    typedef something J16SAMPLE;        a pixel component value, 0..MAXJ16SAMPLE
    typedef J16SAMPLE *J16SAMPROW;      ptr to a row of samples
    typedef J16SAMPROW *J16SAMPARRAY;   ptr to a list of rows
    typedef J16SAMPARRAY *J16SAMPIMAGE; ptr to a list of color-component arrays
```

----------------------------------------

TITLE: GStreamer Configuration Option in OpenCV
DESCRIPTION: Defines the WITH_GSTREAMER build option which enables integration with the GStreamer library for decoding and encoding video files, capturing frames from cameras and network streams.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_12

LANGUAGE: markdown
CODE:
```
`WITH_GSTREAMER` (default: _ON_)
```

----------------------------------------

TITLE: Displaying ZLIB Architecture-Specific Sources in CMake
DESCRIPTION: This CMake command prints a status message listing the architecture-specific source files that have been added to the `ZLIB_ARCH_SRCS` variable based on the detected CPU features and enabled optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_34

LANGUAGE: cmake
CODE:
```
message(STATUS "Architecture-specific source files: ${ZLIB_ARCH_SRCS}")
```

----------------------------------------

TITLE: Exiting the Clojure REPL Session
DESCRIPTION: Simple command to exit the active Clojure REPL session, marking the end of an interactive programming session within the Clojure environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_19

LANGUAGE: clojure
CODE:
```
user=> (exit)
Bye for now!
```

----------------------------------------

TITLE: AGAST Function with Default Corner Pattern
DESCRIPTION: Simplified AGAST function that automatically uses the OAST_9_16 pattern. It serves as a convenience wrapper for the main AGAST implementation, providing a simpler interface for basic feature detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_42

LANGUAGE: C++
CODE:
```
void AGAST(InputArray _img, std::vector<KeyPoint>& keypoints, int threshold, bool nonmax_suppression)
{
    AGAST(_img, keypoints, threshold, nonmax_suppression, AgastFeatureDetector::OAST_9_16);
}
```

----------------------------------------

TITLE: Declaring Doxygen Warning Documentation Comment - C++/Doxygen
DESCRIPTION: This snippet demonstrates how to use a Doxygen-style documentation comment with an @warning tag in C++. This allows custom warning messages to be included in the generated documentation, such as notifying users that the function returns a cv::Mat object. No external dependencies are required except Doxygen. To use, place the comment above your function or class; Doxygen will extract it and display the warning in generated docs. Input is the comment itself and output is the formatted warning in docs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/cross_referencing/tutorial_cross_referencing.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
/**
 * @warning This functions returns a cv::Mat.
 */
```

----------------------------------------

TITLE: Creating OpenCV Mat with the create() Function in C++
DESCRIPTION: Demonstrates using the Mat::create() function to allocate memory for a matrix. This method only reallocates if the new size doesn't fit in the old memory allocation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
// create is another way, but don't use this if you want to initialize with values
M.create(4,4, CV_8UC(2));
cout << "M = " << endl << " " << M << endl << endl;
```

----------------------------------------

TITLE: Drawing Detected ChArUco Diamond Markers with OpenCV ArUco (C++)
DESCRIPTION: This snippet shows how to overlay the results of ChArUco diamond marker detection on an image using cv::aruco::drawDetectedDiamonds(). It takes the original image, the detected diamond corners, and their associated IDs as inputs and visually highlights the diamonds by drawing their outlines and marker IDs on the image. This step is typically performed after successful detection and helps visualize recognition results for validation or debugging. The function requires dependencies on OpenCV's aruco module and expects the outputs from detectDiamonds().
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_diamond_detection/charuco_diamond_detection.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
// Draw detected diamonds on the image
cv::Mat imageWithDiamonds = image.clone();
cv::aruco::drawDetectedDiamonds(imageWithDiamonds, diamondCorners, diamondIds);
cv::imshow("Detected Diamonds", imageWithDiamonds);
cv::waitKey(0);
```

----------------------------------------

TITLE: Corner Detection Conditional Logic in C++
DESCRIPTION: Complex nested conditional logic implementing corner detection by comparing pixel values at different offsets against threshold values. Uses goto statements to branch to 'is_a_corner' or 'is_not_a_corner' based on comparison results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_18

LANGUAGE: C++
CODE:
```
goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  if(ptr[offset8] > cb)
                                    if(ptr[offset10] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset3] > cb)
                                  if(ptr[offset4] > cb)
                                    goto is_a_corner;
                                  else
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  if(ptr[offset8] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                              else
                                if(ptr[offset11] > cb)
                                  if(ptr[offset3] > cb)
                                    if(ptr[offset4] > cb)
                                      goto is_a_corner;
                                    else
                                      if(ptr[offset10] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                  else
                                    if(ptr[offset8] > cb)
                                      if(ptr[offset10] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
```

----------------------------------------

TITLE: Setting Stitching Module Description in CMake
DESCRIPTION: Sets the description for the stitching module in OpenCV. This description is used in the build system to identify the purpose of the module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/stitching/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(the_description "Images stitching")
```

----------------------------------------

TITLE: Architecture Detection and Configuration
DESCRIPTION: Detects CPU architecture and sets appropriate directory paths for architecture-specific optimizations
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_17

LANGUAGE: cmake
CODE:
```
set(GENERIC_ARCHDIR "arch/generic")

set(ZLIB_ARCH_SRCS)
set(ZLIB_ARCH_HDRS ${GENERIC_ARCHDIR}/generic_functions.h)

if(BASEARCH_ARM_FOUND)
    set(ARCHDIR "arch/arm")
elseif(BASEARCH_PPC_FOUND)
    set(ARCHDIR "arch/power")
elseif(BASEARCH_RISCV_FOUND)
    set(ARCHDIR "arch/riscv")
elseif(BASEARCH_S360_FOUND)
    set(ARCHDIR "arch/s390")
elseif(BASEARCH_X86_FOUND)
    set(ARCHDIR "arch/x86")
    if(NOT ${ARCH} MATCHES "x86_64")
        add_feature_info(SSE2 1 "Support the SSE2 instruction set, using \"${SSE2FLAG}\"")
    endif()
else()
    set(ARCHDIR ${GENERIC_ARCHDIR})
    message(STATUS "No optimized architecture: using ${ARCHDIR}")
endif()
```

----------------------------------------

TITLE: Displaying Frame Number on Video Output
DESCRIPTION: Extracts the current frame number from VideoCapture and displays it in the top-left corner of the frame. A white rectangle is drawn behind the text to improve visibility.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/background_subtraction.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
//get the frame number and write it on the current frame
rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
          cv::Scalar(255,255,255), -1);
stringstream ss;
ss << capture.get(CAP_PROP_POS_FRAMES);
string frameNumberString = ss.str();
putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
        FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
```

LANGUAGE: Java
CODE:
```
// get the frame number and write it on the current frame
Imgproc.rectangle(frame, new Point(10, 2), new Point(100,20), new Scalar(255,255,255), -1);
String frameNumberString = String.format("%d", (int)capture.get(Videoio.CAP_PROP_POS_FRAMES));
Imgproc.putText(frame, frameNumberString, new Point(15, 15), Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0,0,0));
```

LANGUAGE: Python
CODE:
```
# get the frame number and write it on the current frame
cv.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)
frame_number = str(int(cap.get(cv.CAP_PROP_POS_FRAMES)))
cv.putText(frame, frame_number, (15, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0))
```

----------------------------------------

TITLE: Executing Pixel Comparison Decision Tree for Feature Classification in C++
DESCRIPTION: This C++ code snippet executes a pre-defined decision tree by comparing pixel intensity values, accessed via `ptr` and pre-calculated `offset` variables, against thresholds `cb` and `c_b`. The nested `if` conditions and `goto` statements implement a highly optimized check, likely for feature detection (e.g., FAST corners), classifying the central pixel and jumping to specific labels (`success_homogeneous`, `homogeneous`, `success_structured`, `structured`) based on the comparison outcomes. It requires `ptr`, `offset` variables, `cb`, `c_b`, and the target labels to be defined in the surrounding context.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
                                    goto success_homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                if(ptr[offset6] > cb)
                                  if(ptr[offset7] > cb)
                                    if(ptr[offset8] > cb)
                                      goto success_homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset1] > cb)
                                if(ptr[offset3] > cb)
                                  if(ptr[offset4] > cb)
                                    goto success_homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        if(ptr[offset9] > cb)
                          if(ptr[offset7] > cb)
                            if(ptr[offset8] > cb)
                              if(ptr[offset10] > cb)
                                if(ptr[offset11] > cb)
                                  if(ptr[offset1] > cb)
                                    goto success_homogeneous;
                                  else
                                    if(ptr[offset6] > cb)
                                      goto success_homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                else
                if(ptr[offset0] < c_b)
                  if(ptr[offset2] > cb)
                    if(ptr[offset5] > cb)
                      if(ptr[offset7] > cb)
                        if(ptr[offset6] > cb)
                          if(ptr[offset4] > cb)
                            if(ptr[offset3] > cb)
                              if(ptr[offset1] > cb)
                                goto success_homogeneous;
                              else
                                if(ptr[offset8] > cb)
                                  goto success_homogeneous;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset9] > cb)
                                if(ptr[offset8] > cb)
                                  if(ptr[offset10] > cb)
                                    goto success_structured;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset9] > cb)
                              if(ptr[offset8] > cb)
                                if(ptr[offset10] > cb)
                                  if(ptr[offset11] > cb)
                                    goto success_structured;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        if(ptr[offset9] < c_b)
                          if(ptr[offset8] < c_b)
                            if(ptr[offset10] < c_b)
                              if(ptr[offset11] < c_b)
                                if(ptr[offset7] < c_b)
                                  if(ptr[offset1] < c_b)
                                    goto success_structured;
                                  else
                                    if(ptr[offset6] < c_b)
                                      goto success_structured;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                    else
                      if(ptr[offset9] < c_b)
                        if(ptr[offset7] < c_b)
                          if(ptr[offset8] < c_b)
                            if(ptr[offset5] < c_b)
                              if(ptr[offset1] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto success_structured;
                                  else
                                    if(ptr[offset6] < c_b)
                                      if(ptr[offset4] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto homogeneous;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset3] < c_b)
                                      if(ptr[offset4] < c_b)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                if(ptr[offset6] < c_b)
                                  if(ptr[offset4] < c_b)
                                    if(ptr[offset3] < c_b)
                                      goto success_structured;
                                    else
                                      if(ptr[offset10] < c_b)
                                        goto success_structured;
                                      else
                                        goto homogeneous;
                                  else
                                    if(ptr[offset10] < c_b)
                                      if(ptr[offset11] < c_b)
                                        goto success_structured;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  if(ptr[offset1] < c_b)
                                    goto success_homogeneous;
                                  else
                                    if(ptr[offset6] < c_b)
                                      goto success_homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        goto homogeneous;
                  else
                    if(ptr[offset2] < c_b)
                      if(ptr[offset9] > cb)
                        if(ptr[offset5] > cb)
                          if(ptr[offset1] < c_b)
                            if(ptr[offset4] < c_b)
                              if(ptr[offset10] < c_b)
                                if(ptr[offset3] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto success_structured;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                if(ptr[offset6] > cb)
                                  if(ptr[offset7] > cb)
                                    if(ptr[offset8] > cb)
                                      if(ptr[offset11] > cb)
                                        if(ptr[offset10] > cb)
                                          goto success_structured;
                                        else
                                          goto structured;
```

----------------------------------------

TITLE: Configuring s390 Intrinsics and Features for ZLIB in CMake
DESCRIPTION: Checks for s390 architecture (BASEARCH_S360_FOUND) and available intrinsics (HAVE_S390_INTRIN). If intrinsics are found, it adds definitions and appends s390-specific header and source files to ZLIB build lists, enabling runtime CPU detection if configured (WITH_RUNTIME_CPU_DETECTION).
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_20

LANGUAGE: cmake
CODE:
```
    elseif(BASEARCH_S360_FOUND)
        check_s390_intrinsics()
        if(HAVE_S390_INTRIN)
            add_definitions(-DS390_FEATURES)
            list(APPEND ZLIB_ARCH_HDRS ${ARCHDIR}/s390_functions.h)
            if(WITH_RUNTIME_CPU_DETECTION)
                list(APPEND ZLIB_ARCH_HDRS ${ARCHDIR}/s390_features.h)
                list(APPEND ZLIB_ARCH_SRCS ${ARCHDIR}/s390_features.c)
            endif()
        endif()
```

----------------------------------------

TITLE: Building OpenCV.js with Performance Tests - Bash
DESCRIPTION: This bash command builds OpenCV.js with performance tests enabled via the '--build_perf' switch. It is run using emcmake, Python, and the OpenCV JS build script. The resulting build includes performance testing suites such as 'cvtColor', 'resize', and 'threshold'. Outputs are performance test binaries suitable for benchmarking using either a local HTTP server in browsers or Node.js.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_21

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --build_perf
```

----------------------------------------

TITLE: Configuring and Validating Dependencies for OpenCV SYCL Samples - CMake
DESCRIPTION: This CMake snippet checks for build-related variables and required dependencies before configuring the OpenCV SYCL sample projects. It ensures that the necessary modules (opencv_core, opencv_imgproc, etc.) are present and only proceeds if conditions like minimum CMake version and build flags are satisfied. It demonstrates conditional flow, dependency registration, and version checks required to safely prepare a heterogeneous build environment for SYCL samples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/sycl/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(OPENCV_SKIP_SAMPLES_SYCL)
  return()
endif()

ocv_install_example_src(sycl *.cpp *.hpp CMakeLists.txt)

set(OPENCV_SYCL_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui)
ocv_check_dependencies(${OPENCV_SYCL_SAMPLES_REQUIRED_DEPS})

if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND OR OPENCV_SKIP_SAMPLES_BUILD_SYCL)
  return()
endif()

if(CMAKE_VERSION VERSION_LESS "3.5")
  message(STATUS "SYCL samples require CMake 3.5+")
  return()
endif()

cmake_policy(VERSION 3.5)
```

----------------------------------------

TITLE: Aggregating Image Paths for Doxygen Configuration in CMake
DESCRIPTION: Collects various directory paths containing images required for the Doxygen documentation into a single CMake list variable `doxygen_image_path`. This includes common images, module-specific doc folders, tutorial paths (core, Python, JavaScript, module-specific), the main source directory, module directories, contrib module paths, and any custom user-defined paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
set(doxygen_image_path
    ${CMAKE_CURRENT_SOURCE_DIR}/images
    ${paths_doc}
    ${tutorial_path}
    ${tutorial_py_path}
    ${tutorial_js_path}
    ${paths_tutorial}
    #${OpenCV_SOURCE_DIR}/samples/data         # TODO: need to resolve ambiguous conflicts first
    ${OpenCV_SOURCE_DIR}
    ${OpenCV_SOURCE_DIR}/modules               # <opencv>/modules
    ${OPENCV_EXTRA_MODULES_PATH}               # <opencv_contrib>/modules
    ${OPENCV_DOCS_EXTRA_IMAGE_PATH}            # custom variable for user modules
)
```

----------------------------------------

TITLE: Setting an Environment Variable for a Single Linux Command
DESCRIPTION: This one-liner shell snippet sets the 'MY_ENV_VARIABLE' environment variable only for the execution scope of './my_app'. Dependencies: POSIX-compatible shell. No global state is changed. Useful for short-lived overrides.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/env_reference/env_reference.markdown#2025-04-22_snippet_2

LANGUAGE: sh
CODE:
```
MY_ENV_VARIABLE=true ./my_app
```

----------------------------------------

TITLE: Disabling DNN Module for Windows RT - CMake
DESCRIPTION: This snippet conditionally disables the dnn module if WINRT is set, preventing builds on Windows RT platforms. This is controlled by checking the 'WINRT' CMake variable and calling 'ocv_module_disable'. No parameters beyond WINRT are required. Intended for platform-specific source exclusion within the build system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(WINRT)
  ocv_module_disable(dnn)
endif()
```

----------------------------------------

TITLE: Nested Conditional Pixel Comparison for FAST Corner Detection in OpenCV
DESCRIPTION: This snippet shows a portion of the FAST corner detection algorithm which compares pixel values against thresholds. The code uses conditional statements to check if pixels at various offsets are above or below thresholds (cb and c_b), determining potential corner points in an image. The algorithm continues or proceeds to a success state based on these comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_35

LANGUAGE: C++
CODE:
```
{} // goto success_homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  if(ptr[offset1] > cb)
    if(ptr[offset12] > cb)
      if(ptr[offset13] > cb)
        if(ptr[offset14] > cb)
          if(ptr[offset15] > cb)
            {} // goto success_homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
if(ptr[offset9] < c_b)
  if(ptr[offset7] < c_b)
    if(ptr[offset8] < c_b)
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          if(ptr[offset6] < c_b)
            if(ptr[offset5] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  {} // goto success_homogeneous;
                else
                  if(ptr[offset12] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset12] < c_b)
                if(ptr[offset13] < c_b)
                  if(ptr[offset14] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset12] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
if(ptr[offset0] < c_b)
  if(ptr[offset2] > cb)
    if(ptr[offset9] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset6] > cb)
            if(ptr[offset5] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset3] > cb)
                  if(ptr[offset1] > cb)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset10] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      if(ptr[offset12] > cb)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
              else
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    if(ptr[offset12] > cb)
                      if(ptr[offset13] > cb)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
            else
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset12] > cb)
                    if(ptr[offset13] > cb)
                      if(ptr[offset14] > cb)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset12] > cb)
                  if(ptr[offset13] > cb)
                    if(ptr[offset14] > cb)
                      if(ptr[offset15] > cb)
                        {} // goto success_homogeneous;
                      else
                        continue; // goto homogeneous;
                    else
                      continue; // goto homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
    if(ptr[offset9] < c_b)
      if(ptr[offset10] < c_b)
        if(ptr[offset11] < c_b)
          if(ptr[offset8] < c_b)
            if(ptr[offset12] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset7] < c_b)
                        {} // goto success_homogeneous;
                      else
```

----------------------------------------

TITLE: Destroying JPEG Compression Object in C
DESCRIPTION: This snippet illustrates how to destroy a JPEG compression object using 'jpeg_destroy_compress'. This frees all associated resources. Developers must manually free any additional allocations such as structures created with malloc().
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_9

LANGUAGE: C
CODE:
```
jpeg_destroy_compress(&cinfo);
```

----------------------------------------

TITLE: Configuring x86 PCLMULQDQ Optimization for ZLIB in CMake
DESCRIPTION: Checks if PCLMULQDQ optimization is enabled (WITH_PCLMULQDQ), if intrinsics are available (HAVE_PCLMULQDQ_INTRIN), and if SSE4.2 is also enabled. If supported, it adds the DX86_PCLMULQDQ_CRC definition for CRC32 calculation, appends the specific source file (`crc32_pclmulqdq.c`), adds feature information, and sets compile flags (SSE42FLAG, PCLMULFLAG, NOLTOFLAG). Otherwise, it disables PCLMULQDQ support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_29

LANGUAGE: cmake
CODE:
```
        if(WITH_PCLMULQDQ)
            check_pclmulqdq_intrinsics()
            if(HAVE_PCLMULQDQ_INTRIN AND WITH_SSE42)
                add_definitions(-DX86_PCLMULQDQ_CRC)
                set(PCLMULQDQ_SRCS ${ARCHDIR}/crc32_pclmulqdq.c)
                add_feature_info(PCLMUL_CRC 1 "Support CRC hash generation using PCLMULQDQ, using \"${SSE42FLAG} ${PCLMULFLAG}\"")
                list(APPEND ZLIB_ARCH_SRCS ${PCLMULQDQ_SRCS})
                set_property(SOURCE ${PCLMULQDQ_SRCS} PROPERTY COMPILE_FLAGS "${SSE42FLAG} ${PCLMULFLAG} ${NOLTOFLAG}")
            else()
                set(WITH_PCLMULQDQ OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Configuring OpenCV Modules and Source Files with CMake
DESCRIPTION: This CMake script sets up the dependencies for an OpenCV application by specifying required OpenCV modules (such as opencv_core, opencv_imgproc, and others) and gathers C++ source files with a glob pattern. It then registers the application 'opencv_interactive-calibration' using these modules and source files, simplifying the build system setup. Dependencies include an installed version of OpenCV with the listed modules available, and the expected input consists of C++ source files in the current directory. The setup is constrained to OpenCV and CMake environments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/interactive-calibration/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(DEPS opencv_core opencv_imgproc opencv_features2d opencv_highgui opencv_calib3d opencv_videoio opencv_objdetect)
file(GLOB SRCS *.cpp)
ocv_add_application(opencv_interactive-calibration MODULES ${DEPS} SRCS ${SRCS})
```

----------------------------------------

TITLE: Defining 8-Bit JPEG Pixel Sample Data Structures in C
DESCRIPTION: Defines C typedefs for handling 8-bit pixel sample data within the libjpeg library. `JSAMPLE` represents a single unsigned 8-bit pixel component (0-255). `JSAMPROW` is a pointer to a row of `JSAMPLE` values. `JSAMPARRAY` is a pointer to an array of `JSAMPROW` (representing a 2D image plane or component). `JSAMPIMAGE` is a pointer to an array of `JSAMPARRAY` (representing multiple color components). This structure uses pointers per row for flexibility and potential performance benefits.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/structure.txt#2025-04-22_snippet_0

LANGUAGE: c
CODE:
```
    typedef something JSAMPLE;          a pixel component value, 0..MAXJSAMPLE
    typedef JSAMPLE *JSAMPROW;          ptr to a row of samples
    typedef JSAMPROW *JSAMPARRAY;       ptr to a list of rows
    typedef JSAMPARRAY *JSAMPIMAGE;     ptr to a list of color-component arrays
```

----------------------------------------

TITLE: Configuring Installation Root with CMake - Shell
DESCRIPTION: Configures the installation root directory for OpenCV build artifacts by specifying the CMAKE_INSTALL_PREFIX variable to a custom absolute path. Requires 'cmake' to be installed and assumes the source code is in '../opencv'. No build is performed; this step only generates configuration for subsequent build steps.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_20

LANGUAGE: shell
CODE:
```
cmake -DCMAKE_INSTALL_PREFIX=/opt/opencv ../opencv
```

----------------------------------------

TITLE: Defining Example Source Installation Function (OpenCV Build) in CMake
DESCRIPTION: Defines a CMake function `ocv_install_example_src` used when building as part of OpenCV. It takes a relative path `relpath` and a list of files (`ARGN`). If the `INSTALL_C_EXAMPLES` CMake variable is ON, it installs the specified files to the `${OPENCV_SAMPLES_SRC_INSTALL_PATH}/${relpath}` directory as part of the `samples` component.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
function(ocv_install_example_src relpath)
  if(INSTALL_C_EXAMPLES)
    file(GLOB files ${ARGN})
    install(FILES ${files}
            DESTINATION "${OPENCV_SAMPLES_SRC_INSTALL_PATH}/${relpath}"
            COMPONENT samples)
  endif()
endfunction()
```

----------------------------------------

TITLE: Configuring Arithmetic/Huffman Coding in libjpeg (C)
DESCRIPTION: A C boolean field within the compression parameters structure (`cinfo`). Set to TRUE to enable arithmetic coding for entropy coding, or FALSE (the default) to use Huffman coding. Arithmetic coding can sometimes offer slightly better compression ratios but may be slower or less widely supported.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_30

LANGUAGE: C
CODE:
```
boolean arith_code
```

----------------------------------------

TITLE: Adding Vendor AI Accelerator Support (TimVX, CANN, WebNN) to DNN Module - CMake
DESCRIPTION: If TimVX, CANN, or WebNN support is enabled, appends their respective include directories and links libraries with whole-archive flags for linker. This enables hardware acceleration for compatible platforms. Inputs: HAVE_TIMVX, HAVE_CANN, HAVE_WEBNN; outputs: extra include directories and linker flags for specified libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_19

LANGUAGE: CMake
CODE:
```
if(HAVE_TIMVX)
    list(APPEND include_dirs ${TIMVX_INCLUDE_DIR})
    list(APPEND libs -Wl,--whole-archive ${TIMVX_LIBRARY} -Wl,--no-whole-archive)
endif()

if(HAVE_CANN)
  list(APPEND include_dirs ${CANN_INCLUDE_DIRS})
  list(APPEND libs -Wl,--whole-archive ${CANN_LIBRARIES} -Wl,--no-whole-archive)
endif()

set(webnn_srcs "")
if(NOT EMSCRIPTEN)
  if(HAVE_WEBNN)
    list(APPEND include_dirs ${WEBNN_HEADER_DIRS})
    list(APPEND include_dirs ${WEBNN_INCLUDE_DIRS})
    list(APPEND libs -Wl,--whole-archive ${WEBNN_LIBRARIES} -Wl,--no-whole-archive)
    list(APPEND webnn_srcs $ENV{WEBNN_NATIVE_DIR}/gen/src/webnn/webnn_cpp.cpp)
  endif()
endif()
```

----------------------------------------

TITLE: Simple OpenCV C++ Program
DESCRIPTION: A C++ program that prints OpenCV build information. Demonstrates basic use of OpenCV library in C++ on the target platform.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_26

LANGUAGE: cpp
CODE:
```
#include <iostream>
#include <opencv2/core.hpp>
int main(void)
{
  std::cout << cv::getBuildInformation() << std::endl;
  return 0;
}
```

----------------------------------------

TITLE: Drawing a Line in Java
DESCRIPTION: Implementation of the MyLine function that draws a line between two points in OpenCV Java. The function takes the image, start and end points, and uses the line() function with specified thickness and line type.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_16

LANGUAGE: java
CODE:
```
private static void MyLine(Mat img, Point start, Point end) {
    int thickness = 2;
    int lineType = Core.LINE_8;

    Imgproc.line(img,
            start,
            end,
            new Scalar(0, 0, 0),
            thickness,
            lineType);
}
```

----------------------------------------

TITLE: Applying Laplacian Operator Full Example in Java
DESCRIPTION: Complete Java code demonstrating loading an image, applying Gaussian blur, converting to grayscale, using the Laplacian operator for edge detection with Imgproc.Laplacian, converting the result to CV_8U, and displaying it using Swing. This code relies on the OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
// The tutorial code's is shown lines below. You can also download it from
// [here](https://raw.githubusercontent.com/opencv/opencv/4.x/samples/java/tutorial_code/ImgTrans/LaPlace/LaplaceDemo.java)
@include samples/java/tutorial_code/ImgTrans/LaPlace/LaplaceDemo.java
```

----------------------------------------

TITLE: Generating Integer FourCC Code using CV_FOURCC Macro (C++)
DESCRIPTION: Demonstrates using the OpenCV `CV_FOURCC` macro to generate the integer representation of a FourCC codec identifier directly from four character literals (e.g., 'P','I','M','1' for the MPEG1 codec). This is useful when the desired codec is known beforehand.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
CV_FOURCC('P','I','M,'1') // this is an MPEG1 codec from the characters to integer
```

----------------------------------------

TITLE: Loading Camera Intrinsic Parameters in OpenCV C++
DESCRIPTION: Code to load camera intrinsic parameters from a file. These parameters include the camera matrix and distortion coefficients needed for undistorting image points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/homography/homography.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
cv::Mat cameraMatrix, distCoeffs;
// Load camera calibration parameters
cv::FileStorage fs(intrinsicPath, cv::FileStorage::READ);
fs["camera_matrix"] >> cameraMatrix;
fs["distortion_coefficients"] >> distCoeffs;
```

----------------------------------------

TITLE: Trackbar Callback Function in Python
DESCRIPTION: This Python snippet defines the `on_trackbar` callback function. It receives the current trackbar value (`val`), calculates `alpha` and `beta`, performs image blending using `cv.addWeighted`, and updates the 'Linear Blend' window display using `cv.imshow`. It relies on `src1`, `src2`, `alpha_slider_max` being accessible from the enclosing scope.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/trackbar.markdown#2025-04-22_snippet_11

LANGUAGE: python
CODE:
```
#![on_trackbar]
def on_trackbar(val):
    alpha = val / alpha_slider_max
    beta = ( 1.0 - alpha )
    dst = cv.addWeighted(src1, alpha, src2, beta, 0.0)
    cv.imshow('Linear Blend', dst)
#![on_trackbar]
```

----------------------------------------

TITLE: Defining PASCAL VOC Annotation Format in XML
DESCRIPTION: Specifies the XML structure required for annotation files in the PASCAL VOC format. Each XML file corresponds to an image and lists object bounding boxes, including coordinates (`xmin`, `ymin`, `xmax`, `ymax`) and the class name ('face'). This format is necessary for the Caffe SSD training data preparation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/face_detector/how_to_train_face_detector.txt#2025-04-22_snippet_0

LANGUAGE: xml
CODE:
```
<annotation>
  <size>
    <width>300</width>
    <height>300</height>
  </size>
  <object>
    <name>face</name>
    <difficult>0</difficult>
    <bndbox>
      <xmin>100</xmin>
      <ymin>100</ymin>
      <xmax>200</xmax>
      <ymax>200</ymax>
    </bndbox>
  </object>
  <object>
    <name>face</name>
    <difficult>0</difficult>
    <bndbox>
      <xmin>0</xmin>
      <ymin>0</ymin>
      <xmax>100</xmax>
      <ymax>100</ymax>
    </bndbox>
  </object>
</annotation>
```

----------------------------------------

TITLE: Drawing an Atom in Python
DESCRIPTION: Drawing an atom using ellipses and circles in OpenCV Python. The atom is represented by ellipses for the electron orbits and a filled circle for the nucleus.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_11

LANGUAGE: python
CODE:
```
# 1. Draw a simple atom:
# -----------------------

# 1.a. Creating ellipses
MyEllipse(atom_image, 90)
MyEllipse(atom_image, 0)
MyEllipse(atom_image, 45)
MyEllipse(atom_image, -45)

# 1.b. Creating circles
MyFilledCircle(atom_image, (w//2, w//2))
```

----------------------------------------

TITLE: Running G-API Graph in Main Function
DESCRIPTION: Demonstrates how to construct and run a G-API graph using cv::GComputation, including input processing and output generation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
int main(int argc, char** argv)
{
    // ... (omitted code for brevity)

    cv::GMat in;
    cv::GMat gst = calcGST(in, w);
    cv::GMat normalized;
    cv::GMat out = cv::gapi::addWeighted(in, 0.8, normalized, 0.2, 0);
    cv::GComputation computation(cv::GIn(in), cv::GOut(out, gst));

    cv::Mat in_mat = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
    cv::Mat out_mat, gst_mat;
    computation.apply(cv::gin(in_mat), cv::gout(out_mat, gst_mat));

    // ... (omitted code for brevity)
}
```

----------------------------------------

TITLE: Creating Regions of Interest (ROI) with OpenCV Mat in C++
DESCRIPTION: Illustrates how to create new Mat headers (`D` and `E`) that refer to a sub-region (Region of Interest - ROI) of an existing Mat object (`A`). Method 1 uses a `cv::Rect` to define the rectangular region. Method 2 uses `cv::Range` to specify row and column boundaries. Both resulting Mat objects share the underlying data with the original matrix `A`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
Mat D (A, Rect(10, 10, 100, 100) ); // using a rectangle
Mat E = A(Range::all(), Range(1,3)); // using row and column boundaries
```

----------------------------------------

TITLE: Visualizing PCA Axis in C++ using OpenCV
DESCRIPTION: Defines a utility function `drawAxis` to draw a line representing a principal component (axis) on an image. It takes the image, center point, endpoint of the axis (scaled eigenvector), color, and line thickness as input. Uses `line` and `circle` from OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
//! [visualization]
// Function to draw the axes of the object detected by PCA
static void drawAxis(Mat &img, Point p, Point q, Scalar colour, const float scale = 0.2)
{
    double angle = atan2( (double) p.y - q.y, (double) p.x - q.x ); // angle in radians
    double hypotenuse = sqrt( (double) (p.y - q.y) * (p.y - q.y) + (p.x - q.x) * (p.x - q.x));

    // Here we lengthen the arrow by a factor of scale
    q.x = (int) (p.x - scale * hypotenuse * cos(angle));
    q.y = (int) (p.y - scale * hypotenuse * sin(angle));
    line(img, p, q, colour, 1, LINE_AA);

    // create the arrow hooks
    p.x = (int) (q.x + 9 * cos(angle + CV_PI / 4));
    p.y = (int) (q.y + 9 * sin(angle + CV_PI / 4));
    line(img, p, q, colour, 1, LINE_AA);

    p.x = (int) (q.x + 9 * cos(angle - CV_PI / 4));
    p.y = (int) (q.y + 9 * sin(angle - CV_PI / 4));
    line(img, p, q, colour, 1, LINE_AA);
}
//! [visualization]
```

----------------------------------------

TITLE: Splitting Image into BGR Planes in Java
DESCRIPTION: Java snippet using OpenCV's `Core.split` function to separate a 3-channel source image (assumed to be in BGR format) into three individual single-channel Mats, stored in a `List<Mat>`. The input is the source image Mat, and the output is the List of plane Mats.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_7

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Separate the image in 3 places ( B, G and R )
```

----------------------------------------

TITLE: Declaring Global Variables for Template Matching (Java)
DESCRIPTION: Declares class member variables used in the Java template matching demo, including `Mat` objects for the input image, template, and result map. Also includes variables for window names and the selected matching method integer.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_11

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/ImgProc/tutorial_template_matching/MatchTemplateDemo.java declare
```

----------------------------------------

TITLE: Drawing an Atom in Java
DESCRIPTION: Drawing an atom using ellipses and circles in OpenCV Java. The atom is represented by ellipses for electron orbits and a filled circle for the nucleus.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_10

LANGUAGE: java
CODE:
```
// 1. Draw a simple atom:
// -----------------------

// 1.a. Creating ellipses
MyEllipse(atom_image, 90);
MyEllipse(atom_image, 0);
MyEllipse(atom_image, 45);
MyEllipse(atom_image, -45);

// 1.b. Creating circles
MyFilledCircle(atom_image, new Point(w/2, w/2));
```

----------------------------------------

TITLE: Customizing Toolchain and Dependency Options for OpenCV (CMake)
DESCRIPTION: These options allow specifying an external toolchain file or enabling/disabling various hardware and software dependencies such as Carotene, Eigen, OpenVX, LAPACK, IPP, and others. Set corresponding WITH_* or BUILD_* options via CMake. Prerequisites vary based on the individual library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_32

LANGUAGE: cmake
CODE:
```
CMAKE_TOOLCHAIN_FILE
WITH_CAROTENE
WITH_KLEIDICV
WITH_CPUFEATURES
WITH_EIGEN
WITH_OPENVX
WITH_DIRECTX
WITH_VA
WITH_LAPACK
WITH_QUIRC
BUILD_ZLIB
BUILD_ITT
WITH_IPP
BUILD_IPP_IW
```

----------------------------------------

TITLE: Checking OpenVX Availability in CMake
DESCRIPTION: This CMake code block checks if the `HAVE_OPENVX` variable is false (meaning OpenVX is not available). If the condition is true, it prints a status message to the console indicating that OpenVX-related HAL features will be disabled and stops further processing within the current CMake script file using the `return()` command.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openvx/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(NOT HAVE_OPENVX)
  message(STATUS "OpenVX is not available, disabling openvx-related HAL and stuff")
  return()
endif()
```

----------------------------------------

TITLE: Pixel Comparison Branching Logic in C++
DESCRIPTION: Implements a series of nested pixel value comparisons using pointer offsets. Uses conditional branching with goto statements to handle different pixel intensity scenarios for image feature detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_13

LANGUAGE: cpp
CODE:
```
if(ptr[offset1] > cb)
  goto success_structured;
else
  if(ptr[offset6] > cb)
    goto success_structured;
  else
    goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
if(ptr[offset0] < c_b)
  if(ptr[offset2] > cb)
    if(ptr[offset5] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset1] > cb)
                goto success_structured;
              else
                if(ptr[offset8] > cb)
                  goto success_structured;
                else
                  goto structured;
            else
              if(ptr[offset9] > cb)
                if(ptr[offset8] > cb)
                  if(ptr[offset10] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
          else
            if(ptr[offset9] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
            else
              goto structured;
        else
          goto structured;
      else
        if(ptr[offset9] < c_b)
          if(ptr[offset8] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset7] < c_b)
                  if(ptr[offset1] < c_b)
                    goto success_structured;
                  else
                    if(ptr[offset6] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                else
                  goto structured;
              else
                goto structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
```

----------------------------------------

TITLE: Including Packaging and Dumping Variables in CMake
DESCRIPTION: This CMake snippet includes the `OpenCVPackaging.cmake` file to incorporate CPack configurations for creating installers or packages. Subsequently, it utilizes the custom function `ocv_cmake_dump_vars` to serialize the current state of all CMake variables into a file named `CMakeVars.txt` for debugging. An optional debug evaluation step (`ocv_cmake_eval`) might be triggered.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_33

LANGUAGE: cmake
CODE:
```
# ----------------------------------------------------------------------------
# CPack stuff
# ----------------------------------------------------------------------------

include(cmake/OpenCVPackaging.cmake)

# This should be the last command
ocv_cmake_dump_vars("" TOFILE "CMakeVars.txt")
ocv_cmake_eval(DEBUG_POST ONCE)
```

----------------------------------------

TITLE: Template Matching Code Formula
DESCRIPTION: Mathematical representation in code showing how template matching stores metric values in result matrix R based on template position (x,y)
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_0

LANGUAGE: text
CODE:
```
R(x,y) = f(I(x,y), T(x,y))
```

----------------------------------------

TITLE: Manipulating OpenCV Objects in Clojure
DESCRIPTION: Shows how to call methods and modify member fields on objects in Clojure using OpenCV, demonstrating operations such as area calculation and object field mutation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_11

LANGUAGE: clojure
CODE:
```
user=> (.area r1)
10000.0
user=> (.area sq-100)
10000.0
user=> (set! (.x p1) 10)
10
user=> p1
#<Point {10.0, 0.0}>
user=> (set! (.width sq-100) 10)
10
user=> (set! (.height sq-100) 10)
10
user=> (.area sq-100)
100.0
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree Fragment in C++
DESCRIPTION: This C++ code snippet represents a portion of a decision tree used for FAST corner detection. It performs a series of nested comparisons between pixel intensity values ('ptr[offsetN]') at specific offsets around a central pixel and pre-defined upper ('cb') and lower ('c_b') thresholds. Based on the outcome of these comparisons, it uses 'goto' statements to jump to labels 'is_a_corner' or 'is_not_a_corner', rapidly classifying the central pixel. This highly optimized, albeit complex, structure minimizes computational overhead for feature detection.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset1] < c_b)
                      if(ptr[offset12] < c_b)
                        if(ptr[offset13] < c_b)
                          if(ptr[offset14] < c_b)
                            if(ptr[offset15] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
          if(ptr[offset2] < c_b)
            if(ptr[offset4] > cb)
              if(ptr[offset11] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset9] > cb)
                      if(ptr[offset10] > cb)
                        if(ptr[offset6] > cb)
                          if(ptr[offset5] > cb)
                            if(ptr[offset3] > cb)
                              goto is_a_corner;
                            else
                              if(ptr[offset12] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset12] > cb)
                              if(ptr[offset13] > cb)
                                if(ptr[offset14] > cb)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset12] > cb)
                            if(ptr[offset13] > cb)
                              if(ptr[offset14] > cb)
                                if(ptr[offset15] > cb)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
              if(ptr[offset11] < c_b)
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    if(ptr[offset10] < c_b)
                      if(ptr[offset14] < c_b)
                        if(ptr[offset15] < c_b)
                          if(ptr[offset1] < c_b)
                            goto is_a_corner;
                          else
                            if(ptr[offset8] < c_b)
                              if(ptr[offset9] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset6] < c_b)
                            if(ptr[offset7] < c_b)
                              if(ptr[offset8] < c_b)
                                if(ptr[offset9] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset5] < c_b)
                          if(ptr[offset6] < c_b)
                            if(ptr[offset7] < c_b)
                              if(ptr[offset8] < c_b)
                                if(ptr[offset9] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset1] < c_b)
                        if(ptr[offset3] < c_b)
                          if(ptr[offset14] < c_b)
                            if(ptr[offset15] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
            if(ptr[offset4] < c_b)
              if(ptr[offset5] > cb)
                if(ptr[offset12] > cb)
                  if(ptr[offset7] > cb)
                    if(ptr[offset8] > cb)
                      if(ptr[offset9] > cb)
                        if(ptr[offset10] > cb)
                          if(ptr[offset11] > cb)
                            if(ptr[offset13] > cb)
                              if(ptr[offset6] > cb)
                                goto is_a_corner;
                              else
                                if(ptr[offset14] > cb)
                                  if(ptr[offset15] > cb)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    if(ptr[offset14] < c_b)
                      if(ptr[offset15] < c_b)
                        if(ptr[offset1] < c_b)
                          if(ptr[offset3] < c_b)
                            goto is_a_corner;
                          else
                            if(ptr[offset10] < c_b)
                              if(ptr[offset11] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset8] < c_b)
                            if(ptr[offset9] < c_b)
                              if(ptr[offset10] < c_b)
                                if(ptr[offset11] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset6] < c_b)
                          if(ptr[offset7] < c_b)
                            if(ptr[offset8] < c_b)
                              if(ptr[offset9] < c_b)
                                if(ptr[offset10] < c_b)
                                  if(ptr[offset11] < c_b)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
```

----------------------------------------

TITLE: Disabling Compiler Warnings for OpenEXR
DESCRIPTION: This code disables various compiler warnings for OpenEXR across different compilers (GCC, Clang, MSVC). It suppresses warnings that are not relevant for the library's functionality to keep the build output clean.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
ocv_warnings_disable(CMAKE_CXX_FLAGS -Wshadow -Wunused -Wsign-compare -Wundef -Wmissing-declarations -Wuninitialized -Wswitch -Wparentheses -Warray-bounds -Wextra
                                     -Wdeprecated-declarations -Wmisleading-indentation -Wdeprecated
                                     -Wsuggest-override -Winconsistent-missing-override
                                     -Wimplicit-fallthrough
                                     -Wtautological-compare  # clang
                                     -Wmissing-prototypes  # gcc/clang
                                     -Wreorder
                                     -Wunused-result
                                     -Wimplicit-const-int-float-conversion  # clang
)
if(CV_GCC AND CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 8.0)
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wclass-memaccess)
endif()

ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4018 /wd4099 /wd4100 /wd4101 /wd4127 /wd4189 /wd4245 /wd4305 /wd4389 /wd4512 /wd4701 /wd4702 /wd4706 /wd4800) # vs2005
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4334) # vs2005 Win64
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4244) # vs2008
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4267) # vs2008 Win64
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4456) # vs2015
ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4819) # vs2019 Win64

if(MSVC AND CV_ICC)
  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /Qrestrict")
  set(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} /Qrestrict")
endif()
```

----------------------------------------

TITLE: Check Compiler Flags and Attributes in CMake
DESCRIPTION: This snippet checks the support for specific compiler flags and attributes, including -fno-semantic-interposition, and attribute visibility (hidden, internal) using check_compiler_flag and check_c_source_compiles commands. It ensures linker and compiler optimizations by defining macros.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: CMake
CODE:
```
#
# Check whether compiler supports -fno-semantic-interposition parameter
#
check_c_compiler_flag(-fno-semantic-interposition HAVE_NO_INTERPOSITION)

#
# Check if we can hide zlib internal symbols that are linked between separate source files using hidden
#
check_c_source_compiles(
    "#define Z_INTERNAL __attribute__((visibility (\"hidden\")))
    int Z_INTERNAL foo;
    int main() {
        return 0;
    }"
    HAVE_ATTRIBUTE_VISIBILITY_HIDDEN FAIL_REGEX "visibility")
if(HAVE_ATTRIBUTE_VISIBILITY_HIDDEN)
    add_definitions(-DHAVE_VISIBILITY_HIDDEN)
endif()

#
# Check if we can hide zlib internal symbols that are linked between separate source files using internal
#
check_c_source_compiles(
    "#define Z_INTERNAL __attribute__((visibility (\"internal\")))
    int Z_INTERNAL foo;
    int main() {
        return 0;
    }"
    HAVE_ATTRIBUTE_VISIBILITY_INTERNAL FAIL_REGEX "visibility")
if(HAVE_ATTRIBUTE_VISIBILITY_INTERNAL)
    add_definitions(-DHAVE_VISIBILITY_INTERNAL)
endif()
```

----------------------------------------

TITLE: Controlling JFIF Header Emission in libjpeg (C)
DESCRIPTION: A C boolean field within the compression parameters structure (`cinfo`). If TRUE, a standard JFIF (JPEG File Interchange Format) APP0 marker is included in the output file. Functions like `jpeg_set_defaults()` typically set this based on the selected color space (TRUE for YCbCr or grayscale).
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_38

LANGUAGE: C
CODE:
```
boolean write_JFIF_header
```

----------------------------------------

TITLE: Cloning OpenCV Repository
DESCRIPTION: Commands to create a working directory and clone the OpenCV repository with minimal history.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/highgui_wayland_ubuntu.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
mkdir work
cd work
git clone --depth=1 https://github.com/opencv/opencv.git
```

----------------------------------------

TITLE: Using CMake to List Available OpenCV Configuration Options
DESCRIPTION: Command to display all available configuration parameters for OpenCV using CMake's list help option.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_10

LANGUAGE: sh
CODE:
```
cmake -LH ../opencv
```

----------------------------------------

TITLE: Overriding Warning/Trace Message Emission in JPEG Library (C)
DESCRIPTION: Defines the `emit_message` function signature, a method within the `jpeg_error_mgr` struct. This function decides whether to output a non-fatal warning (`msg_level` = -1) or a trace message (`msg_level` >= 0) by calling `output_message`. It receives the JPEG object pointer and the message level. Override this method primarily to change the handling of warnings, such as choosing to abort processing when a warning occurs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_47

LANGUAGE: c
CODE:
```
emit_message (j_common_ptr cinfo, int msg_level)
```

----------------------------------------

TITLE: Configuring OpenCV HAL (Hardware Abstraction Layer) in CMake
DESCRIPTION: Sets up the OpenCV Hardware Abstraction Layer (HAL) by registering various acceleration libraries and configuring their inclusion based on build options and platform support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_16

LANGUAGE: CMake
CODE:
```
set(_hal_includes "")
macro(ocv_hal_register HAL_LIBRARIES_VAR HAL_HEADERS_VAR HAL_INCLUDE_DIRS_VAR)
  # 1. libraries
  foreach (l ${${HAL_LIBRARIES_VAR}})
    if(NOT TARGET ${l})
      get_filename_component(l "${l}" ABSOLUTE)
    endif()
    list(APPEND OPENCV_HAL_LINKER_LIBS ${l})
  endforeach()
  # 2. headers
  foreach (h ${${HAL_HEADERS_VAR}})
    set(_hal_includes "${_hal_includes}\n#include \"${h}\"")
  endforeach()
  # 3. include paths
  ocv_include_directories(${${HAL_INCLUDE_DIRS_VAR}})
endmacro()

if(NOT DEFINED OpenCV_HAL)
  set(OpenCV_HAL "OpenCV_HAL")
endif()

# ... (HAL configuration for various accelerations) ...

foreach(hal ${OpenCV_HAL})
  if(hal STREQUAL "carotene")
    if(";${CPU_BASELINE_FINAL};" MATCHES ";NEON;")
      add_subdirectory(3rdparty/carotene/hal)
      ocv_hal_register(CAROTENE_HAL_LIBRARIES CAROTENE_HAL_HEADERS CAROTENE_HAL_INCLUDE_DIRS)
      list(APPEND OpenCV_USED_HAL "carotene (ver ${CAROTENE_HAL_VERSION})")
    else()
      message(STATUS "Carotene: NEON is not available, disabling carotene...")
    endif()
  elseif(hal STREQUAL "fastcv")
    # ... (similar configuration for other HALs) ...
  endif()
endforeach()
configure_file("${OpenCV_SOURCE_DIR}/cmake/templates/custom_hal.hpp.in" "${OPENCV_CONFIG_FILE_INCLUDE_DIR}/custom_hal.hpp" @ONLY)
unset(_hal_includes)
```

----------------------------------------

TITLE: Detecting Line Segments using Probabilistic Hough Transform in OpenCV.js
DESCRIPTION: Uses the Probabilistic Hough Transform, an optimized version, to detect line segments in a binary image. It returns lines represented by their endpoints (x1, y1, x2, y2). Requires a single-channel 8-bit binary input image. Key parameters include `rho`, `theta`, `threshold`, `minLineLength` (minimum segment length), and `maxLineGap` (maximum gap between points on the same line). Depends on the OpenCV.js library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_houghlines/js_houghlines.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
cv.HoughLinesP (image, lines, rho, theta, threshold, minLineLength = 0, maxLineGap = 0)

@param image          8-bit, single-channel binary source image. The image may be modified by the function.
@param lines          output vector of lines(cv.32SC4 type). Each line is represented by a 4-element vector (x1,y1,x2,y2) ,where (x1,y1) and (x2,y2) are the ending points of each detected line segment.
@param rho            distance resolution of the accumulator in pixels.
@param theta          angle resolution of the accumulator in radians.
@param threshold      accumulator threshold parameter. Only those lines are returned that get enough votes
@param minLineLength  minimum line length. Line segments shorter than that are rejected.
@param maxLineGap     maximum allowed gap between points on the same line to link them.
```

----------------------------------------

TITLE: Estimating Camera Response Function for HDR Processing in OpenCV
DESCRIPTION: This code estimates the camera response function (CRF) which is necessary for HDR construction algorithms. It uses a calibration algorithm to calculate the inverse CRF for all 256 possible pixel values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/hdr_imaging.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
Mat response;
Ptr<CalibrateDebevec> calibrate = createCalibrateDebevec();
calibrate->process(images, response, times);
```

LANGUAGE: java
CODE:
```
Mat response = new Mat();
CalibrateDebevec calibrate = Photo.createCalibrateDebevec();
calibrate.process(images, response, times);
```

LANGUAGE: python
CODE:
```
calibrate = cv.createCalibrateDebevec()
response = calibrate.process(images, times)
```

----------------------------------------

TITLE: Handling Full Output Buffer in JPEG Destination Manager (C)
DESCRIPTION: Defines the `empty_output_buffer` function signature, a required method for a custom `jpeg_destination_mgr`. This function is called by the library whenever the output buffer fills up (`free_in_buffer` reaches zero). The implementation should process the entire buffer content (e.g., write it to a file or network stream), reset `next_output_byte` to the start of the buffer, reset `free_in_buffer` to the total buffer size (must be positive), and return `TRUE`. Returning `FALSE` is used for I/O suspension.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_51

LANGUAGE: c
CODE:
```
empty_output_buffer (j_compress_ptr cinfo)
```

----------------------------------------

TITLE: Defining a Point in Java
DESCRIPTION: Two different ways to define a 2D point using the Point class in Java. A Point represents a 2D coordinate with x and y values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
Point pt = new Point();
pt.x = 10;
pt.y = 8;
```

LANGUAGE: java
CODE:
```
Point pt = new Point(10, 8);
```

----------------------------------------

TITLE: Fallback Case for Non-Maximum Suppression in C++
DESCRIPTION: This code snippet handles the fallback case where non-maximum suppression is not applied. In this case, all original keypoints are retained without filtering.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_47

LANGUAGE: C++
CODE:
```
} else
{
  keypoints = kpts;
}

```

----------------------------------------

TITLE: Linking Libraries in OpenCV Module
DESCRIPTION: Links private targets to the specified OpenCV module, facilitating the integration of dependencies required for module functionality. The 'tgts' parameter comprises the names of the targets to be linked. This snippet expects the module and its dependencies to be defined in the build system context.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_19

LANGUAGE: CMake
CODE:
```
ocv_target_link_libraries(${the_module} LINK_PRIVATE ${tgts})
```

----------------------------------------

TITLE: Building Android Projects and Examples with OpenCV (CMake/Environment)
DESCRIPTION: These options control building Android-specific projects and examples. Requires Android SDK and NDK to be installed. Set BUILD_ANDROID_PROJECTS and BUILD_ANDROID_EXAMPLES to ON in the CMake command, and define Android toolchain and SDK/NDK paths using ANDROID_HOME, ANDROID_SDK, ANDROID_NDK, or ANDROID_SDK_ROOT.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_31

LANGUAGE: cmake
CODE:
```
BUILD_ANDROID_PROJECTS
BUILD_ANDROID_EXAMPLES
ANDROID_HOME
ANDROID_SDK
ANDROID_NDK
ANDROID_SDK_ROOT
```

----------------------------------------

TITLE: Accessing an HTML Range Input by ID - JavaScript
DESCRIPTION: This snippet retrieves a previously defined HTML input element of type 'range' using its ID via document.getElementById. This is necessary to read or set the trackbar's value or attach event handlers. The variable 'x' will reference the input range element with ID 'myRange'. No specific dependencies other than a matching DOM element.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_gui/js_trackbar/js_trackbar.markdown#2025-04-22_snippet_2

LANGUAGE: JavaScript
CODE:
```
let x = document.getElementById('myRange');
```

----------------------------------------

TITLE: Example Output of pkg-config for OpenCV Libraries
DESCRIPTION: This illustrates the typical output of the `pkg-config --libs opencv` command. It includes the library search path (`-L/usr/local/lib`) and a list of OpenCV module libraries (`-lopencv_core`, `-lopencv_imgproc`, etc.) needed for linking. This information is used to configure the linker settings in Eclipse.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
-L/usr/local/lib -lopencv_core -lopencv_imgproc -lopencv_highgui -lopencv_ml -lopencv_video -lopencv_features2d -lopencv_calib3d -lopencv_objdetect -lopencv_videoio -lopencv_imgcodecs -lopencv_flann
```

----------------------------------------

TITLE: Including ChArUco Header
DESCRIPTION: Shows how to include the necessary header file for ChArUco functionality
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
#include <opencv2/aruco/charuco.hpp>
```

----------------------------------------

TITLE: Configuring IPP Library Build Settings
DESCRIPTION: Sets up compiler definitions, include directories, linked libraries and output settings for the IPP HAL library. Includes conditional compilation for IPP ICV and IW components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ipphal/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
if(HAVE_IPP_ICV)
  target_compile_definitions(ipphal PRIVATE HAVE_IPP_ICV)
endif()

if(HAVE_IPP_IW)
  target_compile_definitions(ipphal PRIVATE HAVE_IPP_IW)
endif()

target_include_directories(ipphal PRIVATE "${CMAKE_CURRENT_SOURCE_DIR}/include")
ocv_warnings_disable(CMAKE_CXX_FLAGS -Wno-suggest-override)

target_include_directories(ipphal PRIVATE
  "${CMAKE_CURRENT_SOURCE_DIR}/src"
  ${CMAKE_SOURCE_DIR}/modules/core/include
  ${IPP_INCLUDE_DIRS}
)

target_link_libraries(ipphal PUBLIC ${IPP_IW_LIBRARY} ${IPP_LIBRARIES})

set_target_properties(ipphal PROPERTIES ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH})
```

----------------------------------------

TITLE: Setting Include Directories and Compiler Options Based on Toolchain - CMake
DESCRIPTION: Applies collected include directories to the build and selectively disables compiler warnings depending on whether GNU or Clang compiler is used. Ensures source compatibility with warning-free builds, especially for Protobuf-generated and third-party code. Inputs: include_dirs, compiler detection; outputs: build flags and warning suppression.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_20

LANGUAGE: CMake
CODE:
```
ocv_module_include_directories(${include_dirs})
if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
  ocv_append_source_files_cxx_compiler_options(fw_srcs "-Wno-suggest-override")  # GCC
  ocv_append_source_files_cxx_compiler_options(fw_srcs "-Wno-array-bounds")  # GCC 9.3.0 (Ubuntu 20.04)
elif(CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
  ocv_append_source_files_cxx_compiler_options(fw_srcs "-Wno-inconsistent-missing-override")  # Clang
endif()
```

----------------------------------------

TITLE: Defining Quantization Tables in libjpeg (C)
DESCRIPTION: A C field within the compression parameters structure (`cinfo`), representing an array of pointers (`JQUANT_TBL *`) to quantization tables. Each element corresponds to a table slot (indexed 0 to NUM_QUANT_TBLS-1). A NULL pointer indicates that no custom table is defined for that slot, causing libjpeg to use default tables. This allows specifying custom quantization matrices for lossy compression.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_42

LANGUAGE: C
CODE:
```
JQUANT_TBL *quant_tbl_ptrs[NUM_QUANT_TBLS]
```

----------------------------------------

TITLE: Example of Running the Ant Build Script (Windows) (Batch)
DESCRIPTION: This Batch command provides a concrete example of executing the Ant build script on a Windows system. It passes example paths for the OpenCV JAR directory (`X:\opencv-2.4.4\bin`) and the native library directory (`X:\opencv-2.4.4\bin\Release`) using the `-D` flag.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_9

LANGUAGE: bat
CODE:
```
ant -DocvJarDir=X:\opencv-2.4.4\bin -DocvLibDir=X:\opencv-2.4.4\bin\Release
```

----------------------------------------

TITLE: Configuring Android Test Source Directories in CMake
DESCRIPTION: Defines the source directories for Android tests, including the current source directory, common test directory, and generated test directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/android_test/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(ANDROID_TESTS_SRC_DIRS
"'${CMAKE_CURRENT_SOURCE_DIR}/src', \
'${OpenCV_SOURCE_DIR}/modules/java/test/common_test/src', \
'${CMAKE_BINARY_DIR}/modules/java_bindings_generator/gen/test'" CACHE INTERNAL "")
```

----------------------------------------

TITLE: Installing ARM Cross-Compilation Toolchain - Bash
DESCRIPTION: Installs the gcc-arm-linux-gnueabi toolchain required for cross-compiling software from a Linux host for ARM targets using the gnueabi ABI. Dependencies include apt-get and network access to Ubuntu repositories. The primary parameter is the package name, and the command should be run with sudo privileges. This command is specific to distributions using the apt package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/arm_crosscompile_with_cmake.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
sudo apt-get install gcc-arm-linux-gnueabi
```

----------------------------------------

TITLE: Drawing Rectangle with OpenCV in Python
DESCRIPTION: Draws a green rectangle at the top-right corner of the image using the cv.rectangle() function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
cv.rectangle(img,(384,0),(510,128),(0,255,0),3)
```

----------------------------------------

TITLE: Running the SSD MobileNetV1 Model Retrieval Script - Console
DESCRIPTION: Runs the sample Python module that retrieves the SSD MobileNetV1 TensorFlow model and extracts the frozen graph. The command expects the appropriate module path and is executed within the activated environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_2

LANGUAGE: console
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.detection.py_to_py_ssd_mobilenet
```

----------------------------------------

TITLE: FAST Corner Detection Conditional Logic
DESCRIPTION: Complex nested conditional logic for comparing pixel intensity values at different offsets around a candidate corner point. The code uses goto statements to branch between success_structured, structured, and homogeneous cases based on pixel value comparisons against threshold values c_b and cb.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_26

LANGUAGE: cpp
CODE:
```
goto success_structured;
else
  goto structured;
else
  goto structured;
else
  if(ptr[offset1] < c_b)
    goto success_structured;
  else
    goto structured;
else
  if(ptr[offset1] < c_b)
    if(ptr[offset4] < c_b)
      goto success_structured;
    else
      goto structured;
  else
    goto structured;
else
  if(ptr[offset7] > cb)
    if(ptr[offset9] > cb)
      if(ptr[offset5] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset6] > cb)
            if(ptr[offset8] > cb)
              if(ptr[offset10] > cb)
                goto success_structured;
              else
                goto structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    goto structured;
```

----------------------------------------

TITLE: Configuring Restart Markers in libjpeg (C)
DESCRIPTION: These C integer fields within the compression parameters structure (`cinfo`) control the insertion of restart markers in the JPEG data stream. Setting `restart_interval` specifies the interval in Minimum Coded Units (MCUs), while `restart_in_rows` sets the interval based on MCU rows. Non-zero values enable restart markers, which can improve robustness against data corruption. Defaults are zero (no restarts).
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_35

LANGUAGE: C
CODE:
```
unsigned int restart_interval
```

LANGUAGE: C
CODE:
```
int restart_in_rows
```

----------------------------------------

TITLE: Calculating Contour Area in Python with OpenCV
DESCRIPTION: This snippet demonstrates how to calculate the area of a contour using the cv.contourArea() function in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_2

LANGUAGE: Python
CODE:
```
area = cv.contourArea(cnt)
```

----------------------------------------

TITLE: Configuring Random Data Array for CMake Project
DESCRIPTION: This snippet uses CMake to generate random hexadecimal values and populates them into a C array. It relies on CMake's built-in functions like set, string, and math to manipulate and generate data. The process starts by defining the array size and header paths, followed by generating random numbers and formatting them appropriately. The final step uses configure_file to apply the generated data to a header file template. The snippet is specific to CMake's functionalities for managing build properties and files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/semihosting/include/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(RAW_PIXELS_SIZE 102400)
set(RAW_PIXELS_HEADER ${CMAKE_CURRENT_BINARY_DIR}/raw_pixels.hpp)
set(RAW_PIXELS_HEADER_IN ${CMAKE_CURRENT_SOURCE_DIR}/raw_pixels.hpp.in)

set(RAW_PIXEL_VALUES "")
# Seed the random number generator.
string(RANDOM LENGTH 8 ALPHABET 0123456789abcdf RANDOM_SEED 314 number)
math(EXPR LOOP_RANGE "${RAW_PIXELS_SIZE} - 1")

foreach(i RANGE ${LOOP_RANGE})
  string(RANDOM LENGTH 8 ALPHABET 0123456789abcdf number)
  string(CONCAT RAW_PIXEL_VALUES ${RAW_PIXEL_VALUES} "0x${number}, \\\n")
endforeach()

configure_file(${RAW_PIXELS_HEADER_IN} ${RAW_PIXELS_HEADER})
```

----------------------------------------

TITLE: Displaying 32F Image by Conversion to 8U for imshow with OpenCV in C++
DESCRIPTION: Shows how to visualize a 32-bit float image by converting to unsigned 8-bit for imshow. Uses convertTo to cast and possibly normalize. Ensures imshow can display image properly. Be aware of dynamic range mapping.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_43

LANGUAGE: C++
CODE:
```
cv::Mat img8u;\nimg.convertTo(img8u, CV_8U, 255.0);\ncv::imshow("Window", img8u);\ncv::waitKey(0);
```

----------------------------------------

TITLE: Embedding External HTML Content with iframe in HTML
DESCRIPTION: This HTML snippet uses an <iframe> tag to embed the content of `js_imgproc_camera.html` within the current page. The `onload` attribute contains JavaScript code to dynamically adjust the iframe's height to fit the loaded content's height, ensuring the embedded page is fully visible without scrolling within the frame itself. This technique is commonly used in documentation or tutorials to include interactive examples or separate HTML documents.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_imgproc_camera/js_imgproc_camera.markdown#2025-04-22_snippet_0

LANGUAGE: html
CODE:
```
<iframe src="../../js_imgproc_camera.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
```

----------------------------------------

TITLE: JPEG Decompression Operation Structure in C
DESCRIPTION: Basic outline of a JPEG decompression operation showing the sequence of function calls needed to decompress a JPEG image using the IJG JPEG library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_1

LANGUAGE: C
CODE:
```
Allocate and initialize a JPEG decompression object
Specify the source of the compressed data (eg, a file)
Call jpeg_read_header() to obtain image info
Set parameters for decompression
jpeg_start_decompress(...);
while (scan lines remain to be read)
        jpeg_read_scanlines(...);  /* Use jpeg12_read_scanlines() for
                                      9-bit through 12-bit data
```

----------------------------------------

TITLE: Configuring Compiler Warnings for libjasper in CMake
DESCRIPTION: This snippet disables specific compiler warnings for the libjasper library build across different compilers and platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjasper/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
ocv_warnings_disable(CMAKE_C_FLAGS -Wno-implicit-function-declaration -Wno-uninitialized -Wmissing-prototypes
                                   -Wno-unused-but-set-parameter -Wmissing-declarations -Wunused -Wshadow
                                   -Wsign-compare -Wstrict-overflow -Wpointer-compare
                                   -Wabsolute-value  # clang on Linux
                                   -Wimplicit-fallthrough
)
ocv_warnings_disable(CMAKE_C_FLAGS -Wunused-parameter -Wstrict-prototypes) # clang
ocv_warnings_disable(CMAKE_C_FLAGS /wd4013 /wd4018 /wd4101 /wd4244 /wd4267 /wd4715) # vs2005
```

----------------------------------------

TITLE: Aggregating Include Directories and Library Dependencies for DNN Module - CMake
DESCRIPTION: Appends framework include directories and library dependencies to the DNN build based on earlier configuration. Handles special case if protobuf is not internally built, then includes system protobuf includes as well. Input variables derived from previous code (fw_inc, fw_hdrs, etc.). Output aggregates required dependencies for compilation and linking.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_16

LANGUAGE: CMake
CODE:
```
list(APPEND include_dirs ${fw_inc})
list(APPEND libs ${Protobuf_LIBRARIES})
if(NOT BUILD_PROTOBUF)
  list(APPEND include_dirs ${Protobuf_INCLUDE_DIRS})
endif()
```

----------------------------------------

TITLE: Template for Apache License 2.0 Notice (Text)
DESCRIPTION: This is a standard boilerplate notice template recommended by the Apache License 2.0 appendix. It should be included in source files, typically within comments. The placeholders `[yyyy]` (year) and `[name of copyright owner]` must be replaced with the specific project details. It asserts copyright and states the work is licensed under Apache 2.0, providing a link to the full license.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/flatbuffers/LICENSE.txt#2025-04-22_snippet_0

LANGUAGE: text
CODE:
```
Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

----------------------------------------

TITLE: Generating Eclipse Project Files with SBT (Bash)
DESCRIPTION: This Bash snippet shows how to use SBT to generate Eclipse project files. First, `sbt` starts the SBT interactive console. Then, typing `eclipse` within the console invokes the command provided by the `sbteclipse-plugin` (added previously) to create the necessary `.project` and `.classpath` files for importing the project into Eclipse.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_14

LANGUAGE: bash
CODE:
```
sbt # Starts the sbt console
eclipse # Running "eclipse" from within the sbt console
```

----------------------------------------

TITLE: Copying Test Project Files in CMake
DESCRIPTION: Copies essential test project files to the Android test directory. It iterates through a list of files and copies each one.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/android_test/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
list(APPEND TEST_PROJECT_FILES "CMakeLists.txt" "gradle.properties" "settings.gradle")
foreach(TEST_PROJECT_FILE ${TEST_PROJECT_FILES})
    file(COPY "${CMAKE_CURRENT_SOURCE_DIR}/${TEST_PROJECT_FILE}" DESTINATION "${OPENCV_ANDROID_TEST_DIR}")
endforeach()
```

----------------------------------------

TITLE: Calculating Object Orientation via PCA in C++ using OpenCV
DESCRIPTION: Defines a function `getOrientation` that takes a vector of points (a contour) and calculates its orientation using PCA. It formats the contour points into a Mat, performs PCA using `cv::PCA`, and extracts the mean (center), eigenvectors, and eigenvalues. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/introduction_to_pca.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
//! [pca]
// Perform PCA analysis
static double getOrientation(const vector<Point> &pts, Mat &img)
{
    //Construct a buffer used by the PCA analysis
    int sz = static_cast<int>(pts.size());
    Mat data_pts = Mat(sz, 2, CV_64F);
    for (int i = 0; i < data_pts.rows; ++i)
    {
        data_pts.at<double>(i, 0) = pts[i].x;
        data_pts.at<double>(i, 1) = pts[i].y;
    }

    //Perform PCA analysis
    PCA pca_analysis(data_pts, Mat(), PCA::DATA_AS_ROW);

    //Store the center of the object
    Point cntr = Point(static_cast<int>(pca_analysis.mean.at<double>(0, 0)),
                      static_cast<int>(pca_analysis.mean.at<double>(0, 1)));

    //Store the eigenvalues and eigenvectors
    vector<Point2d> eigen_vecs(2);
    vector<double> eigen_val(2);
    for (int i = 0; i < 2; ++i)
    {
        eigen_vecs[i] = Point2d(pca_analysis.eigenvectors.at<double>(i, 0),
                                pca_analysis.eigenvectors.at<double>(i, 1));

        eigen_val[i] = pca_analysis.eigenvalues.at<double>(i);
    }

    // Draw the principal components
    circle(img, cntr, 3, Scalar(255, 0, 255), 2);
    Point p1 = cntr + 0.02 * Point(static_cast<int>(eigen_vecs[0].x * eigen_val[0]), static_cast<int>(eigen_vecs[0].y * eigen_val[0]));
    Point p2 = cntr - 0.02 * Point(static_cast<int>(eigen_vecs[1].x * eigen_val[1]), static_cast<int>(eigen_vecs[1].y * eigen_val[1]));
    drawAxis(img, cntr, p1, Scalar(0, 255, 0), 1);
    drawAxis(img, cntr, p2, Scalar(255, 255, 0), 5);

    double angle = atan2(eigen_vecs[0].y, eigen_vecs[0].x); // orientation in radians

    return angle;
}
//! [pca]
```

----------------------------------------

TITLE: Creating Basic HTML Structure for Image Upload (HTML/JavaScript)
DESCRIPTION: Defines the basic HTML structure for a web page titled 'Hello OpenCV.js'. It includes an `<img>` tag to display an image, a file input element (`<input type='file'>`) for uploading images, and embedded JavaScript to handle the file selection. When a file is selected, the JavaScript updates the `src` attribute of the `<img>` tag to display the chosen image using `URL.createObjectURL`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_usage/js_usage.markdown#2025-04-22_snippet_0

LANGUAGE: html
CODE:
```
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<div>
  <div class="inputoutput">
    <img id="imageSrc" alt="No Image" />
    <div class="caption">imageSrc <input type="file" id="fileInput" name="file" /></div>
  </div>
</div>
<script type="text/javascript">
let imgElement = document.getElementById("imageSrc")
let inputElement = document.getElementById("fileInput");
inputElement.addEventListener("change", (e) => {
  imgElement.src = URL.createObjectURL(e.target.files[0]);
}, false);
</script>
</body>
</html>
```

----------------------------------------

TITLE: JPEG Configuration Structures
DESCRIPTION: Configuration structure members for controlling JPEG decoding behavior and color quantization settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_58

LANGUAGE: c
CODE:
```
cinfo.two_pass_quantize
cinfo.colormap
cinfo.actual_number_of_colors
cinfo.enable_1pass_quant
cinfo.enable_external_quant
cinfo.enable_2pass_quant
```

----------------------------------------

TITLE: Cross-Compiling OpenCV for RISC-V using CMake
DESCRIPTION: This CMake command configures the build environment for cross-compiling OpenCV for RISC-V. It specifies the toolchain file, installation prefix, and paths to the RISC-V toolchain and QEMU.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/riscv/README.md#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
cmake -G Ninja -B ./build-riscv \
  -D CMAKE_TOOLCHAIN_FILE=./cmake/toolchain-riscv.cmake \
  -D CMAKE_INSTALL_PREFIX=./build-riscv/install \
  -D TOOLCHAIN_PATH={TOOLCHAIN_PATH} \
  -D QEMU_PATH={QEMU_PATH} \
  .

cmake --build ./build-riscv
```

----------------------------------------

TITLE: Setting Uniform and Accumulate Flags in Python
DESCRIPTION: Python snippet implicitly sets histogram parameters. While `uniform` and `accumulate` flags exist in the C++ `calcHist` function, they are often handled implicitly or through default arguments in the Python `cv.calcHist` wrapper. The standard usage shown typically implies uniform bins and non-accumulating calculation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_17

LANGUAGE: python
CODE:
```
@snippet samples/python/tutorial_code/Histograms_Matching/histogram_calculation/calcHist_Demo.py Set histogram param
```

----------------------------------------

TITLE: Defining Extended Colorspace Constants in C for libjpeg-turbo
DESCRIPTION: Defines C constants representing extended colorspaces (like RGBX, BGR, ABGR, etc.) supported by libjpeg-turbo. These constants are used with `cinfo.in_color_space` (compression) or `cinfo.out_color_space` (decompression) to handle different pixel buffer orderings directly, improving performance by avoiding manual conversion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/README.md#2025-04-22_snippet_0

LANGUAGE: c
CODE:
```
JCS_EXT_RGB   /* red/green/blue */
JCS_EXT_RGBX  /* red/green/blue/x */
JCS_EXT_BGR   /* blue/green/red */
JCS_EXT_BGRX  /* blue/green/red/x */
JCS_EXT_XBGR  /* x/blue/green/red */
JCS_EXT_XRGB  /* x/red/green/blue */
JCS_EXT_RGBA  /* red/green/blue/alpha */
JCS_EXT_BGRA  /* blue/green/red/alpha */
JCS_EXT_ABGR  /* alpha/blue/green/red */
JCS_EXT_ARGB  /* alpha/red/green/blue */
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Decision Tree in C++
DESCRIPTION: A decision tree implementation for the FAST corner detection algorithm. The code compares pixel values at various offsets against threshold values (cb and c_b) to determine if a point is a corner. The algorithm uses goto statements to branch to either 'is_a_corner' or 'is_not_a_corner' based on the evaluation results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_16

LANGUAGE: C++
CODE:
```
if(ptr[offset4] > cb)
  goto is_a_corner;
else
  if(ptr[offset10] > cb)
    goto is_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset8] > cb)
    if(ptr[offset10] > cb)
      goto is_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset6] > cb)
    if(ptr[offset3] > cb)
      if(ptr[offset4] > cb)
        goto is_a_corner;
      else
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset8] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset11] > cb)
      if(ptr[offset3] > cb)
        if(ptr[offset4] > cb)
          goto is_a_corner;
        else
          if(ptr[offset10] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset1] < c_b)
    goto is_not_a_corner;
  else
    if(ptr[offset1] > cb)
      if(ptr[offset6] > cb)
        if(ptr[offset3] > cb)
          if(ptr[offset4] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset6] < c_b)
          if(ptr[offset3] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset11] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          if(ptr[offset3] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset11] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset9] < c_b)
    if(ptr[offset7] > cb)
      if(ptr[offset1] < c_b)
        if(ptr[offset6] < c_b)
          goto is_not_a_corner;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset8] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset1] > cb)
          if(ptr[offset6] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset8] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
    else
      if(ptr[offset1] < c_b)
        goto is_not_a_corner;
      else
        if(ptr[offset1] > cb)
          if(ptr[offset6] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
        else
          goto is_not_a_corner;
  else
    if(ptr[offset7] > cb)
      if(ptr[offset9] > cb)
        if(ptr[offset1] < c_b)
```

----------------------------------------

TITLE: Configuring and Building libjpeg-turbo - CMake
DESCRIPTION: This CMake code snippet configures compilation and building flags for libjpeg-turbo within OpenCV, setting project variables, compiler options, include files, and versions. It provides macros and options for feature toggling (arithmetic coding support, SIMD), performs feature checks, assigns source files according to build configuration and hardware platform, and defines static library targets. Dependencies include OpenCV's CMake helpers, platform compiler specifics (such as GCC/Clang/MSVC), and relevant source files in the 'src' directory. The input and output revolve around build options, environment detection, and artifacts such as generated header files and static libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(${JPEG_LIBRARY} C)

macro(boolean_number var)
  if(${var})
    set(${var} 1 ${ARGN})
  else()
    set(${var} 0 ${ARGN})
  endif()
endmacro()

ocv_warnings_disable(CMAKE_C_FLAGS -Wunused-parameter -Wsign-compare -Wshorten-64-to-32 -Wimplicit-fallthrough)
if(APPLE)
  ocv_warnings_disable(CMAKE_C_FLAGS -Wunused-variable) # NEON flags are not used on Mac
endif()

if(CV_GCC AND NOT CMAKE_CXX_COMPILER_VERSION VERSION_LESS 13)
  # src/jchuff.c:1042:22: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]
  ocv_warnings_disable(CMAKE_C_FLAGS -Wstringop-overflow)
endif()

set(VERSION 3.1.0)
set(COPYRIGHT_YEAR "1991-2024")
string(REPLACE "." ";" VERSION_TRIPLET ${VERSION})
list(GET VERSION_TRIPLET 0 VERSION_MAJOR)
list(GET VERSION_TRIPLET 1 VERSION_MINOR)
list(GET VERSION_TRIPLET 2 VERSION_REVISION)
function(pad_number NUMBER OUTPUT_LEN)
  string(LENGTH "${${NUMBER}}" INPUT_LEN)
  if(INPUT_LEN LESS OUTPUT_LEN)
    math(EXPR ZEROES "${OUTPUT_LEN} - ${INPUT_LEN} - 1")
    set(NUM ${${NUMBER}})
    foreach(C RANGE ${ZEROES})
      set(NUM "0${NUM}")
    endforeach()
    set(${NUMBER} ${NUM} PARENT_SCOPE)
  endif()
endfunction()
pad_number(VERSION_MINOR 3)
pad_number(VERSION_REVISION 3)
set(LIBJPEG_TURBO_VERSION_NUMBER ${VERSION_MAJOR}${VERSION_MINOR}${VERSION_REVISION})

string(TIMESTAMP BUILD "opencv-${OPENCV_VERSION}-libjpeg-turbo")
if(CMAKE_BUILD_TYPE STREQUAL "Debug")
  set(BUILD "${BUILD}-debug")
endif()

message(STATUS "libjpeg-turbo: VERSION = ${VERSION}, BUILD = ${BUILD}")

math(EXPR BITS "${CMAKE_SIZEOF_VOID_P} * 8")
string(TOLOWER "${CMAKE_SYSTEM_PROCESSOR}" CMAKE_SYSTEM_PROCESSOR_LC)

if(CMAKE_SYSTEM_PROCESSOR_LC MATCHES "x86_64" OR
  CMAKE_SYSTEM_PROCESSOR_LC MATCHES "amd64" OR
  CMAKE_SYSTEM_PROCESSOR_LC MATCHES "i[0-9]86" OR
  CMAKE_SYSTEM_PROCESSOR_LC MATCHES "x86" OR
  CMAKE_SYSTEM_PROCESSOR_LC MATCHES "ia32")
  if(BITS EQUAL 64 OR CMAKE_C_COMPILER_ABI MATCHES "ELF X32")
    set(CPU_TYPE x86_64)
  else()
    set(CPU_TYPE i386)
  endif()
  if(NOT CMAKE_SYSTEM_PROCESSOR STREQUAL ${CPU_TYPE})
    set(CMAKE_SYSTEM_PROCESSOR ${CPU_TYPE})
  endif()
elseif(CMAKE_SYSTEM_PROCESSOR_LC STREQUAL "aarch64" OR
  CMAKE_SYSTEM_PROCESSOR_LC MATCHES "^arm")
  if(BITS EQUAL 64)
    set(CPU_TYPE arm64)
  else()
    set(CPU_TYPE arm)
  endif()
elseif(CMAKE_SYSTEM_PROCESSOR_LC MATCHES "^ppc" OR
  CMAKE_SYSTEM_PROCESSOR_LC MATCHES "^powerpc")
  set(CPU_TYPE powerpc)
else()
  set(CPU_TYPE ${CMAKE_SYSTEM_PROCESSOR_LC})
endif()
if(CMAKE_OSX_ARCHITECTURES MATCHES "x86_64" OR
  CMAKE_OSX_ARCHITECTURES MATCHES "arm64" OR
  CMAKE_OSX_ARCHITECTURES MATCHES "i386")
  set(CPU_TYPE ${CMAKE_OSX_ARCHITECTURES})
endif()
if(CMAKE_OSX_ARCHITECTURES MATCHES "ppc")
  set(CPU_TYPE powerpc)
endif()
if(MSVC_IDE AND CMAKE_GENERATOR_PLATFORM MATCHES "arm64")
  set(CPU_TYPE arm64)
endif()

OCV_OPTION(ENABLE_LIBJPEG_TURBO_SIMD "Include SIMD extensions for libjpeg-turbo, if available for this platform" (NOT CV_DISABLE_OPTIMIZATION))
option(WITH_ARITH_ENC "Include arithmetic encoding support when emulating the libjpeg v6b API/ABI" TRUE)
option(WITH_ARITH_DEC "Include arithmetic decoding support when emulating the libjpeg v6b API/ABI" TRUE)
set(WITH_SIMD 1)
set(HAVE_LIBJPEG_TURBO_SIMD 0 PARENT_SCOPE)

include(CheckCSourceCompiles)
include(CheckIncludeFiles)
include(CheckTypeSize)

check_type_size("size_t" SIZE_T)
check_type_size("unsigned long" UNSIGNED_LONG)

if(SIZEOF_SIZE_T EQUAL SIZEOF_UNSIGNED_LONG)
  check_c_source_compiles("int main(int argc, char **argv) { unsigned long a = argc;  return __builtin_ctzl(a); }"
    HAVE_BUILTIN_CTZL)
endif()
if(MSVC)
  check_include_files("intrin.h" HAVE_INTRIN_H)
endif()

if(UNIX)
  # Check for headers
  check_include_files(locale.h HAVE_LOCALE_H)
  check_include_files(stddef.h HAVE_STDDEF_H)
  check_include_files(stdlib.h HAVE_STDLIB_H)
  check_include_files(sys/types.h NEED_SYS_TYPES_H)

  # Other predefines
  # undef NEED_BSD_STRINGS
  ocv_update(HAVE_UNSIGNED_CHAR 1)
  ocv_update(HAVE_UNSIGNED_SHORT 1)
  # undef INCOMPLETE_TYPES_BROKEN
  ocv_update(RIGHT_SHIFT_IS_UNSIGNED 0)
endif()


set(BITS_IN_JSAMPLE 8)

if(WITH_ARITH_ENC)
  set(C_ARITH_CODING_SUPPORTED 1)
endif()

if(WITH_ARITH_DEC)
  set(D_ARITH_CODING_SUPPORTED 1)
endif()

set(JPEG_LIB_VERSION 70)

# OpenCV
set(JPEG_LIB_VERSION "${VERSION}-${JPEG_LIB_VERSION}" PARENT_SCOPE)

set(THREAD_LOCAL "")  # WITH_TURBOJPEG is not used

add_definitions(-DNO_GETENV -DNO_PUTENV)

if(MSVC)
  add_definitions(-W3 -wd4996 -wd4018)
endif()

include_directories(${CMAKE_CURRENT_BINARY_DIR} ${CMAKE_CURRENT_SOURCE_DIR}/src)

set(JPEG16_SOURCES jcapistd.c jccolor.c jcdiffct.c jclossls.c jcmainct.c
    jcprepct.c jcsample.c jdapistd.c jdcolor.c jddiffct.c jdlossls.c jdmainct.c
    jdpostct.c jdsample.c jutils.c)

set(JPEG12_SOURCES ${JPEG16_SOURCES} jccoefct.c jcdctmgr.c jdcoefct.c
    jddctmgr.c jdmerge.c jfdctfst.c jfdctint.c jidctflt.c jidctfst.c jidctint.c
    jidctred.c jquant1.c jquant2.c)

set(JPEG_SOURCES ${JPEG12_SOURCES} jcapimin.c jchuff.c jcicc.c jcinit.c
    jclhuff.c jcmarker.c jcmaster.c jcomapi.c jcparam.c jcphuff.c jctrans.c
    jdapimin.c jdatadst.c jdatasrc.c jdhuff.c jdicc.c jdinput.c jdlhuff.c
    jdmarker.c jdmaster.c jdphuff.c jdtrans.c jerror.c jfdctflt.c jmemmgr.c
    jmemnobs.c jpeg_nbits.c)

if(WITH_ARITH_ENC OR WITH_ARITH_DEC)
  set(JPEG_SOURCES ${JPEG_SOURCES} jaricom.c)
endif()

if(WITH_ARITH_ENC)
  set(JPEG_SOURCES ${JPEG_SOURCES} jcarith.c)
endif()

if(WITH_ARITH_DEC)
  set(JPEG_SOURCES ${JPEG_SOURCES} jdarith.c)
endif()

if(CMAKE_COMPILER_IS_GNUCC OR CMAKE_C_COMPILER_ID MATCHES "Clang")
  # Use the maximum optimization level for release builds
  foreach(var CMAKE_C_FLAGS_RELEASE CMAKE_C_FLAGS_RELWITHDEBINFO)
    if(${var} MATCHES "-O2")
      string(REGEX REPLACE "-O2" "-O3" ${var} "${${var}}")
    endif()
  endforeach()
endif()

if(CMAKE_SYSTEM_NAME STREQUAL "SunOS")
  if(CMAKE_C_COMPILER_ID MATCHES "SunPro")
    # Use the maximum optimization level for release builds
    foreach(var CMAKE_C_FLAGS_RELEASE CMAKE_C_FLAGS_RELWITHDEBINFO)
      if(${var} MATCHES "-xO3")
        string(REGEX REPLACE "-xO3" "-xO5" ${var} "${${var}}")
      endif()
      if(${var} MATCHES "-xO2")
        string(REGEX REPLACE "-xO2" "-xO5" ${var} "${${var}}")
      endif()
    endforeach()
  endif()
endif()

include(CheckTypeSize)
check_type_size("size_t" SIZE_T)
check_type_size("unsigned long" UNSIGNED_LONG)

if(ENABLE_LIBJPEG_TURBO_SIMD)
  add_subdirectory(simd)
  if(NEON_INTRINSICS)
    add_definitions(-DNEON_INTRINSICS)
  endif()
else()
  set(WITH_SIMD 0)
endif()

if(WITH_SIMD)
  message(STATUS "SIMD extensions: ${CPU_TYPE} (WITH_SIMD = ${WITH_SIMD})")
  set(HAVE_LIBJPEG_TURBO_SIMD 1 PARENT_SCOPE)
  if(MSVC_IDE OR XCODE)
    set_source_files_properties(${SIMD_OBJS} PROPERTIES GENERATED 1)
  endif()
  set(SIMD_TARGET_OBJECTS $<TARGET_OBJECTS:simd>)
endif()

configure_file(jversion.h.in jversion.h)
configure_file(jconfig.h.in jconfig.h)
configure_file(jconfigint.h.in jconfigint.h)

ocv_list_add_prefix(JPEG16_SOURCES src/)
ocv_list_add_prefix(JPEG12_SOURCES src/)
ocv_list_add_prefix(JPEG_SOURCES src/)

set(JPEG_SOURCES ${JPEG_SOURCES} ${SIMD_OBJS})

add_library(jpeg12-static OBJECT ${JPEG12_SOURCES})
set_property(TARGET jpeg12-static PROPERTY COMPILE_FLAGS
  "-DBITS_IN_JSAMPLE=12")
add_library(jpeg16-static OBJECT ${JPEG16_SOURCES})
set_property(TARGET jpeg16-static PROPERTY COMPILE_FLAGS
  "-DBITS_IN_JSAMPLE=16")
add_library(${JPEG_LIBRARY} STATIC ${JPEG_SOURCES} ${SIMD_TARGET_OBJECTS}
  ${SIMD_OBJS} $<TARGET_OBJECTS:jpeg12-static>
  $<TARGET_OBJECTS:jpeg16-static>)

set_target_properties(${JPEG_LIBRARY}
  PROPERTIES OUTPUT_NAME ${JPEG_LIBRARY}
  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
  COMPILE_PDB_NAME ${JPEG_LIBRARY}
  COMPILE_PDB_NAME_DEBUG "${JPEG_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
  )

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${JPEG_LIBRARY} PROPERTIES FOLDER "3rdparty/jpeg")
  set_target_properties(jpeg12-static PROPERTIES FOLDER "3rdparty/jpeg")
  set_target_properties(jpeg16-static PROPERTIES FOLDER "3rdparty/jpeg")
endif()

if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${JPEG_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(libjpeg-turbo README.md LICENSE.md README.ijg)

```

----------------------------------------

TITLE: Configuring zlib-ng Build with SystemZ Hardware Acceleration (Shell)
DESCRIPTION: These commands show how to configure and build zlib-ng with SystemZ deflate hardware acceleration support using either configure or cmake.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/s390/README.md#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
$ ./configure --with-dfltcc-deflate --with-dfltcc-inflate
$ make
```

LANGUAGE: shell
CODE:
```
$ cmake -DWITH_DFLTCC_DEFLATE=1 -DWITH_DFLTCC_INFLATE=1 .
$ make
```

----------------------------------------

TITLE: Defining SBT Project Build Settings (Scala)
DESCRIPTION: This Scala code defines the basic build settings for the SBT project in a file named `project/build.scala`. It sets the Scala version, defines common Scala compiler options (`scalacOptions`), aggregates default settings, and defines the root project named 'JavaSample' located in the current directory (`.`) with the combined settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_12

LANGUAGE: scala
CODE:
```
import sbt._
import Keys._

object JavaSampleBuild extends Build {
  def scalaSettings = Seq(
    scalaVersion := "2.10.0",
    scalacOptions ++= Seq(
      "-optimize",
      "-unchecked",
      "-deprecation"
    )
  )

  def buildSettings =
    Project.defaultSettings ++
    scalaSettings

  lazy val root = {
    val settings = buildSettings ++ Seq(name := "JavaSample")
    Project(id = "JavaSample", base = file("."), settings = settings)
  }
}
```

----------------------------------------

TITLE: Copying Pure Java Test Files in CMake for OpenCV
DESCRIPTION: Gathers and copies specific files for pure Java tests. It uses file(GLOB_RECURSE) to find test files and add_custom_command to copy each file to the test directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/pure_test/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
file(GLOB_RECURSE test_files RELATIVE "${test_dir}" "${test_dir}/src/*")
file(GLOB_RECURSE test_lib_files RELATIVE "${test_dir}" "${test_dir}/lib/*.jar")
foreach(f ${test_files} ${test_lib_files})
  add_custom_command(OUTPUT "${OPENCV_JAVA_TEST_DIR}/${f}"
      COMMAND ${CMAKE_COMMAND} -E copy_if_different "${test_dir}/${f}" "${OPENCV_JAVA_TEST_DIR}/${f}"
      DEPENDS "${test_dir}/${f}"
      COMMENT "Copying ${f}"
  )
  list(APPEND depends "${test_dir}/${f}" "${OPENCV_JAVA_TEST_DIR}/${f}")
endforeach()
```

----------------------------------------

TITLE: Setting up MobileNet SSD Model Downloads in CMake
DESCRIPTION: Downloads the MobileNet SSD caffemodel weights file and prototxt configuration from specified URLs. Includes hash verification and multiple fallback URLs. Files are saved to the res/raw directory of the project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/mobilenet-objdetect/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-mobilenet-objdetect)

ocv_download(FILENAME "mobilenet_iter_73000.caffemodel"
             HASH "bbcb3b6a0afe1ec89e1288096b5b8c66"
             URL
               "${OPENCV_MOBILENET_SSD_WEIGHTS_URL}"
               "$ENV{OPENCV_MOBILENET_SSD_WEIGHTS_URL}"
               "https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/97406996b1eee2d40eb0a00ae567cf41e23369f9/mobilenet_iter_73000.caffemodel"
             DESTINATION_DIR "${CMAKE_CURRENT_LIST_DIR}/res/raw"
             ID OPENCV_MOBILENET_SSD_WEIGHTS
             STATUS res)

ocv_download(FILENAME "deploy.prototxt"
             HASH "f1978dc4fe20c680e850ce99830c5945"
             URL
               "${OPENCV_MOBILENET_SSD_CONFIG_URL}"
               "$ENV{OPENCV_MOBILENET_SSD_CONFIG_URL}"
               "https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/97406996b1eee2d40eb0a00ae567cf41e23369f9/deploy.prototxt"
             DESTINATION_DIR "${CMAKE_CURRENT_LIST_DIR}/res/raw"
             ID OPENCV_MOBILENET_SSD_CONFIG
             STATUS res)
```

----------------------------------------

TITLE: Running OpenCV Unit Tests on RISC-V QEMU
DESCRIPTION: This command runs the OpenCV unit tests in the RISC-V build directory using QEMU user mode emulation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/riscv/README.md#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
cd ./build-riscv && ctest --verbose
```

----------------------------------------

TITLE: Suppressing Warnings in Autogenerated Protocol Buffer Files - CMake
DESCRIPTION: Disables a wide range of compiler warnings, particularly for compiler-generated files such as 'caffe.pb.*'. This is to prevent build interruption from non-critical warnings when building code generated by Protobuf or similar tools. No parameters or outputs beyond altering compiler warning options in the build environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: CMake
CODE:
```
ocv_warnings_disable(CMAKE_CXX_FLAGS
    /wd4125 /wd4267 /wd4127 /wd4244 /wd4512 /wd4702
    /wd4456 /wd4510 /wd4610 /wd4800
    /wd4701 /wd4703                    # potentially uninitialized local/pointer variable 'value' used
    /wd4505                            # unreferenced local function has been removed
    /wd4458                            # declaration of 'x' hides class member. GCC still works, MSVC bug is here: https://developercommunity.visualstudio.com/content/problem/219311/c-c4458-declaration-hides-class-member-warning-iss.html
    -wd858 -wd2196
    -Winvalid-offsetof                 # Apple Clang (attr_value.pb.cc)
)
```

----------------------------------------

TITLE: Single OpenCV World Library
DESCRIPTION: Shows how to link against a single OpenCV world library instead of individual module libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
opencv_world330.lib
```

----------------------------------------

TITLE: Location of Newly Built/Downloaded FastCV Libraries (Path)
DESCRIPTION: This path indicates the directory within the OpenCV build folder (`build/3rdparty/fastcv/libs`) where the FastCV libraries, potentially downloaded or updated during the CMake configuration or build process, are placed. These libraries should be used to replace any older versions residing in the eSDK sysroot path if an update is required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_7

LANGUAGE: text
CODE:
```
build\3rdparty\fastcv\libs
```

----------------------------------------

TITLE: Setting Up OpenCV Sample Project with CMake
DESCRIPTION: This CMake script sets up a sample project named 'norm' within the OpenCV framework. It checks for necessary dependencies such as opencv_core and includes OpenCV modules using ocv utility functions. The script defines the sample, resolves include directories, and links the required libraries for successful compilation. The setup assumes prior configuration of OpenCV in the environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/semihosting/norm/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(PROJECT_NAME norm)
project(${PROJECT_NAME})

ocv_install_example_src(norm *.cpp *.hpp CMakeLists.txt)

set(LOCAL_DEPS
  opencv_core
  ${OPENCV_MODULES_PUBLIC}
  ${OpenCV_LIB_COMPONENTS})
ocv_check_dependencies(${LOCAL_DEPS})

if(NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()

ocv_define_sample(norm norm.cpp ${SEMIHOSTING_SUFFIX})
ocv_include_modules_recurse(${LOCAL_DEPS})
target_include_directories(${norm} PRIVATE ${CMAKE_CURRENT_BINARY_DIR})
target_include_directories(${norm} PRIVATE ${RAW_PIXEL_INCLUDE})
ocv_target_link_libraries(${norm} PRIVATE ${OPENCV_LINKER_LIBS}
  ${LOCAL_DEPS})
```

----------------------------------------

TITLE: Detailed Image Stitching with Configurable Parameters Python
DESCRIPTION: This Python script offers customizable image stitching by adjusting parameters such as the feature type, matcher, and warp strategies. It is powered by OpenCV and is configured through command-line arguments to tailor the stitching process. Inputs involve image files, and it outputs a comprehensive panorama.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/stitcher.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
import cv2
import sys

img_names = ['boat1.jpg', 'boat2.jpg', ...]
imgs = [cv2.imread(name) for name in img_names]
stitcher = cv2.createStitcher(False)
stitcher.setFeaturesFinder(cv2.ORB_create())
stitched, result = stitcher.stitch(imgs)
if stitched == cv2.Stitcher_OK:
    cv2.imwrite('result_detailed_python.jpg', result)
```

----------------------------------------

TITLE: OpenCV Application Creation Function
DESCRIPTION: Defines a function for creating OpenCV applications with proper linking, dependencies, and installation settings. Handles module inclusion, target properties, and installation paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
function(ocv_add_application the_target)
  cmake_parse_arguments(APP "" "" "MODULES;SRCS" ${ARGN})
  ocv_check_dependencies(${APP_MODULES})
  if(NOT OCV_DEPENDENCIES_FOUND)
     return()
  endif()

  project(${the_target})
  ocv_target_include_modules_recurse(${the_target} ${APP_MODULES})
  ocv_target_include_directories(${the_target} PRIVATE "${OpenCV_SOURCE_DIR}/include/opencv")
  ocv_add_executable(${the_target} ${APP_SRCS})
  ocv_target_link_libraries(${the_target} ${APP_MODULES})
  set_target_properties(${the_target} PROPERTIES
                        DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
                        ARCHIVE_OUTPUT_DIRECTORY ${LIBRARY_OUTPUT_PATH}
                        RUNTIME_OUTPUT_DIRECTORY ${EXECUTABLE_OUTPUT_PATH}
                        OUTPUT_NAME "${the_target}")

  if(ENABLE_SOLUTION_FOLDERS)
    set_target_properties(${the_target} PROPERTIES FOLDER "applications")
  endif()

  if(NOT INSTALL_CREATE_DISTRIB
      OR (OPENCV_INSTALL_APPS_LIST STREQUAL "all" OR ";${OPENCV_INSTALL_APPS_LIST};" MATCHES ";${the_target};")
  )
    install(TARGETS ${the_target} RUNTIME DESTINATION ${OPENCV_BIN_INSTALL_PATH} COMPONENT dev)
  elseif(INSTALL_CREATE_DISTRIB)
    if(BUILD_SHARED_LIBS)
      install(TARGETS ${the_target} RUNTIME DESTINATION ${OPENCV_BIN_INSTALL_PATH} CONFIGURATIONS Release COMPONENT dev)
    endif()
  endif()
endfunction()
```

----------------------------------------

TITLE: Handling eSDK Environment Misconfiguration Warning (Shell Output)
DESCRIPTION: This text shows a potential warning message displayed when sourcing the eSDK environment setup script. It indicates that the `LD_LIBRARY_PATH` environment variable is currently set, which might interfere with the correct operation of the SDK's tools and libraries. The recommended action is to unset this variable using `unset LD_LIBRARY_PATH` after verifying it's safe to do so within the user's environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_3

LANGUAGE: shell
CODE:
```
Your environment is misconfigured, you probably need to 'unset LD_LIBRARY_PATH'
but please check why this was set in the first place and that it's safe to unset.
The SDK will not operate correctly in most cases when LD_LIBRARY_PATH is set.
```

----------------------------------------

TITLE: Setting JPEG Data Precision in libjpeg (C)
DESCRIPTION: A C integer field within the compression parameters structure (`cinfo`). This parameter specifies the number of bits per sample (valid range 2 to 16) for the JPEG output. Specific functions (`jpeg12_write_scanlines`, `jpeg16_write_scanlines`) are required for 9-12 bit and 13-16 bit precision respectively. Data precisions other than 8-bit or 12-bit necessitate the use of lossless compression mode.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_31

LANGUAGE: C
CODE:
```
int data_precision
```

----------------------------------------

TITLE: Displaying Python Integration Status in OpenCV Build
DESCRIPTION: Checks and displays information about Python 2 and Python 3 integration for OpenCV, including interpreter and library versions, NumPy support, and installation paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_28

LANGUAGE: cmake
CODE:
```
if(BUILD_opencv_python2)
  status("")
  status("  Python 2:")
  status("    Interpreter:"     PYTHON2INTERP_FOUND  THEN "${PYTHON2_EXECUTABLE} (ver ${PYTHON2_VERSION_STRING})"       ELSE NO)
  if(PYTHON2LIBS_VERSION_STRING)
    status("    Libraries:"   HAVE_opencv_python2  THEN  "${PYTHON2_LIBRARIES} (ver ${PYTHON2LIBS_VERSION_STRING})"   ELSE NO)
  else()
    status("    Libraries:"   HAVE_opencv_python2  THEN  "${PYTHON2_LIBRARIES}"                                      ELSE NO)
  endif()
  status("    numpy:"         PYTHON2_NUMPY_INCLUDE_DIRS THEN "${PYTHON2_NUMPY_INCLUDE_DIRS} (ver ${PYTHON2_NUMPY_VERSION})" ELSE "NO (Python wrappers can not be generated)")
  status("    install path:"  HAVE_opencv_python2  THEN "${__INSTALL_PATH_PYTHON2}"                            ELSE "-")
endif()

if(BUILD_opencv_python3)
  status("")
  status("  Python 3:")
  status("    Interpreter:"     PYTHON3INTERP_FOUND  THEN "${PYTHON3_EXECUTABLE} (ver ${PYTHON3_VERSION_STRING})"       ELSE NO)
  if(PYTHON3LIBS_VERSION_STRING)
    status("    Libraries:"   HAVE_opencv_python3  THEN  "${PYTHON3_LIBRARIES} (ver ${PYTHON3LIBS_VERSION_STRING})"   ELSE NO)
  else()
    status("    Libraries:"   HAVE_opencv_python3  THEN  "${PYTHON3_LIBRARIES}"                                      ELSE NO)
  endif()
  status("    Limited API:" PYTHON3_LIMITED_API THEN "YES (ver ${PYTHON3_LIMITED_API_VERSION})"                    ELSE NO)
  status("    numpy:"         PYTHON3_NUMPY_INCLUDE_DIRS THEN "${PYTHON3_NUMPY_INCLUDE_DIRS} (ver ${PYTHON3_NUMPY_VERSION})" ELSE "NO (Python3 wrappers can not be generated)")
  status("    install path:"  HAVE_opencv_python3  THEN "${__INSTALL_PATH_PYTHON3}"                            ELSE "-")
endif()

status("")
status("  Python (for build):"  PYTHON_DEFAULT_AVAILABLE THEN "${PYTHON_DEFAULT_EXECUTABLE}" ELSE NO)
```

----------------------------------------

TITLE: Command Line Navigation and Execution in Windows
DESCRIPTION: Example showing how to navigate directories and execute an OpenCV program with command line arguments in Windows Command Prompt.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_visual_studio_opencv/windows_visual_studio_opencv.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
D:\nCD OpenCV\MySolutionName\Release\nMySolutionName.exe exampleImage.jpg
```

----------------------------------------

TITLE: Configuring Installation and Solution Settings
DESCRIPTION: Sets up installation targets for static builds and configures solution folder organization when enabled.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ipphal/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(ipphal EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev)
endif()

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(ipphal PROPERTIES FOLDER "3rdparty")
endif()
```

----------------------------------------

TITLE: Configuring OpenCV CMake Build for NVIDIA Jetson TX1
DESCRIPTION: CMake configuration options for building OpenCV with CUDA support on the NVIDIA Jetson TX1 platform. Uses CUDA 8.0 and disables precompiled headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_python2=ON \
    -DBUILD_opencv_python3=OFF \
    -DENABLE_PRECOMPILED_HEADERS=OFF \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0 \
    -DCUDA_ARCH_BIN=5.3 \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=OFF \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Using a Kernel Wrapper Function in a Pipeline (OpenCV G-API, C++)
DESCRIPTION: Applies the C++ kernel wrapper function inside a graph construction to simplify kernel use with optional or default arguments. This enhances readability and usability by hiding verbose kernel interface calls. Relies on previous definition of the wrapper function and G-API context.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/doc/20-kernel-api.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
// Usage of kernel wrapper function for concise graph construction
auto out = myFilter2D(in, kernel);
// 'anchor' argument uses default value as defined in the wrapper
```

----------------------------------------

TITLE: Displaying Results with OpenCV imshow in Java
DESCRIPTION: This Java snippet provides a sample placeholder for displaying images using Java Swing or a helper class, as OpenCV Java does not have a direct imshow function. It typically requires a helper function to convert and show Mat images. Outputs are shown in individual windows.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_19

LANGUAGE: Java
CODE:
```
// Display the images (implementation for showing Mats in Java required)\nHighGui.imshow("Source", src);\nHighGui.imshow("Detected Lines (in red) - Standard Hough Line Transform", color_dst);\nHighGui.imshow("Detected Lines (in green) - Probabilistic Line Transform", color_dstP);\nHighGui.waitKey();\n
```

----------------------------------------

TITLE: Drawing 1-D Hue Histogram in Java with OpenCV
DESCRIPTION: This snippet demonstrates how to draw a 1-D Hue histogram of an image using OpenCV in Java. It creates a histogram image and uses the line function to draw the histogram bars.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_9

LANGUAGE: Java
CODE:
```
int w = 400, h = 400;
int bin_w = (int) Math.round((double) w / histSize);
Mat histImg = Mat.zeros(h, w, CvType.CV_8UC3);
for (int i = 0; i < histSize; i++) {
    Imgproc.line(histImg, new Point(bin_w * (i), h),
            new Point(bin_w * (i), h - Math.round(hist.get(i, 0)[0] * h / 255.0)),
            new Scalar(0, 0, 255), 2, 8, 0);
}
HighGui.imshow("Histogram", histImg);
```

----------------------------------------

TITLE: Default Preprocessing Configuration for PyTorch Input Blob
DESCRIPTION: This Python dictionary defines default parameters for preprocessing images before being passed to a PyTorch input blob, including mean, scale, and standard deviation values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_14

LANGUAGE: python
CODE:
```
pytorch_segm_input_blob = {
    "mean": ["123.675", "116.28", "103.53"],
    "scale": str(1 / 255.0),
    "std": ["0.229", "0.224", "0.225"],
    "crop": "False",
    "rgb": "True"
}
```

----------------------------------------

TITLE: Multiple Data Stream Capture with OpenNI
DESCRIPTION: Example demonstrating how to capture both depth map and BGR image simultaneously using grab() and retrieve() methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/kinect_openni.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
VideoCapture capture(0); // or CAP_OPENNI
for(;;)
{
    Mat depthMap;
    Mat bgrImage;

    capture.grab();

    capture.retrieve( depthMap, CAP_OPENNI_DEPTH_MAP );
    capture.retrieve( bgrImage, CAP_OPENNI_BGR_IMAGE );

    if( waitKey( 30 ) >= 0 )
        break;
}
```

----------------------------------------

TITLE: Loading Data into SIMD Registers using OpenCV Intrinsics (C++)
DESCRIPTION: This collection of snippets demonstrates how to load floating point data into variable-sized and constant-sized SIMD registers using OpenCV intrinsics. It covers construction from pointers, direct argument initialization (for constant registers), and using load functions (vx_load, v_load, v256_load, v512_load). The example assumes 'float ptr[32]', and illustrates how slicing the pointer inputs loads contiguous segments respecting the register's native lane width. Correct pointer alignment may require using vx_load_aligned.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/univ_intrin/univ_intrin.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
float ptr[32] = {1, 2, 3 ..., 32};   // ptr is a pointer to a contiguous memory block of 32 floats

// Variable Sized Registers //
int x = v_float32().nlanes;          // set x as the number of values the register can hold

v_float32 reg1(ptr);                 // reg1 stores first x values according to the maximum register size available.
v_float32 reg2(ptr + x);             // reg stores the next x values

// Constant Sized Registers //
v_float32x4 reg1(ptr);               // reg1 stores the first 4 floats (1, 2, 3, 4)
v_float32x4 reg2(ptr + 4);           // reg2 stores the next 4 floats (5, 6, 7, 8)

// Or we can explicitly write down the values.
v_float32x4(1, 2, 3, 4);
```

LANGUAGE: cpp
CODE:
```
float ptr[32] = {1, 2, 3, ..., 32};
v_float32 reg_var;
reg_var = vx_load(ptr);              // loads values from ptr[0] upto ptr[reg_var.nlanes - 1]

v_float32x4 reg_128;
reg_128 = v_load(ptr);               // loads values from ptr[0] upto ptr[3]

v_float32x8 reg_256;
reg_256 = v256_load(ptr);            // loads values from ptr[0] upto ptr[7]

v_float32x16 reg_512;
reg_512 = v512_load(ptr);            // loads values from ptr[0] upto ptr[15]
```

----------------------------------------

TITLE: Executing DNN Conversion Script for PyTorch FCN ResNet-50
DESCRIPTION: This command executes a Python script located within the `dnn_model_runner` module. The script `py_to_py_fcnresnet50.py` presumably handles the conversion of a PyTorch FCN ResNet-50 segmentation model to ONNX format and potentially runs inference or comparison.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
python -m dnn_model_runner.dnn_conversion.pytorch.segmentation.py_to_py_fcnresnet50
```

----------------------------------------

TITLE: Displaying Java Build Status in CMake
DESCRIPTION: This CMake snippet checks if Java support (`BUILD_JAVA`) is enabled. If so, it uses the `status` command to print configuration details about the Java environment (ANT, Java version, JNI headers), Java wrappers, and Java tests, depending on the values of various CMake variables set earlier in the build process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_29

LANGUAGE: cmake
CODE:
```
# ========================== java ==========================
if(BUILD_JAVA)
  status("")
  status("  Java:"            BUILD_FAT_JAVA_LIB  THEN "export all functions"                                      ELSE "")
  status("    ant:"           ANT_EXECUTABLE      THEN "${ANT_EXECUTABLE} (ver ${ANT_VERSION})"                    ELSE NO)
  if(NOT ANDROID)
    status("    Java:"        Java_FOUND     THEN "YES (ver ${Java_VERSION})"                                      ELSE NO)
    status("    JNI:"         JNI_INCLUDE_DIRS    THEN "${JNI_INCLUDE_DIRS}"                                       ELSE NO)
  endif()
  status("    Java wrappers:" HAVE_opencv_java                                                            THEN "YES (${OPENCV_JAVA_SDK_BUILD_TYPE})" ELSE NO)
  status("    Java tests:"    BUILD_TESTS AND (opencv_test_java_BINARY_DIR OR opencv_test_android_BINARY_DIR) THEN YES ELSE NO)
endif()
```

----------------------------------------

TITLE: Creating a CLAHE Object in JavaScript
DESCRIPTION: Shows how to create an instance of the `cv.CLAHE` class for Contrast Limited Adaptive Histogram Equalization in OpenCV.js. CLAHE works by dividing the image into small tiles (defined by `tileGridSize`, default 8x8) and applying histogram equalization to each tile, limiting contrast amplification using `clipLimit` (default 40) to reduce noise. Bilinear interpolation is used to smooth tile borders. The created CLAHE object needs to be deleted after use.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_histograms/js_histogram_equalization/js_histogram_equalization.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
cv.CLAHE (clipLimit = 40, tileGridSize = new cv.Size(8, 8))
```

----------------------------------------

TITLE: Displaying a Simple Alert View in an iOS ViewController
DESCRIPTION: This Objective-C code snippet, intended for the `viewDidLoad` method within a `ViewController.m` (or `.mm`) file, creates and displays a basic `UIAlertView`. It initializes the alert with a title 'Hello!', a message 'Welcome to OpenCV', sets the current view controller as the delegate, and provides a 'Continue' button. Calling `[alert show]` presents the alert to the user, confirming the application setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/hello/hello.markdown#2025-04-22_snippet_1

LANGUAGE: m
CODE:
```
UIAlertView * alert = [[UIAlertView alloc] initWithTitle:@"Hello!" message:@"Welcome to OpenCV" delegate:self cancelButtonTitle:@"Continue" otherButtonTitles:nil];
[alert show];
```

----------------------------------------

TITLE: Check for Large File Support and System Functions in CMake
DESCRIPTION: This block sets definitions for large file support and checks for optional system functions like fseeko and strerror, adding necessary macros if functions are unavailable. It highlights compiler feature checks using the check_function_exists command.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: CMake
CODE:
```
#
# Check to see if we have large file support
#
set(CMAKE_REQUIRED_DEFINITIONS -D_LARGEFILE64_SOURCE=1 -D__USE_LARGEFILE64)
check_type_size(off64_t OFF64_T)
if(HAVE_OFF64_T)
    add_definitions(-D_LARGEFILE64_SOURCE=1 -D__USE_LARGEFILE64)
else()
    check_type_size(_off64_t _OFF64_T)
    if(HAVE__OFF64_T)
        add_definitions(-D_LARGEFILE64_SOURCE=1 -D__USE_LARGEFILE64)
    else()
        check_type_size(__off64_t __OFF64_T)
    endif()
endif()
set(CMAKE_REQUIRED_DEFINITIONS) # clear variable

#
# Check for fseeko and other optional functions
#
check_function_exists(fseeko HAVE_FSEEKO)
if(NOT HAVE_FSEEKO)
    add_definitions(-DNO_FSEEKO)
endif()

check_function_exists(strerror HAVE_STRERROR)
if(NOT HAVE_STRERROR)
    add_definitions(-DNO_STRERROR)
endif()
```

----------------------------------------

TITLE: Creating Structuring Elements - OpenCV.js - JavaScript
DESCRIPTION: This snippet demonstrates the use of cv.getStructuringElement() in OpenCV.js for generating structuring elements (kernels) of defined shapes and sizes, such as rectangular, elliptical, or cross-shaped. Parameters include shape (from cv.MorphShapes), ksize (size as [width, height]), and anchor (defaults to center). The return value is a cv.Mat kernel usable in other morphological operations. Only cross-shaped elements depend on anchor values; for other shapes the anchor adjusts outcome alignment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_morphological_ops/js_morphological_ops.markdown#2025-04-22_snippet_3

LANGUAGE: JavaScript
CODE:
```
cv.getStructuringElement(shape, ksize, anchor = new cv.Point(-1, -1))
```

----------------------------------------

TITLE: Sample Employer Copyright Disclaimer
DESCRIPTION: This is a sample text for a copyright disclaimer that an employer or educational institution might sign. It explicitly disclaims copyright interest in a specific program written by an employee or student, allowing the actual author to license it freely (e.g., under the GPL). Placeholders for the company name, program name, author name, signatory details, and date need to be replaced.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ittnotify/src/ittnotify/GPL-2.0-only.txt#2025-04-22_snippet_3

LANGUAGE: plaintext
CODE:
```
Yoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision' (which makes passes at compilers) written by James Hacker.
```

----------------------------------------

TITLE: Setting Android Linker Flags for 16k Page Size Support in CMake
DESCRIPTION: Checks if `ANDROID_SUPPORT_FLEXIBLE_PAGE_SIZES` is enabled. If so, and if the target `ANDROID_ABI` is either `arm64-v8a` or `x86_64`, it appends the `-Wl,-z,max-page-size=16384` flag to `CMAKE_SHARED_LINKER_FLAGS`. This ensures compatibility with 16k page sizes on relevant architectures, particularly with older NDKs (prior to 27).
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-2-mixedprocessing/jni/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
# For 16k pages support with NDK prior 27
# Details: https://developer.android.com/guide/practices/page-sizes?hl=en
if(ANDROID_SUPPORT_FLEXIBLE_PAGE_SIZES)
  if(ANDROID_ABI STREQUAL arm64-v8a OR ANDROID_ABI STREQUAL x86_64)
    set(CMAKE_SHARED_LINKER_FLAGS "${CMAKE_SHARED_LINKER_FLAGS} -Wl,-z,max-page-size=16384")
  endif()
endif()
```

----------------------------------------

TITLE: Displaying Vulkan, WebNN, and Tim-VX Integration Status in OpenCV Build
DESCRIPTION: Checks and displays the status of Vulkan, WebNN, and Tim-VX integrations, showing include paths and library information when available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_26

LANGUAGE: cmake
CODE:
```
if(WITH_VULKAN OR HAVE_VULKAN)
  status("")
  status("  Vulkan:"     HAVE_VULKAN THEN "YES" ELSE "NO")
  if(HAVE_VULKAN)
    status("    Include path:"  VULKAN_INCLUDE_DIRS THEN "${VULKAN_INCLUDE_DIRS}" ELSE "NO")
    status("    Link libraries:" VULKAN_LIBRARIES THEN "${VULKAN_LIBRARIES}" ELSE "Dynamic load")
  endif()
endif()

if(WITH_WEBNN OR HAVE_WEBNN)
  status("")
  status("  WebNN:"     HAVE_WEBNN THEN "YES" ELSE "NO")
  if(HAVE_WEBNN AND NOT EMSCRIPTEN)
    status("    Include path:"  WEBNN_HEADER_DIRS THEN "${WEBNN_HEADER_DIRS}" ELSE "NO")
    status("    Link libraries:" WEBNN_LIBRARIES THEN "${WEBNN_LIBRARIES}" ELSE "NO")
  endif()
endif()

if(WITH_TIMVX)
  status("")
  status("  Tim-VX:"     HAVE_TIMVX THEN "YES" ELSE "NO")
  if(HAVE_TIMVX)
    status("    Include path"  TIMVX_INCLUDE_DIR THEN "${TIMVX_INCLUDE_DIR}" ELSE "NO")
    status("    Link libraries:" TIMVX_LIBRARY THEN "${TIMVX_LIBRARY}" ELSE "NO")
    status("    VIVANTE SDK path" VIVANTE_SDK_DIR THEN "${VIVANTE_SDK_DIR}" ELSE "NO")
  endif()
endif()
```

----------------------------------------

TITLE: Using a Kernel Interface in a Pipeline with ::on() (OpenCV G-API, C++)
DESCRIPTION: Demonstrates instantiating a kernel node in a computational graph using the kernel's ::on() method, matching the signature defined in the kernel interface. This allows the kernel interface to be used directly in graph construction, ensuring parameters conform to the declared interface. Requires kernel type to be defined previously via G_TYPED_KERNEL, and all G-API context prerequisites to be met.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/doc/20-kernel-api.markdown#2025-04-22_snippet_1

LANGUAGE: cpp
CODE:
```
// Example of using the kernel interface in a pipeline
auto out = Filter2D::on(in, kernel, anchor);
// 'in'      : input cv::GMat node
// 'kernel'  : input cv::Mat parameter for kernel
// 'anchor'  : input cv::Point for anchor location
// Returns a cv::GMat node as declared
```

----------------------------------------

TITLE: Building OpenCV.js with Threads Optimization - Bash
DESCRIPTION: This bash command builds OpenCV.js with WebAssembly and threads optimization enabled using Emscripten's emcmake, Python, and the OpenCV JS build script. Requires Emscripten toolchain and Python installed. The '--threads' option activates threading support; number of threads defaults to the device's logical core count. Outputs 'opencv.js' with threading support for use in browsers that enable WebAssembly threads. This optimization is not supported in Node.js environments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_15

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --build_wasm --threads
```

----------------------------------------

TITLE: Configuring CMake for libwebp in CMake
DESCRIPTION: This snippet sets up the project and includes necessary directories depending on the target platform. It utilizes CMake functions to gather all source and header files relevant to libwebp. It handles conditional compilation for ARM architectures without NEON support and sets source file properties accordingly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libwebp/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(${WEBP_LIBRARY})

ocv_include_directories(${CMAKE_CURRENT_SOURCE_DIR})
if(ANDROID)
  ocv_include_directories(${CPUFEATURES_INCLUDE_DIRS})
endif()

file(GLOB lib_srcs sharpyuv/*.c src/dec/*.c src/demux/*.c src/dsp/*.c src/enc/*.c src/mux/*.c src/utils/*.c src/webp/*.c)
file(GLOB lib_hdrs sharpyuv/*.h src/dec/*.h src/demux/*.h src/dsp/*.h src/enc/*.h src/mux/*.h src/utils/*.h src/webp/*.h)

# FIXIT
if(ANDROID AND ARMEABI_V7A AND NOT NEON)
  foreach(file ${lib_srcs})
    if("${file}" MATCHES "_neon.c")
      set_source_files_properties("${file}" COMPILE_FLAGS "-mfpu=neon")
    endif()
  endforeach()
endif()
```

----------------------------------------

TITLE: Displaying Various Library Integrations in OpenCV Build
DESCRIPTION: Checks and displays the status of multiple library integrations including VA, LAPACK, and Halide, showing whether they're enabled and their path information when available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_23

LANGUAGE: cmake
CODE:
```
if(WITH_VA OR HAVE_VA)
  status("    VA:"            HAVE_VA          THEN "YES" ELSE NO)
endif()

if(WITH_LAPACK OR HAVE_LAPACK)
  status("    Lapack:"      HAVE_LAPACK     THEN "YES (${LAPACK_LIBRARIES})" ELSE NO)
endif()

if(WITH_HALIDE OR HAVE_HALIDE)
  status("    Halide:"     HAVE_HALIDE      THEN "YES (${HALIDE_LIBRARIES} ${HALIDE_INCLUDE_DIRS})" ELSE NO)
endif()
```

----------------------------------------

TITLE: Manual CMake Command Line Build Configuration for Windows Store 8.1 x64
DESCRIPTION: Provides an example of manually invoking CMake from the command line to configure a build for Windows Store 8.1 x64. It specifies the Visual Studio 2013 Win64 generator, system name, system version, effective platform (x64), and a custom installation prefix path relative to the build directory. Assumes execution within a 'bin' subdirectory of the source.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_15

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013 Win64" -DCMAKE_SYSTEM_NAME:String=WindowsStore -DCMAKE_SYSTEM_VERSION:String=8.1 -DCMAKE_VS_EFFECTIVE_PLATFORMS:String=x64 -DCMAKE_INSTALL_PREFIX:PATH=.\install\WS\8.1\x64\ ..
```

----------------------------------------

TITLE: Generating OpenCV for Windows Phone 8.0 x86 using CMake
DESCRIPTION: Invokes CMake directly using the Visual Studio 2013 generator to create project files for OpenCV targeting Windows Phone 8.0 on the x86 architecture. Specifies the system name and older system version (8.0).
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_9

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013" -DCMAKE_SYSTEM_NAME=WindowsPhone -DCMAKE_SYSTEM_VERSION=8.0 <path-to-source>
```

----------------------------------------

TITLE: Installing libtiff Artifacts with CMake
DESCRIPTION: This section of the script handles the installation directives for the libtiff library. It installs the library archive to a specified path and manages third-party licenses, ensuring the build output is complete with necessary documentation and binaries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: CMake
CODE:
```
if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${TIFF_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()

ocv_install_3rdparty_licenses(libtiff COPYRIGHT)
```

----------------------------------------

TITLE: Rebuilding Container Process
DESCRIPTION: Complete sequence of commands to rebuild the gaplib-actions-runner container, including stopping service, removing old container and image, building new image, and restarting service.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/s390/README.md#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
# Stop actions-runner service
sudo systemctl stop actions-runner

# Delete old container
sudo podman container rm gaplib-actions-runner

# Delete old image
sudo podman image rm localhost/zlib-ng/actions-runner

# Build image
sudo podman build --squash -f Dockerfile.zlib-ng --tag zlib-ng/actions-runner --build-arg .

# Build container
sudo podman create --name=gaplib-actions-runner --env-file=/etc/actions-runner --init --interactive --volume=actions-runner-temp:/home/actions-runner zlib-ng/actions-runner

# Start actions-runner service
sudo systemctl start actions-runner
```

----------------------------------------

TITLE: Accessing Pixel Rows/Columns with Ptr Methods (ucharPtr) in OpenCV.js - JavaScript
DESCRIPTION: Uses ucharPtr to get a Uint8Array for a specific pixel's data, making it possible to efficiently extract or work with all channels at a given coordinate. Optimized for random-access to pixel data and generally faster than repeated calls to at-like methods. Usage depends on matrix type and expected in-place read/write operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_basic_ops/js_basic_ops.markdown#2025-04-22_snippet_8

LANGUAGE: JavaScript
CODE:
```
let row = 3, col = 4;
let src = cv.imread("canvasInput");
let pixel = src.ucharPtr(row, col);
let R = pixel[0];
let G = pixel[1];
let B = pixel[2];
let A = pixel[3];
```

----------------------------------------

TITLE: Constructing Size Structures in OpenCV.js (JavaScript)
DESCRIPTION: Details two options for creating a Size structure: with the cv.Size constructor or using an object literal with width and height properties. This defines the dimensions of shapes or images. It requires OpenCV.js and numerical width and height values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_2

LANGUAGE: JavaScript
CODE:
```
// The first way
let size = new cv.Size(width, height);
// The second way
let size = {width : width, height : height};
```

----------------------------------------

TITLE: Defining UMat Class with Python Bindings in C++
DESCRIPTION: Demonstrates the definition of OpenCV's UMat class with various Python binding annotations. Includes examples of mappable types (CV_WRAP_MAPPABLE), phantom methods (CV_WRAP_PHANTOM), and method wrapping with default arguments (CV_WRAP_AS, CV_WRAP_DEFAULT).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
class CV_EXPORTS_W UMat
{
public:
    //! Mat is mappable to UMat.
    // You would need to provide `static bool cv_mappable_to(const Ptr<Mat>& src, Ptr<UMat>& dst)`
    CV_WRAP_MAPPABLE(Ptr<Mat>);

    /! returns the OpenCL queue used by OpenCV UMat.
    // You would need to provide the method body in the binder code
    CV_WRAP_PHANTOM(static void* queue());

    //! returns the OpenCL context used by OpenCV UMat
    // You would need to provide the method body in the binder code
    CV_WRAP_PHANTOM(static void* context());

    //! The wrapped method become equivalent to `get(int flags = ACCESS_RW)`
    CV_WRAP_AS(get) Mat getMat(int flags CV_WRAP_DEFAULT(ACCESS_RW)) const;
};
```

----------------------------------------

TITLE: Applying 2D Convolution with OpenCV in C++
DESCRIPTION: Demonstrates the use of cv.filter2D() in OpenCV to apply a 2D convolution over an image with a kernel. This method is used to blur images or find edges through different filter kernels like low-pass or high-pass filters. Dependencies include OpenCV. Key parameters are the source image, destination image, kernel, and border type. The snippet highlights an example of a 5x5 averaging filter kernel.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_filtering/js_filtering.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
cv::filter2D(src, dst, ddepth, kernel, cv::Point(-1, -1), 0, cv::BORDER_DEFAULT);
```

----------------------------------------

TITLE: Drawing Face Masks in C++
DESCRIPTION: This snippet handles drawing masks by calculating and manipulating several layers of masks ('sharp', 'bilateral', and 'background') using G-API's threshold and bitwise operations to prepare them for use in face beautification.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_8

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/face_beautification/face_beautification.cpp msk_ppline
```

----------------------------------------

TITLE: Checking C++11 Support for OpenEXR in CMake
DESCRIPTION: This code checks if the compiler supports C++11, which is required for OpenEXR. If C++11 is not supported, it disables the OpenEXR build with a warning message.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(NOT HAVE_CXX11)
  ocv_check_compiler_flag(CXX "-std=c++11" HAVE_STD_CXX11 "${OpenCV_SOURCE_DIR}/cmake/checks/cxx11.cpp")
  if(HAVE_STD_CXX11)
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++11")
  else()
    if(BUILD_OPENEXR)
      message(WARNING "OpenCV: builtin OpenEXR requires C++11 support. OpenEXR is disabled.")
    endif()
    return()
  endif()
endif()
```

----------------------------------------

TITLE: Basic CMakeLists.txt for an OpenCV Project
DESCRIPTION: This snippet shows the content of a simple `CMakeLists.txt` file used to build an OpenCV application with CMake, suitable for generating an Eclipse project. It defines the project name (`helloworld_proj`), finds the required OpenCV package using `FIND_PACKAGE`, specifies the executable name and source file (`ADD_EXECUTABLE`), and links the executable against the necessary OpenCV libraries found by CMake (`TARGET_LINK_LIBRARIES`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_7

LANGUAGE: bash
CODE:
```
PROJECT( helloworld_proj )
FIND_PACKAGE( OpenCV REQUIRED )
ADD_EXECUTABLE( helloworld helloworld.cxx )
TARGET_LINK_LIBRARIES( helloworld \f${OpenCV_LIBS} )
```

----------------------------------------

TITLE: Conditionally Including Android SDK or JAR Subdirectory in CMake
DESCRIPTION: This snippet conditionally includes either the `android_sdk` or the `jar` subdirectory based on the value of the `ANDROID` CMake variable. If building for Android (`ANDROID` is true), it includes `android_sdk` to generate the `${the_module}_android` target. Otherwise, it includes `jar` to generate the `${the_module}_jar` target for standard Java environments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
if(ANDROID)
  add_subdirectory(android_sdk)  # generates ${the_module}_android target
else()
  add_subdirectory(jar)  # generates ${the_module}_jar target
endif()
```

----------------------------------------

TITLE: Handling Standalone Build Initial Pass in CMake
DESCRIPTION: Checks if the CMake script is being run in a standalone build context (not as part of the main OpenCV build). If `OPENCV_INITIAL_PASS` is not defined, it configures a minimal project named 'gapi_standalone', includes a specific CMake file for standalone configuration, and exits the current script processing to prevent further execution in this context.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
# FIXME: Rework standalone build in more generic maner
# (Restructure directories, add common pass, etc)
if(NOT DEFINED OPENCV_INITIAL_PASS)
    cmake_minimum_required(VERSION 3.3)
    project(gapi_standalone)
    include("cmake/standalone.cmake")
    return()
endif()
```

----------------------------------------

TITLE: Custom Implementation of Otsu's Algorithm in Python
DESCRIPTION: Shows a manual implementation of Otsu's thresholding algorithm to demonstrate how it calculates the optimal threshold value by minimizing weighted within-class variance.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
img = cv.imread('noisy2.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
blur = cv.GaussianBlur(img,(5,5),0)

# find normalized_histogram, and its cumulative distribution function
hist = cv.calcHist([blur],[0],None,[256],[0,256])
hist_norm = hist.ravel()/hist.sum()
Q = hist_norm.cumsum()

bins = np.arange(256)

fn_min = np.inf
thresh = -1

for i in range(1,256):
    p1,p2 = np.hsplit(hist_norm,[i]) # probabilities
    q1,q2 = Q[i],Q[255]-Q[i] # cum sum of classes
    if q1 < 1.e-6 or q2 < 1.e-6:
        continue
    b1,b2 = np.hsplit(bins,[i]) # weights

    # finding means and variances
    m1,m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2
    v1,v2 = np.sum(((b1-m1)**2)*p1)/q1,np.sum(((b2-m2)**2)*p2)/q2

    # calculates the minimization function
    fn = v1*q1 + v2*q2
    if fn < fn_min:
        fn_min = fn
        thresh = i

# find otsu's threshold value with OpenCV function
ret, otsu = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)
print( "{} {}".format(thresh,ret) )
```

----------------------------------------

TITLE: Running Object Detection Model with OpenCV
DESCRIPTION: Command line example for running object detection using OpenCV face detection model with custom model and config paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/README.md#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
python object_detection.py opencv_fd --model /path/to/caffemodel --config /path/to/prototxt
```

----------------------------------------

TITLE: Installing OpenCV Binaries using CMake (Shell)
DESCRIPTION: This shell command installs OpenCV or related build products from the build directory to the system or user-selected install prefix. Prerequisites include a successful build step and sufficient permissions for the install path (run with superuser privileges if needed). <build-directory> is where the compiled binaries reside. The --target install argument triggers the install process, and <other-options> may include configuration like release/debug mode. The installed files will go to the default or specified installation location.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/general_install/general_install.markdown#2025-04-22_snippet_3

LANGUAGE: shell
CODE:
```
cmake --build <build-directory> --target install <other-options>
```

----------------------------------------

TITLE: Custom Serialization Usage with FileStorage for Custom Classes - OpenCV Python
DESCRIPTION: This Python snippet illustrates using the custom class's write and read methods to serialize and deserialize an instance using OpenCV's FileStorage. The class methods must handle all attributes. Requires that the class and its serialization methods are properly implemented.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_17

LANGUAGE: Python
CODE:
```
data = MyData()\ndata.write(fs)\ndata2 = MyData()\ndata2.read(node)
```

----------------------------------------

TITLE: Loading Animation Frames in OpenCV
DESCRIPTION: Shows how to use cv::imreadanimation to load frames from an animated WebP image file. The function loads all frames into the animation structure for processing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/animations.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cv::imreadanimation("animated.webp", animation);
```

LANGUAGE: Python
CODE:
```
animation = cv.imreadanimation("animated.webp")
```

----------------------------------------

TITLE: Comparing PyTorch Preprocessing Order
DESCRIPTION: This Python-like pseudocode illustrates the standard image preprocessing steps often used with PyTorch models trained on ImageNet. It involves scaling pixel values to the [0, 1] range, subtracting the per-channel mean, and then dividing by the per-channel standard deviation. This clarifies why the `mean` values in the `cv2.dnn.blobFromImage` example were multiplied by 255.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_6

LANGUAGE: python
CODE:
```
img /= 255.0
img -= [0.485, 0.456, 0.406]
img /= [0.229, 0.224, 0.225]
```

----------------------------------------

TITLE: Drawing an Atom in C++
DESCRIPTION: Drawing an atom using ellipses and circles in OpenCV C++. The atom is represented by ellipses for orbits and filled circles for electrons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
/// 1. Draw a simple atom:
/// -----------------------

/// 1.a. Creating ellipses
MyEllipse( atom_image, 90 );
MyEllipse( atom_image, 0 );
MyEllipse( atom_image, 45 );
MyEllipse( atom_image, -45 );

/// 1.b. Creating circles
MyFilledCircle( atom_image, Point( w/2, w/2) );

```

----------------------------------------

TITLE: Accessing 1D Histogram Bin Value in C++
DESCRIPTION: C++ code example demonstrating how to access the value of a specific bin in a 1D histogram stored in a `cv::Mat`. It uses the `.at<float>(i)` method, where `i` is the index of the desired bin.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_30

LANGUAGE: cpp
CODE:
```
b_hist.at<float>(i)
```

----------------------------------------

TITLE: Executing Text Recognition Using Bash
DESCRIPTION: These bash examples illustrate how to execute text recognition using pre-trained models available in the OpenCV repository. The commands run binary executable files with specific model paths and image paths as parameters. It requires OpenCV compiled binaries and ONNX or protobuf model files. Inputs include paths to models, images, and an alphabet file for recognition, with options like '-rgb' flag for preprocessing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_8

LANGUAGE: bash
CODE:
```
example_dnn_scene_text_recognition -mp=path/to/crnn_cs.onnx -i=path/to/an/image -rgb=1 -vp=/path/to/alphabet_94.txt
example_dnn_scene_text_detection -mp=path/to/DB_TD500_resnet50.onnx -i=path/to/an/image -ih=736 -iw=736
example_dnn_scene_text_spotting -dmp=path/to/DB_IC15_resnet50.onnx -rmp=path/to/crnn_cs.onnx -i=path/to/an/image -iw=1280 -ih=736 -rgb=1 -vp=/path/to/alphabet_94.txt
example_dnn_text_detection -dmp=path/to/EAST.pb -rmp=path/to/crnn_cs.onnx -i=path/to/an/image -rgb=1 -vp=path/to/alphabet_94.txt
```

----------------------------------------

TITLE: Segmentation Test Module Configuration
DESCRIPTION: Defines the configuration for the segmentation test module, including paths to test data, input image, and model parameters such as frame dimensions, preprocessing options for scaling, mean subtraction, and normalization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_12

LANGUAGE: python
CODE:
```
@dataclass
class TestSegmModuleConfig:
    segm_test_data_dir: str = "test_data/sem_segm"
    test_module_name: str = "segmentation"
    test_module_path: str = "segmentation.py"
    input_img: str = os.path.join(segm_test_data_dir, "2007_000033.jpg")
    model: str = ""

    frame_height: str = str(TestSegmConfig.frame_size)
    frame_width: str = str(TestSegmConfig.frame_size)
    scale: float = 1.0
    mean: List[float] = field(default_factory=lambda: [0.0, 0.0, 0.0])
    std: List[float] = field(default_factory=list)
    crop: bool = False
    rgb: bool = True
    classes: str = os.path.join(segm_test_data_dir, "pascal-classes.txt")
```

----------------------------------------

TITLE: Setting eSDK Root Environment Variable for Qualcomm Linux Build (Shell)
DESCRIPTION: This shell command sets the `ESDK_ROOT` environment variable to the installation path of the Qualcomm Embedded Software Development Kit (eSDK). This variable is essential for the subsequent build steps, as it allows the build system and environment setup scripts to locate the necessary tools and libraries within the eSDK. Replace `<eSDK install location>` with the actual directory where the eSDK is installed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_1

LANGUAGE: shell
CODE:
```
export ESDK_ROOT=<eSDK install location>
```

----------------------------------------

TITLE: Text Detection on Public Datasets Using Bash
DESCRIPTION: These bash examples are for detecting text on public datasets using models specified in ONNX format. They demonstrate the execution of text detection with adjustable input dimensions and evaluation paths. Required dependencies include pre-compiled OpenCV and model files along with the evaluation dataset. Users should adjust '-ih' and '-iw' options based on the input image resolution constraints.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_text_spotting/dnn_text_spotting.markdown#2025-04-22_snippet_10

LANGUAGE: bash
CODE:
```
example_dnn_scene_text_detection -mp=path/to/DB_TD500_resnet50.onnx -e=true -edp=path/to/evaluation_data_det/TD500 -ih=736 -iw=736
example_dnn_scene_text_detection -mp=path/to/DB_IC15_resnet50.onnx -e=true -edp=path/to/evaluation_data_det/IC15 -ih=736 -iw=1280
```

----------------------------------------

TITLE: Building OpenCV.js on Windows with Docker Using Emscripten Version 2.0.10 - Bash/PowerShell
DESCRIPTION: This command runs the OpenCV.js build process from within a Docker container on Windows using a specific tested tag of emscripten/emsdk (2.0.10). It ensures compatibility and uses PowerShell pathing for mounting the source directory. Outputs are OpenCV.js builds. Requires Docker, PowerShell, and correct permissions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_26

LANGUAGE: bash
CODE:
```
docker run --rm --workdir /src -v "$(get-location):/src" "emscripten/emsdk:2.0.10" emcmake python3 ./platforms/js/build_js.py build_js
```

----------------------------------------

TITLE: Building OpenCV.js with emcmake and Build Script - Bash
DESCRIPTION: Invokes the build script for OpenCV.js using Python with emcmake to set up the Emscripten toolchain. It targets a directory named build_js for output. Prerequisites: emcmake, Python, and CMake are installed. Parameters: paths to the build script and build directory. Output is a bundled opencv.js file with WebAssembly embedded or separate, depending on flags. For production, additional options can be passed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js
```

----------------------------------------

TITLE: Markdown Tutorial Navigation Structure for SVM
DESCRIPTION: Markdown structure defining the navigation hierarchy for SVM tutorials, including links to basic concepts and OpenCV implementation pages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_svm/py_svm_index.markdown#2025-04-22_snippet_0

LANGUAGE: markdown
CODE:
```
Support Vector Machines (SVM) {#tutorial_py_svm_index}
=============================

-   @subpage tutorial_py_svm_basics

    Get a basic understanding of what SVM is

-   @subpage tutorial_py_svm_opencv

    Let's use SVM functionalities in OpenCV
```

----------------------------------------

TITLE: Library Target Definition
DESCRIPTION: Defines the PNG library target with its source files, linking dependencies, and output properties.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libpng/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
add_library(${PNG_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${lib_srcs} ${lib_hdrs})
target_link_libraries(${PNG_LIBRARY} ${ZLIB_LIBRARIES})

set_target_properties(${PNG_LIBRARY}
  PROPERTIES OUTPUT_NAME ${PNG_LIBRARY}
  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
  COMPILE_PDB_NAME ${PNG_LIBRARY}
  COMPILE_PDB_NAME_DEBUG "${PNG_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
  )
```

----------------------------------------

TITLE: Configuring Platform-Specific Settings for OpenEXR
DESCRIPTION: This code detects the platform (Windows, Apple, or UNIX) and sets appropriate platform-specific configuration flags for OpenEXR. It handles special cases like semaphore support on different platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
if(WIN32)
  set(HAVE_COMPLETE_IOMANIP 1)
  set(OPENEXR_IMF_HAVE_COMPLETE_IOMANIP 1)
  set(PLATFORM_WINDOWS 1)
elseif(APPLE)
  set(HAVE_POSIX_SEMAPHORES 0)  # Unnamed semaphores are not supported: https://github.com/opencv/opencv/issues/9361
  if(DARWIN)
    set(OPENEXR_IMF_HAVE_DARWIN 1)
  endif()
elseif(UNIX)
  include(CheckIncludeFile)
  check_include_file(semaphore.h HAVE_POSIX_SEMAPHORES)
endif()
```

----------------------------------------

TITLE: Displaying an Image using OpenCV in Python
DESCRIPTION: This snippet shows how to display an image in Python using OpenCV's cv.imshow. It creates a window with the specified title and shows the image array until a key is pressed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/display_image/display_image.markdown#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
cv.imshow('Display window', image)
cv.waitKey(0)
```

----------------------------------------

TITLE: Template Matching Formula: TM_CCOEFF (LaTeX)
DESCRIPTION: Mathematical formula for the Correlation Coefficient (TM_CCOEFF) template matching method used in OpenCV's `matchTemplate` function. It uses mean-subtracted template (T') and image patches (I'). R(x,y) is the result, T is the template, I is the image, w is width, and h is height.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_5

LANGUAGE: latex
CODE:
```
\f[R(x,y)= \sum _{x',y'} (T'(x',y')  \cdot I'(x+x',y+y'))\f]

where

\f[\begin{array}{l} T'(x',y')=T(x',y') - 1/(w  \cdot h)  \cdot \sum _{x'',y''} T(x'',y'') \\ I'(x+x',y+y')=I(x+x',y+y') - 1/(w  \cdot h)  \cdot \sum _{x'',y''} I(x+x'',y+y'') \end{array}\f]
```

----------------------------------------

TITLE: Loading Images with OpenCV in Java
DESCRIPTION: This snippet loads an image using OpenCV's Imgcodecs module in Java. It uses Imgcodecs.imread and checks for null or empty image matrices. The required parameter is the file path; the output is a Mat object. OpenCV Java bindings must be correctly configured.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_1

LANGUAGE: Java
CODE:
```
import org.opencv.core.*;\nimport org.opencv.imgcodecs.Imgcodecs;\n\nMat src = Imgcodecs.imread("path_to_image", Imgcodecs.IMREAD_COLOR);\nif(src.empty()) {\n    System.out.println("Could not open or find the image!");\n    return;\n}\n
```

----------------------------------------

TITLE: Feature Matching with FLANN Matcher - Python
DESCRIPTION: This snippet uses the FLANN-based matcher in OpenCV to find matching features between two sets of SIFT descriptors. It requires a previous initialization of descriptors with SIFT and outputs matching points with a ratio test to filter the best matches.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
# FLANN parameters
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks=50)

flann = cv.FlannBasedMatcher(index_params,search_params)
matches = flann.knnMatch(des1,des2,k=2)

pts1 = []
pts2 = []

# ratio test as per Lowe's paper
for i,(m,n) in enumerate(matches):
    if m.distance < 0.8*n.distance:
        pts2.append(kp2[m.trainIdx].pt)
        pts1.append(kp1[m.queryIdx].pt)
```

----------------------------------------

TITLE: Pixel Intensity Comparison for Corner Detection in C++
DESCRIPTION: This code snippet implements a corner detection algorithm by comparing pixel intensities at different offsets. It uses nested if-else statements to navigate through various conditions, ultimately determining whether a point is a corner or not.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_23

LANGUAGE: C++
CODE:
```
if(ptr[offset3] < c_b)
  if(ptr[offset4] < c_b)
    if(ptr[offset8] < c_b)
      goto is_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;

// ... (more nested conditions)

if(ptr[offset9] > cb)
  if(ptr[offset1] < c_b)
    if(ptr[offset6] < c_b)
      goto is_not_a_corner;
    else
      if(ptr[offset6] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto is_a_corner;
```

----------------------------------------

TITLE: Markdown Header for VideoIO Module Documentation
DESCRIPTION: Markdown section header defining the documentation title for OpenCV's videoio module with an HTML anchor tag reference.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/_old/table_of_content_videoio.markdown#2025-04-22_snippet_0

LANGUAGE: markdown
CODE:
```
Video Input and Output (videoio module) {#tutorial_table_of_content_videoio}
=========================================

Content has been moved to this page: @ref tutorial_table_of_content_app
```

----------------------------------------

TITLE: Defining and Exporting the OpenCV imgproc Module with Language Bindings in CMake
DESCRIPTION: This CMake snippet defines the 'imgproc' module and declares its dependency on 'opencv_core'. Additionally, it specifies that wrappers should be generated for Java, Objective-C, Python, and JavaScript, enabling cross-language bindings of this module's functionality. Dependencies must be available and WRAP flags ensure the proper bindings generation for the specified languages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/imgproc/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
ocv_define_module(imgproc opencv_core WRAP java objc python js)
```

----------------------------------------

TITLE: Querying Color Conversion Flags with OpenCV in Python
DESCRIPTION: This snippet illustrates querying all available color conversion flags in OpenCV by listing any attribute starting with 'COLOR_' from the cv2 module. Useful for checking supported color-space conversions at runtime. Requires OpenCV (cv2) to be installed. No inputs other than the Python interpreter; output is a printed list of conversion flags.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
>>> import cv2 as cv\n>>> flags = [i for i in dir(cv) if i.startswith('COLOR_')]\n>>> print( flags )
```

----------------------------------------

TITLE: Formatting Module Reference Lists for Doxygen in CMake
DESCRIPTION: Formats the previously gathered main and extra module references (`refs_main`, `refs_extra`) into markdown lists suitable for inclusion in the Doxygen documentation root file. Each list is prefixed with a header ('- Main modules:' or '- Extra modules:').
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
# fix references
# set(ref_header "Module name | Folder\n----------- | ------")
# if(refs_main)
#    set(refs_main "### Main modules\n${ref_header}\n${refs_main}")
# endif()
# if(refs_extra)
#   set(refs_extra "### Extra modules\n${ref_header}\n${refs_extra}")
# endif()
if(refs_main)
  set(refs_main "- Main modules:\n${refs_main}")
endif()
if(refs_extra)
  set(refs_extra "- Extra modules:\n${refs_extra}")
endif()
```

----------------------------------------

TITLE: Enabling ICC Profile Extraction via Marker Saving - libjpeg - C
DESCRIPTION: Illustrates the use of jpeg_save_markers to enable extraction of embedded ICC profiles from JPEG markers. This call configures the decompression context to save all APP2 (ICC) markers for subsequent retrieval by jpeg_read_icc_profile. Must be called before reading JPEG header in decompression; third parameter indicates maximum marker length to save.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_63

LANGUAGE: c
CODE:
```
jpeg_save_markers(cinfo, JPEG_APP0 + 2, 0xFFFF);
```

----------------------------------------

TITLE: Applying Laplacian Operator in Python
DESCRIPTION: Applies the Laplacian operator to the grayscale image (`src_gray`) using cv2.Laplacian. The output depth (`ddepth`) is specified as cv2.CV_16S to handle potential negative values from the second derivative and prevent overflow. Kernel size, scale, delta, and border type use predefined values. Requires cv2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_17

LANGUAGE: python
CODE:
```
#! [laplacian]
# [laplacian]
# Apply Laplace function
dst = cv.Laplacian( src_gray, ddepth, ksize=kernel_size )
# [laplacian]
# ! [laplacian]
```

----------------------------------------

TITLE: Setting RANSAC Parameters for Pose Estimation in C++
DESCRIPTION: Defines RANSAC parameters for iterative pose estimation in OpenCV, detailing iteration counts, reprojection errors, and confidence levels in a C++ application.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_16

LANGUAGE: cpp
CODE:
```
// RANSAC parameters

int iterationsCount = 500;        // number of Ransac iterations.
float reprojectionError = 2.0;    // maximum allowed distance to consider it an inlier.
float confidence = 0.95;          // RANSAC successful confidence.
```

----------------------------------------

TITLE: Processing OpenCV Install Apps List
DESCRIPTION: Converts comma-separated list of apps to semicolon-separated for CMake compatibility.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
string(REPLACE "," ";" OPENCV_INSTALL_APPS_LIST "${OPENCV_INSTALL_APPS_LIST}")
```

----------------------------------------

TITLE: Build Options Configuration
DESCRIPTION: Defines various build options for controlling features, compatibility, testing, optimizations, and runtime behavior of the library
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
option(WITH_GZFILEOP "Compile with support for gzFile related functions" ON)
option(ZLIB_COMPAT "Compile with zlib compatible API" ON)
option(ZLIB_ENABLE_TESTS "Build test binaries" OFF)
option(ZLIBNG_ENABLE_TESTS "Test zlib-ng specific API" OFF)
option(WITH_GTEST "Build gtest_zlib" OFF)
option(WITH_FUZZERS "Build test/fuzz" OFF)
option(WITH_BENCHMARKS "Build test/benchmarks" OFF)
option(WITH_BENCHMARK_APPS "Build application benchmarks" OFF)
option(WITH_OPTIM "Build with optimisation" ON)
option(WITH_REDUCED_MEM "Reduced memory usage for special cases (reduces performance)" OFF)
option(WITH_NEW_STRATEGIES "Use new strategies" ON)
option(WITH_NATIVE_INSTRUCTIONS
    "Instruct the compiler to use the full instruction set on this host (gcc/clang -march=native)" OFF)
option(WITH_RUNTIME_CPU_DETECTION "Build with runtime detection of CPU architecture" ON)
option(WITH_MAINTAINER_WARNINGS "Build with project maintainer warnings" OFF)
option(WITH_CODE_COVERAGE "Enable code coverage reporting" OFF)
option(WITH_INFLATE_STRICT "Build with strict inflate distance checking" OFF)
option(WITH_INFLATE_ALLOW_INVALID_DIST "Build with zero fill for inflate invalid distances" OFF)
option(WITH_UNALIGNED "Support unaligned reads on platforms that support it" ON)
```

----------------------------------------

TITLE: Preparing TBB Version Information for Build
DESCRIPTION: Sets up the TBB source files list and configures the version string file that will be embedded in the library. This ensures the built library contains proper version information.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
set(TBB_SOURCE_FILES ${lib_srcs} ${lib_hdrs})

set(tbb_version_file "version_string.ver")
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/${tbb_version_file}.cmakein" "${CMAKE_CURRENT_BINARY_DIR}/${tbb_version_file}" @ONLY)
list(APPEND TBB_SOURCE_FILES "${CMAKE_CURRENT_BINARY_DIR}/${tbb_version_file}")
```

----------------------------------------

TITLE: Running the Ant Build Script (Bash)
DESCRIPTION: This Bash command executes the Ant build process defined in `build.xml`. It uses the '-D' flag to pass Java system properties required by the build script: `ocvJarDir` specifies the directory containing the OpenCV JAR file (e.g., `opencv-xxx.jar`), and `ocvLibDir` specifies the directory containing the native OpenCV Java library (e.g., `libopencv_javaxxx.so` or `opencv_javaxxx.dll`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_8

LANGUAGE: bash
CODE:
```
ant -DocvJarDir=path/to/dir/containing/opencv-244.jar -DocvLibDir=path/to/dir/containing/opencv_java244/native/library
```

----------------------------------------

TITLE: Displaying Animation Frames with OpenCV
DESCRIPTION: Illustrates how to iterate through and display each frame of the animation with a delay to simulate animated playback using OpenCV windows.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/animations.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
for (size_t i = 0; i < animation.frames.size(); i++) {
    cv::imshow("Animation", animation.frames[i]);
    cv::waitKey(animation.delays[i]);
}
```

LANGUAGE: Python
CODE:
```
for frame, delay in zip(animation["frames"], animation["delays"]):
    cv.imshow("Animation", frame)
    cv.waitKey(delay)
```

----------------------------------------

TITLE: Creating and Plotting One-Dimensional Test Data for K-Means Clustering in Python
DESCRIPTION: This code generates random one-dimensional test data, reshapes it into a column vector format for K-means, and plots a histogram of the data. The data consists of 50 values divided into two groups (25 values in range 25-100 and 25 values in range 175-255).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

x = np.random.randint(25,100,25)
y = np.random.randint(175,255,25)
z = np.hstack((x,y))
z = z.reshape((50,1))
z = np.float32(z)
plt.hist(z,256,[0,256]),plt.show()
```

----------------------------------------

TITLE: Applying Top Hat Transform with OpenCV Python
DESCRIPTION: Shows how to perform top hat transformation which finds the difference between input image and its opening.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.markdown#2025-04-22_snippet_5

LANGUAGE: Python
CODE:
```
tophat = cv.morphologyEx(img, cv.MORPH_TOPHAT, kernel)
```

----------------------------------------

TITLE: Loading Images for Histogram Comparison in OpenCV
DESCRIPTION: Code for loading three test images with different environment settings to be used for histogram comparison testing.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
Mat src_base = imread( argv[1], IMREAD_COLOR );
Mat src_test1 = imread( argv[2], IMREAD_COLOR );
Mat src_test2 = imread( argv[3], IMREAD_COLOR );
```

LANGUAGE: java
CODE:
```
Mat src_base = Imgcodecs.imread( samples.findFile(args[0]) );
Mat src_test1 = Imgcodecs.imread( samples.findFile(args[1]) );
Mat src_test2 = Imgcodecs.imread( samples.findFile(args[2]) );
```

LANGUAGE: python
CODE:
```
src_base = cv.imread(samples.findFile(argv[1]))
src_test1 = cv.imread(samples.findFile(argv[2]))
src_test2 = cv.imread(samples.findFile(argv[3]))
```

----------------------------------------

TITLE: Configuring OpenMP Backend with CMake
DESCRIPTION: This snippet checks and configures OpenMP as a parallel backend for an OpenCV example. It finds OpenMP and sets up a project if OpenMP is available. The `example-openmp.cpp` is added as an executable, and necessary libraries are linked. This configuration requires OpenCV's core module and the OpenMP C++ libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/cpp/tutorial_code/core/parallel_backend/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(NOT OPENCV_EXAMPLES_SKIP_PARALLEL_BACKEND_OPENMP
    AND NOT OPENCV_EXAMPLES_SKIP_OPENMP
)
  project(opencv_example_openmp_backend)
  find_package(OpenMP)
  if(OpenMP_FOUND)
    add_executable(opencv_example_openmp_backend example-openmp.cpp)
    target_link_libraries(opencv_example_openmp_backend PRIVATE
        opencv_core
        OpenMP::OpenMP_CXX
    )
  endif()
endif()
```

----------------------------------------

TITLE: Moving OpenCV Python Module to System Site-Packages (Shell)
DESCRIPTION: Uses the `mv` command as root (`su`) to relocate the compiled OpenCV Python wrapper (`cv2.so`) from its installation directory (`/usr/local/lib/python2.7/site-packages/`) to a standard Python site-packages location (`/usr/lib/python2.7/site-packages`). This makes the module discoverable by the Python interpreter without modifying environment variables, but may need repeating after updates.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_16

LANGUAGE: sh
CODE:
```
su mv /usr/local/lib/python2.7/site-packages/cv2.so /usr/lib/python2.7/site-packages
```

----------------------------------------

TITLE: Adaptive Thresholding Implementation in OpenCV Python
DESCRIPTION: Shows implementation of adaptive thresholding using both mean and Gaussian methods. Compares global thresholding with adaptive thresholding approaches for images with varying illumination.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

img = cv.imread('sudoku.png', cv.IMREAD_GRAYSCALE)
assert img is not None, "file could not be read, check with os.path.exists()"
img = cv.medianBlur(img,5)

ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)
th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\
            cv.THRESH_BINARY,11,2)
th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv.THRESH_BINARY,11,2)

titles = ['Original Image', 'Global Thresholding (v = 127)',
            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']
images = [img, th1, th2, th3]

for i in range(4):
    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])
plt.show()
```

----------------------------------------

TITLE: Performing Meanshift in OpenCV.js
DESCRIPTION: This snippet demonstrates the use of cv.meanShift to track objects using their histogram backprojection in OpenCV.js. Required dependencies include OpenCV.js library. Key parameters are probImage (back projection of the object histogram), window (initial search window), and criteria (stop criteria). Outputs the number of iterations and the new location of the window.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_video/js_meanshift/js_meanshift.markdown#2025-04-22_snippet_0

LANGUAGE: JavaScript
CODE:
```
cv.meanShift(probImage, window, criteria);
```

----------------------------------------

TITLE: Enabling Noisy Compiler Warnings in OpenCV via CMake (CMake)
DESCRIPTION: This CMake option enables additional compiler warnings considered less critical (noisy warnings). It can be set by using -DENABLE_NOISY_WARNINGS=ON in the CMake command. There are no dependencies, but enabling it will result in more detailed output from the compiler. Used to help developers identify potential issues even if not all are critical.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_25

LANGUAGE: cmake
CODE:
```
ENABLE_NOISY_WARNINGS
```

----------------------------------------

TITLE: Setting Up Working Directory and Cloning Repositories (Bash)
DESCRIPTION: Navigates to the home directory, creates a 'work' directory, changes into it, and then clones the main OpenCV repository and the OpenCV Contrib repository from GitHub. The `--depth=1` flag performs a shallow clone, downloading only the latest revision to save time and space.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
cd ~
mkdir work
cd work
git clone --depth=1 https://github.com/opencv/opencv.git
git clone --depth=1 https://github.com/opencv/opencv_contrib.git
```

----------------------------------------

TITLE: OpenCV Wayland Sample Application
DESCRIPTION: Example C++ application demonstrating basic Wayland window creation and image display using OpenCV. Shows how to create a window, load an image, and handle basic window events.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/highgui_wayland_ubuntu.markdown#2025-04-22_snippet_2

LANGUAGE: cpp
CODE:
```
// g++ main.cpp -o a.out -I /usr/local/include/opencv4 -lopencv_core -lopencv_highgui -lopencv_imgcodecs
#include <opencv2/core.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgcodecs.hpp>
#include <iostream>
#include <string>

int main(void)
{
  std::cout << "cv::currentUIFramework() returns " << cv::currentUIFramework() << std::endl;

  cv::Mat src;
  src = cv::imread("opencv-logo.png");

  cv::namedWindow("src");

  int key = 0;
  do
  {
      cv::imshow("src", src );
      key = cv::waitKey(50);
  } while( key != 'q' );
  return 0;
}
```

----------------------------------------

TITLE: Computing Histograms for BGR Channels in Java
DESCRIPTION: Java snippet calculating histograms for each B, G, and R plane using `Imgproc.calcHist`. It takes the list of planes (`bgrPlanes`), specifies the channel index (0), uses no mask (`new Mat()`), defines output Mats (`bHist`, `gHist`, `rHist`), and provides parameters (`histSize`, `histRange`, `histUniform`, `accumulate`).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_19

LANGUAGE: java
CODE:
```
@snippet samples/java/tutorial_code/Histograms_Matching/histogram_calculation/CalcHistDemo.java Compute the histograms
```

----------------------------------------

TITLE: Defining a Helper Function for Random Color Generation in OpenCV C++
DESCRIPTION: Defines a static helper function `randomColor` that takes a reference to a cv::RNG object. It generates a random unsigned integer from the RNG and then extracts byte-sized components using bitwise operations to create a random BGR color represented as a cv::Scalar object.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/random_generator_and_text/random_generator_and_text.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
@code{.cpp}
static Scalar randomColor( RNG& rng )
  {
  int icolor = (unsigned) rng;
  return Scalar( icolor&255, (icolor>>8)&255, (icolor>>16)&255 );
  }
@endcode
```

----------------------------------------

TITLE: Drawing Probabilistic Hough Line Segments in OpenCV (Python)
DESCRIPTION: This Python snippet draws the line segments detected by HoughLinesP onto the image. For every segment, it draws a green line between the two endpoints using cv2.line. Expects output from HoughLinesP and OpenCV/numpy imports.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_17

LANGUAGE: Python
CODE:
```
if linesP is not None:\n    for i in range(0, len(linesP)):\n        l = linesP[i][0]\n        cv2.line(img, (l[0], l[1]), (l[2], l[3]), (0,255,0), 3, cv2.LINE_AA)\n
```

----------------------------------------

TITLE: Enabling OpenCV Contrib Modules in Build - Bash
DESCRIPTION: Passes a CMake option to the build_js.py script for including modules from the opencv_contrib repository. Dependency: emcmake, Python, and opencv_contrib modules available in the specified location. Parameter: --cmake_option specifying path to contrib modules. The output is an OpenCV.js build with extra features enabled.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_10

LANGUAGE: bash
CODE:
```
emcmake python ./platforms/js/build_js.py build_js --cmake_option="-DOPENCV_EXTRA_MODULES_PATH=opencv_contrib/modules"
```

----------------------------------------

TITLE: Setting Module Description in CMakeLists - CMake
DESCRIPTION: This snippet sets a descriptive string for the module using the CMake set command. The variable the_description is assigned the value \"Machine Learning\" for potential use in documentation generation, build introspection, or module metadata. There are no required dependencies or special inputs, and this value is not programmatically enforced beyond assignment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ml/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(the_description "Machine Learning")
```

----------------------------------------

TITLE: Converting Laplacian Output to CV_8U in Python
DESCRIPTION: Converts the Laplacian output (`dst`), which has a depth of CV_16S, to an 8-bit unsigned integer image (`abs_dst`) using cv2.convertScaleAbs. This calculates the absolute value and scales the pixel values to fit the 0-255 range, preparing the image for display. Requires cv2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_20

LANGUAGE: python
CODE:
```
#! [convert]
# [convert]
# converting back to CV_8U
abs_dst = cv.convertScaleAbs(dst)
# [convert]
# ! [convert]
```

----------------------------------------

TITLE: Version Extraction from Header
DESCRIPTION: Extracts version information from zlib.h.in header file using regex patterns to parse both ZLIB and ZLIBNG version strings
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
file(READ ${CMAKE_CURRENT_SOURCE_DIR}/zlib.h.in _zlib_h_contents)
string(REGEX REPLACE ".*#define[ \t]+ZLIB_VERSION[ \t]+\"([0-9]+.[0-9]+.[0-9]+).*\".*"
        "\\1" ZLIB_HEADER_VERSION ${_zlib_h_contents})
string(REGEX REPLACE ".*#define[ \t]+ZLIBNG_VERSION[ \t]+\"([-0-9A-Za-z.]+)\".*"
        "\\1" ZLIBNG_HEADER_VERSION ${_zlib_h_contents})
message(STATUS "ZLIB_HEADER_VERSION: ${ZLIB_HEADER_VERSION}")
message(STATUS "ZLIBNG_HEADER_VERSION: ${ZLIBNG_HEADER_VERSION}")
```

----------------------------------------

TITLE: Optimizing TensorFlow Graph with TransformGraph
DESCRIPTION: This Python function uses TensorFlow's TransformGraph to optimize the frozen model graph. It requires the TF graph, input and output layer names, and a set of transformation rules. It is crucial for enhancing the model's performance by reducing graph complexity.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
def optimize_tf_graph(
        in_graph,
        out_graph=DEFAULT_OPT_GRAPH_NAME,
        inputs=DEFAULT_INPUTS,
        outputs=DEFAULT_OUTPUTS,
        transforms=DEFAULT_TRANSFORMS,
        is_manual=True,
        was_optimized=True
):
    # ...

    tf_opt_graph = TransformGraph(
        tf_graph,
        inputs,
        outputs,
        transforms
    )
```

----------------------------------------

TITLE: Configuring x86 SSE2 Optimizations for ZLIB in CMake
DESCRIPTION: Checks if SSE2 optimization is enabled (WITH_SSE2) and if intrinsics are available (HAVE_SSE2_INTRIN). If so, it adds the DX86_SSE2 definition, appends SSE2-specific source files to ZLIB_ARCH_SRCS, and sets compile flags (SSE2FLAG, NOLTOFLAG) specifically for non-x86_64 architectures. It also handles the FORCE_SSE2 option to assume SSE2 capability without runtime checks. Otherwise, it disables SSE2 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_26

LANGUAGE: cmake
CODE:
```
        if(WITH_SSE2)
            check_sse2_intrinsics()
            if(HAVE_SSE2_INTRIN)
                add_definitions(-DX86_SSE2)
                set(SSE2_SRCS ${ARCHDIR}/chunkset_sse2.c ${ARCHDIR}/compare256_sse2.c ${ARCHDIR}/slide_hash_sse2.c)
                list(APPEND ZLIB_ARCH_SRCS ${SSE2_SRCS})
                if(NOT ${ARCH} MATCHES "x86_64")
                    set_property(SOURCE ${SSE2_SRCS} PROPERTY COMPILE_FLAGS "${SSE2FLAG} ${NOLTOFLAG}")
                    add_feature_info(FORCE_SSE2 FORCE_SSE2 "Assume CPU is SSE2 capable")
                    if(FORCE_SSE2)
                        add_definitions(-DX86_NOCHECK_SSE2)
                    endif()
                endif()
            else()
                set(WITH_SSE2 OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Displaying Background Subtraction Results
DESCRIPTION: Shows the original frame and the resulting foreground mask in separate windows using the imshow function. This allows real-time visualization of the background subtraction process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/background_subtraction.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
//show the current frame and the fg masks
imshow("Frame", frame);
imshow("FG Mask", fgMask);
```

LANGUAGE: Java
CODE:
```
// show the current frame and the fg masks
ImgCodecs.imencode(".png", frame, buffer);
Image frameImg = ImageIO.read(new ByteArrayInputStream(buffer.toArray()));
ImgCodecs.imencode(".png", fgMask, buffer);
Image fgMaskImg = ImageIO.read(new ByteArrayInputStream(buffer.toArray()));
imageFrame.setImage(frameImg);
fgMaskFrame.setImage(fgMaskImg);
```

LANGUAGE: Python
CODE:
```
# show the current frame and the fg masks
cv.imshow('Frame', frame)
cv.imshow('FG Mask', fgMask)
```

----------------------------------------

TITLE: Pixel Comparison Logic for FAST Corner Detection in C++
DESCRIPTION: This code implements the decision tree for FAST corner detection algorithm. It compares pixel values against threshold values (cb and c_b) in specific offsets around a central pixel to determine if the current point is a corner or not.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_8

LANGUAGE: C++
CODE:
```
goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset12] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              if(ptr[offset13] > cb)
                if(ptr[offset14] > cb)
                  if(ptr[offset6] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset15] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
  if(ptr[offset12] < c_b)
    if(ptr[offset13] < c_b)
      if(ptr[offset14] < c_b)
        if(ptr[offset15] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset3] < c_b)
              goto is_a_corner;
            else
              if(ptr[offset10] < c_b)
                if(ptr[offset11] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset8] < c_b)
              if(ptr[offset9] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset6] < c_b)
            if(ptr[offset7] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset9] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset11] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset12] > cb)
              if(ptr[offset13] > cb)
                if(ptr[offset6] > cb)
                  if(ptr[offset5] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset14] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset14] > cb)
                    if(ptr[offset15] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
  if(ptr[offset11] < c_b)
    if(ptr[offset12] < c_b)
      if(ptr[offset13] < c_b)
        if(ptr[offset10] < c_b)
          if(ptr[offset14] < c_b)
            if(ptr[offset15] < c_b)
              if(ptr[offset1] < c_b)
                goto is_a_corner;
              else
                if(ptr[offset8] < c_b)
                  if(ptr[offset9] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset7] < c_b)
                  if(ptr[offset8] < c_b)
                    if(ptr[offset9] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset5] < c_b)
              if(ptr[offset6] < c_b)
                if(ptr[offset7] < c_b)
                  if(ptr[offset8] < c_b)
                    if(ptr[offset9] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset14] < c_b)
                if(ptr[offset15] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset9] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            if(ptr[offset6] > cb)
              if(ptr[offset5] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset3] > cb)
                    goto is_a_corner;
                  else
                    if(ptr[offset12] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset12] > cb)
                    if(ptr[offset13] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset12] > cb)
                  if(ptr[offset13] > cb)
                    if(ptr[offset14] > cb)
                      goto is_a_corner;
```

----------------------------------------

TITLE: OAST_9_16 Feature Detection Function Implementation
DESCRIPTION: Main implementation of the OAST_9_16 feature detection algorithm. Initializes necessary variables and offsets for the detection process and sets up the scanning loop structure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_30

LANGUAGE: C++
CODE:
```
static void OAST_9_16(InputArray _img, std::vector<KeyPoint>& keypoints, int threshold)
{
    cv::Mat img;
    if(!_img.getMat().isContinuous())
      img = _img.getMat().clone();
    else
      img = _img.getMat();

    size_t total = 0;
    int xsize = img.cols;
    int ysize = img.rows;
    size_t nExpectedCorners = keypoints.capacity();
    int x, y;
    int xsizeB=xsize - 4;
    int ysizeB=ysize - 3;
    int width;

    keypoints.resize(0);

    int pixel_9_16_[16];
    makeAgastOffsets(pixel_9_16_, (int)img.step, AgastFeatureDetector::OAST_9_16);
```

----------------------------------------

TITLE: Transforming TensorFlow Segmentation Mask to Colored Visualization
DESCRIPTION: Converts a segmentation mask from TensorFlow model predictions into a colored visualization using PASCAL VOC class colors. The mask is resized to match the original image dimensions and converted from BGR to RGB color space.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
colors = np.array(colors)
processed_mask = colors[segm_mask[0]]

img_height = original_img_shape[0]
img_width = original_img_shape[1]

processed_mask = cv2.resize(processed_mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST).astype(
    np.uint8)

# convert colored mask from BGR to RGB for compatibility with PASCAL VOC colors
processed_mask = cv2.cvtColor(processed_mask, cv2.COLOR_BGR2RGB)
```

----------------------------------------

TITLE: Playing Video from File in Python with OpenCV
DESCRIPTION: This code snippet shows how to play a video from a file using OpenCV. It uses cv.VideoCapture() with a file name, reads frames in a loop, converts them to grayscale, and displays them until 'q' is pressed or the video ends.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_video_display/py_video_display.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
import numpy as np
import cv2 as cv

cap = cv.VideoCapture('vtest.avi')

while cap.isOpened():
    ret, frame = cap.read()

    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)

    cv.imshow('frame', gray)
    if cv.waitKey(1) == ord('q'):
        break

cap.release()
cv.destroyAllWindows()
```

----------------------------------------

TITLE: Sourcing eSDK Environment Setup Script for Qualcomm Linux (Shell)
DESCRIPTION: This shell command executes the eSDK environment setup script (`environment-setup-armv8-2a-qcom-linux`) provided by the Qualcomm Linux SDK. Sourcing this script configures the current shell session with the appropriate cross-compilation toolchain paths, library paths, and other environment variables required to build OpenCV specifically for the target ARMv8.2-A Qualcomm Linux platform.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_2

LANGUAGE: shell
CODE:
```
source environment-setup-armv8-2a-qcom-linux
```

----------------------------------------

TITLE: Visualizing K-Means Clustering Results for One-Dimensional Data
DESCRIPTION: This code plots the clustering results by showing histograms of the two separate clusters in different colors (red and blue) along with their centroids in yellow. This visualization helps to see how the algorithm has separated the data.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.markdown#2025-04-22_snippet_3

LANGUAGE: python
CODE:
```
# Now plot 'A' in red, 'B' in blue, 'centers' in yellow
plt.hist(A,256,[0,256],color = 'r')
plt.hist(B,256,[0,256],color = 'b')
plt.hist(centers,32,[0,256],color = 'y')
plt.show()
```

----------------------------------------

TITLE: Building OpenCV for ARM with Make - Bash
DESCRIPTION: Invokes 'make' in the build directory to compile OpenCV for ARM using previously configured build files. Requires prior execution of CMake with the proper toolchain. All targets configured via CMake will be built. The command must be run in the appropriate build directory, and may take significant time depending on hardware.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/arm_crosscompile_with_cmake.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
make
```

----------------------------------------

TITLE: Defining Doxygen Citelist Warning Filter Pattern (Plaintext)
DESCRIPTION: This pattern identifies lines starting with 'citelist :' followed by any characters and the specific warning text 'Unexpected new line character.'. It is likely used within a build script or configuration file to suppress or handle this particular Doxygen warning during the documentation generation for the OpenCV project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/disabled_doc_warnings.txt#2025-04-22_snippet_0

LANGUAGE: plaintext
CODE:
```
citelist : .*Unexpected new line character.*
```

----------------------------------------

TITLE: Creating Platform-Specific and Combined Objective-C Generation Targets in CMake
DESCRIPTION: Sets up build targets for each platform (iOS, macOS, visionOS) based on configuration, and creates a combined target that depends on all platform-specific targets. This allows selective generation of Objective-C bindings for specific platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/generator/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
if(OPENCV_OBJC_TARGET)
  ocv_add_objc_generated_target(${OPENCV_OBJC_TARGET})
else()
  ocv_add_objc_generated_target(osx)
  ocv_add_objc_generated_target(ios)
  ocv_add_objc_generated_target(visionos)
endif()

add_custom_target(gen_opencv_objc_source
    # excluded from all: ALL
    DEPENDS ${objc_generated_targets}
)
```

----------------------------------------

TITLE: OpenCL Implementation in OpenCV 2.x vs 3.x
DESCRIPTION: Compares OpenCL-aware code between OpenCV 2.x and 3.x versions, showing how the explicit ocl namespace and classes have been replaced with the transparent API using UMat.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
// initialization
VideoCapture vcap(...);
ocl::OclCascadeClassifier fd("haar_ff.xml");
ocl::oclMat frame, frameGray;
Mat frameCpu;
vector<Rect> faces;
for(;;){
    // processing loop
    vcap >> frameCpu;
    frame = frameCpu;
    ocl::cvtColor(frame, frameGray, BGR2GRAY);
    ocl::equalizeHist(frameGray, frameGray);
    fd.detectMultiScale(frameGray, faces, ...);
    // draw rectangles …
    // show image …
}
```

LANGUAGE: cpp
CODE:
```
// initialization
VideoCapture vcap(...);
CascadeClassifier fd("haar_ff.xml");
UMat frame, frameGray; // the only change from plain CPU version
vector<Rect> faces;
for(;;){
    // processing loop
    vcap >> frame;
    cvtColor(frame, frameGray, BGR2GRAY);
    equalizeHist(frameGray, frameGray);
    fd.detectMultiScale(frameGray, faces, ...);
    // draw rectangles …
    // show image …
}
```

----------------------------------------

TITLE: Asset Copy Configuration for Tutorials
DESCRIPTION: Sets up custom commands to copy JavaScript assets and Haar cascade files to the tutorial directory, creating necessary dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_20

LANGUAGE: cmake
CODE:
```
foreach(f ${js_assets})
    get_filename_component(fname "${f}" NAME)
    add_custom_command(OUTPUT "${opencv_tutorial_html_dir}/${fname}"
                       COMMAND ${CMAKE_COMMAND} -E copy_if_different "${f}" "${opencv_tutorial_html_dir}/${fname}"
                       DEPENDS "${f}"
                       COMMENT "Copying ${fname}"
    )
    list(APPEND js_tutorials_assets_deps "${f}" "${opencv_tutorial_html_dir}/${fname}")
  endforeach()
```

----------------------------------------

TITLE: Installing Specific Emscripten Version (2.0.10) - Bash
DESCRIPTION: Updates the Emsdk, installs version 2.0.10 of Emscripten, and activates that specific version for future builds. Use this for compatibility and webassembly feature verification. Dependency: Emscripten SDK. No parameters needed. Outputs: Emscripten 2.0.10 environment setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
./emsdk update\n./emsdk install 2.0.10\n./emsdk activate 2.0.10
```

----------------------------------------

TITLE: Disabling Compiler Warnings for Zlib in CMake
DESCRIPTION: Disables specific compiler warnings that are triggered by Zlib code but can be safely ignored. This improves build output clarity by reducing unnecessary warnings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
ocv_warnings_disable(CMAKE_C_FLAGS -Wshorten-64-to-32 -Wattributes -Wstrict-prototypes -Wmissing-prototypes -Wmissing-declarations -Wshift-negative-value
    -Wundef  # _LFS64_LARGEFILE is not defined
    /wd4267  # MSVS 2015 (x64) + zlib 1.2.11
    -Wimplicit-fallthrough
    /wd4244  # MSVS + zlib 1.2.12: warning C4244: '=': conversion from 'ush' to 'uchf', possible loss of data
)
```

----------------------------------------

TITLE: Creating Display Window for Threshold Output (C++)
DESCRIPTION: This C++ snippet creates an OpenCV highgui window with namedWindow for displaying the output image after thresholding. It sets up the GUI environment required for user interaction. Requires OpenCV highgui module. No parameters; creates a window titled 'Threshold Demo'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_6

LANGUAGE: C++
CODE:
```
// [window]\nnamedWindow( window_name, WINDOW_AUTOSIZE );\n// [window]
```

----------------------------------------

TITLE: Setting Up EMSDK Environment Variables - Bash
DESCRIPTION: Sources the EMSDK environment script to set environment variables and then echoes the EMSDK path. This step ensures that Emscripten tools are accessible in the current shell session. Dependency: Emscripten SDK must be installed. Parameters: none. Prints the EMSDK environment variable as confirmation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
source ./emsdk_env.sh\necho ${EMSDK}
```

----------------------------------------

TITLE: Applying Sobel Operator in Java
DESCRIPTION: This Java snippet provides an implementation of the Sobel operator using OpenCV to detect edges in an input image. It involves loading the image, applying Gaussian blur for noise reduction, converting to grayscale, and then computing the gradient using Sobel. The snippet outputs an edge-highlighted image and requires OpenCV and a sample image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.markdown#2025-04-22_snippet_1

LANGUAGE: java
CODE:
```
Mat image = Imgcodecs.imread("lena.jpg"); // Load source image
```

LANGUAGE: java
CODE:
```
Imgproc.GaussianBlur(src, src, new Size(3, 3), 0, 0, Core.BORDER_DEFAULT); // Reduce noise
```

LANGUAGE: java
CODE:
```
Imgproc.cvtColor(src, src_gray, Imgproc.COLOR_BGR2GRAY); // Convert to grayscale
```

LANGUAGE: java
CODE:
```
Imgproc.Sobel(src_gray, grad_x, CvType.CV_16S, 1, 0, 3, scale, delta, Core.BORDER_DEFAULT); // Sobel for x-gradient
Imgproc.Sobel(src_gray, grad_y, CvType.CV_16S, 0, 1, 3, scale, delta, Core.BORDER_DEFAULT); // Sobel for y-gradient
```

LANGUAGE: java
CODE:
```
Core.convertScaleAbs(grad_x, abs_grad_x); 
Core.convertScaleAbs(grad_y, abs_grad_y);
```

LANGUAGE: java
CODE:
```
Core.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0, grad); // Approximate the gradient
```

LANGUAGE: java
CODE:
```
HighGui.imshow("Sobel Demo", grad); // Display results
HighGui.waitKey();
```

----------------------------------------

TITLE: Using Median Blurring for Noise Reduction in C++
DESCRIPTION: Details the use of cv.medianBlur() to remove noise from images, effective against salt-and-pepper noise. The median filter replaces the center pixel with the median from the kernel area. Requires OpenCV and parameters such as source image and kernel size, which must be a positive odd integer.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_filtering/js_filtering.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
cv::medianBlur(src, dst, ksize);
```

----------------------------------------

TITLE: Calibrating the Camera with OpenCV in Python
DESCRIPTION: This snippet demonstrates how to calibrate a camera using the collected object and image points using OpenCV. The cv.calibrateCamera() function computes the camera matrix, distortion coefficients, and others elements needed. Input consists of object and image points; output includes values like mtx and dist.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)
```

----------------------------------------

TITLE: Customizing CMake Hook Scripts Directory for OpenCV (CMake)
DESCRIPTION: This setting allows specifying a directory containing custom CMake hook scripts. OpenCV will include scripts from this directory at key stages during the configuration process. Files should follow naming conventions like CMAKE_INIT.cmake, PRE_CMAKE_BOOTSTRAP.cmake, etc. Set using -DOPENCV_CMAKE_HOOKS_DIR=your/hooks/dir.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_28

LANGUAGE: cmake
CODE:
```
OPENCV_CMAKE_HOOKS_DIR
```

----------------------------------------

TITLE: Copying Mat Data Using clone() in OpenCV in Java
DESCRIPTION: Shows how to create a deep copy of an image Mat in Java using clone(). The new Mat owns its own storage and modifications do not affect the original. Always use for value semantics or if the original may be deallocated.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_23

LANGUAGE: Java
CODE:
```
Mat copy = img.clone();
```

----------------------------------------

TITLE: Loading and Setting Up for Generalized Hough Transform in C++
DESCRIPTION: This code snippet initializes the variables and loads the image and template necessary for running the Generalized Hough Transform using OpenCV. The position vectors store the detected matches with four key parameters related to object location, scale, and orientation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/generalized_hough_ballard_guil/generalized_hough_ballard_guil.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
# Load image, template and setup variables
@snippet samples/cpp/tutorial_code/ImgTrans/generalizedHoughTransform.cpp generalized-hough-transform-load-and-setup
```

----------------------------------------

TITLE: Creating Display Window for Threshold Output (Python)
DESCRIPTION: This Python snippet creates a named window using cv.namedWindow to display thresholded images via OpenCV's GUI utilities. Needs to be called prior to setting up trackbars and display. Requires cv2. No parameters.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_8

LANGUAGE: Python
CODE:
```
# [window]\ncv.namedWindow(window_name)\n# [window]
```

----------------------------------------

TITLE: Memory Configuration Block
DESCRIPTION: Configures reduced memory settings by defining buffer sizes and memory limitations
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_16

LANGUAGE: cmake
CODE:
```
if(WITH_REDUCED_MEM)
    add_definitions(-DHASH_SIZE=32768u -DGZBUFSIZE=8192 -DNO_LIT_MEM)
    message(STATUS "Configured for reduced memory environment")
endif()
```

----------------------------------------

TITLE: Defining Placeholder Installation Function (Standalone Build) in CMake
DESCRIPTION: Defines an empty `ocv_install_example_src` function within the standalone build context. This serves as a no-op, effectively disabling the source installation behavior defined for the integrated build, as installation is not typically managed by the standalone sample build script itself.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: cmake
CODE:
```
function(ocv_install_example_src)
  # not used in this branch
endfunction()
```

----------------------------------------

TITLE: Setting JPEG Colorspace and Related Parameters (C)
DESCRIPTION: This function sets the JPEG file's colorspace and other color-space-dependent parameters. It should be called before setting individual parameters if you plan to change the colorspace.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_21

LANGUAGE: C
CODE:
```
jpeg_set_colorspace (j_compress_ptr cinfo, J_COLOR_SPACE colorspace)
```

----------------------------------------

TITLE: Adding DNN Module and Language Bindings - CMake
DESCRIPTION: This adds the DNN module to the OpenCV build and enables bindings for Python, Java, Objective-C, and JavaScript. 'ocv_add_module' specifies the module dependencies (opencv_core, opencv_imgproc) and sets up language wrappers for cross-language support. Parameters list module dependencies and languages to generate bindings for.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
ocv_add_module(dnn opencv_core opencv_imgproc WRAP python java objc js)
```

----------------------------------------

TITLE: Defining Custom Layer Interface OpenCV C++
DESCRIPTION: This snippet shows the interface for defining a custom layer in OpenCV by deriving from cv::dnn::Layer.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_custom_layers/dnn_custom_layers.md#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
@snippet dnn/custom_layers.hpp A custom layer interface
```

----------------------------------------

TITLE: Overloading and Renaming Functions for Python Bindings with OpenCV Macros in C++
DESCRIPTION: This set of function declarations demonstrates how to export overloaded functions to Python, each with a unique Python-exposed name using CV_EXPORTS_W and CV_EXPORTS_AS. The functions perform variations on integral image computations, with each overload exposed under a distinct name. Inputs include images and optional output arrays; the macros ensure each function is accessible by name in Python. The snippet shows how argument defaults are handled.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
//! computes the integral image
CV_EXPORTS_W void integral( InputArray src, OutputArray sum, int sdepth = -1 );

//! computes the integral image and integral for the squared image
CV_EXPORTS_AS(integral2) void integral( InputArray src, OutputArray sum,
                                        OutputArray sqsum, int sdepth = -1, int sqdepth = -1 );

//! computes the integral image, integral for the squared image and the tilted integral image
CV_EXPORTS_AS(integral3) void integral( InputArray src, OutputArray sum,
                                        OutputArray sqsum, OutputArray tilted,
                                        int sdepth = -1, int sqdepth = -1 );
```

----------------------------------------

TITLE: Predicate for Filtering Values Greater Than Zero
DESCRIPTION: A simple predicate functor that returns true for values greater than zero, used for filtering operations with Thrust algorithms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_6

LANGUAGE: CUDA
CODE:
```
struct is_greater : public thrust::unary_function<float, bool>
{
    __host__ __device__
    bool operator()(const float &x) const
    {
        return x > 0;
    }
};
```

----------------------------------------

TITLE: Saving HDR and LDR Results in OpenCV
DESCRIPTION: This code saves the results of the HDR processing. The HDR image is saved in Radiance format (.hdr), while the tonemapped LDR and fusion results are saved as standard 8-bit images.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/hdr_imaging.markdown#2025-04-22_snippet_5

LANGUAGE: cpp
CODE:
```
imwrite("ldr.jpg", ldr_8bit);
imwrite("fusion.jpg", fusion_8bit);
imwrite("hdr.hdr", hdr);
```

LANGUAGE: java
CODE:
```
Imgcodecs.imwrite("ldr.jpg", ldr8bit);
Imgcodecs.imwrite("fusion.jpg", fusion8bit);
Imgcodecs.imwrite("hdr.hdr", hdr);
```

LANGUAGE: python
CODE:
```
cv.imwrite('ldr.jpg', ldr_8bit)
cv.imwrite('fusion.jpg', fusion_8bit)
cv.imwrite('hdr.hdr', hdr)
```

----------------------------------------

TITLE: Verifying OpenCV Installation on macOS using Python
DESCRIPTION: This Python command imports OpenCV and prints its version to verify the installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_8

LANGUAGE: bash
CODE:
```
python3 -c "import cv2; print(cv2.__version__)"
```

----------------------------------------

TITLE: Building OpenCV.js with WebAssembly SIMD Optimization - Bash
DESCRIPTION: This bash command builds the WebAssembly version of OpenCV.js with SIMD optimization enabled. It requires Emscripten's LLVM upstream backend, Python, and the OpenCV JS build script. '--simd' enables SIMD instructions for better performance, but this feature is experimental and requires enabling SIMD support flags in browsers or Node.js. Outputs are optimized builds that may not work on all environments; using the latest browser or Node.js is recommended.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_16

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --build_wasm --simd
```

----------------------------------------

TITLE: Configuring OpenCV Build with CMake for Ninja
DESCRIPTION: Command to configure OpenCV build using CMake, generating Ninja build files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_13

LANGUAGE: bash
CODE:
```
cmake -G Ninja ../opencv
```

----------------------------------------

TITLE: Invoking detect_board_charuco.cpp with Command Line Parameters - OpenCV C++
DESCRIPTION: This snippet shows example command line parameters for running the 'detect_board_charuco.cpp' sample provided in OpenCV. It uses the CommandLineParser utility to specify board dimensions, marker sizes, dictionary, and optionally the location of an input image and a camera calibration file. This enables flexible execution for various board and camera configurations. All parameters are passed as command-line options and must be formatted as shown.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
-w=5 -h=7 -sl=0.04 -ml=0.02 -d=10 -v=/path_to_opencv/opencv/doc/tutorials/objdetect/charuco_detection/images/choriginal.jpg
```

LANGUAGE: cpp
CODE:
```
-w=5 -h=7 -sl=0.04 -ml=0.02 -d=10
-v=/path_to_opencv/opencv/doc/tutorials/objdetect/charuco_detection/images/choriginal.jpg
-c=/path_to_opencv/opencv/samples/cpp/tutorial_code/objectDetection/tutorial_camera_charuco.yml
```

----------------------------------------

TITLE: Configuring Face Detection Android Example with CMake
DESCRIPTION: Configures an Android face detection example project by downloading the required ONNX model and setting up the Android project with OpenCV dependencies. The script downloads a YuNet face detection model and configures the Android project with appropriate SDK targets and library dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/face-detection/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-face-detection)

ocv_download(FILENAME "face_detection_yunet_2023mar.onnx"
             HASH "4ae92eeb150c82ce15ac80738b3b8167"
             URL
               "${OPENCV_FACE_DETECT_YN_URL}"
               "$ENV{OPENCV_FACE_DETECT_YN_URL}"
               "https://media.githubusercontent.com/media/opencv/opencv_zoo/main/models/face_detection_yunet/face_detection_yunet_2023mar.onnx"
             DESTINATION_DIR "${CMAKE_CURRENT_LIST_DIR}/res/raw"
             ID OPENCV_FACE_DETECT_YN
             STATUS res)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Filling OpenCV Mat with Random Values in C++
DESCRIPTION: Shows how to fill a matrix with random values using the randu() function. Requires specifying lower and upper limits for the random values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_9

LANGUAGE: C++
CODE:
```
// fill with random values
Mat R = Mat(3, 2, CV_8UC3);
randu(R, Scalar::all(0), Scalar::all(255));
```

----------------------------------------

TITLE: Importing OpenCV in Prefix Header (Objective-C)
DESCRIPTION: This snippet shows how to import the OpenCV library in the project's prefix header file. It's important to include OpenCV before UIKit and Foundation to avoid macro conflicts.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/video_processing/video_processing.markdown#2025-04-22_snippet_0

LANGUAGE: Objective-C
CODE:
```
#import <Availability.h>

#ifndef __IPHONE_4_0
#warning "This project uses features only available in iOS SDK 4.0 and later."
#endif

#ifdef __cplusplus
#import <opencv2/opencv.hpp>
#endif

#ifdef __OBJC__
    #import <UIKit/UIKit.h>
    #import <Foundation/Foundation.h>
#endif
```

----------------------------------------

TITLE: Running Segmentation Evaluation for DeepLab MobileNet model
DESCRIPTION: Command to run the evaluation pipeline on the PASCAL VOC dataset for the DeepLab MobileNet segmentation model. The evaluation compares TensorFlow and OpenCV DNN implementations, measuring pixel accuracy, mean IoU, and inference time.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_9

LANGUAGE: bash
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.segmentation.py_to_py_segm
```

----------------------------------------

TITLE: Displaying Help for gen_pattern.py Script (Shell)
DESCRIPTION: This shell command executes the Python script `gen_pattern.py` using the `python` interpreter and passes the `--help` argument. This is a standard way to request usage instructions and available command-line options for a script, in this case, for generating various SVG calibration patterns.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/pattern_tools/README.txt#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
python gen_pattern.py --help
```

----------------------------------------

TITLE: Configuring OpenCV Documentation, Tests, and Examples Build using CMake (Shell)
DESCRIPTION: Instructs CMake to build the OpenCV documentation (`BUILD_DOCS=ON`) while disabling the compilation of tests (`BUILD_TESTS=OFF`), performance tests (`BUILD_PERF_TESTS=OFF`), and examples (`BUILD_EXAMPLES=OFF`). This can save build time if these components are not needed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_11

LANGUAGE: sh
CODE:
```
cmake -D BUILD_DOCS=ON -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF -D BUILD_EXAMPLES=OFF ..
```

----------------------------------------

TITLE: Initializing ORB Feature Detector and Descriptor Extractor in C++
DESCRIPTION: Instantiates and configures the RobustMatcher with ORB feature detector and descriptor extractor for efficient feature extraction. Describes creating detectors and extractors, setting them in a RobustMatcher instance.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
RobustMatcher rmatcher;                                                          // instantiate RobustMatcher

cv::FeatureDetector * detector = new cv::OrbFeatureDetector(numKeyPoints);       // instantiate ORB feature detector
cv::DescriptorExtractor * extractor = new cv::OrbDescriptorExtractor();          // instantiate ORB descriptor extractor

rmatcher.setFeatureDetector(detector);                                           // set feature detector
rmatcher.setDescriptorExtractor(extractor);                                      // set descriptor extractor
```

----------------------------------------

TITLE: PyTorch Model Inference
DESCRIPTION: This Python snippet demonstrates inference with the original PyTorch ResNet-50 model. It prepares the preprocessed image, invokes the model for prediction, and extracts information like class ID and prediction confidence.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_7

LANGUAGE: Python
CODE:
```
original_net.eval()
preproc_img = torch.FloatTensor(preproc_img)

out = original_net(preproc_img)
print("\nPyTorch model prediction: \n")
print("* shape: ", out.shape)
imagenet_class_id = torch.argmax(out, axis=1).item()
print("* class ID: {}, label: {}".format(imagenet_class_id, imagenet_labels[imagenet_class_id]))
confidence = out[0][imagenet_class_id]
print("* confidence: {:.4f}".format(confidence.item()))
```

----------------------------------------

TITLE: Defining Highgui Source Files in CMake
DESCRIPTION: Sets the CMake variable `highgui_srcs` to a list containing the paths to the core source files (`backend.cpp`, `window.cpp`, `roiSelector.cpp`) for the highgui module. This variable will be used when defining the module's target to specify its source files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
set(highgui_srcs
    ${CMAKE_CURRENT_LIST_DIR}/src/backend.cpp
    ${CMAKE_CURRENT_LIST_DIR}/src/window.cpp
    ${CMAKE_CURRENT_LIST_DIR}/src/roiSelector.cpp
    )
```

----------------------------------------

TITLE: Loading Source Image in Python
DESCRIPTION: Loads the source image using cv2.imread based on the path obtained from command-line arguments. Includes error handling to check if the image loading was successful.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_8

LANGUAGE: python
CODE:
```
#! [load]
# [load]
parser = argparse.ArgumentParser(description='Code for Laplace Operator tutorial.')
parser.add_argument('--input', help='Path to input image.', default='lena.jpg')
args = parser.parse_args()

src = cv.imread(cv.samples.findFile(args.input), cv.IMREAD_COLOR)

# Check if image is loaded fine
if src is None:
    print ('Error opening image')
    print ('Program Arguments: [image_name -- default lena.jpg]')
    exit()
# [load]
# ! [load]
```

----------------------------------------

TITLE: Setting OpenJPEG Build Identifier and Status Message in CMake
DESCRIPTION: Constructs a build identifier string `OPENJPEG_BUILD` incorporating OpenCV and OpenJPEG versions. It appends '-debug' if the build type is Debug and prints a status message indicating the detected OpenJPEG version and the generated build identifier.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
set(OPENJPEG_BUILD "opencv-${OPENCV_VERSION}-openjp2-${OPENJPEG_VERSION}")
if(CMAKE_BUILD_TYPE STREQUAL "Debug")
  set(OPENJPEG_BUILD "${OPENJPEG_BUILD}-debug")
endif()

message(STATUS "OpenJPEG: VERSION = ${OPENJPEG_VERSION}, BUILD = ${OPENJPEG_BUILD}")
```

----------------------------------------

TITLE: Merging Exposures into HDR Image with OpenCV Python
DESCRIPTION: Merges loaded exposure images into a single HDR image using Debevec and Robertson methods available in OpenCV. The resulting HDR images have a float32 type to retain full dynamic range.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_photo/py_hdr/py_hdr.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
# Merge exposures to HDR image
merge_debevec = cv.createMergeDebevec()
hdr_debevec = merge_debevec.process(img_list, times=exposure_times.copy())
merge_robertson = cv.createMergeRobertson()
hdr_robertson = merge_robertson.process(img_list, times=exposure_times.copy())
```

----------------------------------------

TITLE: Loading an Image from File in Grayscale with OpenCV in Java
DESCRIPTION: Shows loading an image as grayscale with OpenCV's Java interface by supplying Imgcodecs.IMREAD_GRAYSCALE flag. Needs OpenCV Java bindings. Image at input path is loaded as a single-channel Mat. Only one channel (intensity) is present in the result.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_4

LANGUAGE: Java
CODE:
```
Mat img_gray = Imgcodecs.imread("my_image.jpg", Imgcodecs.IMREAD_GRAYSCALE);
```

----------------------------------------

TITLE: Detecting SIFT Keypoints in OpenCV Python
DESCRIPTION: This code demonstrates how to create a SIFT object, detect keypoints in a grayscale image, and draw those keypoints on the image. It uses the SIFT_create() method and detect() function to find keypoints.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
import numpy as np
import cv2 as cv

img = cv.imread('home.jpg')
gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp = sift.detect(gray,None)

img=cv.drawKeypoints(gray,kp,img)

cv.imwrite('sift_keypoints.jpg',img)
```

----------------------------------------

TITLE: Fitting a Line to Contours in Python with OpenCV
DESCRIPTION: This code shows how to fit a line to a set of points in a contour using cv.fitLine() and then draw the line using cv.line(). It calculates the line parameters and endpoints to draw across the image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
rows,cols = img.shape[:2]
[vx,vy,x,y] = cv.fitLine(cnt, cv.DIST_L2,0,0.01,0.01)
lefty = int((-x*vy/vx) + y)
righty = int(((cols-x)*vy/vx)+y)
cv.line(img,(cols-1,righty),(0,lefty),(0,255,0),2)
```

----------------------------------------

TITLE: Configuring IPP Optimizations
DESCRIPTION: Sets up Intel IPP (Integrated Performance Primitives) optimization options for specific operations like mean, minmax, and sum calculations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
if(HAVE_IPP)
  OCV_OPTION(OPENCV_IPP_ENABLE_ALL "Enable all OPENCV_IPP_ options at once" OFF)
  OCV_OPTION(OPENCV_IPP_MEAN "Enable IPP optimizations for mean (+200Kb in binary size)" OPENCV_IPP_ENABLE_ALL)
  OCV_OPTION(OPENCV_IPP_MINMAX "Enable IPP optimizations for minMaxLoc/minMaxIdx (+200Kb in binary size)" OPENCV_IPP_ENABLE_ALL)
  OCV_OPTION(OPENCV_IPP_SUM "Enable IPP optimizations for sum (+100Kb in binary size)" OPENCV_IPP_ENABLE_ALL)
```

----------------------------------------

TITLE: Compiling and Running Streaming Pipelines in C++
DESCRIPTION: This snippet compiles the G-API graph for streaming mode, optimizing the execution for video streams. It involves defining the input source, utilizing start() method to fetch pipeline results, and managing GUI event handling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_11

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/face_beautification/face_beautification.cpp str_comp
```

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/face_beautification/face_beautification.cpp str_src
```

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/face_beautification/face_beautification.cpp str_loop
```

----------------------------------------

TITLE: Translating Images using OpenCV
DESCRIPTION: Shows the translation of images using the cv.warpAffine function by creating a transformation matrix for shifting in the (x,y) direction. It ensures the output image has the same type as the input, allowing pixel position adjustments via the transformation matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_geometric_transformations/js_geometric_transformations.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cv.warpAffine(src, dst, M, dsize, flags = cv.INTER_LINEAR, borderMode = cv.BORDER_CONSTANT, borderValue = new cv.Scalar())
```

----------------------------------------

TITLE: Generating OpenCV for Windows Store 8.0 x86 using CMake
DESCRIPTION: Invokes CMake directly using the Visual Studio 2013 generator to create project files for OpenCV targeting Windows Store 8.0 on the x86 architecture. Specifies the system name (WindowsStore) and older system version (8.0).
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_11

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013" -DCMAKE_SYSTEM_NAME=WindowsStore -DCMAKE_SYSTEM_VERSION=8.0 <path-to-source>
```

----------------------------------------

TITLE: Setting Default JPEG Quantization Tables (C)
DESCRIPTION: This function sets default quantization tables with linear q_scale_factor[] values. It's only available in libjpeg v7+ API/ABI emulation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_26

LANGUAGE: C
CODE:
```
jpeg_default_qtables (j_compress_ptr cinfo, boolean force_baseline)
```

----------------------------------------

TITLE: Configuring Protobuf Library Build
DESCRIPTION: Sets up the static library build configuration for Protobuf, including source files, include directories, and build properties. Also handles platform-specific linking requirements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/protobuf/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
add_library(libprotobuf STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${Protobuf_SRCS})
target_include_directories(libprotobuf SYSTEM PUBLIC $<BUILD_INTERFACE:${PROTOBUF_ROOT}/src>)
set_target_properties(libprotobuf
    PROPERTIES
    FOLDER "3rdparty"
    OUTPUT_NAME libprotobuf
    DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
    COMPILE_PDB_NAME libprotobuf
    COMPILE_PDB_NAME_DEBUG "libprotobuf${OPENCV_DEBUG_POSTFIX}"
    ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
    )
```

----------------------------------------

TITLE: Setting up Platform-Specific Target Configuration for Objective-C Bindings
DESCRIPTION: Determines the target platform (iOS, visionOS, or macOS) based on the build environment and sets the appropriate framework name. This configures the generator to produce platform-specific bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/generator/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
set(objc_generated_files
    # "${OPENCV_OBJC_SIGNATURES_FILE}"
)

string(REPLACE "opencv_" "" MODULES "${OPENCV_OBJC_MODULES}")

if(NOT DEFINED OPENCV_OBJC_TARGET AND APPLE_FRAMEWORK)
  if(IOS)
    set(OPENCV_OBJC_TARGET "ios")
  elseif(XROS)
    set(OPENCV_OBJC_TARGET "visionos")
  else()
    set(OPENCV_OBJC_TARGET "osx")
  endif()
endif()

if(NOT DEFINED OPENCV_OBJC_FRAMEWORK_NAME)
  if(DEFINED FRAMEWORK_NAME)
    set(OPENCV_OBJC_FRAMEWORK_NAME "${FRAMEWORK_NAME}")
  else()
    set(OPENCV_OBJC_FRAMEWORK_NAME "opencv2")
  endif()
endif()
```

----------------------------------------

TITLE: Copying Module-Specific Test Files in CMake for OpenCV Java
DESCRIPTION: Copies test files specific to each OpenCV module to the Java test directory. It uses ocv_copyfiles_append_dir and ocv_copyfiles_add_target functions to manage the copy process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/pure_test/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
ocv_copyfiles_append_dir(JAVA_TEST_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/test" "${OPENCV_JAVA_TEST_DIR}/src")

list(APPEND depends gen_opencv_java_source "${OPENCV_DEPHELPER}/gen_opencv_java_source")
ocv_copyfiles_add_target(${the_module}_test_source_copy JAVA_TEST_SRC_COPY "Copy Java(Test) source files" ${depends})
set(depends ${the_module}_test_source_copy "${OPENCV_DEPHELPER}/${the_module}_test_source_copy")
```

----------------------------------------

TITLE: Waiting for User Exit in Java OpenCV Program
DESCRIPTION: Code snippet showing how to wait for a user to press a key to exit an OpenCV application in Java. This keeps the result window visible until the user decides to close the application.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_22

LANGUAGE: java
CODE:
```
// Wait until user exit program by pressing a key
HighGui.waitKey(0);
```

----------------------------------------

TITLE: Appending CMake Hooks to Module Initialization - CMake
DESCRIPTION: Appends a module-specific CMake script hook (INIT_MODULE_SOURCES_opencv_dnn.cmake) to perform custom source initialization for the DNN module. Hook file is specified relative to the current directory. Used to extend or override default module initialization behavior.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: CMake
CODE:
```
ocv_cmake_hook_append(INIT_MODULE_SOURCES_opencv_dnn "${CMAKE_CURRENT_LIST_DIR}/cmake/hooks/INIT_MODULE_SOURCES_opencv_dnn.cmake")
```

----------------------------------------

TITLE: Finishing JPEG Compression Cycle in C
DESCRIPTION: This snippet shows how to complete a JPEG compression cycle using 'jpeg_finish_compress'. It ensures the final data buffer is written and releases memory. This is critical for ensuring that all data is successfully saved and to free resources. This step follows the writing of scanlines.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_8

LANGUAGE: C
CODE:
```
jpeg_finish_compress(&cinfo);
```

----------------------------------------

TITLE: Main Loop for Advanced Shape Drawing in OpenCV with Python
DESCRIPTION: This snippet shows the main loop for the advanced drawing application. It sets up the window, binds the mouse callback function, and handles keyboard input to toggle between drawing modes.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_mouse_handling/py_mouse_handling.markdown#2025-04-22_snippet_3

LANGUAGE: Python
CODE:
```
img = np.zeros((512,512,3), np.uint8)
cv.namedWindow('image')
cv.setMouseCallback('image',draw_circle)

while(1):
    cv.imshow('image',img)
    k = cv.waitKey(1) & 0xFF
    if k == ord('m'):
        mode = not mode
    elif k == 27:
        break

cv.destroyAllWindows()
```

----------------------------------------

TITLE: Extracting Vertices from RotatedRect in OpenCV.js (JavaScript)
DESCRIPTION: Illustrates how to extract the four vertices of a RotatedRect using the cv.RotatedRect.points function. The input is a RotatedRect structure; the output is an array of Point objects representing the corners. Requires OpenCV.js and a valid RotatedRect.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_6

LANGUAGE: JavaScript
CODE:
```
let vertices = cv.RotatedRect.points(rotatedRect);
let point1 = vertices[0];
let point2 = vertices[1];
let point3 = vertices[2];
let point4 = vertices[3];
```

----------------------------------------

TITLE: Generating OpenCV for Windows Phone 8.0 ARM using CMake
DESCRIPTION: Invokes CMake directly using the Visual Studio 2013 ARM generator to create project files for OpenCV targeting Windows Phone 8.0 on the ARM architecture. Specifies the system name and older system version (8.0).
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_10

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013 ARM" -DCMAKE_SYSTEM_NAME=WindowsPhone -DCMAKE_SYSTEM_VERSION=8.0 <path-to-source>
```

----------------------------------------

TITLE: Initializing SURF and Detecting Keypoints in OpenCV Python
DESCRIPTION: This snippet demonstrates how to create a SURF object, set the Hessian threshold, and detect keypoints and descriptors in an image using OpenCV's SURF implementation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
>>> img = cv.imread('fly.png', cv.IMREAD_GRAYSCALE)

# Create SURF object. You can specify params here or later.
# Here I set Hessian Threshold to 400
>>> surf = cv.xfeatures2d.SURF_create(400)

# Find keypoints and descriptors directly
>>> kp, des = surf.detectAndCompute(img,None)

>>> len(kp)
 699
```

----------------------------------------

TITLE: Setting Image to Black with OpenCV in C++
DESCRIPTION: Shows how to set all pixels to zero (black) for a cv::Mat in C++. cv::Mat::setTo fills the entire image. Input is a Mat instance; after operation, all channels are 0.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_28

LANGUAGE: C++
CODE:
```
img.setTo(cv::Scalar(0));
```

----------------------------------------

TITLE: Checking ADE Dependency and Disabling G-API Module in CMake
DESCRIPTION: Verifies if the 'ade' (Adequacy) target, a prerequisite for G-API, exists. If the 'ade' target is not found, it disables the G-API module using `ocv_module_disable` and stops further processing for this module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(NOT TARGET ade)
  # can't build G-API because of the above reasons
  ocv_module_disable(gapi)
  return()
endif()
```

----------------------------------------

TITLE: Computing Bounding Rectangle from RotatedRect in OpenCV.js (JavaScript)
DESCRIPTION: Shows how to compute the axis-aligned bounding rectangle for a given RotatedRect using cv.RotatedRect.boundingRect. Accepts a RotatedRect and returns a Rect that fully contains it. The input must be a valid RotatedRect; OpenCV.js is required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_core/js_some_data_structures/js_image_arithmetics.markdown#2025-04-22_snippet_7

LANGUAGE: JavaScript
CODE:
```
let boundingRect = cv.RotatedRect.boundingRect(rotatedRect);
```

----------------------------------------

TITLE: Loading Source Image in Java
DESCRIPTION: Loads the source image from the path provided as a command-line argument using Imgcodecs.imread. Includes basic error handling if the image fails to load.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_7

LANGUAGE: java
CODE:
```
//! [load]
String imagePath = (args.length > 0) ? args[0] : "../../data/lena.jpg";
src = Imgcodecs.imread(imagePath, Imgcodecs.IMREAD_COLOR);
if (src.empty()) {
    System.out.println("Error opening image");
    System.out.println("Program Arguments: [image_path -- default ../../data/lena.jpg]");
    System.exit(-1);
}
//! [load]
```

----------------------------------------

TITLE: Configuring OpenCV Build Type and Installation Prefix using CMake (Shell)
DESCRIPTION: Sets the CMake build type to 'RELEASE' for optimization and specifies '/usr/local' as the installation directory using the `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX` flags. The '..' indicates the source directory is one level up from the current build directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_8

LANGUAGE: sh
CODE:
```
cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..
```

----------------------------------------

TITLE: Running Robust Descriptor Matcher with Parameters in Command Line
DESCRIPTION: Executes a C++ tutorial program with specific parameters for descriptor matching, including ratio test and fast matcher options, exemplifying command-line control over the matching process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/real_time_pose/real_time_pose.markdown#2025-04-22_snippet_13

LANGUAGE: cpp
CODE:
```
./cpp-tutorial-pnp_detection --ratio=0.8 --keypoints=1000 --fast=false
```

----------------------------------------

TITLE: Perspective Transformation with OpenCV
DESCRIPTION: Shows perspective transformation using cv.getPerspectiveTransform to find a 3x3 matrix with four points mapping between the input and output image. The cv.warpPerspective function applies the transformation, maintaining straight lines.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_geometric_transformations/js_geometric_transformations.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
cv.warpPerspective(src, dst, M, dsize, flags = cv.INTER_LINEAR, borderMode = cv.BORDER_CONSTANT, borderValue = new cv.Scalar())
```

LANGUAGE: C++
CODE:
```
cv.getPerspectiveTransform(src, dst)
```

----------------------------------------

TITLE: Verifying EMSCRIPTEN Path with emcmake - Bash
DESCRIPTION: Runs a subshell using emcmake to echo the EMSCRIPTEN environment variable, verifying Emscripten setup. Dependency: emcmake launcher must be available in the path. Parameters: none. Output: prints location of the EMSCRIPTEN installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
emcmake sh -c 'echo ${EMSCRIPTEN}'
```

----------------------------------------

TITLE: Creating Thrust Begin Iterator for GpuMat
DESCRIPTION: Defines a function to create a Thrust iterator that points to the beginning of a GpuMat. This iterator properly handles the pitched memory layout of the matrix.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gpu/gpu-thrust-interop/gpu_thrust_interop.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
template<typename T>
thrust::transform_iterator<step_functor<T>, thrust::counting_iterator<int> > begin_itr(const cv::cuda::GpuMat& mat)
{
    return thrust::make_transform_iterator(
        thrust::counting_iterator<int>(0),
        step_functor<T>(mat.cols, mat.rows, mat.step / sizeof(T))
    );
}
```

----------------------------------------

TITLE: Rotating Images with OpenCV
DESCRIPTION: Demonstrates image rotation using OpenCV's cv.getRotationMatrix2D function, which provides rotated matrices that support arbitrary angles and scales. It allows focusing on a specified center for rotation, with matrices adjusted for scaling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_geometric_transformations/js_geometric_transformations.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
cv.getRotationMatrix2D(center, angle, scale)
```

----------------------------------------

TITLE: Reducing Noise with Gaussian Blur in Python
DESCRIPTION: Applies a 3x3 Gaussian blur to the source image using cv2.GaussianBlur to reduce noise before edge detection. Requires cv2 (OpenCV Python bindings).
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_11

LANGUAGE: python
CODE:
```
#! [reduce_noise]
# [reduce_noise]
# Reduce noise by blurring with a Gaussian filter ( kernel size = 3 )
src = cv.GaussianBlur( src, (3, 3), 0, 0, cv.BORDER_DEFAULT )
# [reduce_noise]
# ! [reduce_noise]
```

----------------------------------------

TITLE: Using Memory Manager for Automatic Structure Allocation in libjpeg-turbo - C
DESCRIPTION: This snippet demonstrates how to use the memory manager in libjpeg-turbo to allocate structures that will automatically be freed during various JPEG processing stages. To allocate memory, the alloc_small method of the memory manager is called, which is particularly handy for structures smaller than a few kilobytes. Larger structures can use alloc_large. Prerequisites include initializing the JPEG compression or decompression object (cinfo).
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_66

LANGUAGE: C
CODE:
```
ptr = (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE, size);
```

----------------------------------------

TITLE: Saving an Image to File with OpenCV in Java
DESCRIPTION: Demonstrates how to export a Mat to an image file in Java using Imgcodecs.imwrite. OpenCV Java bindings required. Input is filename and image Mat; output is boolean for success. Format is auto-detected from extension.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_operations.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
Imgcodecs.imwrite("my_image_copy.png", img);
```

----------------------------------------

TITLE: Copying OpenCV JAR and Build Files in CMake for Java Tests
DESCRIPTION: Copies the OpenCV JAR file and build.xml to the test directory. It uses add_custom_command to ensure the JAR is copied after it's generated and to copy the build.xml file.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/pure_test/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
add_custom_command(OUTPUT "${OPENCV_JAVA_TEST_DIR}/bin/${JAR_NAME}"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different "${OPENCV_JAR_FILE}" "${OPENCV_JAVA_TEST_DIR}/bin/${JAR_NAME}"
    DEPENDS "${OPENCV_JAR_FILE}" "${OPENCV_DEPHELPER}/${the_module}_jar"
    COMMENT "Copying the OpenCV jar"
)

add_custom_command(OUTPUT "${OPENCV_JAVA_TEST_DIR}/build.xml"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different "${CMAKE_CURRENT_SOURCE_DIR}/build.xml" "${OPENCV_JAVA_TEST_DIR}/build.xml"
    DEPENDS "${CMAKE_CURRENT_SOURCE_DIR}/build.xml"
    COMMENT "Copying build.xml"
)
```

----------------------------------------

TITLE: Applying Bilateral Filter with OpenCV in Python
DESCRIPTION: In this Python snippet, the bilateralFilter() function from OpenCV applies a bilateral filter for smoothing while maintaining edges. Dependencies include OpenCV, and parameters include diameter, and standard deviations for color and space.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/gausian_median_blur_bilateral_filter/gausian_median_blur_bilateral_filter.markdown#2025-04-22_snippet_11

LANGUAGE: Python
CODE:
```
@snippet samples/python/tutorial_code/imgProc/Smoothing/smoothing.py bilateralfilter
```

----------------------------------------

TITLE: Declaring Global Variables for Template Matching (C++)
DESCRIPTION: Declares global variables used in the C++ template matching demo, including `Mat` objects for the input image, template, result map, and display image. Also includes variables for window names and the selected matching method.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_10

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/MatchTemplate_Demo.cpp declare
```

----------------------------------------

TITLE: Calculating Extent using OpenCV.js
DESCRIPTION: Computes the extent of a contour, which is the ratio of the contour's area to the area of its bounding rectangle. Requires a contour (`cnt`). Uses `cv.contourArea` for the contour area and `cv.boundingRect` to calculate the bounding rectangle area.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_properties/js_contour_properties.markdown#2025-04-22_snippet_1

LANGUAGE: javascript
CODE:
```
let area = cv.contourArea(cnt, false);
let rect = cv.boundingRect(cnt));
let rectArea = rect.width * rect.height;
let extent = area / rectArea;
```

----------------------------------------

TITLE: Displaying a cv.Mat on an HTML Canvas (JavaScript)
DESCRIPTION: Demonstrates how to use the `cv.imshow()` function from OpenCV.js to display the contents of a `cv.Mat` object (`mat`) onto an HTML `<canvas>` element. The canvas is identified by its ID, 'outputCanvas'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_usage/js_usage.markdown#2025-04-22_snippet_5

LANGUAGE: javascript
CODE:
```
cv.imshow("outputCanvas", mat);
```

----------------------------------------

TITLE: Default Preprocessing Configuration
DESCRIPTION: Configuration constants for default image preprocessing parameters including scaling, dimensions, and normalization values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_13

LANGUAGE: python
CODE:
```
BASE_IMG_SCALE_FACTOR = 1 / 255.0
PYTORCH_RSZ_HEIGHT = 256
PYTORCH_RSZ_WIDTH = 256

pytorch_resize_input_blob = {
    "mean": ["123.675", "116.28", "103.53"],
    "scale": str(BASE_IMG_SCALE_FACTOR),
    "std": ["0.229", "0.224", "0.225"],
    "crop": "True",
    "rgb": "True",
    "rsz_height": str(PYTORCH_RSZ_HEIGHT),
    "rsz_width": str(PYTORCH_RSZ_WIDTH)
}
```

----------------------------------------

TITLE: Setting Up Module Sources and Include Directories
DESCRIPTION: Configures source files, headers, and include directories for the core module, including CUDA, OpenCL, and parallel processing components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
file(GLOB lib_cuda_hdrs
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cuda/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cuda/*.h")
file(GLOB lib_cuda_hdrs_detail
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cuda/detail/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cuda/detail/*.h")
```

----------------------------------------

TITLE: Cloning OpenCV Source Repository - Bash
DESCRIPTION: Uses git to clone the official OpenCV repository. Requires Git to be installed and network access. Only parameter is the repository URL. The output is a local directory containing the OpenCV source code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
git clone https://github.com/opencv/opencv.git
```

----------------------------------------

TITLE: Point Polygon Testing in OpenCV Python
DESCRIPTION: Shows how to find the shortest distance between a point and a contour using cv.pointPolygonTest(). The function returns negative values for points outside the contour, positive for inside, and zero for points on the contour.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contours_more_functions/py_contours_more_functions.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
dist = cv.pointPolygonTest(cnt,(50,50),True)
```

----------------------------------------

TITLE: Applying Histogram Equalization with the Look-up Table
DESCRIPTION: This single line of code applies the histogram equalization transform to the original image using the previously calculated look-up table. It uses the pixel values of the original image as indices into the CDF array to obtain the equalized values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_equalization/py_histogram_equalization.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
img2 = cdf[img]
```

----------------------------------------

TITLE: Running Complete OpenCV Segmentation Workflow
DESCRIPTION: Command to reproduce the full OpenCV segmentation workflow using the dnn_model_runner with default image preprocessing settings. This executes the steps described in the 'Model Conversion Pipeline' section.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/tf_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_14

LANGUAGE: bash
CODE:
```
python -m dnn_model_runner.dnn_conversion.tf.segmentation.py_to_py_segm --test True --default_img_preprocess True --evaluate False
```

----------------------------------------

TITLE: Enabling Hardware Compression for Levels 1-6 (C)
DESCRIPTION: This code snippet shows how to enable hardware compression for levels 1-6 by adding a CFLAGS option when building zlib-ng.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/s390/README.md#2025-04-22_snippet_1

LANGUAGE: c
CODE:
```
-DDFLTCC_LEVEL_MASK=0x7e
```

----------------------------------------

TITLE: Applying Gaussian Blur in OpenCV Python
DESCRIPTION: This code snippet demonstrates how to apply Gaussian blurring to an image using cv.GaussianBlur(). It uses a 5x5 kernel with automatic sigma calculation, which is effective for removing Gaussian noise.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_filtering/py_filtering.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
blur = cv.GaussianBlur(img,(5,5),0)
```

----------------------------------------

TITLE: Displaying Objective-C Wrappers Status in CMake
DESCRIPTION: This CMake snippet checks if Objective-C support (`BUILD_OBJC`) is enabled. If true, it prints a status message using the `status` command, indicating whether Objective-C wrappers (`HAVE_opencv_objc`) were successfully configured based on the value of the `HAVE_opencv_objc` variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_30

LANGUAGE: cmake
CODE:
```
# ========================== Objective-C =======================
if(BUILD_OBJC)
  status("")
  status("  Objective-C wrappers:" HAVE_opencv_objc                                                       THEN YES ELSE NO)
endif()
```

----------------------------------------

TITLE: Generating Checkerboard Pattern using Python Script (Shell)
DESCRIPTION: Executes the 'gen_pattern.py' script to create a checkerboard pattern SVG file named 'chessboard.svg'. The pattern will have 9 rows, 6 columns, and each square will have a size of 20mm. Requires Python and the 'gen_pattern.py' script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration_pattern/camera_calibration_pattern.markdown#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
python gen_pattern.py -o chessboard.svg --rows 9 --columns 6 --type checkerboard --square_size 20
```

----------------------------------------

TITLE: Configuring CMake for OpenCL Samples in OpenCV
DESCRIPTION: This CMake script checks for the necessary version of CMake and required OpenCV and OpenCL dependencies, and sets up project configuration for building OpenCL samples. Dependencies include opencv_core, opencv_imgproc, and others. The script uses find_package to locate OpenCL and configures the environment to compile and link OpenCL sample projects. If dependencies are not met, it exits early.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/opencl/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
ocv_install_example_src(opencl *.cpp *.hpp CMakeLists.txt)

# cmake 3.1 needed for find_package(OpenCL)
if(CMAKE_VERSION VERSION_LESS "3.1")
  message(STATUS "OpenCL samples require CMakes 3.1+")
  return()
endif()

set(OPENCV_OPENCL_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_video
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui)
ocv_check_dependencies(${OPENCV_OPENCL_SAMPLES_REQUIRED_DEPS})

if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()

find_package(OpenCL 1.2 QUIET)
if(NOT OpenCL_FOUND)
  message(STATUS "OpenCL samples are skipped: OpenCL SDK is required")
  return()
endif()

project(opencl_samples)
ocv_include_modules_recurse(${OPENCV_OPENCL_SAMPLES_REQUIRED_DEPS})
ocv_include_directories(${OpenCL_INCLUDE_DIR})
file(GLOB all_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
foreach(sample_filename ${all_samples})
  ocv_define_sample(tgt ${sample_filename} opencl)
  ocv_target_link_libraries(${tgt} PRIVATE
    ${OPENCV_LINKER_LIBS}
    ${OPENCV_OPENCL_SAMPLES_REQUIRED_DEPS}
    ${OpenCL_LIBRARY})
endforeach()

```

----------------------------------------

TITLE: Trackbar Callback in OpenCV Java
DESCRIPTION: Creates a trackbar for an OpenCV window and associates a callback function to it in Java, responding to state changes. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_9

LANGUAGE: Java
CODE:
```
Imgproc.createTrackbar("Trackbar", "Source", sliderValue, maxValue, on_trackbar);
```

----------------------------------------

TITLE: Configuring CMake for WINCE versions earlier than 8.0
DESCRIPTION: Example configuration parameters for targeting WINCE versions earlier than 8.0. Specifies system version, toolset, and processor architecture for the build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/wince/readme.md#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
-DCMAKE_SYSTEM_VERSION=7.0 -DCMAKE_GENERATOR_TOOLSET=CE700 -DCMAKE_SYSTEM_PROCESSOR=arm-v4
```

----------------------------------------

TITLE: Displaying Results in C++
DESCRIPTION: C++ snippet displaying the original source image and the generated histogram image in separate windows using `cv::imshow`. It then waits indefinitely for a key press using `cv::waitKey` before exiting.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/histogram_calculation/histogram_calculation.markdown#2025-04-22_snippet_32

LANGUAGE: cpp
CODE:
```
@snippet samples/cpp/tutorial_code/Histograms_Matching/calcHist_Demo.cpp Display
```

----------------------------------------

TITLE: Multi-GPU Stereo Block Matching Algorithm Steps
DESCRIPTION: Pseudo-algorithm showing the steps for implementing stereo block matching across multiple GPUs, demonstrating how to split processing across devices for improved performance.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/cuda.markdown#2025-04-22_snippet_1

LANGUAGE: text
CODE:
```
1. Split each image of the stereo pair into two horizontal overlapping stripes.
2. Process each pair of stripes (from the left and right images) on a separate Fermi* GPU.
3. Merge the results into a single disparity map.
```

----------------------------------------

TITLE: Simple Progressive Decoding Loop in C
DESCRIPTION: Alternative loop structure for progressive JPEG decoding without special final pass processing. Continues until all input is processed and output is complete.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_55

LANGUAGE: c
CODE:
```
for (;;) {
    absorb any waiting input by calling jpeg_consume_input()
    jpeg_start_output(&cinfo, cinfo.input_scan_number);
    ...
    jpeg_finish_output()
    if (jpeg_input_complete(&cinfo) &&
        cinfo.input_scan_number == cinfo.output_scan_number)
      break;
}
```

----------------------------------------

TITLE: Calculating Centroid of Contours in Python with OpenCV
DESCRIPTION: This code snippet shows how to calculate the centroid of a contour using the moments obtained from cv.moments(). It uses the formulas Cx = M10/M00 and Cy = M01/M00.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.markdown#2025-04-22_snippet_1

LANGUAGE: Python
CODE:
```
cx = int(M['m10']/M['m00'])
cy = int(M['m01']/M['m00'])
```

----------------------------------------

TITLE: Calculating Mean Color or Intensity using OpenCV.js
DESCRIPTION: Computes the average color (for multi-channel images) or mean intensity (for grayscale images) of an array (`src`), optionally considering only the region specified by a `mask`. Uses the `cv.mean` function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_contours/js_contour_properties/js_contour_properties.markdown#2025-04-22_snippet_6

LANGUAGE: javascript
CODE:
```
let average = cv.mean(src, mask);
```

----------------------------------------

TITLE: Example Interactive Program Startup Notice (GPLv2)
DESCRIPTION: This is an example of a short notice that an interactive program licensed under the GPLv2 should display upon startup. It includes the program name, version, copyright holder, a clear statement of ABSOLUTELY NO WARRANTY, and mentions that the software is free and redistributable under certain conditions, prompting the user to type specific commands (`show w` and `show c`) for more details.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ittnotify/src/ittnotify/GPL-2.0-only.txt#2025-04-22_snippet_1

LANGUAGE: plaintext
CODE:
```
Gnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details.
```

----------------------------------------

TITLE: Including JNI Subdirectory in CMake
DESCRIPTION: This command includes the `jni` subdirectory into the CMake build process. This subdirectory is responsible for building the Java Native Interface (JNI) components required for the OpenCV Java bindings. The comment notes that this generates the `${the_module}` target directly.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
add_subdirectory(jni)  # generates ${the_module} target (${the_module}_jni doesn't work properly with Android non-gradle samples)
```

----------------------------------------

TITLE: Default Formatting for OpenCV Mat Output in C++
DESCRIPTION: Demonstrates the default formatting option for printing OpenCV Mat objects to the console using the << operator.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_10

LANGUAGE: C++
CODE:
```
cout << "R (default) = " << endl << R << endl << endl;
```

----------------------------------------

TITLE: Configuring Library Installation Paths
DESCRIPTION: Sets up installation directory paths for pkg-config, handling both absolute and relative paths for includes and libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_37

LANGUAGE: cmake
CODE:
```
if(IS_ABSOLUTE "${CMAKE_INSTALL_INCLUDEDIR}")
    set(PC_INC_INSTALL_DIR "${CMAKE_INSTALL_INCLUDEDIR}")
else()
    set(PC_INC_INSTALL_DIR "\${prefix}/${CMAKE_INSTALL_INCLUDEDIR}")
endif()

if(IS_ABSOLUTE "${CMAKE_INSTALL_LIBDIR}")
    set(PC_LIB_INSTALL_DIR "${CMAKE_INSTALL_LIBDIR}")
else()
    set(PC_LIB_INSTALL_DIR "\${exec_prefix}/${CMAKE_INSTALL_LIBDIR}")
endif()
```

----------------------------------------

TITLE: ARM NEON Compatibility Check
DESCRIPTION: Tests for ARM NEON compatibility and required floating-point ABI settings on 32-bit systems
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: c
CODE:
```
#if defined(__ARM_NEON__) || (!defined(__linux__) && !defined(ANDROID) && !defined(__ANDROID__))
#error "Neon run-time auto-detection will not be used"
#endif
#if __ARM_PCS_VFP == 1
#error "float ABI = hard"
#endif
#if __SOFTFP__ != 1
#error "float ABI = softfp"
#endif
int main(void) { return 0; }
```

----------------------------------------

TITLE: Initializing OpenCV Mat using C/C++ Arrays in C++
DESCRIPTION: Creates matrices of different dimensions using C/C++ arrays with the Mat constructor. Demonstrates both 2D and 3D matrix initialization with data values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
// Creates a matrix with custom data type and initial values
int sz[3] = {2,2,2};
Mat L(3,sz, CV_8UC(1), Scalar::all(0));
```

----------------------------------------

TITLE: Listing Available Mouse Events in OpenCV with Python
DESCRIPTION: This snippet demonstrates how to list all available mouse events in OpenCV using Python. It uses a list comprehension to filter directory contents of cv module for event-related items.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_mouse_handling/py_mouse_handling.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
import cv2 as cv
events = [i for i in dir(cv) if 'EVENT' in i]
print( events )
```

----------------------------------------

TITLE: Verifying OpenCV Installation in Python
DESCRIPTION: The Python snippet is used to verify whether OpenCV has been correctly installed by importing the cv2 library and printing its version. This requires Python and OpenCV to be installed beforehand.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_windows/py_setup_in_windows.markdown#2025-04-22_snippet_0

LANGUAGE: Python
CODE:
```
>>> import cv2 as cv
>>> print(cv.__version__)
```

----------------------------------------

TITLE: Command Line Parameters for ArUco Marker Creation
DESCRIPTION: Code snippet showing the command line parameters for the create_marker.cpp sample. This demonstrates how to specify the output file, dictionary type, and marker ID.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/aruco_detection/aruco_detection.markdown#2025-04-22_snippet_2

LANGUAGE: C++
CODE:
```
"marker23.png" -d=10 -id=23
```

----------------------------------------

TITLE: Building with Extra Modules in OpenCV
DESCRIPTION: This snippet illustrates adding extra modules to the OpenCV build using the `OPENCV_EXTRA_MODULES_PATH` option. The modules must be organized with compatible CMakeLists.txt files. Note that only 0- and 1-level deep locations are supported.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_1

LANGUAGE: sh
CODE:
```
# build with all modules in opencv_contrib
cmake -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules ../opencv

# build with one of opencv_contrib modules
cmake -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules/bgsegm ../opencv

# build with two custom modules (semicolon must be escaped in bash)
cmake -DOPENCV_EXTRA_MODULES_PATH=../my_mod1\;../my_mod2 ../opencv
```

----------------------------------------

TITLE: Installing Valgrind on GNU/Linux
DESCRIPTION: This command installs Valgrind and Massif Visualizer tools on a Debian/Ubuntu system. These tools are necessary to profile application memory usage.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
$ sudo apt-get install valgrind massif-visualizer
```

----------------------------------------

TITLE: Executing Video Similarity Check via Command Line
DESCRIPTION: Demonstrates how to run the described C++ application from the command line, providing the reference video file, the comparison video file, and potentially other numerical arguments. This example uses relative paths for the video files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_input_psnr_ssim.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
video/Megamind.avi video/Megamind_bug.avi  35 10
```

----------------------------------------

TITLE: Accessing Algorithm Properties in OpenCV 3.0
DESCRIPTION: Shows how to access algorithm properties using virtual methods instead of the deprecated generic get/set methods.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
// good way
double clipLimit = clahe->getClipLimit();
clahe->setClipLimit(clipLimit);
// bad way
double clipLimit = clahe->getDouble("clipLimit");
clahe->set("clipLimit", clipLimit);
clahe->setDouble("clipLimit", clipLimit);
```

----------------------------------------

TITLE: Hypothetical Commands for License Details
DESCRIPTION: These are hypothetical command examples (`show w` for warranty details, `show c` for redistribution conditions) mentioned in the context of the interactive program startup notice. They represent placeholders for actual commands, menu items, or other UI elements a program might implement to display the relevant sections of the GPL.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ittnotify/src/ittnotify/GPL-2.0-only.txt#2025-04-22_snippet_2

LANGUAGE: plaintext
CODE:
```
`show w`
```

LANGUAGE: plaintext
CODE:
```
`show c`
```

----------------------------------------

TITLE: Initializing OpenCV Android Test Project in CMake
DESCRIPTION: Sets up the project name and configures the Android test directory. It also removes any existing test directory to ensure a clean setup.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/android_test/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(opencv_test_android)

set(OPENCV_ANDROID_TEST_DIR "${OpenCV_BINARY_DIR}/android_test" CACHE INTERNAL "")
file(REMOVE_RECURSE "${OPENCV_ANDROID_TEST_DIR}")
```

----------------------------------------

TITLE: Waiting for User Exit in Python OpenCV Program
DESCRIPTION: Code snippet illustrating how to wait for a user keystroke to exit an OpenCV application in Python. This ensures the result windows remain open until the user chooses to close the program.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.markdown#2025-04-22_snippet_23

LANGUAGE: python
CODE:
```
# Wait until user exit program by pressing a key
cv.waitKey(0)
```

----------------------------------------

TITLE: Declaring Deep Learning Networks with G-API
DESCRIPTION: Declaration of two neural networks used in face beautification: a face detector and a facial landmarks detector using G_API_NET macro.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_0

LANGUAGE: cpp
CODE:
```
// G-API network declaration
G_API_NET(FaceDetector, <cv::GMat(cv::GMat)>, "face-detector");
G_API_NET(LandmarksDetector, <cv::GMat(cv::GMat)>, "landmarks-detector");
```

----------------------------------------

TITLE: Configuring OpenCV Build for ARM Cross Compilation - Bash
DESCRIPTION: Runs CMake with a toolchain file targeting ARM gnueabi on Linux, configuring OpenCV for cross-compilation. Requires CMake 2.6 or higher and the relevant toolchain file from the OpenCV source tree. Optional parameters can be added to customize the build. Replace placeholder paths as appropriate. This command does not initiate the build process but prepares the configuration.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/arm_crosscompile_with_cmake.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
cmake [<some optional parameters>] -DCMAKE_TOOLCHAIN_FILE=<path to the OpenCV source directory>/platforms/linux/arm-gnueabi.toolchain.cmake <path to the OpenCV source directory>
```

----------------------------------------

TITLE: Embedding OpenCV.js Pose Estimation Demo with HTML Iframe
DESCRIPTION: This HTML snippet utilizes an `<iframe>` tag to embed an external HTML page (`../../js_pose_estimation.html`), which is expected to contain the OpenCV.js pose estimation demonstration. The `onload` JavaScript event handler dynamically adjusts the iframe's height to match the height of the loaded content's body, ensuring the entire embedded page is visible without internal scrollbars. The width is set to 100% to occupy the full width of its container.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_dnn/js_pose_estimation/js_pose_estimation.markdown#2025-04-22_snippet_0

LANGUAGE: html
CODE:
```
<iframe src="../../js_pose_estimation.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
```

----------------------------------------

TITLE: Outputting 2D Points in OpenCV C++
DESCRIPTION: Shows how to output 2D point objects using the << operator. OpenCV supports direct streaming of various data structures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_15

LANGUAGE: C++
CODE:
```
Point2f P(5, 1);
cout << "Point (2D) = " << P << endl << endl;
```

----------------------------------------

TITLE: Building and Installing OpenCV using Make (Shell)
DESCRIPTION: Commands to compile the configured OpenCV source code using `make` within the build directory, switch to the root user using `su` (required for installation to system directories like /usr/local), and then install the built library files using `make install`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_15

LANGUAGE: sh
CODE:
```
make
su
make install
```

----------------------------------------

TITLE: Approximating Forehead Contour using C++
DESCRIPTION: The code snippet approximates the forehead contour using detected facial landmarks of the jaw. It creates a half-ellipse based on three jaw points, assuming the jaw width is equivalent to the forehead width. The forehead height is estimated based on jaw height without direct y-axis points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/face_beautification/face_beautification.markdown#2025-04-22_snippet_7

LANGUAGE: cpp
CODE:
```
@snippet cpp/tutorial_code/gapi/face_beautification/face_beautification.cpp ld_pp_fhd
```

----------------------------------------

TITLE: Cloning OpenCV Repository
DESCRIPTION: Commands to install Git and clone the OpenCV source code repository.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
sudo apt-get install git
git clone https://github.com/opencv/opencv.git
```

----------------------------------------

TITLE: Building OpenCV.js with WebAssembly Intrinsics Tests - Bash
DESCRIPTION: This bash command builds OpenCV.js with both SIMD and intrinsic tests enabled, requiring Emscripten, Python, and the platform's build script. The options '--simd' and '--build_wasm_intrin_test' are used for adding SIMD and intrinsic tests, respectively, while '--build_wasm' targets WebAssembly output. Output includes test-enabled versions of OpenCV.js for use in browser and/or Node.js.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_18

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --build_wasm --simd --build_wasm_intrin_test
```

----------------------------------------

TITLE: Setting OpenCV Build Type and Install Path via CMake (Shell)
DESCRIPTION: Specifies the CMake build type as 'RELEASE' and sets the installation prefix to '/usr/local'. This command ensures the final build is optimized and installed in the standard local directory. It is shown as a separate step for clarity, although flags can be combined.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_13

LANGUAGE: sh
CODE:
```
cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..
```

----------------------------------------

TITLE: Starting the Camera (Objective-C)
DESCRIPTION: This snippet shows how to start the camera when a button is pressed. It assumes that the UI is properly connected to the ViewController.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/video_processing/video_processing.markdown#2025-04-22_snippet_4

LANGUAGE: Objective-C
CODE:
```
#pragma mark - UI Actions

- (IBAction)actionStart:(id)sender;
{
    [self.videoCamera start];
}
```

----------------------------------------

TITLE: Draw Final Matches and Output in OpenCV using Java
DESCRIPTION: Java code that draws the final matches of keypoints and outputs them, with additional statistics provided about the matching process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/akaze_matching/akaze_matching.markdown#2025-04-22_snippet_16

LANGUAGE: Java
CODE:
```
samples/java/tutorial_code/features2D/akaze_matching/AKAZEMatchDemo.java draw final matches
```

----------------------------------------

TITLE: Preventing In-Source Builds in CMake
DESCRIPTION: Checks and prevents in-source builds by comparing source and binary directories. Displays an error message if build is attempted in source directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(" ${CMAKE_SOURCE_DIR}" STREQUAL " ${CMAKE_BINARY_DIR}")
  message(FATAL_ERROR "
FATAL: In-source builds are not allowed.
       You should create a separate directory for build files.
")
endif()
```

----------------------------------------

TITLE: Python-Style Formatting for OpenCV Mat Output in C++
DESCRIPTION: Shows how to format OpenCV Mat output to resemble Python syntax using the format() method with FormatPython flag.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/mat_the_basic_image_container/mat_the_basic_image_container.markdown#2025-04-22_snippet_11

LANGUAGE: C++
CODE:
```
cout << "R (python) = " << endl << format(R, Formatter::FMT_PYTHON) << endl << endl;
```

----------------------------------------

TITLE: Closing the Clojure REPL
DESCRIPTION: Illustrates how to gracefully exit from the Clojure REPL to wrap up a session. Useful for beginners to understand how to end interactive sessions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_14

LANGUAGE: clojure
CODE:
```
user=> (exit)
Bye for now!
```

----------------------------------------

TITLE: Declaring Variables for Image Border Processing
DESCRIPTION: Declaration of variables including source image, window name, and random number generator for border color generation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/copyMakeBorder/copyMakeBorder.markdown#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
Mat src, dst;
char window_name[] = "copyMakeBorder Demo";
RNG rng(12345);
```

LANGUAGE: Java
CODE:
```
Mat src = new Mat(), dst = new Mat();
String window_name = "copyMakeBorder Demo";
Random rng = new Random(12345);
```

LANGUAGE: Python
CODE:
```
window_name = "copyMakeBorder Demo"
```

----------------------------------------

TITLE: Computing Grayscale Value from Iteration Number for Mandelbrot Set - C++
DESCRIPTION: This function computes the pixel grayscale value for a Mandelbrot image, setting it to black if the iteration count reaches the max (inside the set), or scaling the escaped iteration to [0,255]. Depends on info from iteration algorithm, accepts current iteration and maximum as input, outputs uchar grayscale value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/how_to_use_OpenCV_parallel_for_/how_to_use_OpenCV_parallel_for_.markdown#2025-04-22_snippet_3

LANGUAGE: C++
CODE:
```
// Grayscale value assignment for Mandelbrot image
uchar grayscaleValue(int iter, int maxIter)
{
    if (iter == maxIter)
        return 0; // black
    else
        return (uchar)(255.0 * iter / maxIter);
}

```

----------------------------------------

TITLE: Detect Edges with Canny in OpenCV Python
DESCRIPTION: Uses the OpenCV Canny function for edge detection in an image using Python. Requires OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_17

LANGUAGE: Python
CODE:
```
edges = cv2.Canny(gray, lowThreshold, highThreshold)
```

----------------------------------------

TITLE: Find Contours in OpenCV Python
DESCRIPTION: Finds contours in an image and saves them to lists using OpenCV in Python. Dependencies include OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_18

LANGUAGE: Python
CODE:
```
contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
```

----------------------------------------

TITLE: Create and Display Windows with OpenCV Java
DESCRIPTION: Creates a window and displays an image within it using OpenCV in Java. Requires OpenCV library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/shapedescriptors/bounding_rects_circles/bounding_rects_circles.markdown#2025-04-22_snippet_8

LANGUAGE: Java
CODE:
```
HighGui.namedWindow("Source", HighGui.WINDOW_AUTOSIZE);
HighGui.imshow("Source", src);
```

----------------------------------------

TITLE: Drawing Back Projection in Java with OpenCV
DESCRIPTION: This code demonstrates how to display the back projection result using OpenCV in Java. It creates a window and shows the back projection image.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/back_projection/back_projection.markdown#2025-04-22_snippet_6

LANGUAGE: Java
CODE:
```
HighGui.imshow("BackProj", backproj);
```

----------------------------------------

TITLE: Installing Image Format Dependencies
DESCRIPTION: Installs development libraries for various image formats like PNG, JPEG, TIFF, etc.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_4

LANGUAGE: shell
CODE:
```
yum install libpng-devel
yum install libjpeg-turbo-devel
yum install jasper-devel
yum install openexr-devel
yum install libtiff-devel
yum install libwebp-devel
```

----------------------------------------

TITLE: Installing Required Build Dependencies
DESCRIPTION: Commands to install essential build dependencies including CMake, GCC, and Python development packages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
sudo apt-get install cmake
sudo apt-get install gcc g++
```

----------------------------------------

TITLE: Defining Segmentation Test Configuration in Python
DESCRIPTION: This Python data class defines configuration parameters necessary for segmentation model evaluation with defaults set for directories and frame size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_segmentation/pytorch_sem_segm_model_conversion_tutorial.md#2025-04-22_snippet_11

LANGUAGE: python
CODE:
```
@dataclass
class TestSegmConfig:
    frame_size: int = 500
    img_root_dir: str = "./VOC2012"
    img_dir: str = os.path.join(img_root_dir, "JPEGImages/")
    img_segm_gt_dir: str = os.path.join(img_root_dir, "SegmentationClass/")
    segm_val_file: str = os.path.join(img_root_dir, "ImageSets/Segmentation/seg11valid.txt")
    colour_file_cls: str = os.path.join(img_root_dir, "ImageSets/Segmentation/pascal-classes.txt")
```

----------------------------------------

TITLE: Handling Non-Existent Files in C++ with OpenCV
DESCRIPTION: Demonstrates how to handle attempts to read from non-existent files in C++ using OpenCV, which initializes the data structure with default values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.markdown#2025-04-22_snippet_19

LANGUAGE: cpp
CODE:
```
cpp/tutorial_code/core/file_input_output/file_input_output.cpp nonexist
```

----------------------------------------

TITLE: Installing OpenCV-Python via Package Manager
DESCRIPTION: Installs OpenCV-Python and NumPy using Fedora's package manager yum.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
$ yum install numpy opencv*
```

----------------------------------------

TITLE: Running G-API Pipeline in Serial Mode
DESCRIPTION: Shows the reference implementation of running the pipeline in serial (non-streaming) mode for benchmarking. Processes frames one at a time without pipelining optimization.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/interactive_face_detection/interactive_face_detection.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
cv::VideoCapture cap;
if (!cmd.get<std::string>("input").empty()) cap.open(cmd.get<std::string>("input"));
else cap.open(0);

cv::TickMeter tm;
tm.start();

cv::Mat in_frame;
size_t frames = 0;
while (keep_running) {
    if (!cap.read(in_frame)) break;
    cv::Mat out;
    std::vector<cv::Rect> faces;
    std::vector<cv::Str> age_strings, emo_strings;

    auto out_vector = pipeline(cv::gin(in_frame),
                              cv::gout(out, faces, age_strings, emo_strings));
    frames++;
    if (!cmd.get<bool>("pure")) {
        cv::imshow("Out", out);
        const int key = cv::waitKey(1);
        if (key == 27) break;
    }
}
tm.stop();
```

----------------------------------------

TITLE: Building OpenCV Framework with Extra Modules for iOS in Bash
DESCRIPTION: Command to build the OpenCV framework for iOS including extra modules from opencv_contrib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/ios_install/ios_install.markdown#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
cd ~/<my_working_directory>
python opencv/platforms/ios/build_framework.py ios --contrib opencv_contrib
```

----------------------------------------

TITLE: Installing Xcode Command Line Tools in Bash
DESCRIPTION: Command to install Xcode command line tools, which are required for building OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/ios_install/ios_install.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
xcode-select --install
```

----------------------------------------

TITLE: Drawing Detected Corners
DESCRIPTION: Demonstrates how to visualize detected ChArUco corners on the image
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/objdetect/charuco_detection/charuco_detection.markdown#2025-04-22_snippet_6

LANGUAGE: cpp
CODE:
```
cv::Mat imageCopy;
image.copyTo(imageCopy);
cv::aruco::drawDetectedCornersCharuco(imageCopy, charucoCorners, charucoIds);
```

----------------------------------------

TITLE: Importing and Utilizing OpenCV Classes in Clojure
DESCRIPTION: Illustrates using import in Clojure to bring OpenCV classes into scope, facilitating the creation of objects like Point, Rect, and Size for further operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_10

LANGUAGE: clojure
CODE:
```
user=> (import '[org.opencv.core Point Rect Size])
org.opencv.core.Size
user=> (def r1 (Rect. p1 p2))
#'user/r1
user=> r1
#<Rect {0, 0, 100x100}>
user=> (class r1)
org.opencv.core.Rect
user=> (instance? org.opencv.core.Rect r1)
true
user=> (Size. 100 100)
#<Size 100x100>
user=> (def sq-100 (Size. 100 100))
#'user/sq-100
user=> (class sq-100)
org.opencv.core.Size
user=> (instance? org.opencv.core.Size sq-100)
true
```

----------------------------------------

TITLE: Installing Git on Linux
DESCRIPTION: Command to install Git version control system on Linux using the package manager.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_8

LANGUAGE: bash
CODE:
```
sudo apt-get install git
```

----------------------------------------

TITLE: Setting OpenCV Photo Module Description
DESCRIPTION: Defines the description for the OpenCV photo module as 'Computational Photography'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/photo/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(the_description "Computational Photography")
```

----------------------------------------

TITLE: Adding OpenCV Binaries to Windows PATH using Batch Variable Expansion
DESCRIPTION: This snippet demonstrates how to add the OpenCV binaries directory to the system PATH variable using environment variable expansion (%OPENCV_DIR%\bin). This ensures dynamic link libraries are discoverable at runtime. The approach presumes OPENCV_DIR is previously set, and adding this path is essential for loading DLLs without manually copying them near each executable. After changing PATH, applications relying on OpenCV can locate required binaries when executed from any location.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/windows_install/windows_install.markdown#2025-04-22_snippet_7

LANGUAGE: batch
CODE:
```
%OPENCV_DIR%\bin
```

----------------------------------------

TITLE: Specifying OpenCV Directory in CMake Projects on macOS
DESCRIPTION: This command shows how to specify the OpenCV_DIR variable in CMake projects to find the installed OpenCV package.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/macos_install/macos_install.markdown#2025-04-22_snippet_7

LANGUAGE: bash
CODE:
```
cmake -DOpenCV_DIR=~/build_opencv ..
```

----------------------------------------

TITLE: Creating Display Window for Threshold Output (Java)
DESCRIPTION: This Java snippet uses HighGui.namedWindow to open a window named 'Threshold Demo', providing the display surface for thresholded images. Must be called before showing results. Requires OpenCV Java highgui bindings. No input, just creates the window.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/threshold/threshold.markdown#2025-04-22_snippet_7

LANGUAGE: Java
CODE:
```
// [window]\nHighGui.namedWindow(window_name);\n// [window]
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree Implementation in C++
DESCRIPTION: A portion of the FAST corner detection algorithm that uses a decision tree of pixel comparisons against brightness thresholds (cb and c_b). The algorithm evaluates surrounding pixels at various offsets to determine if the current point is a corner by branching to either 'is_a_corner' or 'is_not_a_corner'.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_24

LANGUAGE: C++
CODE:
```
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset1] > cb)
    if(ptr[offset6] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset10] > cb)
          if(ptr[offset11] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      if(ptr[offset6] < c_b)
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
  else
    if(ptr[offset6] < c_b)
      goto is_not_a_corner;
    else
      if(ptr[offset6] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset2] > cb)
    if(ptr[offset7] < c_b)
      if(ptr[offset9] < c_b)
        if(ptr[offset1] < c_b)
          goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset6] > cb)
              if(ptr[offset3] > cb)
                if(ptr[offset4] > cb)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset3] > cb)
                  if(ptr[offset4] > cb)
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset3] > cb)
                  if(ptr[offset4] > cb)
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset9] > cb)
          if(ptr[offset1] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset1] > cb)
              if(ptr[offset6] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    if(ptr[offset3] > cb)
                      goto is_a_corner;
                    else
                      if(ptr[offset8] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      if(ptr[offset3] > cb)
                        goto is_a_corner;
                      else
                        if(ptr[offset8] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  if(ptr[offset10] > cb)
                    if(ptr[offset11] > cb)
                      if(ptr[offset3] > cb)
                        goto is_a_corner;
                      else
                        if(ptr[offset8] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
            goto is_not_a_corner;
          else
            if(ptr[offset1] > cb)
              if(ptr[offset6] > cb)
                if(ptr[offset3] > cb)
                  if(ptr[offset4] > cb)
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset3] > cb)
                    if(ptr[offset4] > cb)
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto is_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  if(ptr[offset3] > cb)
                    if(ptr[offset4] > cb)
                      if(ptr[offset10] > cb)
                        if(ptr[offset11] > cb)
                          goto is_a_corner;
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Logic in C++
DESCRIPTION: This snippet shows a portion of the FAST corner detection algorithm. It compares pixel intensities at different offsets to determine if a point is a corner. The code uses goto statements for control flow and implements a decision tree structure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_15

LANGUAGE: C++
CODE:
```
if(ptr[offset10] < c_b)
  if(ptr[offset11] < c_b)
    goto success_structured;
  else
    goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
  goto structured;
else
  if(ptr[offset9] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset8] < c_b)
        if(ptr[offset5] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                goto success_structured;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset4] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              goto structured;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              if(ptr[offset1] < c_b)
                goto success_structured;
              else
                if(ptr[offset6] < c_b)
                  goto success_structured;
                else
                  goto structured;
            else
              goto structured;
          else
            goto structured;
      else
        goto structured;
    else
      goto structured;
  else
    if(ptr[offset5] > cb)
      if(ptr[offset9] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset7] > cb)
            if(ptr[offset8] > cb)
              if(ptr[offset4] > cb)
                if(ptr[offset3] > cb)
                  goto success_structured;
                else
                  if(ptr[offset10] > cb)
                    goto success_structured;
                  else
                    goto structured;
              else
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
      else
        goto homogeneous;
    else
      goto structured;
else
  if(ptr[offset5] > cb)
    if(ptr[offset9] > cb)
      if(ptr[offset6] > cb)
        if(ptr[offset7] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset8] > cb)
                goto success_structured;
              else
                if(ptr[offset1] > cb)
                  if(ptr[offset2] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                goto structured;
          else
            if(ptr[offset11] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                goto structured;
            else
              goto structured;
        else
          goto structured;
      else
        goto structured;
    else
      if(ptr[offset2] > cb)
        if(ptr[offset3] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset7] > cb)
              if(ptr[offset1] > cb)
                if(ptr[offset6] > cb)
                  goto success_structured;
                else
                  goto structured;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset8] > cb)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
      else
        goto structured;
  else
    if(ptr[offset5] < c_b)
      if(ptr[offset9] < c_b)
        if(ptr[offset6] < c_b)
          if(ptr[offset7] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset8] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset1] < c_b)
                    if(ptr[offset2] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
              else
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset11] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
```

----------------------------------------

TITLE: Configuring and Building OpenCV
DESCRIPTION: Commands to configure OpenCV build with CMake and compile/install the library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_ubuntu/py_setup_in_ubuntu.markdown#2025-04-22_snippet_7

LANGUAGE: bash
CODE:
```
cmake ../
make
sudo make install
```

----------------------------------------

TITLE: Configuring Android OpenCV Example Project with CMake
DESCRIPTION: Sets up an Android project build configuration for a 15-puzzle example application using OpenCV. Specifies the project name, dependencies, and minimum SDK target version of 11.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/15-puzzle/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-15-puzzle)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Cloning OpenCV and Building with Docker for Emscripten - Bash
DESCRIPTION: This snippet clones the OpenCV GitHub repository, changes into its root directory, then uses Docker to run an emscripten/emsdk container that builds OpenCV.js. It maps the local directory for persistence, sets user permissions, and uses emcmake and Python3 to invoke the build. Requires Docker and Git. Works on Linux/MacOS systems that support vanilla shell scripting.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_23

LANGUAGE: bash
CODE:
```
git clone https://github.com/opencv/opencv.git\ncd opencv\ndocker run --rm -v $(pwd):/src -u $(id -u):$(id -g) emscripten/emsdk emcmake python3 ./platforms/js/build_js.py build_js
```

----------------------------------------

TITLE: FAST Corner Detection Pixel Comparison Logic
DESCRIPTION: Complex nested conditional logic for comparing pixel values against brightness thresholds (c_b and cb) using pointer offsets to determine corner features. The code implements part of the FAST corner detection algorithm's decision tree for classifying pixels as corners based on their surrounding intensity values.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_21

LANGUAGE: C++
CODE:
```
if(ptr[offset7] < c_b)
  if(ptr[offset1] < c_b)
    if(ptr[offset6] < c_b)
      goto success_homogeneous;
    else
      if(ptr[offset11] < c_b)
        goto success_homogeneous;
      else
        goto homogeneous;
  else
    if(ptr[offset6] < c_b)
      if(ptr[offset8] < c_b)
        goto success_homogeneous;
      else
        goto homogeneous;
    else
      goto homogeneous;
else
  if(ptr[offset1] < c_b)
    if(ptr[offset6] < c_b)
      goto success_homogeneous;
    else
      if(ptr[offset11] < c_b)
        goto success_homogeneous;
      else
        goto homogeneous;
  else
    goto homogeneous;
```

----------------------------------------

TITLE: Implementing Pixel Comparison Logic for Feature Detection in C++
DESCRIPTION: This code snippet implements a complex decision tree for comparing pixel values against thresholds. It uses nested if-else statements to navigate through different pixel offsets, determining whether to proceed to a 'homogeneous' or 'success_homogeneous' state based on comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_22

LANGUAGE: C++
CODE:
```
goto homogeneous;
else
  if(ptr[offset11] > cb)
    if(ptr[offset8] > cb)
      if(ptr[offset10] > cb)
        goto success_homogeneous;
      else
        goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset2] > cb)
    if(ptr[offset3] > cb)
      if(ptr[offset4] > cb)
        if(ptr[offset1] > cb)
          if(ptr[offset6] > cb)
            goto success_homogeneous;
          else
            goto homogeneous;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset8] > cb)
              goto success_homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
      else
        goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset5] < c_b)
    if(ptr[offset7] < c_b)
      if(ptr[offset9] < c_b)
        if(ptr[offset6] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset8] < c_b)
                goto success_homogeneous;
              else
                if(ptr[offset1] < c_b)
                  if(ptr[offset2] < c_b)
                    goto success_homogeneous;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset11] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          goto homogeneous;
      else
        if(ptr[offset2] < c_b)
          if(ptr[offset3] < c_b)
            if(ptr[offset4] < c_b)
              if(ptr[offset1] < c_b)
                if(ptr[offset6] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset8] < c_b)
                    goto success_homogeneous;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
```

----------------------------------------

TITLE: Building Android AAR Package using Gradle via CMake
DESCRIPTION: This CMake snippet defines a custom command to build the OpenCV Android library project as an AAR file. It specifies the output AAR file path and a dependency helper file. The command executes `./gradlew opencv:assemble` in the `ANDROID_BUILD_BASE_DIR`, potentially with verbose options. After the Gradle command completes, it touches the dependency helper file to signal completion. The command depends on the targets/files listed in the `depends` variable (set previously) and the `${the_module}` target itself. A `file(REMOVE)` command ensures the build is triggered after CMake re-runs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
# build jar
set(AAR_FILE "${OPENCV_JAVA_DIR}/build/outputs/aar/opencv-release.aar")
add_custom_command(
    OUTPUT "${AAR_FILE}" "${OPENCV_DEPHELPER}/${the_module}_android"
    COMMAND ./gradlew ${OPENCV_GRADLE_VERBOSE_OPTIONS} "opencv:assemble"
    COMMAND ${CMAKE_COMMAND} -E touch "${OPENCV_DEPHELPER}/${the_module}_android"
    WORKING_DIRECTORY "${ANDROID_BUILD_BASE_DIR}"
    DEPENDS ${depends} ${the_module}
    COMMENT "Building OpenCV Android library project"
)
file(REMOVE "${OPENCV_DEPHELPER}/${the_module}_android")  # force rebuild after CMake run
```

----------------------------------------

TITLE: Installing Required Python Dependencies
DESCRIPTION: This console snippet installs dependencies specified in a requirements.txt file into the activated virtual environment. It ensures all necessary libraries are available for running the model conversion pipeline with OpenCV and PyTorch.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_1

LANGUAGE: console
CODE:
```
pip install -r requirements.txt
```

----------------------------------------

TITLE: Installing with Stripped Binaries to Reduce Size - Shell
DESCRIPTION: Runs the CMake 'install/strip' target to install binaries with symbol information removed, reducing the resulting binary size by 10-15%. This step should be used on platforms (typically Linux) when release builds are prioritized and debugging information is not required. Caution: Once stripped, debugging the binaries will be limited.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_24

LANGUAGE: shell
CODE:
```
cmake --build . --target install/strip
```

----------------------------------------

TITLE: Toggle Example for C++, Java, and Python - Doxygen with @snippet
DESCRIPTION: Provides a multi-language toggle button example, each embedding a code snippet by referencing its source file and section. Inputs are language toggle directives and @snippet commands; outputs are code blocks displayed according to selected language. Used to demonstrate the same logic across C++, Java, and Python snippets in documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_14

LANGUAGE: markdown
CODE:
```
@add_toggle_cpp

   Text for C++ button
   @snippet samples/cpp/tutorial_code/introduction/documentation/documentation.cpp hello_world

@end_toggle

@add_toggle_java

   Text for Java button
   @snippet samples/java/tutorial_code/introduction/documentation/Documentation.java  hello_world

@end_toggle

@add_toggle_python

   Text for Python button
   @snippet samples/python/tutorial_code/introduction/documentation/documentation.py hello_world

@end_toggle
```

----------------------------------------

TITLE: Installing Maven and JDK Dependencies via APT for OpenCV Build
DESCRIPTION: Command to install Maven and the default JDK using the aptitude package manager, which are prerequisites for the OpenCV Maven build process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/maven/README.md#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
sudo aptitude install maven default-jdk
```

----------------------------------------

TITLE: Configuring OpenCV Video Module Dependencies
DESCRIPTION: Defines the OpenCV video module with its required and optional dependencies. Includes support for multiple programming language wrappers including Java, Objective-C, Python, and JavaScript.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/video/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(the_description "Video Analysis")
ocv_define_module(video
    opencv_imgproc
    OPTIONAL
      opencv_calib3d
      opencv_dnn
    WRAP
      java
      objc
      python
      js
)
```

----------------------------------------

TITLE: Setting an Environment Variable in Python Using the os Module
DESCRIPTION: This Python snippet assigns a string value to 'MY_ENV_VARIABLE' using 'os.environ', and shows an example of importing OpenCV ('cv2') which may read such variables. Dependencies: Python's 'os' and 'cv2' (OpenCV) modules. Limitations: On some platforms or Python distributions (notably Windows), this may not affect native libraries like OpenCV, depending on process model.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/env_reference/env_reference.markdown#2025-04-22_snippet_3

LANGUAGE: py
CODE:
```
import os\nos.environ["MY_ENV_VARIABLE"] = "True" # value must be a string\nimport cv2 # variables set after this may not have effect
```

----------------------------------------

TITLE: Configuring TIFF Support in CMake
DESCRIPTION: CMake configuration option for enabling TIFF and zlib support in OpenCV imgcodecs module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/readme.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
WITH_TIFF=ON # Enable TIFF and zlib support
```

----------------------------------------

TITLE: Declaring Variables for Laplacian Demo in C++
DESCRIPTION: Declares necessary C++ variables for the Laplacian demo, including Mat objects to store the source, grayscale, and destination images, kernel size, scale, delta, desired output depth (ddepth), and window name. Requires OpenCV headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/imgtrans/laplace_operator/laplace_operator.markdown#2025-04-22_snippet_3

LANGUAGE: cpp
CODE:
```
//! [variables]
// Declare the variables we are going to use
Mat src, src_gray, dst;
int kernel_size = 3;
int scale = 1;
int delta = 0;
int ddepth = CV_16S;
const char* window_name = "Laplace Demo";
//! [variables]
```

----------------------------------------

TITLE: Setup OpenCV Environment with Leiningen
DESCRIPTION: Demonstrates setting up a Leiningen environment that automatically takes care of OpenCV library initialization, simplifying the process to start the project with necessary dependencies pre-loaded.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_16

LANGUAGE: bash
CODE:
```
lein repl
nREPL server started on port 51645 on host 127.0.0.1
REPL-y 0.3.0
Clojure 1.5.1
    Docs: (doc function-name-here)
          (find-doc "part-of-name-here")
  Source: (source function-name-here)
 Javadoc: (javadoc java-object-or-class-here)
    Exit: Control+D or (exit) or (quit)
 Results: Stored in vars *1, *2, *3, an exception in *e

user=>
```

----------------------------------------

TITLE: Adding CUDA Support Option and Validating Dependencies for DNN Module - CMake
DESCRIPTION: Defines and validates variables for enabling CUDA support (OPENCV_DNN_CUDA) in the DNN module. Checks that dependencies (CUDA Toolkit, cuBLAS, cuDNN) are available; emits error messages if not. Enables CUDA-specific code compilation if all requirements are present. Inputs include HAVE_CUDA, HAVE_CUBLAS, and HAVE_CUDNN; outputs are compile definitions or fatal error messages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: CMake
CODE:
```
ocv_option(OPENCV_DNN_CUDA "Build with CUDA support"
    HAVE_CUDA
    AND HAVE_CUBLAS
    AND HAVE_CUDNN
)

if(OPENCV_DNN_CUDA)
  if(HAVE_CUDA AND HAVE_CUBLAS AND HAVE_CUDNN)
    ocv_target_compile_definitions(${the_module} PRIVATE "CV_CUDA4DNN=1")
  else()
    if(NOT HAVE_CUDA)
      message(SEND_ERROR "DNN: CUDA backend requires CUDA Toolkit. Please resolve dependency or disable OPENCV_DNN_CUDA=OFF")
    elseif(NOT HAVE_CUBLAS)
      message(SEND_ERROR "DNN: CUDA backend requires cuBLAS. Please resolve dependency or disable OPENCV_DNN_CUDA=OFF")
    elseif(NOT HAVE_CUDNN)
      message(SEND_ERROR "DNN: CUDA backend requires cuDNN. Please resolve dependency or disable OPENCV_DNN_CUDA=OFF")
    endif()
  endif()
endif()
```

----------------------------------------

TITLE: Implementing calcGST() Function Header in G-API
DESCRIPTION: Shows the implementation of the calcGST() function header using G-API operations, demonstrating syntax differences from traditional OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/gapi/anisotropic_segmentation/porting_anisotropic_segmentation.markdown#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
cv::GMat calcGST(const cv::GMat& inputImage, const int w)
{
    auto img = cv::gapi::convertTo(inputImage, CV_32F);
    auto imgDiffX = cv::gapi::Sobel(img, CV_32F, 1, 0, 3);
    auto imgDiffY = cv::gapi::Sobel(img, CV_32F, 0, 1, 3);
    auto imgDiffXY = cv::gapi::mul(imgDiffX, imgDiffY);
    auto imgDiffXX = cv::gapi::mul(imgDiffX, imgDiffX);
    auto imgDiffYY = cv::gapi::mul(imgDiffY, imgDiffY);
```

----------------------------------------

TITLE: Checking OpenCV Build Results
DESCRIPTION: Commands to check the presence of built OpenCV libraries and executables.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_16

LANGUAGE: bash
CODE:
```
ls lib/*
ls bin/*
```

----------------------------------------

TITLE: Running build_xcframework.py to Build XCFramework - Python/Bash
DESCRIPTION: This example shows how to execute the build_xcframework.py script from the command line to create an OpenCV xcframework. It requires Python 3.6+, CMake 3.18.5+, and Xcode 12.2+ with command line tools. The command builds OpenCV for multiple Apple architectures and outputs results to the specified directory. Expected output is an opencv2.xcframework. Ensure the script and Python/CMake dependencies are present in your environment.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/apple/readme.md#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
cd ~/<my_working_directory>\npython opencv/platforms/apple/build_xcframework.py --out ./build_xcframework
```

----------------------------------------

TITLE: Building OpenCV with Make
DESCRIPTION: Command to build OpenCV using Make, utilizing multiple CPU cores for faster compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_install/linux_install.markdown#2025-04-22_snippet_14

LANGUAGE: bash
CODE:
```
make -j4
```

----------------------------------------

TITLE: Running OpenCV Tests with Custom Arguments
DESCRIPTION: Command to run OpenCV tests with custom arguments passed to ctest, such as verbose output and parallel test execution.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_10

LANGUAGE: bash
CODE:
```
$ make test ARGS="--verbose --parallel 3"
```

----------------------------------------

TITLE: Camera API Abstract Methods Definition
DESCRIPTION: Abstract methods that need to be implemented by camera API inheritors. These methods handle camera operations for both Camera and Camera2 APIs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_ocl_intro.markdown#2025-04-22_snippet_8

LANGUAGE: Java
CODE:
```
    protected abstract void openCamera();
    protected abstract void closeCamera();
    protected abstract void setCameraPreviewSize(int width, int height);
```

----------------------------------------

TITLE: Forcing Compilation of Fast GEMM Kernels for Various Architectures - CMake
DESCRIPTION: This registers the 'fast_gemm_kernels' implementation for a range of architectures using 'ocv_add_dispatched_file_force_all'. This optimizes matrix multiplication performance in DNN layers. Source file and architecture flags are required as input. Output is build configuration including the optimized kernels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
ocv_add_dispatched_file_force_all("layers/cpu_kernels/fast_gemm_kernels" AVX AVX2 NEON LASX)
```

----------------------------------------

TITLE: Creating OpenCV World Target and Configuring VTK Integration (CMake)
DESCRIPTION: Uses the custom `ocv_create_module` function to define the build target for the `opencv_world` library, passing the aggregated link dependencies (`link_deps`). This function utilizes the previously collected sources, headers, and include directories. Additionally, it checks if the `opencv_viz` module is being built, is part of the world build, and if the VTK version is 8.90.0 or newer. If all conditions are met, it calls `vtk_module_autoinit` to handle VTK module initialization for the `opencv_world` target, linking necessary VTK libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
#message(STATUS "${OPENCV_MODULE_${the_module}_HEADERS}")
#message(STATUS "${OPENCV_MODULE_${the_module}_SOURCES}")
ocv_create_module(${link_deps})

if(";${OPENCV_MODULES_BUILD};" MATCHES ";opencv_viz;" AND OPENCV_MODULE_opencv_viz_IS_PART_OF_WORLD AND NOT (VTK_VERSION VERSION_LESS "8.90.0"))
  vtk_module_autoinit(TARGETS opencv_world MODULES ${VTK_LIBRARIES})
endif()
```

----------------------------------------

TITLE: Configuring CUDA Architecture Binary Support in CMake
DESCRIPTION: CMake configuration example showing how to specify CUDA architecture binary support for different compute capabilities. This setting controls which GPU architectures the compiled code will support natively.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/doc/cuda.markdown#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
CUDA_ARCH_BIN="1.0 1.3 2.0"
```

----------------------------------------

TITLE: OpenCV Linker Configuration
DESCRIPTION: Links OpenCV libraries to the project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/apps/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
link_libraries(${OPENCV_LINKER_LIBS})
```

----------------------------------------

TITLE: Installing Dependencies and Cross-Compiling OpenCV for ARMv7 using CMake
DESCRIPTION: This bash script installs necessary dependencies for cross-compiling OpenCV for ARMv7 architecture. It then uses CMake to configure the build with NEON optimization and a custom toolchain file. Finally, it builds and installs the project, creating a compressed archive of the installation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_29

LANGUAGE: bash
CODE:
```
sudo apt install -y \
    linux-libc-dev:armhf \
    libavcodec-dev:armhf \
    libavformat-dev:armhf \
    libavutil-dev:armhf \
    libswscale-dev:armhf \
    libfreetype-dev:armhf \
    libharfbuzz-dev:armhf

PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig:/usr/share/pkgconfig \
    PKG_CONFIG_LIBDIR=/usr/lib/arm-linux-gnueabihf \
    PKG_CONFIG_SYSROOT_DIR=/ \
        cmake -S opencv \
              -B build4-full_armhf \
              -DENABLE_NEON=ON \
              -DCMAKE_TOOLCHAIN_FILE=/home/kmtr/work/opencv/platforms/linux/arm-gnueabi.toolchain.cmake \
              -DOPENCV_EXTRA_MODULES_PATH=opencv_contrib/modules \
              -GNinja

cmake      --build   build4-full_armhf
sudo cmake --install build4-full_armhf
tar czvf opencv_armhf.tgz -C build4-full_armhf/install .
```

----------------------------------------

TITLE: Installing Optional Dependencies
DESCRIPTION: Installs TBB, Eigen, and documentation tools for enhanced functionality.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_5

LANGUAGE: shell
CODE:
```
yum install tbb-devel
yum install eigen3-devel
yum install doxygen
```

----------------------------------------

TITLE: Executing FAST Segment Test Logic with Nested Conditionals and Goto in C++
DESCRIPTION: This C++ code implements a segment of a decision tree, likely for FAST corner detection. It compares pixel intensities at various offsets (`offset1` to `offset11`) around a central point (`ptr`) against upper (`cb`) and lower (`c_b`) thresholds. The deeply nested `if-else` structure, combined with `goto` statements, rapidly determines if the pixel pattern matches criteria for a feature, jumping to predefined labels like `success_structured`, `success_homogeneous`, `structured`, or `homogeneous` accordingly. This structure is designed for performance in image processing loops. Dependencies include the `ptr` to pixel data, pre-calculated integer `offset` values, threshold variables `cb` and `c_b`, and the existence of the specified `goto` labels elsewhere in the code.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_4

LANGUAGE: cpp
CODE:
```
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                    else
                      if(ptr[offset9] > cb)
                        if(ptr[offset7] > cb)
                          if(ptr[offset8] > cb)
                            if(ptr[offset1] > cb)
                              if(ptr[offset10] > cb)
                                if(ptr[offset11] > cb)
                                  goto success_homogeneous;
                                else
                                  if(ptr[offset6] > cb)
                                    if(ptr[offset4] > cb)
                                      goto success_structured;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                if(ptr[offset6] > cb)
                                  if(ptr[offset3] > cb)
                                    if(ptr[offset4] > cb)
                                      goto success_structured;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  goto homogeneous;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset3] > cb)
                                    goto success_homogeneous;
                                  else
                                    if(ptr[offset10] > cb)
                                      goto success_homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto success_homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            goto homogeneous;
                        else
                          goto homogeneous;
                      else
                        goto homogeneous;
                  else
                    if(ptr[offset5] < c_b)
                      if(ptr[offset9] > cb)
                        if(ptr[offset3] < c_b)
                          if(ptr[offset4] < c_b)
                            if(ptr[offset11] > cb)
                              if(ptr[offset1] > cb)
                                if(ptr[offset8] > cb)
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset2] > cb)
                                      goto success_structured;
                                    else
                                      if(ptr[offset7] > cb)
                                        goto success_structured;
                                      else
                                        goto structured;
                                  else
                                    goto homogeneous;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset2] < c_b)
                                      if(ptr[offset7] < c_b)
                                        if(ptr[offset8] < c_b)
                                          goto success_structured;
                                        else
                                          goto structured;
                                      else
                                        goto structured;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                if(ptr[offset6] > cb)
                                  if(ptr[offset7] > cb)
                                    if(ptr[offset8] > cb)
                                      if(ptr[offset10] > cb)
                                        goto success_structured;
                                      else
                                        goto structured;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                                else
                                  if(ptr[offset6] < c_b)
                                    if(ptr[offset2] < c_b)
                                      if(ptr[offset7] < c_b)
                                        if(ptr[offset1] < c_b)
                                          goto success_structured;
                                        else
                                          if(ptr[offset8] < c_b)
                                            goto success_structured;
                                          else
                                            goto structured;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                            else
                              if(ptr[offset2] < c_b)
                                if(ptr[offset7] < c_b)
                                  if(ptr[offset1] < c_b)
                                    if(ptr[offset6] < c_b)
                                      goto success_structured;
                                    else
                                      goto homogeneous;
                                  else
                                    if(ptr[offset6] < c_b)
                                      if(ptr[offset8] < c_b)
                                        goto success_structured;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                          else
                            if(ptr[offset11] > cb)
                              if(ptr[offset8] > cb)
                                if(ptr[offset10] > cb)
                                  if(ptr[offset1] > cb)
                                    if(ptr[offset2] > cb)
                                      goto success_structured;
                                    else
                                      if(ptr[offset7] > cb)
                                        goto success_structured;
                                      else
                                        goto homogeneous;
                                  else
                                    if(ptr[offset6] > cb)
                                      if(ptr[offset7] > cb)
                                        goto success_structured;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  goto homogeneous;
                              else
                                goto homogeneous;
                            else
                              goto homogeneous;
                        else
                          if(ptr[offset11] > cb)
                            if(ptr[offset10] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset1] > cb)
                                  if(ptr[offset2] > cb)
                                    goto success_homogeneous;
                                  else
                                    if(ptr[offset7] > cb)
                                      if(ptr[offset8] > cb)
                                        goto success_structured;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                else
                                  if(ptr[offset6] > cb)
                                    if(ptr[offset7] > cb)
                                      if(ptr[offset8] > cb)
                                        goto success_structured;
                                      else
                                        goto homogeneous;
                                    else
                                      goto homogeneous;
                                  else
                                    goto homogeneous;
                              else
                                if(ptr[offset8] > cb)
                                  if(ptr[offset1] > cb)
                                    if(ptr[offset2] > cb)
```

----------------------------------------

TITLE: Starting Clojure REPL with OpenCV
DESCRIPTION: This snippet shows how to start a Clojure REPL environment using Leiningen, preparing for OpenCV operations by importing necessary classes such as Mat, Imgcodecs, and Imgproc.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_21

LANGUAGE: Clojure
CODE:
```
lein repl
nREPL server started on port 50624 on host 127.0.0.1
REPL-y 0.3.0
Clojure 1.5.1
    Docs: (doc function-name-here)
          (find-doc "part-of-name-here")
  Source: (source function-name-here)
 Javadoc: (javadoc java-object-or-class-here)
    Exit: Control+D or (exit) or (quit)
 Results: Stored in vars *1, *2, *3, an exception in *e

user=> (import '[org.opencv.core Mat Size CvType]
               '[org.opencv.imgcodecs Imgcodecs]
               '[org.opencv.imgproc Imgproc])
org.opencv.imgproc.Imgproc
```

----------------------------------------

TITLE: Installing GPU Example Source Files in CMake
DESCRIPTION: Uses the custom `ocv_install_example_src` CMake function to install the source files (*.cpp, *.hpp) and the CMakeLists.txt file associated with the 'gpu' examples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
ocv_install_example_src(gpu *.cpp *.hpp CMakeLists.txt)
```

----------------------------------------

TITLE: Including Code in Documentation with @code Command - Doxygen Markup
DESCRIPTION: Demonstrates using @code and @endcode to embed code blocks in documentation. Syntax highlighting is automatic based on file type, or can be overridden manually (e.g., with {.xml}). No external dependencies. Inputs are code text; output is formatted code in rendered documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_9

LANGUAGE: cpp
CODE:
```
@code
float val = img.at<float>(borderInterpolate(100, img.rows, cv::BORDER_REFLECT_101),
                          borderInterpolate(-5, img.cols, cv::BORDER_WRAP));
@endcode
```

----------------------------------------

TITLE: Configuring udev Rules for Android Device Access - Linux (guess)
DESCRIPTION: This snippet sets the necessary udev permissions to allow a Linux system to detect and grant appropriate access to an Android device via USB using its vendor ID. Place this line into /etc/udev/rules.d/51-android.rules, adjusting 'idVendor' as needed for your specific device, and assign the correct user group to permit device communication using adb. This configuration is required for device enumeration and debugging over USB with Android tools on Linux systems.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/android_binary_package/android_dev_intro.markdown#2025-04-22_snippet_0

LANGUAGE: guess
CODE:
```
SUBSYSTEM=="usb", ATTR{idVendor}=="1004",  MODE="0666", GROUP="plugdev"
```

----------------------------------------

TITLE: Implementing Corner Detection Logic in C++ for OpenCV
DESCRIPTION: This snippet contains a series of nested if-else statements that compare pixel values at various offsets to determine if a point is a corner. It uses goto statements to branch to 'is_a_corner' or 'is_not_a_corner' based on the conditions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_14

LANGUAGE: C++
CODE:
```
if(ptr[offset11] < c_b)
  if(ptr[offset1] < c_b)
    if(ptr[offset3] < c_b)
      goto is_a_corner;
    else
      if(ptr[offset8] < c_b)
        goto is_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset6] < c_b)
      if(ptr[offset7] < c_b)
        if(ptr[offset8] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  goto is_not_a_corner;

// ... (additional nested conditions)

if(ptr[offset5] > cb)
  if(ptr[offset9] > cb)
    if(ptr[offset6] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset3] > cb)
              goto is_a_corner;
            else
              if(ptr[offset10] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset10] > cb)
              if(ptr[offset11] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
```

----------------------------------------

TITLE: Configuring CMake for OpenCV with OpenVX Support
DESCRIPTION: CMake command line options to enable OpenVX support in OpenCV. The configuration requires specifying the path to prebuilt OpenVX and explicitly enabling the OpenVX module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openvx/hal/README.md#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
-DOPENVX_ROOT=/path/to/prebuilt/openvx -DWITH_OPENVX=YES
```

----------------------------------------

TITLE: Directory Structure Example for Training Data
DESCRIPTION: Shows the basic directory structure for organizing negative samples used in cascade classifier training.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/traincascade.markdown#2025-04-22_snippet_0

LANGUAGE: text
CODE:
```
/img
  img1.jpg
  img2.jpg
bg.txt
```

----------------------------------------

TITLE: Defining OpenCV ml Module with Bindings - CMake
DESCRIPTION: This snippet defines the OpenCV Machine Learning (ml) module and its dependencies using the ocv_define_module command in CMake. The ml module depends on opencv_core and is enabled for Java, Objective-C, and Python wrappers. This setup allows the module to be built with support for these external interfaces, requiring the relevant language toolchains and wrapper generators to be available during the configuration process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ml/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
ocv_define_module(ml opencv_core WRAP java objc python)
```

----------------------------------------

TITLE: Installing OpenCV
DESCRIPTION: Command to install the built OpenCV libraries and headers. May require root privileges depending on the installation location.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_11

LANGUAGE: bash
CODE:
```
$ make install
```

----------------------------------------

TITLE: Defining and Configuring the OpenCV ObjDetect Module (CMake)
DESCRIPTION: This CMake script defines the 'objdetect' module in the OpenCV build system, establishing its description and specifying dependencies such as core, imgproc, and calib3d modules. It also marks the DNN module as optional and enables wrapping for Python, Java, Objective-C, and JavaScript. The script further includes conditional statements to include QUIRC if present in the environment, configuring include directories and linking the appropriate library. Required dependencies include OpenCV's core modules and potentially QUIRC, which must be available for its code path to activate.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objdetect/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(the_description "Object Detection")
ocv_define_module(objdetect
    opencv_core
    opencv_imgproc
    opencv_calib3d
    OPTIONAL
        opencv_dnn
    WRAP
        python
        java
        objc
        js
)

if(HAVE_QUIRC)
    get_property(QUIRC_INCLUDE GLOBAL PROPERTY QUIRC_INCLUDE_DIR)
    ocv_include_directories(${QUIRC_INCLUDE})
    ocv_target_link_libraries(${the_module} quirc)
endif()

```

----------------------------------------

TITLE: Implementing FAST Corner Detection Pixel Comparisons in C++
DESCRIPTION: This code snippet is part of the FAST corner detection algorithm. It performs pixel intensity comparisons at various offsets around a central pixel to determine if it's a corner. The algorithm uses goto statements for efficient branching based on comparison results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_19

LANGUAGE: C++
CODE:
```
if(ptr[offset4] > cb)
  goto success_structured;
else
  goto homogeneous;
else
  goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset6] > cb)
    if(ptr[offset4] > cb)
      if(ptr[offset3] > cb)
        goto success_homogeneous;
      else
        if(ptr[offset10] > cb)
          goto success_homogeneous;
        else
          goto homogeneous;
    else
      if(ptr[offset10] > cb)
        if(ptr[offset11] > cb)
          goto success_homogeneous;
        else
          goto homogeneous;
      else
        goto homogeneous;
  else
    goto homogeneous;
else
  if(ptr[offset10] > cb)
    if(ptr[offset11] > cb)
      if(ptr[offset1] > cb)
        goto success_homogeneous;
      else
        if(ptr[offset6] > cb)
          goto success_homogeneous;
        else
          goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
  goto homogeneous;
else
  goto homogeneous;
else
  if(ptr[offset7] < c_b)
    if(ptr[offset5] < c_b)
      if(ptr[offset2] < c_b)
        if(ptr[offset6] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset1] < c_b)
                goto success_homogeneous;
              else
                if(ptr[offset8] < c_b)
                  goto success_homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset9] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset9] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          goto homogeneous;
      else
        if(ptr[offset9] < c_b)
          if(ptr[offset6] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto success_homogeneous;
                else
                  if(ptr[offset10] < c_b)
                    goto success_homogeneous;
                  else
                    goto homogeneous;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_homogeneous;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              goto homogeneous;
          else
            goto homogeneous;
        else
          goto homogeneous;
    else
      goto homogeneous;
  else
    goto homogeneous;
else
if(ptr[offset0] < c_b)
  if(ptr[offset2] < c_b)
    if(ptr[offset9] < c_b)
      if(ptr[offset5] < c_b)
        if(ptr[offset7] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset6] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto homogeneous;
              else
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset4] < c_b)
                      goto success_structured;
                    else
                      if(ptr[offset11] < c_b)
                        goto success_structured;
                      else
                        goto structured;
                  else
                    goto homogeneous;
                else
                  goto homogeneous;
            else
              if(ptr[offset11] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    goto success_structured;
                  else
                    if(ptr[offset10] < c_b)
                      goto success_structured;
                    else
                      goto homogeneous;
                else
                  if(ptr[offset8] < c_b)
                    if(ptr[offset10] < c_b)
                      goto success_structured;
                    else
                      goto homogeneous;
                  else
                    goto homogeneous;
              else
                goto homogeneous;
          else
            if(ptr[offset6] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset4] < c_b)
                  if(ptr[offset3] < c_b)
                    goto success_structured;
                  else
                    if(ptr[offset10] < c_b)
                      goto success_structured;
                    else
                      goto homogeneous;
                else
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto success_structured;
                    else
                      goto homogeneous;
                  else
                    goto homogeneous;
              else
                goto homogeneous;
            else
              goto homogeneous;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset11] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  goto success_homogeneous;
                else
                  if(ptr[offset10] < c_b)
                    goto success_homogeneous;
```

----------------------------------------

TITLE: Starting Clojure REPL with Leiningen
DESCRIPTION: This snippet demonstrates how to start a Clojure REPL using Leiningen. It sets up a REPL environment necessary for Clojure development, enabling evaluation of Clojure expressions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_6

LANGUAGE: bash
CODE:
```
cd simple-sample
lein repl
...
...
nREPL server started on port 50907 on host 127.0.0.1
REPL-y 0.3.0
Clojure 1.5.1
    Docs: (doc function-name-here)
          (find-doc "part-of-name-here")
  Source: (source function-name-here)
 Javadoc: (javadoc java-object-or-class-here)
    Exit: Control+D or (exit) or (quit)
 Results: Stored in vars *1, *2, *3, an exception in *e

user=>
```

----------------------------------------

TITLE: AGAST Corner Detection Function in C++
DESCRIPTION: Implementation of AGAST_7_12s corner detection algorithm that processes image data to detect corner points. The function handles image continuity checks, manages keypoint storage, and implements the core detection logic using pixel offset comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_16

LANGUAGE: C++
CODE:
```
static void AGAST_7_12s(InputArray _img, std::vector<KeyPoint>& keypoints, int threshold)
{
    cv::Mat img;
    if(!_img.getMat().isContinuous())
      img = _img.getMat().clone();
    else
      img = _img.getMat();

    size_t total = 0;
    int xsize = img.cols;
    int ysize = img.rows;
    size_t nExpectedCorners = keypoints.capacity();
    int x, y;
    int xsizeB=xsize - 3;
    int ysizeB=ysize - 2;
    int width;

    keypoints.resize(0);

    int pixel_7_12s_[16];
    makeAgastOffsets(pixel_7_12s_, (int)img.step, AgastFeatureDetector::AGAST_7_12s);

    short offset0 = (short) pixel_7_12s_[0];
    short offset1 = (short) pixel_7_12s_[1];
    short offset2 = (short) pixel_7_12s_[2];
    short offset3 = (short) pixel_7_12s_[3];
    short offset4 = (short) pixel_7_12s_[4];
    short offset5 = (short) pixel_7_12s_[5];
    short offset6 = (short) pixel_7_12s_[6];
    short offset7 = (short) pixel_7_12s_[7];
    short offset8 = (short) pixel_7_12s_[8];
    short offset9 = (short) pixel_7_12s_[9];
    short offset10 = (short) pixel_7_12s_[10];
    short offset11 = (short) pixel_7_12s_[11];

    width = xsize;
```

----------------------------------------

TITLE: Creating AgastFeatureDetector Instances with Factory Method
DESCRIPTION: Factory method for creating AgastFeatureDetector instances. Uses the Implementation class and smart pointers to handle memory management for the detector objects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_44

LANGUAGE: C++
CODE:
```
Ptr<AgastFeatureDetector> AgastFeatureDetector::create( int threshold, bool nonmaxSuppression, int type )
{
    return makePtr<AgastFeatureDetector_Impl>(threshold, nonmaxSuppression, type);
}
```

----------------------------------------

TITLE: Setting Python3 Module Properties in CMake
DESCRIPTION: Configures the Python3 module properties including description, module name, and installation subdirectory. These properties are used during the build process to properly generate and install the Python3 bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/python3/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(the_description "The python3 bindings")
set(MODULE_NAME python3)
set(MODULE_INSTALL_SUBDIR python3)

set(PYTHON PYTHON3)
```

----------------------------------------

TITLE: Injecting OpenCV Libraries in Leiningen Project
DESCRIPTION: Modifies the project.clj file to automate loading of OpenCV native libraries in Clojure, removing the need for manual loading every time the REPL starts. Enhances productivity.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_15

LANGUAGE: clojure
CODE:
```
(defproject simple-sample "0.1.0-SNAPSHOT"
  ...
injections [(clojure.lang.RT/loadLibrary org.opencv.core.Core/NATIVE_LIBRARY_NAME)])
```

----------------------------------------

TITLE: Installing Compulsory Dependencies
DESCRIPTION: Installs required dependencies including CMake, Python development tools, and compilation tools.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_2

LANGUAGE: shell
CODE:
```
yum install cmake
yum install python-devel numpy
yum install gcc gcc-c++
```

----------------------------------------

TITLE: Two-class Discrete AdaBoost Algorithm in Mathematical Notation
DESCRIPTION: Formal mathematical description of the AdaBoost algorithm implemented in OpenCV, including initialization, iteration steps, and classification formula. The algorithm combines weak classifiers to create a strong classifier for binary classification tasks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ml/doc/ml_intro.markdown#2025-04-22_snippet_1

LANGUAGE: LaTeX
CODE:
```
- Set \f$N\f$ examples \f${(x_i,y_i)}1N\f$ with \f$x_i \in{R^K}, y_i \in{-1, +1}\f$ .

- Assign weights as \f$w_i = 1/N, i = 1,...,N\f$ .

- Repeat for \f$m = 1,2,...,M\f$ :

    - Fit the classifier \f$f_m(x) \in{-1,1}\f$, using weights \f$w_i\f$ on the training data.

    - Compute \f$err_m = E_w [1_{(y \neq f_m(x))}], c_m = log((1 - err_m)/err_m)\f$ .

    - Set \f$w_i \Leftarrow w_i exp[c_m 1_{(y_i \neq f_m(x_i))}], i = 1,2,...,N,\f$ and
        renormalize so that \f$\Sigma i w_i = 1\f$ .

- Classify new samples _x_ using the formula: \f$\textrm{sign} (\Sigma m = 1M c_m f_m(x))\f$ .
```

----------------------------------------

TITLE: Creating Generator Configuration File in CMake
DESCRIPTION: Generates a JSON configuration file that includes the root directory, build directory, and modules information. The file is only updated if the content has changed to avoid unnecessary rebuilds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/generator/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
if(HAVE_opencv_objc)
  set(__objc_build_dir "\"objc_build_dir\": \"${CMAKE_CURRENT_BINARY_DIR}/../objc\",")
endif()

set(CONFIG_FILE "${CMAKE_CURRENT_BINARY_DIR}/gen_objc.json")
set(__config_str
"{
  \"rootdir\": \"${OpenCV_SOURCE_DIR}\",
  ${__objc_build_dir}
  \"modules\": [
${__modules_config}
  ]
}
")
#TODO: ocv_update_file("${CONFIG_FILE}" "${__config_str}" ON_CHANGE_REMOVE "${OPENCV_DEPHELPER}/gen_opencv_objc_source")
if(EXISTS "${CONFIG_FILE}")
  file(READ "${CONFIG_FILE}" __content)
else()
  set(__content "")
endif()
if(NOT "${__content}" STREQUAL "${__config_str}")
  file(WRITE "${CONFIG_FILE}" "${__config_str}")
  file(REMOVE "${OPENCV_DEPHELPER}/gen_opencv_objc_source")
endif()
unset(__config_str)
```

----------------------------------------

TITLE: Defining a Point in Python
DESCRIPTION: How to define a 2D point using a tuple in Python for OpenCV functions. The tuple contains x and y coordinates.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/basic_geometric_drawing/basic_geometric_drawing.markdown#2025-04-22_snippet_2

LANGUAGE: python
CODE:
```
pt = (10, 0) # x = 10, y = 0
```

----------------------------------------

TITLE: Example Output of pkg-config for OpenCV Include Paths
DESCRIPTION: This shows example output from the `pkg-config --cflags opencv` command. It lists the directories (`-I/usr/local/include/opencv` and `-I/usr/local/include`) where the compiler should search for OpenCV header files. This output can be used to configure the include paths in Eclipse.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/linux_eclipse/linux_eclipse.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
-I/usr/local/include/opencv -I/usr/local/include
```

----------------------------------------

TITLE: Configuring OpenCV Android Camera Tutorial Build
DESCRIPTION: CMake configuration for building an OpenCV Android camera control tutorial example. Sets the project name, adds Android build target with OpenCV library dependencies, and specifies minimum SDK version 11.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-3-cameracontrol/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-tutorial-3-cameracontrol)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Scoring AGAST Corners with OAST_9_16 in OpenCV (C++)
DESCRIPTION: Implements a template specialization for agast_cornerScore with OAST_9_16, which calculates the AGAST score for a given image pixel. The function uses precomputed neighborhood offsets and a binary search approach to threshold testing for rapid corner classification. Depends on OpenCV data types and assumes ptr, pixel, and threshold are valid. Input is a pointer to the source pixel, a list of pixel offsets, and a detection threshold; computations involve intensity comparisons and early exits based on the AGAST algorithm. Output is an integer corner score, and the code is heavily optimized for branching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
// 16 pixel mask
template<>
int agast_cornerScore<AgastFeatureDetector::OAST_9_16>(const uchar* ptr, const int pixel[], int threshold)
{
    int bmin = threshold;
    int bmax = 255;
    int b_test = (bmax + bmin) / 2;

    short offset0 = (short) pixel[0];
    short offset1 = (short) pixel[1];
    short offset2 = (short) pixel[2];
    short offset3 = (short) pixel[3];
    short offset4 = (short) pixel[4];
    short offset5 = (short) pixel[5];
    short offset6 = (short) pixel[6];
    short offset7 = (short) pixel[7];
    short offset8 = (short) pixel[8];
    short offset9 = (short) pixel[9];
    short offset10 = (short) pixel[10];
    short offset11 = (short) pixel[11];
    short offset12 = (short) pixel[12];
    short offset13 = (short) pixel[13];
    short offset14 = (short) pixel[14];
    short offset15 = (short) pixel[15];

    while(true)
    {
        const int cb = *ptr + b_test;
        const int c_b = *ptr - b_test;
        if(ptr[offset0] > cb)
          if(ptr[offset2] > cb)
            if(ptr[offset4] > cb)
              if(ptr[offset5] > cb)
                if(ptr[offset7] > cb)
                  if(ptr[offset3] > cb)
                    if(ptr[offset1] > cb)
                      if(ptr[offset6] > cb)
                        if(ptr[offset8] > cb)
                          goto is_a_corner;
                        else
                          if(ptr[offset15] > cb)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset13] > cb)
                          if(ptr[offset14] > cb)
                            if(ptr[offset15] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset8] > cb)
                        if(ptr[offset9] > cb)
                          if(ptr[offset10] > cb)
                            if(ptr[offset6] > cb)
                              goto is_a_corner;
                            else
                              if(ptr[offset11] > cb)
                                if(ptr[offset12] > cb)
                                  if(ptr[offset13] > cb)
                                    if(ptr[offset14] > cb)
                                      if(ptr[offset15] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset10] > cb)
                      if(ptr[offset11] > cb)
                        if(ptr[offset12] > cb)
                          if(ptr[offset8] > cb)
                            if(ptr[offset9] > cb)
                              if(ptr[offset6] > cb)
                                goto is_a_corner;
                              else
                                if(ptr[offset13] > cb)
                                  if(ptr[offset14] > cb)
                                    if(ptr[offset15] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset1] > cb)
                                if(ptr[offset13] > cb)
                                  if(ptr[offset14] > cb)
                                    if(ptr[offset15] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset1] > cb)
                              if(ptr[offset13] > cb)
                                if(ptr[offset14] > cb)
                                  if(ptr[offset15] > cb)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                if(ptr[offset7] < c_b)
                  if(ptr[offset14] > cb)
                    if(ptr[offset15] > cb)
                      if(ptr[offset1] > cb)
                        if(ptr[offset3] > cb)
                          if(ptr[offset6] > cb)
                            goto is_a_corner;
                          else
                            if(ptr[offset13] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset10] > cb)
                            if(ptr[offset11] > cb)
                              if(ptr[offset12] > cb)
                                if(ptr[offset13] > cb)

```

----------------------------------------

TITLE: Setting JPEG Quality Levels in C
DESCRIPTION: Demonstrates how to set separate quality levels for luminance and chrominance in JPEG compression using libjpeg. It also shows how to disable chrominance subsampling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_43

LANGUAGE: C
CODE:
```
jpeg_set_defaults(cinfo);

/* Set luminance quality 90. */
cinfo->q_scale_factor[0] = jpeg_quality_scaling(90);
/* Set chrominance quality 70. */
cinfo->q_scale_factor[1] = jpeg_quality_scaling(70);

jpeg_default_qtables(cinfo, force_baseline);

/* Disable chrominance subsampling */
cinfo->comp_info[0].v_samp_factor = 1;
cinfo->comp_info[0].h_samp_factor = 1;
```

----------------------------------------

TITLE: Configuring APT Sources for MultiArch on Ubuntu 23.04 (Unparsed)
DESCRIPTION: Example content to be added to `/etc/apt/sources.list` (or a file in `/etc/apt/sources.list.d/`) using `sudo apt edit-sources`. These lines configure APT to find packages for `arm64` and `armhf` architectures in the Ubuntu 23.04 (Lunar) repositories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_4

LANGUAGE: unparsed
CODE:
```
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar main restricted
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar-updates main restricted
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar universe
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar-updates universe
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar multiverse
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar-updates multiverse
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar-backports main restricted universe multiverse
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar-security main restricted
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar-security universe
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports lunar-security multiverse
```

----------------------------------------

TITLE: Implementing Pixel Comparison Logic for Feature Detection in OpenCV C++
DESCRIPTION: This code snippet implements a decision tree algorithm for feature detection in images. It compares pixel values at various offsets against thresholds ('cb' and 'c_b') and uses control flow with goto statements to efficiently handle different detection cases. This is likely part of a FAST or similar corner detection algorithm in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_25

LANGUAGE: C++
CODE:
```
if(ptr[offset8] > cb)
  if(ptr[offset5] > cb)
    if(ptr[offset1] > cb)
      if(ptr[offset10] > cb)
        if(ptr[offset11] > cb)
          goto success_structured;
        else
          if(ptr[offset6] > cb)
            if(ptr[offset4] > cb)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
      else
        if(ptr[offset6] > cb)
          if(ptr[offset3] > cb)
            if(ptr[offset4] > cb)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
    else
      if(ptr[offset6] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset3] > cb)
            goto success_structured;
          else
            if(ptr[offset10] > cb)
              goto success_structured;
            else
              goto structured;
        else
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto success_structured;
            else
              goto structured;
          else
            goto structured;
      else
        goto structured;
  else
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset1] > cb)
          goto success_structured;
        else
          if(ptr[offset6] > cb)
            goto success_structured;
          else
            goto structured;
      else
        goto structured;
    else
      goto structured;
else
  goto structured;
else
  goto structured;
else
  if(ptr[offset7] < c_b)
    if(ptr[offset5] < c_b)
      if(ptr[offset2] < c_b)
        if(ptr[offset6] < c_b)
          if(ptr[offset4] < c_b)
            if(ptr[offset3] < c_b)
              if(ptr[offset1] < c_b)
                goto success_structured;
              else
                if(ptr[offset8] < c_b)
                  goto success_structured;
                else
                  goto structured;
            else
              if(ptr[offset9] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
          else
            if(ptr[offset9] < c_b)
              if(ptr[offset8] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
              else
                goto structured;
            else
              goto structured;
        else
          goto structured;
      else
        if(ptr[offset9] < c_b)
          if(ptr[offset6] < c_b)
            if(ptr[offset8] < c_b)
              if(ptr[offset4] < c_b)
                if(ptr[offset3] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
              else
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto success_structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              goto structured;
          else
            goto structured;
        else
          goto structured;
    else
      goto structured;
  else
    goto structured;
else
if(ptr[offset0] < c_b)
  if(ptr[offset2] < c_b)
    if(ptr[offset11] < c_b)
      if(ptr[offset3] < c_b)
        if(ptr[offset5] < c_b)
          if(ptr[offset9] < c_b)
            if(ptr[offset7] < c_b)
              if(ptr[offset1] < c_b)
                if(ptr[offset4] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset8] < c_b)
                    if(ptr[offset4] < c_b)
                      goto success_structured;
                    else
                      if(ptr[offset10] < c_b)
                        goto success_structured;
                      else
                        goto structured;
                  else
                    goto structured;
                else
                  goto structured;
            else
              if(ptr[offset1] < c_b)
                if(ptr[offset4] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset10] < c_b)
                    goto success_structured;
                  else
                    goto structured;
              else
                goto structured;
          else
            if(ptr[offset4] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset1] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset8] < c_b)
                      goto success_structured;
                    else
                      goto structured;
                  else
                    goto structured;
              else
                if(ptr[offset1] < c_b)
                  goto success_structured;
                else
                  goto structured;
            else
              goto structured;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset9] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset1] < c_b)
                  goto success_structured;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset8] < c_b)
```

----------------------------------------

TITLE: AGAST 7-12s Corner Score Template Implementation in C++
DESCRIPTION: Template specialization implementing the AGAST corner scoring algorithm with a 7-12 square pixel mask pattern. The function performs pixel comparisons using a decision tree to determine if a point is a corner based on intensity differences with neighboring pixels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_15

LANGUAGE: C++
CODE:
```
template<>
int agast_cornerScore<AgastFeatureDetector::AGAST_7_12s>(const uchar* ptr, const int pixel[], int threshold)
{
    int bmin = threshold;
    int bmax = 255;
    int b_test = (bmax + bmin)/2;

    short offset0 = (short) pixel[0];
    short offset1 = (short) pixel[1];
    short offset2 = (short) pixel[2];
    short offset3 = (short) pixel[3];
    short offset4 = (short) pixel[4];
    short offset5 = (short) pixel[5];
    short offset6 = (short) pixel[6];
    short offset7 = (short) pixel[7];
    short offset8 = (short) pixel[8];
    short offset9 = (short) pixel[9];
    short offset10 = (short) pixel[10];
    short offset11 = (short) pixel[11];

    while(true)
    {
        const int cb = *ptr + b_test;
        const int c_b = *ptr - b_test;
        if(ptr[offset0] > cb)
          if(ptr[offset5] > cb)
            if(ptr[offset2] < c_b)
              if(ptr[offset7] > cb)
                if(ptr[offset9] < c_b)
                  goto is_not_a_corner;
                else
                  if(ptr[offset9] > cb)
                    if(ptr[offset1] < c_b)
                      if(ptr[offset6] < c_b)
                        goto is_not_a_corner;
                      else
                        if(ptr[offset6] > cb)
                          if(ptr[offset8] > cb)
                            if(ptr[offset4] > cb)
                              if(ptr[offset3] > cb)
                                goto is_a_corner;
                              else
                                if(ptr[offset10] > cb)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset10] > cb)
                                if(ptr[offset11] > cb)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
```

----------------------------------------

TITLE: FAST Corner Detection Pixel Comparison Logic in C++
DESCRIPTION: Nested conditional logic for comparing pixel intensities against threshold values in FAST corner detection. The code checks surrounding pixels against center brightness (cb) and darker threshold (c_b) values to determine corner points.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_40

LANGUAGE: cpp
CODE:
```
continue; // goto homogeneous;
else
  if(ptr[offset9] < c_b)
    if(ptr[offset10] < c_b)
      if(ptr[offset11] < c_b)
        if(ptr[offset8] < c_b)
          if(ptr[offset12] < c_b)
            if(ptr[offset13] < c_b)
              if(ptr[offset14] < c_b)
                if(ptr[offset15] < c_b)
                  {} // goto success_homogeneous;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset7] < c_b)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
```

----------------------------------------

TITLE: Corner Detection Binary Search Implementation
DESCRIPTION: A binary search implementation for corner detection that compares pixel values at different offsets to determine if a point is a corner. Uses goto statements for control flow and maintains binary search bounds (bmin, bmax) to converge on the optimal threshold value.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_44

LANGUAGE: C++
CODE:
```
if(ptr[offset3] < c_b)
    if(ptr[offset5] < c_b)
      if(ptr[offset1] < c_b)
        if(ptr[offset4] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset4] < c_b)
          if(ptr[offset6] < c_b)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset1] < c_b)
        if(ptr[offset4] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset5] > cb)
      if(ptr[offset3] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset6] > cb)
            goto is_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;

is_a_corner:
    bmin=b_test;
    goto end;

is_not_a_corner:
    bmax=b_test;
    goto end;

end:

if(bmin == bmax - 1 || bmin == bmax)
    return bmin;
b_test = (bmin + bmax) / 2;
}

} // namespace cv
```

----------------------------------------

TITLE: Declaring Small Value-Passed Structs with OpenCV Macros in C++
DESCRIPTION: This snippet defines the DMatch struct for matching features in OpenCV, using CV_EXPORTS_W_SIMPLE to mark it for Python export. Constructors and fields are annotated with CV_WRAP and CV_PROP_RW, respectively, indicating which methods and data members should be accessible in Python. Required dependencies include OpenCV headers. Instances can be directly manipulated in both C++ and Python, with fields controlling indices and distances.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_bindings/py_bindings_basics/py_bindings_basics.markdown#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
class CV_EXPORTS_W_SIMPLE DMatch
{
public:
    CV_WRAP DMatch();
    CV_WRAP DMatch(int _queryIdx, int _trainIdx, float _distance);
    CV_WRAP DMatch(int _queryIdx, int _trainIdx, int _imgIdx, float _distance);

    CV_PROP_RW int queryIdx; // query descriptor index
    CV_PROP_RW int trainIdx; // train descriptor index
    CV_PROP_RW int imgIdx;   // train image index

    CV_PROP_RW float distance;
};
```

----------------------------------------

TITLE: Linking OpenCV Java Library in CMake
DESCRIPTION: Configures linking for the OpenCV Java library, handling different scenarios for fat Java library builds and platform-specific linking rules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jni/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
set(__deps ${OPENCV_MODULE_${the_module}_DEPS})
list(REMOVE_ITEM __deps opencv_java_bindings_generator) # don't add dummy module to target_link_libraries list

if(BUILD_FAT_JAVA_LIB)
  ocv_list_unique(__deps)
  set(__extradeps ${__deps})
  ocv_list_filterout(__extradeps "^opencv_")
  if(__extradeps)
    list(REMOVE_ITEM __deps ${__extradeps})
  endif()
  if(APPLE)
    foreach(_dep ${__deps})
      ocv_target_link_libraries(${the_module} PRIVATE -Wl,-force_load "${_dep}")
    endforeach()
  elseif(((CV_GCC OR CV_CLANG OR UNIX) OR (OPENCV_FORCE_FAT_JAVA_LIB_LD_RULES)) AND (NOT OPENCV_SKIP_FAT_JAVA_LIB_LD_RULES))
    ocv_target_link_libraries(${the_module} PRIVATE -Wl,-whole-archive ${__deps} -Wl,-no-whole-archive)
  else()
    ocv_target_link_libraries(${the_module} PRIVATE ${__deps})
  endif()
  ocv_target_link_libraries(${the_module} PRIVATE ${__extradeps} ${OPENCV_LINKER_LIBS})
else()
  ocv_target_link_libraries(${the_module} PRIVATE ${__deps} ${OPENCV_LINKER_LIBS})
endif()
```

----------------------------------------

TITLE: Configuring OpenCV Build Options in CMake
DESCRIPTION: This snippet defines various CMake options for configuring the OpenCV build. It includes options for building shared libraries, examples, documentation, and platform-specific features.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
OCV_OPTION(BUILD_SHARED_LIBS        "Build shared libraries (.dll/.so) instead of static ones (.lib/.a)" NOT (ANDROID OR APPLE_FRAMEWORK) )
OCV_OPTION(BUILD_opencv_apps        "Build utility applications (used for example to train classifiers)" (NOT ANDROID AND NOT WINRT) IF (NOT APPLE_FRAMEWORK) )
OCV_OPTION(BUILD_opencv_js          "Build JavaScript bindings by Emscripten" OFF )
OCV_OPTION(BUILD_ANDROID_PROJECTS   "Build Android projects providing .apk files" ON  IF ANDROID )
OCV_OPTION(BUILD_ANDROID_EXAMPLES   "Build examples for Android platform"         ON  IF ANDROID )
OCV_OPTION(BUILD_DOCS               "Create build rules for OpenCV Documentation" OFF  IF (NOT WINRT AND NOT APPLE_FRAMEWORK))
OCV_OPTION(BUILD_EXAMPLES           "Build all examples"                          OFF )
OCV_OPTION(BUILD_PACKAGE            "Enables 'make package_source' command"       ON  IF NOT WINRT)
OCV_OPTION(BUILD_PERF_TESTS         "Build performance tests"                     NOT INSTALL_CREATE_DISTRIB  IF (NOT APPLE_FRAMEWORK) )
OCV_OPTION(BUILD_TESTS              "Build accuracy & regression tests"           NOT INSTALL_CREATE_DISTRIB  IF (NOT APPLE_FRAMEWORK) )
OCV_OPTION(BUILD_WITH_DEBUG_INFO    "Include debug info into release binaries ('OFF' means default settings)" OFF )
OCV_OPTION(BUILD_WITH_STATIC_CRT    "Enables use of statically linked CRT for statically linked OpenCV" ON IF MSVC )
OCV_OPTION(BUILD_WITH_DYNAMIC_IPP   "Enables dynamic linking of IPP (only for standalone IPP)" OFF )
OCV_OPTION(BUILD_FAT_JAVA_LIB       "Create Java wrapper exporting all functions of OpenCV library (requires static build of OpenCV modules)" ANDROID IF NOT BUILD_SHARED_LIBS)
OCV_OPTION(BUILD_ANDROID_SERVICE    "Build OpenCV Manager for Google Play" OFF IF ANDROID )
OCV_OPTION(BUILD_CUDA_STUBS         "Build CUDA modules stubs when no CUDA SDK" OFF  IF (NOT APPLE_FRAMEWORK) )
OCV_OPTION(BUILD_JAVA               "Enable Java support"                         (ANDROID OR NOT CMAKE_CROSSCOMPILING)  IF (ANDROID OR (NOT APPLE_FRAMEWORK AND NOT WINRT)) )
OCV_OPTION(BUILD_OBJC               "Enable Objective-C support"                  ON  IF APPLE_FRAMEWORK )
OCV_OPTION(BUILD_KOTLIN_EXTENSIONS  "Build Kotlin extensions (Android)"           ON  IF ANDROID )
```

----------------------------------------

TITLE: Generating Configuration JSON (`gen_java.json`) for Java Bindings in CMake
DESCRIPTION: Constructs the content for the `gen_java.json` file. This JSON file provides configuration to the Python generator script, including the OpenCV source root directory, a list of modules to process (using `__modules_config` generated previously), and a list of remapped template files (using `__remap_config`). It checks if the existing `gen_java.json` file content differs from the newly generated content; if so, it overwrites the file and removes a dependency helper file (`gen_opencv_java_source`) to ensure the generator script is re-run.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/generator/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
set(CONFIG_FILE "${CMAKE_CURRENT_BINARY_DIR}/gen_java.json")
set(__config_str
"{
  \"rootdir\": \"${OpenCV_SOURCE_DIR}\",
  \"modules\": [
${__modules_config}
  ],
  \"files_remap\": [
${__remap_config}
  ]
}
")
if(EXISTS "${CONFIG_FILE}")
  file(READ "${CONFIG_FILE}" __content)
else()
  set(__content "")
endif()
if(NOT "${__content}" STREQUAL "${__config_str}")
  file(WRITE "${CONFIG_FILE}" "${__config_str}")
  file(REMOVE "${OPENCV_DEPHELPER}/gen_opencv_java_source")
endif()
unset(__config_str)
```

----------------------------------------

TITLE: Adding Dispatched Source File for Winograd Convolution Kernel - CMake
DESCRIPTION: This snippet registers the Winograd convolution kernel implementation ('conv_winograd_f63') for multiple architectures via 'ocv_add_dispatched_file'. It allows these kernels to be built for the specified hardware. Parameters define which CPU instruction sets to use. No external dependencies are required beyond supported toolchains.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
ocv_add_dispatched_file("layers/cpu_kernels/conv_winograd_f63" AVX AVX2 NEON NEON_FP16)
```

----------------------------------------

TITLE: CMake Configuration for Python Bindings
DESCRIPTION: Configures Python bindings generation in OpenCV using CMake. Includes setting module names, directories, and list of Python modules. It uses conditions and commands to manage module wrapping, dependencies, and custom targets. Key operations include directory configuration, list building, file writing, and command creation. Dependencies include various Python scripts and OpenCV module headers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/bindings/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(MODULE_NAME "python_bindings_generator")
set(OPENCV_MODULE_IS_PART_OF_WORLD FALSE)
ocv_add_module(${MODULE_NAME} INTERNAL)

set(OPENCV_PYTHON_SIGNATURES_FILE "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_signatures.json" CACHE INTERNAL "")
set(OPENCV_PYTHON_BINDINGS_DIR "${CMAKE_CURRENT_BINARY_DIR}" CACHE INTERNAL "")

# This file is included from a subdirectory
set(PYTHON_SOURCE_DIR "${CMAKE_CURRENT_SOURCE_DIR}/../")

if(NOT OPENCV_SKIP_PYTHON_LOADER)
  include("${PYTHON_SOURCE_DIR}/python_loader.cmake")
endif()

# get list of modules to wrap
set(OPENCV_PYTHON_MODULES)
foreach(m ${OPENCV_MODULES_BUILD})
  if (";${OPENCV_MODULE_${m}_WRAPPERS};" MATCHES ";python;" AND HAVE_${m})
    list(APPEND OPENCV_PYTHON_MODULES ${m})
    #message(STATUS "\t${m}")
  endif()
endforeach()

set(opencv_hdrs "")
set(opencv_userdef_hdrs "")
foreach(m ${OPENCV_PYTHON_MODULES})
  foreach (hdr ${OPENCV_MODULE_${m}_HEADERS})
    ocv_is_subdir(is_sub "${OPENCV_MODULE_${m}_LOCATION}/include" "${hdr}")
    if(is_sub)
      list(APPEND opencv_hdrs "${hdr}")
    endif()
  endforeach()

  # both wrapping and C++ implementation
  file(GLOB hdr2 ${OPENCV_MODULE_${m}_LOCATION}/misc/python/python_*.hpp)
  list(SORT hdr2)
  list(APPEND opencv_hdrs ${hdr2})
  list(APPEND opencv_userdef_hdrs ${hdr2})

  file(GLOB hdr ${OPENCV_MODULE_${m}_LOCATION}/misc/python/shadow*.hpp)
  list(SORT hdr)
  list(APPEND opencv_hdrs ${hdr})
  file(GLOB userdef_hdrs ${OPENCV_MODULE_${m}_LOCATION}/misc/python/pyopencv*.hpp)
  list(SORT userdef_hdrs)
  list(APPEND opencv_userdef_hdrs ${userdef_hdrs})
endforeach(m)

# header blacklist
ocv_list_filterout(opencv_hdrs "modules/.*\\.h$")
ocv_list_filterout(opencv_hdrs "modules/core/.*/cuda/")
ocv_list_filterout(opencv_hdrs "modules/core/.*/hal/")
ocv_list_filterout(opencv_hdrs "modules/core/.*/opencl/")
ocv_list_filterout(opencv_hdrs "modules/.+/utils/.*")
ocv_list_filterout(opencv_hdrs "modules/.*\\.inl\\.h*")
ocv_list_filterout(opencv_hdrs "modules/.*_inl\\.h*")
ocv_list_filterout(opencv_hdrs "modules/.*\\.details\\.h*")
ocv_list_filterout(opencv_hdrs "modules/.*\\.private\\.h*")
ocv_list_filterout(opencv_hdrs "modules/.*/private\\.h*")
ocv_list_filterout(opencv_hdrs "modules/.*/legacy/.*")
ocv_list_filterout(opencv_hdrs "modules/.*/detection_based_tracker\\.hpp") # Conditional compilation
if(NOT HAVE_CUDA)
  ocv_list_filterout(opencv_hdrs "modules/cuda.*")
  ocv_list_filterout(opencv_hdrs "modules/cudev")
endif()

set(cv2_generated_files
    "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_enums.h"
    "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_funcs.h"
    "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_include.h"
    "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_modules.h"
    "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_modules_content.h"
    "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_types.h"
    "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_generated_types_content.h"
    "${OPENCV_PYTHON_SIGNATURES_FILE}"
)

string(REPLACE ";" "\n" opencv_hdrs_ "${opencv_hdrs}")
file(WRITE "${CMAKE_CURRENT_BINARY_DIR}/headers.txt" "${opencv_hdrs_}")
file(GLOB_RECURSE typing_stubs_generation_files "${PYTHON_SOURCE_DIR}/src2/typing_stubs_generation/*.py")
add_custom_command(
    OUTPUT ${cv2_generated_files}
    COMMAND "${PYTHON_DEFAULT_EXECUTABLE}" "${PYTHON_SOURCE_DIR}/src2/gen2.py" "${CMAKE_CURRENT_BINARY_DIR}" "${CMAKE_CURRENT_BINARY_DIR}/headers.txt"
    DEPENDS "${PYTHON_SOURCE_DIR}/src2/gen2.py"
            "${PYTHON_SOURCE_DIR}/src2/hdr_parser.py"
            "${typing_stubs_generation_files}"
            "${PYTHON_SOURCE_DIR}/src2/typing_stubs_generator.py"
            # not a real build dependency (file(WRITE) result): ${CMAKE_CURRENT_BINARY_DIR}/headers.txt
            ${opencv_hdrs}
    COMMENT "Generate files for Python bindings and documentation"
)

add_custom_target(gen_opencv_python_source DEPENDS ${cv2_generated_files})

if(TARGET copy_opencv_typing_stubs)
  add_dependencies(copy_opencv_typing_stubs gen_opencv_python_source)
endif()

set(cv2_custom_hdr "${CMAKE_CURRENT_BINARY_DIR}/pyopencv_custom_headers.h")
set(cv2_custom_hdr_str "//user-defined headers\n")
foreach(uh ${opencv_userdef_hdrs})
    set(cv2_custom_hdr_str "${cv2_custom_hdr_str}#include \"${uh}\"\n")
endforeach(uh)
if(EXISTS "${cv2_custom_hdr}")
  file(READ "${cv2_custom_hdr}" __content)
else()
  set(__content "")
endif()
if("${__content}" STREQUAL "${cv2_custom_hdr_str}")
  # Up-to-date
else()
  file(WRITE "${cv2_custom_hdr}" "${cv2_custom_hdr_str}")
endif()
unset(__content)


#
# Configuration for standalone build of Python bindings
#
set(PYTHON_CONFIG_SCRIPT "")
ocv_cmake_script_append_var(PYTHON_CONFIG_SCRIPT
    CMAKE_BUILD_TYPE
    BUILD_SHARED_LIBS

    CMAKE_C_FLAGS CMAKE_C_FLAGS_DEBUG CMAKE_C_FLAGS_RELEASE
    CMAKE_CXX_FLAGS CMAKE_CXX_FLAGS_DEBUG CMAKE_CXX_FLAGS_RELEASE

    CV_GCC CV_CLANG ENABLE_NOISY_WARNINGS

    CMAKE_MODULE_LINKER_FLAGS
    CMAKE_INSTALL_PREFIX
    OPENCV_PYTHON_INSTALL_PATH

    OpenCV_SOURCE_DIR

    OPENCV_FORCE_PYTHON_LIBS
    OPENCV_PYTHON_SKIP_LINKER_EXCLUDE_LIBS

    OPENCV_PYTHON_BINDINGS_DIR
    cv2_custom_hdr
    cv2_generated_files
)
set(CMAKE_HELPER_SCRIPT "${CMAKE_BINARY_DIR}/opencv_python_config.cmake")
file(GENERATE OUTPUT "${CMAKE_HELPER_SCRIPT}" CONTENT "${PYTHON_CONFIG_SCRIPT}")
```

----------------------------------------

TITLE: Running OpenCV.js Node.js Tests - Shell
DESCRIPTION: This shell script initializes the Node.js environment for OpenCV.js by changing to the build output directory, installing dependencies using npm, and running the JavaScript test suite. Dependencies include Node.js (ideally version 8.x) and npm. Input consists of local build artifacts in the 'build_js/bin' directory, and output is test results printed to the console. Ensure Node.js is properly installed and that all necessary permissions are granted.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_14

LANGUAGE: sh
CODE:
```
cd build_js/bin\nnpm install\nnode tests.js
```

----------------------------------------

TITLE: Mimicking OpenCV Java Examples in Clojure
DESCRIPTION: Translates an OpenCV Java example into Clojure using REPL, illustrating how to perform matrix modifications and data display by intermingling Java interop in Clojure.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_13

LANGUAGE: java
CODE:
```
import org.opencv.core.Mat;
import org.opencv.core.CvType;
import org.opencv.core.Scalar;

class SimpleSample {

  static{ System.loadLibrary("opencv_java244"); }

  public static void main(String[] args) {
    Mat m = new Mat(5, 10, CvType.CV_8UC1, new Scalar(0));
    System.out.println("OpenCV Mat: " + m);
    Mat mr1 = m.row(1);
    mr1.setTo(new Scalar(1));
    Mat mc5 = m.col(5);
    mc5.setTo(new Scalar(5));
    System.out.println("OpenCV Mat data:\n" + m.dump());
  }

}
```

----------------------------------------

TITLE: Suppressing Deprecated C Warnings on Windows (MSVC) in CMake
DESCRIPTION: Adds specific preprocessor definitions when compiling with MSVC on Windows (excluding Borland, Cygwin, MinGW) to suppress warnings about deprecated C standard library functions, unless explicitly enabled via `ITK_ENABLE_VISUAL_STUDIO_DEPRECATED_C_WARNINGS`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
# --------------------------------------------------------------------------
# On Visual Studio 8 MS deprecated C. This removes all 1.276E1265 security
# warnings
if(WIN32)
  if(NOT BORLAND)
    if(NOT CYGWIN)
      if(NOT MINGW)
        if(NOT ITK_ENABLE_VISUAL_STUDIO_DEPRECATED_C_WARNINGS)
          add_definitions(
            -D_CRT_FAR_MAPPINGS_NO_DEPRECATE
            -D_CRT_IS_WCTYPE_NO_DEPRECATE
            -D_CRT_MANAGED_FP_NO_DEPRECATE
            -D_CRT_NONSTDC_NO_DEPRECATE
            -D_CRT_SECURE_NO_DEPRECATE
            -D_CRT_SECURE_NO_DEPRECATE_GLOBALS
            -D_CRT_SETERRORMODE_BEEP_SLEEP_NO_DEPRECATE
            -D_CRT_TIME_FUNCTIONS_NO_DEPRECATE
            -D_CRT_VCCLRIT_NO_DEPRECATE
            -D_SCL_SECURE_NO_DEPRECATE
            )
        endif()
      endif()
    endif()
  endif()
endif()
```

----------------------------------------

TITLE: Linking TBB and Freetype with OpenCV GAPI Tests
DESCRIPTION: Adds Freetype and TBB support to the OpenCV test module opencv_test_gapi by defining necessary preprocessor flags and linking with respective libraries. Ensures that TBB and Freetype's functionality are accessible to GAPI tests.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: CMake
CODE:
```
if(HAVE_TBB AND TARGET opencv_test_gapi)
  ocv_target_link_libraries(opencv_test_gapi PRIVATE tbb)
endif()
```

LANGUAGE: CMake
CODE:
```
if(HAVE_FREETYPE)
  ocv_target_compile_definitions(${the_module} PRIVATE -DHAVE_FREETYPE)
  if(TARGET opencv_test_gapi)
    ocv_target_compile_definitions(opencv_test_gapi PRIVATE -DHAVE_FREETYPE)
  endif()
  ocv_target_link_libraries(${the_module} PRIVATE ${FREETYPE_LIBRARIES})
  ocv_target_include_directories(${the_module} PRIVATE ${FREETYPE_INCLUDE_DIRS})
endif()
```

----------------------------------------

TITLE: Setting Target Linkage Property in CMake
DESCRIPTION: Sets the CMake variable `tgts` to the string "PRIVATE". This variable is likely used later in `target_link_libraries` or similar commands to specify that subsequent libraries should be linked privately to the highgui target.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
set(tgts "PRIVATE")
```

----------------------------------------

TITLE: Evaluating Corner Detection in FAST Algorithm using Pixel Comparisons in C++
DESCRIPTION: Part of the FAST corner detection algorithm that uses a decision tree structure to compare pixel values at various offsets against brightness thresholds. The code examines a pattern of pixels around a center point to determine if the point qualifies as a corner based on continuous segments that are brighter or darker than the center pixel.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_12

LANGUAGE: C++
CODE:
```
if(ptr[offset8] < c_b)
  if(ptr[offset4] < c_b)
    if(ptr[offset3] < c_b)
      goto is_a_corner;
    else
      if(ptr[offset10] < c_b)
        goto is_a_corner;
      else
        goto is_not_a_corner;
  else
    if(ptr[offset10] < c_b)
      if(ptr[offset11] < c_b)
        goto is_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset2] < c_b)
    if(ptr[offset1] < c_b)
      if(ptr[offset3] < c_b)
        if(ptr[offset4] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset2] > cb)
    if(ptr[offset1] > cb)
      if(ptr[offset3] > cb)
        if(ptr[offset4] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              goto is_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset2] < c_b)
      if(ptr[offset3] < c_b)
        if(ptr[offset4] < c_b)
          if(ptr[offset7] < c_b)
            if(ptr[offset1] < c_b)
              if(ptr[offset6] < c_b)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset8] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset2] > cb)
    if(ptr[offset10] > cb)
      if(ptr[offset11] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              goto is_a_corner;
            else
              if(ptr[offset8] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset6] > cb)
              if(ptr[offset7] > cb)
                if(ptr[offset8] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset4] > cb)
                goto is_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    if(ptr[offset9] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset8] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              if(ptr[offset1] > cb)
                goto is_a_corner;
              else
                if(ptr[offset6] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
if(ptr[offset0] < c_b)
  if(ptr[offset2] > cb)
    if(ptr[offset5] > cb)
      if(ptr[offset7] > cb)
        if(ptr[offset6] > cb)
          if(ptr[offset4] > cb)
            if(ptr[offset3] > cb)
              if(ptr[offset1] > cb)
                goto is_a_corner;
              else
                if(ptr[offset8] > cb)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
            else
              if(ptr[offset9] > cb)
                if(ptr[offset8] > cb)
                  if(ptr[offset10] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset9] > cb)
              if(ptr[offset8] > cb)
                if(ptr[offset10] > cb)
                  if(ptr[offset11] > cb)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          goto is_not_a_corner;
      else
        if(ptr[offset9] < c_b)
          if(ptr[offset8] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset7] < c_b)
                  if(ptr[offset1] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            goto is_not_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset9] < c_b)
        if(ptr[offset7] < c_b)
          if(ptr[offset8] < c_b)
            if(ptr[offset5] < c_b)
              if(ptr[offset1] < c_b)
                if(ptr[offset10] < c_b)
                  if(ptr[offset11] < c_b)
                    goto is_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset4] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset3] < c_b)
                      if(ptr[offset4] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset3] < c_b)
                      goto is_a_corner;
                    else
                      if(ptr[offset10] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
```

----------------------------------------

TITLE: Detecting DOT Executable for Doxygen Graph Generation in CMake
DESCRIPTION: Checks if the DOT executable (part of Graphviz), required for generating graphs in Doxygen, is found (`DOXYGEN_DOT_EXECUTABLE` is set). If found, it reports the path via a status message and sets initial internal variables (`init_dot_path`, `init_dot_mode`) accordingly. If not found, it sets these variables to indicate DOT is unavailable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_10

LANGUAGE: cmake
CODE:
```
if (DOXYGEN_DOT_EXECUTABLE)
  message(STATUS "Found DOT executable: ${DOXYGEN_DOT_EXECUTABLE}")
  set(init_dot_path "${DOXYGEN_DOT_EXECUTABLE}")
  set(init_dot_mode "YES")
else()
  set(init_dot_path "")
  set(init_dot_mode "NO")
endif()
```

----------------------------------------

TITLE: Configuring GTK Backend for HighGUI in CMake
DESCRIPTION: Sets up the GTK backend (GTK2 or GTK3) for OpenCV HighGUI. Handles both plugin and built-in configurations, and adds OpenGL support through GtkGLExt if available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_16

LANGUAGE: CMake
CODE:
```
if(TARGET ocv.3rdparty.gtk3 OR TARGET ocv.3rdparty.gtk2)
  if(TARGET ocv.3rdparty.gtk3 AND NOT WITH_GTK_2_X)
    set(__gtk_dependency "ocv.3rdparty.gtk3")
  else()
    set(__gtk_dependency "ocv.3rdparty.gtk2")
  endif()
  if(
    NOT HIGHGUI_PLUGIN_LIST STREQUAL "all"
    AND NOT "gtk" IN_LIST HIGHGUI_PLUGIN_LIST
    AND NOT "gtk2" IN_LIST HIGHGUI_PLUGIN_LIST
    AND NOT "gtk3" IN_LIST HIGHGUI_PLUGIN_LIST
    AND NOT OPENCV_HIGHGUI_BUILTIN_BACKEND
  )
    if(__gtk_dependency STREQUAL "ocv.3rdparty.gtk3")
      set(OPENCV_HIGHGUI_BUILTIN_BACKEND "GTK3")
      if(OPENGL_LIBRARIES)
        list(APPEND HIGHGUI_LIBRARIES "${OPENGL_LIBRARIES}")
      endif()
    elseif(__gtk_dependency STREQUAL "ocv.3rdparty.gtk2")
      set(OPENCV_HIGHGUI_BUILTIN_BACKEND "GTK2")
    else()
      set(OPENCV_HIGHGUI_BUILTIN_BACKEND "GTK")
    endif()
    list(APPEND highgui_srcs ${CMAKE_CURRENT_LIST_DIR}/src/window_gtk.cpp)
    list(APPEND tgts ${__gtk_dependency})
    if(TARGET ocv.3rdparty.gtkglext
        AND __gtk_dependency STREQUAL "ocv.3rdparty.gtk2"
        AND NOT OPENCV_GTK_DISABLE_GTKGLEXT
    )
      list(APPEND tgts ocv.3rdparty.gtkglext)
      if(TARGET ocv.3rdparty.gtk_opengl
          AND __gtk_dependency STREQUAL "ocv.3rdparty.gtk2"
          AND NOT OPENCV_GTK_DISABLE_OPENGL
      )
        list(APPEND tgts ocv.3rdparty.gtk_opengl)
      endif()
    endif()
  elseif("gtk" IN_LIST HIGHGUI_PLUGIN_LIST)
    ocv_create_builtin_highgui_plugin(opencv_highgui_gtk ${__gtk_dependency} "window_gtk.cpp")
    if(TARGET ocv.3rdparty.gtkglext)
      ocv_target_link_libraries(opencv_highgui_gtk ocv.3rdparty.gtkglext)
    endif()
  else()
    if(TARGET ocv.3rdparty.gtk3 AND ("gtk3" IN_LIST HIGHGUI_PLUGIN_LIST OR HIGHGUI_PLUGIN_LIST STREQUAL "all"))
      ocv_create_builtin_highgui_plugin(opencv_highgui_gtk3 ocv.3rdparty.gtk3 "window_gtk.cpp")
      if(TARGET ocv.3rdparty.gtkglext)
        ocv_target_link_libraries(opencv_highgui_gtk3 ocv.3rdparty.gtkglext)
      endif()
    endif()
    if(TARGET ocv.3rdparty.gtk2 AND ("gtk2" IN_LIST HIGHGUI_PLUGIN_LIST OR HIGHGUI_PLUGIN_LIST STREQUAL "all"))
      ocv_create_builtin_highgui_plugin(opencv_highgui_gtk2 ocv.3rdparty.gtk2 "window_gtk.cpp")
      if(TARGET ocv.3rdparty.gtkglext)
        ocv_target_link_libraries(opencv_highgui_gtk2 ocv.3rdparty.gtkglext)
      endif()
    endif()
  endif()
endif()
```

----------------------------------------

TITLE: Installing Python Example Files with CMake - CMake
DESCRIPTION: This CMake snippet checks if the INSTALL_PYTHON_EXAMPLES variable is set, then gathers all .py files in the current directory using file(GLOB) and prepares them for installation with the install() command. The files are placed in the directory specified by OPENCV_SAMPLES_SRC_INSTALL_PATH under a 'python' subfolder, with read-only permissions for owner, group, and world. Users must ensure that OPENCV_SAMPLES_SRC_INSTALL_PATH is set in the parent CMake configuration and that CMake has access to the correct permissions and paths. The snippet is intended to be included in a larger CMake build script and assumes that Python example scripts are available in the current directory. If INSTALL_PYTHON_EXAMPLES is not set, no action is taken.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/python/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if(INSTALL_PYTHON_EXAMPLES)
  file(GLOB install_list *.py )
  install(FILES ${install_list}
          DESTINATION ${OPENCV_SAMPLES_SRC_INSTALL_PATH}/python
          PERMISSIONS OWNER_READ GROUP_READ WORLD_READ COMPONENT samples)
endif()
```

----------------------------------------

TITLE: Configuring and Initializing CMake Project for OpenCV JNI Shared Library - CMake
DESCRIPTION: This snippet configures a CMake project intended to package an OpenCV JNI shared library by setting a minimum CMake version, declaring the project name, and creating a dummy static library target. It relies on 'dummy.cpp' as a placeholder source file to ensure the build integrates the required 'libc++_shared.so' dependency into the final package. No external dependencies are needed beyond a compatible CMake installation and the presence of 'dummy.cpp' in the project's root directory. Output is a dummy static library target for dependency inclusion.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/libcxx_helper/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.6)

project(opencv_jni_shared)

# dummy target to bring libc++_shared.so into packages
add_library(opencv_jni_shared STATIC dummy.cpp)
```

----------------------------------------

TITLE: Enabling FastCV in OpenCV Android Build Configuration (Python)
DESCRIPTION: This Python configuration snippet demonstrates how to enable FastCV support within the OpenCV Android build system. It modifies the `opencv/platforms/android/default.config.py` file by adding the `WITH_FASTCV='ON'` flag to the `cmake_vars` dictionary for the `arm64-v8a` Application Binary Interface (ABI), targeting API level 24. This step ensures that the CMake build process includes the FastCV Hardware Abstraction Layer (HAL) and/or extensions when compiling OpenCV for compatible Android devices.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_0

LANGUAGE: python
CODE:
```
 ABI("3", "arm64-v8a", None, 24, cmake_vars=dict(WITH_FASTCV='ON')),
```

----------------------------------------

TITLE: Setting Cache and Configuration Variables for DOT Usage in CMake
DESCRIPTION: Sets CMake cache variables (`OPENCV_DOCS_DOT_PATH`, `OPENCV_DOCS_HAVE_DOT`) based on the detected DOT executable status, allowing users to override the path or enable/disable DOT usage. It also sets corresponding internal CMake variables (`CMAKECONFIG_DOT_PATH`, `CMAKECONFIG_HAVE_DOT`) used for configuring the Doxyfile template.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_11

LANGUAGE: cmake
CODE:
```
set(OPENCV_DOCS_DOT_PATH "${init_dot_path}" CACHE PATH "Doxygen/DOT_PATH value")
set(OPENCV_DOCS_HAVE_DOT "${init_dot_mode}" CACHE BOOL "Doxygen: build extra diagrams")
set(CMAKECONFIG_DOT_PATH "${OPENCV_DOCS_DOT_PATH}")
set(CMAKECONFIG_HAVE_DOT "${OPENCV_DOCS_HAVE_DOT}")
```

----------------------------------------

TITLE: Configuring Framework Dependencies and Protocol Buffer Handling - CMake
DESCRIPTION: Sets up detection and code generation for Protobuf-based frameworks (Caffe, TensorFlow, ONNX). Conditionally generates protocol buffer source/header files or uses pre-generated files depending on the PROTOBUF_UPDATE_FILES variable. Also sets include directories for each framework. Requires Protobuf, its discovery, and available source files. Outputs are lists of generated or prebuilt source/header files and include paths.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_14

LANGUAGE: CMake
CODE:
```
if(HAVE_PROTOBUF)
  ocv_target_compile_definitions(${the_module} PRIVATE "HAVE_PROTOBUF=1")

  if(PROTOBUF_UPDATE_FILES)
    file(GLOB proto_files "${CMAKE_CURRENT_LIST_DIR}/src/tensorflow/*.proto" "${CMAKE_CURRENT_LIST_DIR}/src/caffe/opencv-caffe.proto" "${CMAKE_CURRENT_LIST_DIR}/src/onnx/opencv-onnx.proto")
    set(PROTOBUF_GENERATE_CPP_APPEND_PATH ON) # required for tensorflow
    protobuf_generate_cpp(fw_srcs fw_hdrs ${proto_files})
  else()
    file(GLOB fw_srcs "${CMAKE_CURRENT_LIST_DIR}/misc/tensorflow/*.cc" "${CMAKE_CURRENT_LIST_DIR}/misc/caffe/opencv-caffe.pb.cc" "${CMAKE_CURRENT_LIST_DIR}/misc/onnx/opencv-onnx.pb.cc")
    file(GLOB fw_hdrs "${CMAKE_CURRENT_LIST_DIR}/misc/tensorflow/*.h" "${CMAKE_CURRENT_LIST_DIR}/misc/caffe/opencv-caffe.pb.h" "${CMAKE_CURRENT_LIST_DIR}/misc/onnx/opencv-onnx.pb.h")
    set(fw_inc "${CMAKE_CURRENT_LIST_DIR}/misc/caffe" "${CMAKE_CURRENT_LIST_DIR}/misc/tensorflow" "${CMAKE_CURRENT_LIST_DIR}/misc/onnx")
  endif()
endif()
```

----------------------------------------

TITLE: Building OpenCV with Verbose Output
DESCRIPTION: Command to build OpenCV using make with verbose output, showing detailed compilation steps for each unit.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_8

LANGUAGE: bash
CODE:
```
$ make -j6 VERBOSE=1
```

----------------------------------------

TITLE: Initializing JPEG Compression Object with libjpeg in C
DESCRIPTION: This C code demonstrates how to set up and initialize the JPEG compression object (struct jpeg_compress_struct) and associated error handler (struct jpeg_error_mgr) using the libjpeg library. The error manager is initialized first and then linked with the compression object, followed by a call to jpeg_create_compress() to allocate necessary structures. Dependencies include the libjpeg headers and linking against the libjpeg library. Key parameters include the pointer relationships between the compression info structure and the error handler. This initialization is required before performing any compression operations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_2

LANGUAGE: C
CODE:
```
struct jpeg_compress_struct cinfo;
struct jpeg_error_mgr jerr;
...
cinfo.err = jpeg_std_error(&jerr);
jpeg_create_compress(&cinfo);
```

----------------------------------------

TITLE: Configuring OpenCV.js Performance Tests in CMake
DESCRIPTION: Sets up custom commands and targets for copying and preparing performance test files for OpenCV.js.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
set(opencv_perf_js_bin_dir "${EXECUTABLE_OUTPUT_PATH}/perf")
set(perf_dir ${CMAKE_CURRENT_SOURCE_DIR}/perf)

set(opencv_perf_js_file_deps "")

file(MAKE_DIRECTORY "${opencv_perf_js_bin_dir}")

file(GLOB_RECURSE perf_files RELATIVE "${perf_dir}" "${perf_dir}/*")
foreach(f ${perf_files})
  add_custom_command(OUTPUT "${opencv_perf_js_bin_dir}/${f}"
                     COMMAND ${CMAKE_COMMAND} -E copy_if_different "${perf_dir}/${f}" "${opencv_perf_js_bin_dir}/${f}"
                     DEPENDS "${perf_dir}/${f}"
                     COMMENT "Copying ${f}"
                    )
  list(APPEND opencv_perf_js_file_deps "${perf_dir}/${f}" "${opencv_perf_js_bin_dir}/${f}")
endforeach()

add_custom_target(${PROJECT_NAME}_perf
                  DEPENDS ${OCV_JS_PATH} ${opencv_perf_js_file_deps})
```

----------------------------------------

TITLE: Conditionally Disabling OpenCV Java Module in CMake
DESCRIPTION: This CMake code block defines conditions under which the `opencv_java` module should be disabled. It checks for specific target platforms (Apple Framework, WinRT), the absence of default Python, missing build tools (Ant, Java for non-Gradle Android), unavailable JNI support (or old Android NDK), or if the unified `opencv_world` module is being built. If any of these conditions are true, the `ocv_module_disable(java)` command prevents the Java module from being built.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(APPLE_FRAMEWORK OR WINRT
    OR NOT PYTHON_DEFAULT_AVAILABLE
    OR NOT (ANT_EXECUTABLE OR Java_FOUND OR ANDROID_PROJECTS_BUILD_TYPE STREQUAL "GRADLE")
    OR NOT (JNI_FOUND OR (ANDROID AND (NOT DEFINED ANDROID_NATIVE_API_LEVEL OR ANDROID_NATIVE_API_LEVEL GREATER 7)))
    OR BUILD_opencv_world
    )
  ocv_module_disable(java)
endif()
```

----------------------------------------

TITLE: Skipping Scanlines During JPEG Decompression in C using libjpeg
DESCRIPTION: Shows the function signature for `jpeg_skip_scanlines` (and its 12-bit variant `jpeg12_skip_scanlines`) used for partial image decompression. This function allows skipping a specified number of rows (`num_lines`) to efficiently jump to a vertical offset in the image. It has limitations: it does not support suspending data sources or two-pass color quantization. It is most effective when skipping large chunks of rows.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_18

LANGUAGE: C
CODE:
```
jpeg_skip_scanlines(j_decompress_ptr cinfo, JDIMENSION num_lines);
        /* Use jpeg12_skip_scanlines() for 12-bit data precision. */
```

----------------------------------------

TITLE: Configuring Debug Modules and Conditional Dependencies - CMake
DESCRIPTION: This block defines an initially empty debug_modules variable and conditionally appends opencv_highgui to it if debugging is enabled for the calib3d module. It uses a CMake if/list block and evaluates the presence of the DEBUG_opencv_calib3d variable. Key parameter: DEBUG_opencv_calib3d.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/calib3d/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
set(debug_modules "")
if(DEBUG_opencv_calib3d)
  list(APPEND debug_modules opencv_highgui)
endif()
```

----------------------------------------

TITLE: Corner Detection Conditional Logic in OpenCV
DESCRIPTION: Nested conditional structure comparing pixel values against threshold values (c_b and cb) to determine corner points. Uses pointer arithmetic and offset values to check surrounding pixels and branches to either 'is_a_corner' or 'is_not_a_corner' based on the comparison results.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_39

LANGUAGE: C++
CODE:
```
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset5] < c_b)
    if(ptr[offset7] > cb)
      goto is_not_a_corner;
    else
      if(ptr[offset7] < c_b)
        if(ptr[offset2] > cb)
          if(ptr[offset9] > cb)
            goto is_not_a_corner;
          else
            if(ptr[offset9] < c_b)
              if(ptr[offset1] > cb)
                if(ptr[offset6] > cb)
                  goto is_not_a_corner;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset8] < c_b)
                      if(ptr[offset4] < c_b)
                        if(ptr[offset3] < c_b)
                          goto is_a_corner;
                        else
                          if(ptr[offset10] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset10] < c_b)
                          if(ptr[offset11] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset1] < c_b)
                  if(ptr[offset6] > cb)
                    goto is_not_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset8] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset3] < c_b)
                            goto is_a_corner;
                          else
                            if(ptr[offset10] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset10] < c_b)
                            if(ptr[offset11] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset6] > cb)
                    goto is_not_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset8] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset3] < c_b)
                            goto is_a_corner;
                          else
                            if(ptr[offset10] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset10] < c_b)
                            if(ptr[offset11] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
            else
              goto is_not_a_corner;
        else
          if(ptr[offset2] < c_b)
            if(ptr[offset9] > cb)
              if(ptr[offset1] < c_b)
                if(ptr[offset6] > cb)
                  goto is_not_a_corner;
                else
                  if(ptr[offset6] < c_b)
                    if(ptr[offset3] < c_b)
                      if(ptr[offset4] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
              else
                if(ptr[offset1] > cb)
                  if(ptr[offset6] > cb)
                    goto is_not_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset8] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset6] > cb)
                    goto is_not_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset3] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset8] < c_b)
                            goto is_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
            else
              if(ptr[offset9] < c_b)
                if(ptr[offset1] > cb)
                  if(ptr[offset6] > cb)
                    goto is_not_a_corner;
                  else
                    if(ptr[offset6] < c_b)
                      if(ptr[offset8] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset3] < c_b)
                            goto is_a_corner;
                          else
                            if(ptr[offset10] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset10] < c_b)
                            if(ptr[offset11] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset1] < c_b)
                    if(ptr[offset6] > cb)
                      goto is_not_a_corner;
                    else
                      if(ptr[offset6] < c_b)
                        if(ptr[offset4] < c_b)
                          if(ptr[offset3] < c_b)
                            goto is_a_corner;
                          else
                            if(ptr[offset8] < c_b)
                              if(ptr[offset10] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset8] < c_b)
                            if(ptr[offset10] < c_b)
                              if(ptr[offset11] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset6] > cb)
                      goto is_not_a_corner;
                    else
                      if(ptr[offset6] < c_b)
                        if(ptr[offset8] < c_b)
                          if(ptr[offset4] < c_b)
                            if(ptr[offset3] < c_b)
```

----------------------------------------

TITLE: Copying Common Test Files in CMake for OpenCV Java Tests
DESCRIPTION: Copies common test files including resources and utilities to the Java test directory. It uses a custom function 'copy_common_tests' to perform the copy operation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/pure_test/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
copy_common_tests("${CMAKE_CURRENT_SOURCE_DIR}/../common_test" "${OPENCV_JAVA_TEST_DIR}" depends)
```

----------------------------------------

TITLE: Including OpenCV DNN Module Directory in C++
DESCRIPTION: This snippet specifies a directory inclusion with CMake to access necessary headers for the OpenCV DNN module. It ensures that the path to 'layers/layers_common.simd_declarations.hpp' is included during the build process. The inclusion is essential for accessing SIMD declarations which are used for optimizing performance in the DNN module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/misc/plugin/openvino/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: C++
CODE:
```
#include_directories("${OPENCV_MODULE_opencv_dnn_BINARY_DIR}")  // Cannot open include file: 'layers/layers_common.simd_declarations.hpp'
```

----------------------------------------

TITLE: Adding Preprocessor Definition for WebP Support in CMake
DESCRIPTION: Checks if the `HAVE_WEBP` variable is defined (indicating that the WebP library was found and enabled during configuration). If true, it adds the preprocessor definition `-DHAVE_WEBP` using `add_definitions`. This allows conditional compilation of code within highgui that depends on WebP functionality.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
if(HAVE_WEBP)
  add_definitions(-DHAVE_WEBP)
endif()
```

----------------------------------------

TITLE: Installing GUI and Media Dependencies
DESCRIPTION: Installs GTK support, camera support, and media dependencies for OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_3

LANGUAGE: shell
CODE:
```
yum install gtk2-devel
yum install libdc1394-devel
yum install ffmpeg-devel
yum install gstreamer-plugins-base-devel
```

----------------------------------------

TITLE: Configuring JNI Output Path in CMake
DESCRIPTION: Sets the JNI output path based on whether the target platform is Android or not.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jni/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
if(ANDROID)
  ocv_update(JNI_OUTPUT_PATH  "${OpenCV_BINARY_DIR}/jni/${ANDROID_NDK_ABI_NAME}")
else()
  ocv_update(JNI_OUTPUT_PATH  "${LIBRARY_OUTPUT_PATH}")
endif()
```

----------------------------------------

TITLE: Defining WebNN and Other Hardware Backends for DNN Module - CMake
DESCRIPTION: These snippets configure compile definitions to enable WebNN, TimVX, and CANN support if the corresponding options are enabled and available. Each hardware/backend feature is conditionally checked and, if present, a respective compiler definition is set. Inputs are HAVE_WEBNN, HAVE_TIMVX, and HAVE_CANN variables; output is enabling backend-specific code compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: CMake
CODE:
```
if(WITH_WEBNN AND HAVE_WEBNN)
  ocv_target_compile_definitions(${the_module} PRIVATE "HAVE_WEBNN=1")
endif()

if(HAVE_TIMVX)
  ocv_target_compile_definitions(${the_module} PRIVATE "HAVE_TIMVX=1")
endif()

if(HAVE_CANN)
  ocv_target_compile_definitions(${the_module} PRIVATE "HAVE_CANN=1")
endif()
```

----------------------------------------

TITLE: Installing Python 3 Development Packages (Bash)
DESCRIPTION: Installs Python 3 minimal package and the NumPy library. These are prerequisites if the Python 3 wrapper for OpenCV needs to be enabled during the cross-compilation process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_1

LANGUAGE: bash
CODE:
```
sudo apt install -y \
    python3-minimal \
    python3-numpy
```

----------------------------------------

TITLE: Configuring CUDA Compiler Warnings
DESCRIPTION: Disables specific compiler warnings (-Wundef, -Wmissing-declarations, -Wshadow) when CUDA support is enabled.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/photo/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(HAVE_CUDA)
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wundef -Wmissing-declarations -Wshadow)
endif()
```

----------------------------------------

TITLE: Adding Dispatched CPU Implementations for Fluid Backend in CMake
DESCRIPTION: Uses the `ocv_add_dispatched_file` function to register CPU-optimized implementations (using SSE4.1 and AVX2 instruction sets) for specific functions within the G-API Fluid backend (`gfluidimgproc_func` and `gfluidcore_func`). This enables runtime dispatch to the most efficient implementation available on the target CPU.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
ocv_add_dispatched_file(backends/fluid/gfluidimgproc_func SSE4_1 AVX2)
ocv_add_dispatched_file(backends/fluid/gfluidcore_func SSE4_1 AVX2)
```

----------------------------------------

TITLE: Threading Plugins Configuration Option in OpenCV
DESCRIPTION: Defines the PARALLEL_ENABLE_PLUGINS option available since OpenCV 4.5.2 to support dynamically loaded threading backends, requiring separate compilation process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_17

LANGUAGE: markdown
CODE:
```
| Option | Default | Description |
| ------ | ------- | ----------- |
| PARALLEL_ENABLE_PLUGINS | ON | Enable plugin support, if this option is disabled OpenCV will not try to load anything |
```

----------------------------------------

TITLE: Setting Minimum CMake Version and Checking OpenCV Dependencies
DESCRIPTION: This CMake snippet sets the minimum required CMake version to 3.5. It defines a list variable `OPENCV_OPENVX_SAMPLE_REQUIRED_DEPS` containing necessary OpenCV modules (core, imgproc, imgcodecs, videoio, highgui) for the OpenVX samples. It then uses the OpenCV-specific function `ocv_check_dependencies` to verify if these modules are available. If the `BUILD_EXAMPLES` option is disabled or if dependencies are not found (`OCV_DEPENDENCIES_FOUND` is false), the script execution returns early.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/openvx/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.5)

set(OPENCV_OPENVX_SAMPLE_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui)
ocv_check_dependencies(${OPENCV_OPENVX_SAMPLE_REQUIRED_DEPS})

if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()
```

----------------------------------------

TITLE: Building Slow HAL Replacement Library with CMake
DESCRIPTION: This snippet outlines the steps to build a custom HAL replacement library 'slow_hal' using CMake. It guides on creating a build directory and executing the CMake command to compile the library, resulting in a static library 'libslow_hal.a'. The slow_hal library showcases naive C++ implementations for logical operations to intentionally reduce performance, serving as a study for function replacements.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/hal/README.md#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
cmake <opencv-src>/samples/hal/slow_hal
```

LANGUAGE: shell
CODE:
```
make
```

----------------------------------------

TITLE: Selecting DCT Algorithm in libjpeg (C)
DESCRIPTION: A C field of type `J_DCT_METHOD` within the compression parameters structure (`cinfo`). This parameter selects the algorithm used for the Discrete Cosine Transform step in lossy compression. Options include `JDCT_ISLOW` (accurate integer), `JDCT_IFAST` (faster, less accurate integer), `JDCT_FLOAT` (floating-point, legacy), `JDCT_DEFAULT`, and `JDCT_FASTEST`. The choice impacts compression speed and quality, particularly at high quality settings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_32

LANGUAGE: C
CODE:
```
J_DCT_METHOD dct_method
```

----------------------------------------

TITLE: Setting YCbCr Component Sampling Factors for Raw Data - libjpeg - C
DESCRIPTION: Demonstrates how to set the horizontal and vertical sampling factors for each color component in YCbCr JPEG encoding when supplying raw (downsampled) image data. Proper values ensure compatibility between input buffers and JPEG encoding pipeline, and are required for applications bypassing automatic downsampling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_64

LANGUAGE: c
CODE:
```
cinfo->comp_info[0].h_samp_factor = 2;           // for Y
cinfo->comp_info[0].v_samp_factor = 2;
cinfo->comp_info[1].h_samp_factor = 1;           // for Cb
cinfo->comp_info[1].v_samp_factor = 1;
cinfo->comp_info[2].h_samp_factor = 1;           // for Cr
cinfo->comp_info[2].v_samp_factor = 1;
```

----------------------------------------

TITLE: Creating Built-in DNN Plugin with OpenCV in C++
DESCRIPTION: This snippet creates a built-in DNN plugin using OpenCV's custom plugin system. It integrates OpenVINO with the OpenCV DNN module, allowing enhanced inference capabilities. The function 'ocv_create_builtin_dnn_plugin' requires OpenCV DNN and OpenVINO to be linked as dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/misc/plugin/openvino/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: C++
CODE:
```
ocv_create_builtin_dnn_plugin(opencv_dnn_openvino ocv.3rdparty.openvino ${dnn_plugin_srcs})
```

----------------------------------------

TITLE: Running All WebAssembly Intrinsic Tests in OpenCV.js - JavaScript
DESCRIPTION: This JavaScript snippet runs all WebAssembly intrinsic (HAL) tests in the OpenCV.js environment. Depends on 'cv' being loaded and initialized in context. Outputs test results to the debug console. Use to comprehensively test all supported WebAssembly intrinsics.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_19

LANGUAGE: js
CODE:
```
cv.test_hal_intrin_all()
```

----------------------------------------

TITLE: Disabling CUDA-related Warnings in CMake
DESCRIPTION: Disables specific compiler warnings related to CUDA if CUDA support is enabled. This helps to reduce noise during the build process for CUDA-enabled builds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/stitching/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
if(HAVE_CUDA)
  ocv_warnings_disable(CMAKE_CXX_FLAGS -Wundef -Wmissing-declarations -Wshadow -Wstrict-aliasing)
endif()
```

----------------------------------------

TITLE: Setting Up Intel Samples in OpenCV with CMake
DESCRIPTION: The CMake script starts by configuring an example project using the `ocv_install_example_src` function to specify the source files. It ensures required dependencies (such as `opencv_core`, `opencv_imgproc`, etc.) are found before defining the project `va_intel_samples`. It includes necessary modules and sets up sample targets, linking them with specified libraries. The script uses conditional logic to exit early if examples or dependencies are not available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/va_intel/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
ocv_install_example_src(opencl *.cpp *.inc CMakeLists.txt)

set(OPENCV_VA_INTEL_SAMPLES_REQUIRED_DEPS
  opencv_core
  opencv_imgproc
  opencv_imgcodecs
  opencv_videoio
  opencv_highgui)
ocv_check_dependencies(${OPENCV_VA_INTEL_SAMPLES_REQUIRED_DEPS})

if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()

project(va_intel_samples)
ocv_include_modules_recurse(${OPENCV_VA_INTEL_SAMPLES_REQUIRED_DEPS})
file(GLOB all_samples RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} *.cpp)
foreach(sample_filename ${all_samples})
  ocv_define_sample(tgt ${sample_filename} va_intel)
  ocv_target_link_libraries(${tgt} PRIVATE ${OPENCV_LINKER_LIBS} ${OPENCV_VA_INTEL_SAMPLES_REQUIRED_DEPS} ${VA_LIBRARIES})
endforeach()

```

----------------------------------------

TITLE: Linking LAPACK Libraries to calib3d Target - CMake
DESCRIPTION: This snippet links LAPACK libraries to the module target, using variables to represent the module and LAPACK dependency list. Proper use requires the_module and LAPACK_LIBRARIES to be defined in the build context. This ensures the calib3d module has access to linear algebra and numerical computation routines.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/calib3d/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
ocv_target_link_libraries(${the_module} ${LAPACK_LIBRARIES})
```

----------------------------------------

TITLE: Generating OpenCV for Windows Store 8.1 ARM using CMake
DESCRIPTION: Invokes CMake directly to generate Visual Studio 2013 project files for OpenCV targeting Windows Store 8.1 on the ARM architecture. Specifies the ARM-specific generator, system name (WindowsStore), and system version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013 ARM" -DCMAKE_SYSTEM_NAME=WindowsStore -DCMAKE_SYSTEM_VERSION=8.1 <path-to-source>
```

----------------------------------------

TITLE: Generating Windows Store 8.1 x64 Configuration for Testing
DESCRIPTION: Executes the `setup_winrt.bat` script specifically to generate the Visual Studio project files needed for building and testing OpenCV for Windows Store 8.1 on the x64 architecture. This is presented as a step in the test setup process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_14

LANGUAGE: batch
CODE:
```
setup_winrt.bat "WS" "8.1" "x64"
```

----------------------------------------

TITLE: Configuring OpenCV Android Camera Preview Example
DESCRIPTION: CMake configuration that sets up an Android camera preview example project. It creates a project variable, adds an Android project with OpenCV library dependencies, and establishes build dependencies if the target exists.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-1-camerapreview/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(sample example-tutorial-1-camerapreview)

add_android_project(${sample} "${CMAKE_CURRENT_SOURCE_DIR}" LIBRARY_DEPS "${OPENCV_ANDROID_LIB_DIR}" SDK_TARGET 11 "${ANDROID_SDK_TARGET}")
if(TARGET ${sample})
  add_dependencies(opencv_android_examples ${sample})
endif()
```

----------------------------------------

TITLE: Executing the OpenCV Video Writing Example (Bash)
DESCRIPTION: Shows an example command line execution of the video writing program compiled from the C++ source. It specifies the input video file (`video/Megamind.avi`), the channel to extract ('R' for Red), and indicates ('Y') that the user should be prompted to select a video codec at runtime.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/video_write.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
video-write.exe video/Megamind.avi R Y
```

----------------------------------------

TITLE: Configuring and Building OpenCV GStreamer VideoIO Plugin (CMake)
DESCRIPTION: This CMake script sets the minimum required version (3.5), locates the main OpenCV source directory relative to the current file, and includes a common OpenCV plugin helper CMake file (`OpenCVPluginStandalone.cmake`). It explicitly enables GStreamer support, includes video I/O initialization logic, defines the plugin's dependencies on OpenCV modules (core, imgproc, imgcodecs), and uses the custom `ocv_create_plugin` macro to define the `opencv_videoio_gstreamer` plugin based on the source file `src/cap_gstreamer.cpp`. Finally, it prints a status message indicating the detected GStreamer version being used.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/misc/plugin_gstreamer/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.5)

get_filename_component(OpenCV_SOURCE_DIR "${CMAKE_CURRENT_LIST_DIR}/../../../.." ABSOLUTE)
include("${OpenCV_SOURCE_DIR}/cmake/OpenCVPluginStandalone.cmake")

# scan dependencies
set(WITH_GSTREAMER ON)
include("${OpenCV_SOURCE_DIR}/modules/videoio/cmake/init.cmake")

set(OPENCV_PLUGIN_DEPS core imgproc imgcodecs)
ocv_create_plugin(videoio "opencv_videoio_gstreamer" "ocv.3rdparty.gstreamer" "GStreamer" "src/cap_gstreamer.cpp")

message(STATUS "Using GStreamer: ${GSTREAMER_VERSION}")
```

----------------------------------------

TITLE: Configuring Android Test Module Files in CMake
DESCRIPTION: Copies and configures specific files for the Android test module, including the AndroidManifest.xml and build.gradle files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/android_test/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
file(COPY "${CMAKE_CURRENT_SOURCE_DIR}/tests_module/AndroidManifest.xml" DESTINATION "${OPENCV_ANDROID_TEST_DIR}/tests_module")
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/tests_module/build.gradle.in" "${OPENCV_ANDROID_TEST_DIR}/tests_module/build.gradle" @ONLY)
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/build.gradle.in" "${OPENCV_ANDROID_TEST_DIR}/build.gradle" @ONLY)
```

----------------------------------------

TITLE: Architecture Detection for macOS
DESCRIPTION: Determines the target architecture on macOS systems by checking CMAKE_OSX_ARCHITECTURES or falling back to CMAKE_SYSTEM_PROCESSOR.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libpng/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(APPLE AND CMAKE_OSX_ARCHITECTURES)
  set(TARGET_ARCH ${CMAKE_OSX_ARCHITECTURES})
else()
  set(TARGET_ARCH ${CMAKE_SYSTEM_PROCESSOR})
endif()
```

----------------------------------------

TITLE: Building Modules Configuration JSON for Objective-C Bindings in CMake
DESCRIPTION: Creates a JSON configuration with information about OpenCV modules to be wrapped in Objective-C. This includes each module's name and relative location in the source tree, which is used by the generator script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/generator/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
# This file is included from a subdirectory
set(OBJC_SOURCE_DIR "${CMAKE_CURRENT_SOURCE_DIR}/..")
include(${OBJC_SOURCE_DIR}/common.cmake)  # fill OPENCV_OBJC_MODULES

# common files
file(GLOB_RECURSE deps "${CMAKE_CURRENT_SOURCE_DIR}/templates/*")

set(__modules_config "") # list of OpenCV modules
foreach(m ${OPENCV_OBJC_MODULES})
  set(module_objc_dir "${OPENCV_MODULE_${m}_LOCATION}/misc/objc")
  list(APPEND deps ${OPENCV_MODULE_${m}_HEADERS})
  file(GLOB_RECURSE misc_files "${module_objc_dir}/*")
  list(APPEND deps ${misc_files})

  string(REGEX REPLACE "^opencv_" "" m_ "${m}")
  if(__modules_config)
    set(__modules_config "${__modules_config},\n")
  endif()
  file(RELATIVE_PATH rel_path "${OpenCV_SOURCE_DIR}" "${OPENCV_MODULE_${m}_LOCATION}")
  set(__modules_config "${__modules_config}    { \"name\": \"${m_}\", \"location\": \"${rel_path}\" }")
endforeach(m)
```

----------------------------------------

TITLE: Selecting Default JPEG Colorspace (C)
DESCRIPTION: This function selects an appropriate JPEG colorspace based on the input color space and calls jpeg_set_colorspace(). It's a subroutine of jpeg_set_defaults().
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_22

LANGUAGE: C
CODE:
```
jpeg_default_colorspace (j_compress_ptr cinfo)
```

----------------------------------------

TITLE: Conditionally Including JNI Generator Subdirectory in CMake
DESCRIPTION: This snippet checks if CMake is performing its initial configuration pass using the `OPENCV_INITIAL_PASS` variable. If it is the initial pass, it includes the `generator` subdirectory, which is responsible for generating JNI/JAR source code and documentation signatures for the OpenCV Java bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
if(OPENCV_INITIAL_PASS)
  # generator for JNI/JAR source code and documentation signatures
  add_subdirectory(generator)
endif()
```

----------------------------------------

TITLE: Overriding Message Output in JPEG Library (C)
DESCRIPTION: Defines the `output_message` function signature, a method within the `jpeg_error_mgr` struct. This function handles the actual output of any JPEG message (fatal errors, warnings, traces). It receives a pointer to the JPEG object (`j_common_ptr`). Override this method to redirect messages from the default `stderr` to a custom destination like a log file or UI element. This function only handles *sending* the message, not formatting it.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_45

LANGUAGE: c
CODE:
```
output_message (j_common_ptr cinfo)
```

----------------------------------------

TITLE: Checking OpenCV Version with CMake
DESCRIPTION: The code snippet demonstrates how to use the OpenCV_VERSION variable in CMake to differentiate configurations for OpenCV version 2.4 and 3.x. If the version is less than 3.0, the script configures the project to use version 2.4 modules; otherwise, it configures the project to use version 3.x modules. This setup requires CMake and an environment where OpenCV_VERSION is defined.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/transition_guide/transition_guide.markdown#2025-04-22_snippet_8

LANGUAGE: cmake
CODE:
```
if(OpenCV_VERSION VERSION_LESS "3.0")
# use 2.4 modules
else()
# use 3.x modules
endif()
```

----------------------------------------

TITLE: Installing Emscripten SDK - Bash
DESCRIPTION: Installs and activates the latest Emscripten SDK in a Unix-like environment. These commands update the SDK, install the most recent version, and set it as active. Dependency: The Emscripten SDK (downloaded from emscripten.org) must be present. No parameters are needed. Outputs the installed SDK to be used for compiling to WebAssembly. Ensure you run these commands inside the EMSDK root directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
./emsdk update\n./emsdk install latest\n./emsdk activate latest
```

----------------------------------------

TITLE: Initializing a C++ CMake Project
DESCRIPTION: Sets the minimum required CMake version to 3.6. Defines a variable `target` with the value `mixed_sample` and initializes a C++ project (`CXX`) with this name.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/android/tutorial-2-mixedprocessing/jni/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
cmake_minimum_required(VERSION 3.6)

set(target mixed_sample)
project(${target} CXX)
```

----------------------------------------

TITLE: Setting Up Python Virtual Environment
DESCRIPTION: This console code snippet demonstrates setting up a Python 3.7+ virtual environment using virtualenv. It is essential for installing and managing dependencies for the OpenCV and PyTorch integration tutorial.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_classification/pytorch_cls_model_conversion_tutorial.md#2025-04-22_snippet_0

LANGUAGE: console
CODE:
```
virtualenv -p /usr/bin/python3.7 <env_dir_path>
source <env_dir_path>/bin/activate
```

----------------------------------------

TITLE: Corner Detection Conditional Logic - C++
DESCRIPTION: Complex nested conditional structure for determining corner pixels by comparing neighboring pixel values using pointer arithmetic. The code uses goto statements to jump to either 'is_a_corner' or 'is_not_a_corner' based on various threshold comparisons.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_36

LANGUAGE: cpp
CODE:
```
else
  goto is_not_a_corner;
else
  if(ptr[offset2] < c_b)
    if(ptr[offset7] > cb)
      if(ptr[offset9] > cb)
        if(ptr[offset1] > cb)
          goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset6] > cb)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  if(ptr[offset10] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
```

----------------------------------------

TITLE: Configuring Android Library Build System using CMake
DESCRIPTION: This snippet sets up the necessary environment and configuration for building an OpenCV library for Android. It manages file removal and creation, establishes source directories, and applies Gradle configurations if not using an Android executable. The setup includes flexibly handling SDK versioning and configurations for publishing through Maven.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
project(${the_module}_android)

if(ANDROID_EXECUTABLE)
  set(OPENCV_JAVA_DIR "${OpenCV_BINARY_DIR}/android_sdk" CACHE INTERNAL "")
else()  # gradle
  set(OPENCV_JAVA_DIR "${ANDROID_BUILD_BASE_DIR}/opencv" CACHE INTERNAL "")
endif()
set(OPENCV_ANDROID_LIB_DIR "${OPENCV_JAVA_DIR}" CACHE INTERNAL "")  # for OpenCV samples

file(REMOVE_RECURSE "${OPENCV_JAVA_DIR}")
file(MAKE_DIRECTORY "${OPENCV_JAVA_DIR}/bin")
set(java_src_dir "${OPENCV_JAVA_DIR}/src")
file(MAKE_DIRECTORY "${java_src_dir}")

ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/java" "${java_src_dir}")

set(SOURSE_SETS_JNI_LIBS_SRC_DIRS "'native/libs'")
set(SOURSE_SETS_JAVA_SRC_DIRS "'java/src'")
set(SOURSE_SETS_RES_SRC_DIRS "'java/res'")
set(SOURSE_SETS_MANIFEST_SRC_FILE "'java/AndroidManifest.xml'")
set(BUILD_GRADLE_COMPILE_OPTIONS "
    android {
        buildFeatures {
            buildConfig true
        }
    }
    compileOptions {
        sourceCompatibility JavaVersion.VERSION_${ANDROID_GRADLE_JAVA_VERSION_INIT}
        targetCompatibility JavaVersion.VERSION_${ANDROID_GRADLE_JAVA_VERSION_INIT}
    }
")
set(MAVEN_PUBLISH_PLUGIN_DECLARATION "apply plugin: 'maven-publish'")
set(BUILD_GRADLE_ANDROID_PUBLISHING_CONFIG "
    buildFeatures {
        prefabPublishing true
        buildConfig true
    }

    prefab {
        opencv_jni_shared {
            headers 'native/jni/include'
        }
    }

    publishing {
        singleVariant('release') {
            withSourcesJar()
            withJavadocJar()
        }
    }
")

set(BUILD_GRADLE_PUBLISHING_CONFIG "
publishing {
    publications {
        release(MavenPublication) {
            groupId = 'org.opencv'
            artifactId = 'opencv'
            version = '${OPENCV_VERSION_PLAIN}'

            afterEvaluate {
               from components.release
           }
        }
    }
    repositories {
        maven {
            name = 'myrepo'
            url = "\${project.buildDir}/repo"
        }
    }
}
")

if(ANDROID_EXECUTABLE)

ocv_assert(ANDROID_TOOLS_Pkg_Revision GREATER 13)

ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/android/java" "${java_src_dir}")

# calc default SDK Target
android_get_compatible_target(ANDROID_SDK_COMPATIBLE_TARGET ${ANDROID_NATIVE_API_LEVEL} ${ANDROID_SDK_TARGET} 14)
if(ANDROID_SDK_COMPATIBLE_TARGET)
  set(ANDROID_SDK_COMPATIBLE_TARGET "${ANDROID_SDK_COMPATIBLE_TARGET}" CACHE INTERNAL "")
endif()
string(REGEX REPLACE "android-" "" android_sdk_target_num ${ANDROID_SDK_COMPATIBLE_TARGET})

if( (ANDROID_SDK_TARGET AND ANDROID_SDK_TARGET LESS 21) OR (android_sdk_target_num LESS 21) )
  message(STATUS "[OpenCV for Android SDK]: A new OpenGL Camera Bridge (CameraGLSurfaceView, CameraGLRendererBase, CameraRenderer, Camera2Renderer) is disabled, because ANDROID_SDK_TARGET (${android_sdk_target_num}) < 21")
else()
  ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/android-21/java" "${java_src_dir}")
endif()

if( (ANDROID_SDK_TARGET AND ANDROID_SDK_TARGET LESS 24) OR (android_sdk_target_num LESS 24) )
  message(STATUS "[OpenCV for Android SDK]: An experiemntal Native Camera is disabled, because ANDROID_SDK_TARGET (${android_sdk_target_num}) < 24")
else()
  ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/android-24/java" "${java_src_dir}")
endif()

# copy boilerplate
file(GLOB_RECURSE seed_project_files_rel RELATIVE "${CMAKE_CURRENT_SOURCE_DIR}/android_lib/" "${CMAKE_CURRENT_SOURCE_DIR}/android_lib/*")
list(REMOVE_ITEM seed_project_files_rel "${ANDROID_MANIFEST_FILE}")
foreach(file ${seed_project_files_rel})
  configure_file("${CMAKE_CURRENT_SOURCE_DIR}/android_lib/${file}" "${OPENCV_JAVA_DIR}/${file}" @ONLY)
  list(APPEND depends "${CMAKE_CURRENT_SOURCE_DIR}/android_lib/${file}")
  get_filename_component(install_subdir "${file}" PATH)
  install(FILES "${OPENCV_JAVA_DIR}/${file}" DESTINATION "${JAVA_INSTALL_ROOT}/${install_subdir}" COMPONENT java)
endforeach()

list(APPEND depends gen_opencv_java_source "${OPENCV_DEPHELPER}/gen_opencv_java_source")
ocv_copyfiles_add_target(${the_module}_android_source_copy JAVA_SRC_COPY "Copy Java(Android SDK) source files" ${depends})
file(REMOVE "${OPENCV_DEPHELPER}/${the_module}_android_source_copy")  # force rebuild after CMake run

set(depends ${the_module}_android_source_copy "${OPENCV_DEPHELPER}/${the_module}_android_source_copy")

# generate Android library project
set(android_sdk_project_files ${ANDROID_LIB_PROJECT_FILES})  # build.xml;local.properties;proguard-project.txt;project.properties
ocv_list_add_prefix(android_sdk_project_files "${OPENCV_JAVA_DIR}/")

configure_file("${CMAKE_CURRENT_SOURCE_DIR}/android_lib/${ANDROID_MANIFEST_FILE}" "${CMAKE_CURRENT_BINARY_DIR}/${ANDROID_MANIFEST_FILE}" @ONLY)

add_custom_command(
    OUTPUT ${android_sdk_project_files} "${OPENCV_JAVA_DIR}/${ANDROID_MANIFEST_FILE}"
    COMMAND ${CMAKE_COMMAND} -E remove ${android_sdk_project_files}
    COMMAND ${CMAKE_COMMAND} -E copy_if_different "${CMAKE_CURRENT_BINARY_DIR}/${ANDROID_MANIFEST_FILE}" "${OPENCV_JAVA_DIR}/${ANDROID_MANIFEST_FILE}"
    COMMAND ${ANDROID_EXECUTABLE} --silent create lib-project --path "${OPENCV_JAVA_DIR}" --target "${ANDROID_SDK_COMPATIBLE_TARGET}" --name OpenCV --package org.opencv 2>"${CMAKE_CURRENT_BINARY_DIR}/create_lib_project.log"
    COMMAND ${CMAKE_COMMAND} -E copy_if_different "${CMAKE_CURRENT_BINARY_DIR}/${ANDROID_MANIFEST_FILE}" "${OPENCV_JAVA_DIR}/${ANDROID_MANIFEST_FILE}"
    WORKING_DIRECTORY "${OPENCV_JAVA_DIR}"
    MAIN_DEPENDENCY "${CMAKE_CURRENT_BINARY_DIR}/${ANDROID_MANIFEST_FILE}"
    DEPENDS ${depends}
    COMMENT "Generating OpenCV Android library project. SDK target: ${lib_target_sdk_target}"
)
list(APPEND depends ${android_sdk_project_files} "${OPENCV_JAVA_DIR}/${ANDROID_MANIFEST_FILE}")

install(DIRECTORY "${OPENCV_JAVA_DIR}/src" DESTINATION "${JAVA_INSTALL_ROOT}" COMPONENT java)
install(FILES "${OPENCV_JAVA_DIR}/${ANDROID_PROJECT_PROPERTIES_FILE}" DESTINATION ${JAVA_INSTALL_ROOT} COMPONENT java)
install(FILES "${OPENCV_JAVA_DIR}/${ANDROID_MANIFEST_FILE}" DESTINATION ${JAVA_INSTALL_ROOT} COMPONENT java)

# build jar
set(JAR_FILE "${OpenCV_BINARY_DIR}/bin/classes.jar")
# build the library project
# normally we should do this after a native part, but for a library project we can build the java part first
add_custom_command(
    OUTPUT "${JAR_FILE}" "${OPENCV_DEPHELPER}/${the_module}_android"
    COMMAND ${ANT_EXECUTABLE} -q -noinput -k debug -Djava.target=1.6 -Djava.source=1.6
    COMMAND ${CMAKE_COMMAND} -E touch "${OPENCV_DEPHELPER}/${the_module}_android"
    WORKING_DIRECTORY "${OPENCV_JAVA_DIR}"
    DEPENDS ${depends}
    COMMENT "Building OpenCV Android library project"
)

add_custom_target(${the_module}_android DEPENDS "${OPENCV_DEPHELPER}/${the_module}_android" SOURCES "${CMAKE_CURRENT_SOURCE_DIR}/android_lib/${ANDROID_MANIFEST_FILE}")
add_dependencies(${the_module} ${the_module}_android)

# empty 'gen' and 'res' folders
install(CODE "
FILE(MAKE_DIRECTORY \"\$ENV{DESTDIR}\${CMAKE_INSTALL_PREFIX}/${JAVA_INSTALL_ROOT}/gen\")
FILE(MAKE_DIRECTORY \"\$ENV{DESTDIR}\${CMAKE_INSTALL_PREFIX}/${JAVA_INSTALL_ROOT}/res\")
" COMPONENT java)

ocv_update(ANDROID_COMPILE_SDK_VERSION "27")
ocv_update(ANDROID_MIN_SDK_VERSION "14")
if(ANDROID_NATIVE_API_LEVEL GREATER 21)
  ocv_update(ANDROID_TARGET_SDK_VERSION "${ANDROID_NATIVE_API_LEVEL}")
else()
  ocv_update(ANDROID_TARGET_SDK_VERSION "21")
endif()

configure_file("${CMAKE_CURRENT_SOURCE_DIR}/build.gradle.in" "${CMAKE_CURRENT_BINARY_DIR}/build.gradle" @ONLY)
install(FILES "${CMAKE_CURRENT_BINARY_DIR}/build.gradle" DESTINATION ${JAVA_INSTALL_ROOT}/.. COMPONENT java)

else()  # gradle build
#
# Android Gradle-based project
#

configure_file("${CMAKE_CURRENT_SOURCE_DIR}/build.gradle.in" "${ANDROID_TMP_INSTALL_BASE_DIR}/opencv/build.gradle" @ONLY)

#TODO: INSTALL ONLY
ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/android/java" "${java_src_dir}")
ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/android-21/java" "${java_src_dir}")
ocv_copyfiles_append_dir(JAVA_SRC_COPY "${OPENCV_JAVA_BINDINGS_DIR}/gen/android-24/java" "${java_src_dir}")

# copy boilerplate
set(SOURSE_SETS_JNI_LIBS_SRC_DIRS "'../../jni'")
set(SOURSE_SETS_JAVA_SRC_DIRS "'src'")
set(SOURSE_SETS_RES_SRC_DIRS "'${OpenCV_SOURCE_DIR}/modules/java/android_sdk/android_gradle_lib/res'")
set(SOURSE_SETS_MANIFEST_SRC_FILE "'AndroidManifest.xml'")
set(MAVEN_PUBLISH_PLUGIN_DECLARATION "")
set(BUILD_GRADLE_ANDROID_PUBLISHING_CONFIG "")
set(BUILD_GRADLE_PUBLISHING_CONFIG "")

set(__base_dir "${CMAKE_CURRENT_SOURCE_DIR}/android_gradle_lib/")
file(GLOB_RECURSE seed_project_files_rel RELATIVE "${__base_dir}/" "${__base_dir}/*")
list(REMOVE_ITEM seed_project_files_rel "${ANDROID_MANIFEST_FILE}")
foreach(file ${seed_project_files_rel})
  configure_file("${__base_dir}/${file}" "${OPENCV_JAVA_DIR}/${file}" @ONLY)
  list(APPEND depends "${__base_dir}/${file}")
  get_filename_component(install_subdir "${file}" PATH)
  if(NOT file STREQUAL "build.gradle")
    install(FILES "${OPENCV_JAVA_DIR}/${file}" DESTINATION "${JAVA_INSTALL_ROOT}/${install_subdir}" COMPONENT java)
  endif()
endforeach()
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/build.gradle.in" "${OPENCV_JAVA_DIR}/build.gradle" @ONLY)
```

----------------------------------------

TITLE: Including Required OpenCV Modules Recursively in CMake
DESCRIPTION: Uses the custom `ocv_include_modules_recurse` CMake function to include necessary headers and potentially other build settings for all modules listed in the `OPENCV_CUDA_SAMPLES_REQUIRED_DEPS` variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
ocv_include_modules_recurse(${OPENCV_CUDA_SAMPLES_REQUIRED_DEPS})
```

----------------------------------------

TITLE: Setting JFIF Resolution Information in libjpeg (C)
DESCRIPTION: C fields within the compression parameters structure (`cinfo`) used to specify pixel density information in the JFIF marker. `density_unit` indicates the units (0=unknown, 1=dots/inch, 2=dots/cm), while `X_density` and `Y_density` (both `UINT16`) provide the horizontal and vertical densities. Default values are 0, 1, 1, signifying square pixels of unknown size.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_40

LANGUAGE: C
CODE:
```
UINT8 density_unit
```

LANGUAGE: C
CODE:
```
UINT16 X_density
```

LANGUAGE: C
CODE:
```
UINT16 Y_density
```

----------------------------------------

TITLE: Configuring and Building an OpenCV Highgui GTK Plugin - CMake
DESCRIPTION: This CMake snippet configures the build process for the opencv_highgui_gtk plugin, scanning for GTK dependencies, verifying their availability, and setting up conditional OpenGL integration. It uses custom OpenCV CMake includes and macros to manage features, handle versioned GTK dependencies, and ensure that the correct components are included for successful compilation. Dependencies include OpenCV modules (core, imgproc, imgcodecs) and third-party GTK libraries, with input parameters such as HAVE_GTK, WITH_GTK, and WITH_OPENGL determining build features. Output is the plugin target; missing dependencies or incorrect setup will terminate the build with informative error messages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/misc/plugins/plugin_gtk/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
cmake_minimum_required(VERSION 3.5)
project(opencv_highgui_gtk)

get_filename_component(OpenCV_SOURCE_DIR "${CMAKE_CURRENT_LIST_DIR}/../../../../.." ABSOLUTE)
include("${OpenCV_SOURCE_DIR}/cmake/OpenCVPluginStandalone.cmake")

# scan dependencies
set(WITH_GTK ON)
include("${OpenCV_SOURCE_DIR}/modules/highgui/cmake/init.cmake")

if(NOT HAVE_GTK)
  message(FATAL_ERROR "GTK: NO")
endif()

ocv_warnings_disable(CMAKE_CXX_FLAGS -Wno-deprecated-declarations)

set(OPENCV_PLUGIN_DEPS core imgproc imgcodecs)
if(TARGET ocv.3rdparty.gtk3)
  set(__deps ocv.3rdparty.gtk3)
elif(TARGET ocv.3rdparty.gtk2)
  set(__deps ocv.3rdparty.gtk2)
elif(TARGET ocv.3rdparty.gtk)
  set(__deps ocv.3rdparty.gtk)
else()
  message(FATAL_ERROR "Missing dependency target for GTK libraries")
endif()
ocv_create_plugin(highgui "opencv_highgui_gtk" "${__deps}" "GTK" "src/window_gtk.cpp")
if(WITH_OPENGL)
  if(HAVE_GTK2
      AND TARGET ocv.3rdparty.gtkglext
      AND TARGET ocv.3rdparty.gtk_opengl
      AND NOT OPENCV_GTK_DISABLE_GTKGLEXT
      AND NOT OPENCV_GTK_DISABLE_OPENGL
  )
    message(STATUS "OpenGL: YES")
    target_link_libraries(${OPENCV_PLUGIN_NAME} PRIVATE
        ocv.3rdparty.gtkglext ocv.3rdparty.gtk_opengl
    )
  else()
    message(WARNING "OpenGL dependencies are not available!")
  endif()
endif()

if(HAVE_GTK3)
  message(STATUS "GTK3+: ver ${GTK3_VERSION}")
elif(HAVE_GTK3)
  message(STATUS "GTK2+: ver ${GTK2_VERSION}")
elif(DEFINED GTK_VERSION)
  message(STATUS "GTK+: ver ${GTK_VERSION}")
else()
  message(STATUS "GTK+: YES")
endif()
```

----------------------------------------

TITLE: Handling OpenCL Source Exclusion and Compiler Flags for the DNN Module - CMake
DESCRIPTION: Checks OpenCL and related options for the DNN module, adding required include directories if OpenCL is enabled; otherwise, excludes OpenCL-specific source files. Modifies the sources_options variable accordingly. Inputs are OPENCV_DNN_OPENCL and HAVE_OPENCL variables, output modifies include_dirs and sources_options.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/dnn/CMakeLists.txt#2025-04-22_snippet_17

LANGUAGE: CMake
CODE:
```
if(OPENCV_DNN_OPENCL AND HAVE_OPENCL)
  list(APPEND include_dirs ${OPENCL_INCLUDE_DIRS})
else()
  set(sources_options EXCLUDE_OPENCL)
endif()
```

----------------------------------------

TITLE: Configuring Build Type and Flags for OpenCV World Module (CMake)
DESCRIPTION: Initializes CMake variables `the_description`, `OPENCV_MODULE_IS_PART_OF_WORLD`, and `BUILD_opencv_world_INIT`. It then conditionally sets `OPENCV_MODULE_TYPE` to `STATIC` or leaves it unset (implicitly shared) and `OPENCV_WORLD_FLAGS_PROPERTY` to `STATIC_LIBRARY_FLAGS` or `LINK_FLAGS` based on the value of the `BUILD_SHARED_LIBS` variable. This prepares the environment for building the aggregated `opencv_world` library.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/world/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(the_description "All OpenCV modules")
set(OPENCV_MODULE_IS_PART_OF_WORLD FALSE)
set(BUILD_opencv_world_INIT OFF)

if(NOT BUILD_SHARED_LIBS)
  set(OPENCV_MODULE_TYPE STATIC)
  set(OPENCV_WORLD_FLAGS_PROPERTY STATIC_LIBRARY_FLAGS)
else()
  set(OPENCV_WORLD_FLAGS_PROPERTY LINK_FLAGS)
endif()
```

----------------------------------------

TITLE: Building OpenCV Java Tests JAR using Ant in CMake
DESCRIPTION: Configures the build process for the OpenCV Java tests JAR using Ant. It sets up the build command and specifies dependencies for the build process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/pure_test/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
add_custom_command(OUTPUT "${OPENCV_JAVA_TEST_DIR}/build/jar/opencv-test.jar"
    COMMAND "${ANT_EXECUTABLE}" -noinput -k build
    WORKING_DIRECTORY "${OPENCV_JAVA_TEST_DIR}"
    DEPENDS ${depends} "${OPENCV_JAVA_TEST_DIR}/build.xml" "${CMAKE_CURRENT_SOURCE_DIR}/build.xml" "${OPENCV_JAR_FILE}" "${OPENCV_JAVA_TEST_DIR}/bin/${JAR_NAME}"
    COMMENT "Build Java tests"
)

file(GENERATE OUTPUT "${OPENCV_JAVA_TEST_DIR}/ant-$<CONFIGURATION>.properties" CONTENT "opencv.lib.path=$<TARGET_FILE_DIR:${the_module}>")
```

----------------------------------------

TITLE: Configuring WinRT Video Capture Support
DESCRIPTION: Conditionally adds WinRT-specific video capture implementation files when building for Windows Runtime 8.1+. Includes headers and source files for WinRT capture, bridge, and media streaming components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
if(DEFINED WINRT AND NOT DEFINED WINRT_8_0 AND NOT DEFINED ENABLE_WINRT_MODE_NATIVE)
    message(STATUS "  ${name}: WinRT detected. Adding WinRT API header")
    list(APPEND videoio_ext_hdrs "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cap_winrt.hpp")

    list(APPEND videoio_srcs
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt_capture.cpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt_bridge.cpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt_video.cpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt/CaptureFrameGrabber.cpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt/MediaStreamSink.cpp)
    list(APPEND videoio_hdrs
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt_capture.hpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt_bridge.hpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt_video.hpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt/MFIncludes.hpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt/CaptureFrameGrabber.hpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt/MediaSink.hpp
        ${CMAKE_CURRENT_LIST_DIR}/src/cap_winrt/MediaStreamSink.hpp)
endif()
```

----------------------------------------

TITLE: Configuring Acceleration Libraries for OpenCV Tests
DESCRIPTION: Checks for available acceleration libraries such as OpenVINO and ADE, and configures the OpenCV test modules accordingly. It links appropriate libraries and includes directories to use these accelerations, ensuring optimal performance of tests linked directly to these symbols.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: CMake
CODE:
```
set(__test_extra_deps "")
if(TARGET ocv.3rdparty.openvino AND OPENCV_GAPI_WITH_OPENVINO)
  list(APPEND __test_extra_deps ocv.3rdparty.openvino)
endif()
ocv_add_accuracy_tests(${__test_extra_deps})
```

LANGUAGE: CMake
CODE:
```
if(TARGET opencv_test_gapi)
  target_include_directories(opencv_test_gapi PRIVATE "${CMAKE_CURRENT_LIST_DIR}/src")
  target_link_libraries(opencv_test_gapi PRIVATE ade)
endif()
```

----------------------------------------

TITLE: Writing Inline and Block Formulas - Doxygen Markup
DESCRIPTION: Presents usage of Doxygen's inline (\f$ ... \f$) and block (\f[ ... \f]) formula tags for mathematical expressions. No dependencies aside from doxygen itself. Inputs are LaTeX-formatted formulas, outputs are rendered math in documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_8

LANGUAGE: markdown
CODE:
```
\f$ ... \f$
```

LANGUAGE: markdown
CODE:
```
\f[ ... \f]
```

----------------------------------------

TITLE: Configuring Relative Paths and Dependency Checks in CMake
DESCRIPTION: This CMake snippet appends the relative path of pattern tools to the OpenCV configuration if not cross-compiling. It also checks the BUILD_DOCS flag to determine whether to return early or continue to process documentation dependencies. Essential dependencies include doxygen for documentation generation and optional tools such as javadoc and python bindings.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
if (NOT CMAKE_CROSSCOMPILING)\n  file(RELATIVE_PATH __loc_relative \"${OpenCV_BINARY_DIR}\" \"${CMAKE_CURRENT_LIST_DIR}/pattern_tools\n\")\n  file(APPEND \"${OpenCV_BINARY_DIR}/opencv_apps_python_tests.cfg\" \"${__loc_relative}\")\nendif()\n\nif(NOT BUILD_DOCS)\n  return()\nendif()\n\n# Dependencies scheme (* - optional):\n#\n# javadoc* -> doxygen_javadoc* -> doxygen_cpp ---------> doxygen -> opencv_docs\n#    \                               \                     /        /\n#     \                               -> doxygen_python* ->        /
```

----------------------------------------

TITLE: Enabling CMake Download in OpenCV Maven Build
DESCRIPTION: Maven command-line option to download the latest CMake binary instead of using the native package. This is an optional configuration for x86 processors.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/maven/README.md#2025-04-22_snippet_2

LANGUAGE: shell
CODE:
```
-Ddownload.cmake=true
```

----------------------------------------

TITLE: Adding Example Subdirectories for Standalone Build in CMake
DESCRIPTION: Includes a specific subset of example subdirectories (cpp, directx (if Win32), dnn, opencl, sycl, tapi) when building the samples standalone. Some directories included in the integrated build (like gpu, opengl, openvx) are commented out or omitted, likely reflecting dependencies or typical usage scenarios for standalone builds against a pre-installed OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: cmake
CODE:
```
add_subdirectory(cpp)
if(WIN32)
  add_subdirectory(directx)
endif()
add_subdirectory(dnn)
# add_subdirectory(gpu)
add_subdirectory(opencl)
add_subdirectory(sycl)
# add_subdirectory(opengl)
# add_subdirectory(openvx)
add_subdirectory(tapi)
# add_subdirectory(va_intel)
```

----------------------------------------

TITLE: Configuring Dispatched Files for CPU Optimizations
DESCRIPTION: Adds CPU architecture-specific dispatched files for core mathematical and matrix operations using SSE2, AVX, AVX2, and LASX optimizations.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/core/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
ocv_add_dispatched_file(mathfuncs_core SSE2 AVX AVX2 LASX)
ocv_add_dispatched_file(stat SSE4_2 AVX2 LASX)
ocv_add_dispatched_file(arithm SSE2 SSE4_1 AVX2 VSX3 LASX)
```

----------------------------------------

TITLE: Running Individual WebAssembly Intrinsic Type Tests in OpenCV.js - JavaScript
DESCRIPTION: These JavaScript snippets allow for targeting WebAssembly intrinsic (HAL) tests for specific data types (uint8, int8, uint16, etc.) within OpenCV.js. Requires 'cv' to be loaded. Each function call tests the intrinsics for one particular data type, with results reported in the debug console. Useful for isolating and diagnosing issues with specific SIMD types.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_20

LANGUAGE: js
CODE:
```
cv.test_hal_intrin_uint8()\ncv.test_hal_intrin_int8()\ncv.test_hal_intrin_uint16()\ncv.test_hal_intrin_int16()\ncv.test_hal_intrin_uint32()\ncv.test_hal_intrin_int32()\ncv.test_hal_intrin_uint64()\ncv.test_hal_intrin_int64()\ncv.test_hal_intrin_float32()\ncv.test_hal_intrin_float64()
```

----------------------------------------

TITLE: Carotene Library Integration
DESCRIPTION: Configures and compiles the Carotene library component, setting up NEON support when available in the CPU baseline.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/carotene/hal/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
function(compile_carotene)
  if(";${CPU_BASELINE_FINAL};" MATCHES ";NEON;")
    set(WITH_NEON ON)
  endif()

  add_subdirectory("${CAROTENE_DIR}" "${CMAKE_CURRENT_BINARY_DIR}/carotene")
endfunction()

compile_carotene()
```

----------------------------------------

TITLE: Enabling Foreign Architectures in DPKG (Bash)
DESCRIPTION: Configures the `dpkg` package manager to recognize and allow the installation of packages built for the `arm64` and `armhf` architectures alongside the native host architecture. This is a core step in enabling MultiArch functionality.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_7

LANGUAGE: bash
CODE:
```
sudo dpkg --add-architecture arm64
sudo dpkg --add-architecture armhf
```

----------------------------------------

TITLE: Updating Python Tests Configuration File in CMake for OpenCV
DESCRIPTION: Converts the list of test locations to a newline-separated string and updates the configuration file with this content using the ocv_update_file function.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/test/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
string(REPLACE ";" "\n" opencv_tests_locations_ "${opencv_tests_locations}")
ocv_update_file("${OPENCV_PYTHON_TESTS_CONFIG_FILE}" "${opencv_tests_locations_}")
```

----------------------------------------

TITLE: General CMake Command Line Syntax for OpenCV
DESCRIPTION: Shows the basic syntax for invoking CMake from the command line to configure an OpenCV build. Requires specifying options and the path to the OpenCV source directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
cmake [options] <path-to-source>
```

----------------------------------------

TITLE: MIPS DSPr2 Capability Test
DESCRIPTION: Checks for MIPS DSPr2 instruction support on MIPS32r2 platforms
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: c
CODE:
```
#if !(defined(__mips__) && __mips_isa_rev >= 2)
#error MIPS DSPr2 is currently only available on MIPS32r2 platforms.
#endif
int main(void) {
  int c = 0, a = 0, b = 0;
  __asm__ __volatile__ (
    "precr.qb.ph %[c], %[a], %[b]"
    : [c] "=r" (c)
    : [a] "r" (a), [b] "r" (b)
  );
  return c;
}
```

----------------------------------------

TITLE: CMake Build Configuration Output
DESCRIPTION: Example output showing successful Wayland configuration during CMake setup, displaying version information for various dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/highgui_wayland_ubuntu.markdown#2025-04-22_snippet_1

LANGUAGE: plaintext
CODE:
```
--
--   GUI:                           Wayland
--     Wayland:                     (Experimental) YES
--       Wayland Client:            YES (ver 1.22.0)
--       Wayland Cursor:            YES (ver 1.22.0)
--       Wayland Protocols:         YES (ver 1.34)
--       Xkbcommon:                 YES (ver 1.6.0)
--       Wayland EGL(Option):       YES (ver 18.1.0)
--     GTK+:                        NO
--     VTK support:                 NO
```

----------------------------------------

TITLE: Configuring Namespace Settings for IlmBase and OpenEXR
DESCRIPTION: This snippet configures namespace settings for IlmBase and OpenEXR components. It sets up internal namespaces with version suffixes to avoid conflicts when embedded in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
set(ILMBASE_VERSION_API "opencv")
set(ILMBASE_INTERNAL_NAMESPACE_CUSTOM 1)
set(IMATH_INTERNAL_NAMESPACE "Imath_${ILMBASE_VERSION_API}")
set(IEX_INTERNAL_NAMESPACE "Iex_${ILMBASE_VERSION_API}")
set(ILMTHREAD_INTERNAL_NAMESPACE "IlmThread_${ILMBASE_VERSION_API}")

set(ILMBASE_NAMESPACE_CUSTOM 0)
set(IMATH_NAMESPACE "Imath")
set(IEX_NAMESPACE "Iex")
set(ILMTHREAD_NAMESPACE "IlmThread")
set(ILMBASE_VERSION_STRING "\"${ILMBASE_VERSION}\"" )
set(ILMBASE_PACKAGE_STRING "\"IlmBase ${ILMBASE_VERSION}\"" )


set(OPENEXR_VERSION_API "opencv")
set(OPENEXR_IMF_INTERNAL_NAMESPACE_CUSTOM 1)
set(OPENEXR_IMF_INTERNAL_NAMESPACE "Imf_${ILMBASE_VERSION_API}")
set(OPENEXR_IMF_NAMESPACE_CUSTOM 0)
set(OPENEXR_IMF_NAMESPACE "Imf")

set(OPENEXR_VERSION_STRING "\"${OPENEXR_VERSION}\"" )
set(OPENEXR_PACKAGE_STRING "\"OpenEXR ${OPENEXR_VERSION}\"" )
```

----------------------------------------

TITLE: Python Documentation Generation Setup
DESCRIPTION: Configures Python documentation generation target with signature injection when all required dependencies are available.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_23

LANGUAGE: cmake
CODE:
```
if(PYTHON_DEFAULT_EXECUTABLE
      AND HAVE_PYTHON_BS4
      AND OPENCV_PYTHON_SIGNATURES_FILE
      AND TARGET gen_opencv_python_source)
    add_custom_target(doxygen_python
      COMMAND ${PYTHON_DEFAULT_EXECUTABLE} "${CMAKE_CURRENT_SOURCE_DIR}/tools/add_signatures.py" "${CMAKE_CURRENT_BINARY_DIR}/doxygen/html/" "${OPENCV_PYTHON_SIGNATURES_FILE}" "python"
      DEPENDS doxygen_cpp gen_opencv_python_source
      COMMENT "Inject Python signatures into documentation"
    )
  endif()
```

----------------------------------------

TITLE: Collecting G-API 3rd Party Source Files (VASOT) in CMake
DESCRIPTION: Uses `file(GLOB_RECURSE ...)` to find and collect all C++ source files (`.cpp`) from the VAS Object Tracking (vasot) third-party library located within the G-API module's source directory. The results are stored in the `gapi_3rdparty_srcs` variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
file(GLOB_RECURSE gapi_3rdparty_srcs
    "${CMAKE_CURRENT_LIST_DIR}/src/3rdparty/vasot/src/*.cpp"
)
```

----------------------------------------

TITLE: Defining libjasper Library Target in CMake
DESCRIPTION: This snippet defines the libjasper library target as a static library and sets up compiler definitions for Windows builds.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjasper/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
add_library(${JASPER_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${lib_srcs} ${lib_hdrs} ${lib_ext_hdrs})

if(WIN32 AND NOT MINGW)
  add_definitions(-DJAS_WIN_MSVC_BUILD)
endif(WIN32 AND NOT MINGW)
```

----------------------------------------

TITLE: Converting JPEG Quality Scale to Linear Scaling Percentage (C)
DESCRIPTION: This function converts a value on the IJG-recommended quality scale to a linear scaling percentage. Note that this function may change in future releases.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_25

LANGUAGE: C
CODE:
```
int jpeg_quality_scaling (int quality)
```

----------------------------------------

TITLE: Check for Memory Allocation Functions in CMake
DESCRIPTION: This block of code verifies the presence of memory allocation functions like posix_memalign and aligned_alloc, setting the appropriate macros for conditional compilation. This ensures compatibility for dynamic memory handling.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: CMake
CODE:
```
set(CMAKE_REQUIRED_DEFINITIONS -D_POSIX_C_SOURCE=200112L)
check_symbol_exists(posix_memalign stdlib.h HAVE_POSIX_MEMALIGN)
if(HAVE_POSIX_MEMALIGN)
    add_definitions(-DHAVE_POSIX_MEMALIGN)
endif()
set(CMAKE_REQUIRED_DEFINITIONS)

set(CMAKE_REQUIRED_DEFINITIONS -D_ISOC11_SOURCE=1)
check_symbol_exists(aligned_alloc stdlib.h HAVE_ALIGNED_ALLOC)
if(HAVE_ALIGNED_ALLOC)
    add_definitions(-DHAVE_ALIGNED_ALLOC)
endif()
set(CMAKE_REQUIRED_DEFINITIONS)
```

----------------------------------------

TITLE: Adaptive Progressive Decoding Loop in C
DESCRIPTION: Shows the recommended loop structure for handling progressive JPEG decoding with final pass processing. Automatically adapts to incoming data speed and ensures full quality display.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_54

LANGUAGE: c
CODE:
```
do {
    absorb any waiting input by calling jpeg_consume_input()
    final_pass = jpeg_input_complete(&cinfo);
    adjust output decompression parameters if required
    jpeg_start_output(&cinfo, cinfo.input_scan_number);
    ...
    jpeg_finish_output()
} while (!final_pass);
```

----------------------------------------

TITLE: Building OpenCV.js Tests - Bash
DESCRIPTION: Adds the --build_test option to the OpenCV.js build script to include test source code in the build. Dependency: emcmake, Python. Output is test files placed alongside opencv.js for testing functionality either in browser or automated environments.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_9

LANGUAGE: bash
CODE:
```
emcmake python ./opencv/platforms/js/build_js.py build_js --build_test
```

----------------------------------------

TITLE: Location of libwebp Library in eSDK Sysroot (Path)
DESCRIPTION: This file path shows the location of the `libwebp.so.7` shared library within the Qualcomm eSDK sysroot. This library might be a runtime dependency for some OpenCV tests or applications. If tests fail on the target device due to this library being missing, it should be located at this path within the eSDK and manually copied (pushed) to the appropriate library directory on the target device.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_fastcv/building_fastcv.markdown#2025-04-22_snippet_8

LANGUAGE: text
CODE:
```
<ESDK_PATH>\qcom-wayland_sdk\tmp\sysroots\qcs6490-rb3gen2-vision-kit\usr\lib\libwebp.so.7
```

----------------------------------------

TITLE: Copying and Configuring libcxx_helper Files in CMake
DESCRIPTION: This CMake snippet recursively finds all files within the `libcxx_helper` directory relative to the current source directory. It then iterates through these files, configures each one (replacing `@VAR@` placeholders) and copies it to the `OPENCV_JAVA_DIR`. Each original file is added to the `depends` list, and an installation rule is created to install the configured file into the appropriate subdirectory under `${JAVA_INSTALL_ROOT}/..` as part of the 'java' component.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/android_sdk/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
# copy libcxx_helper
set(__base_dir "${CMAKE_CURRENT_SOURCE_DIR}/")
file(GLOB_RECURSE __files_rel RELATIVE "${__base_dir}/" "${__base_dir}/libcxx_helper/*")
foreach(file ${__files_rel})
  configure_file("${__base_dir}/${file}" "${OPENCV_JAVA_DIR}/${file}" @ONLY)
  list(APPEND depends "${__base_dir}/${file}")
  get_filename_component(install_subdir "${file}" PATH)
  install(FILES "${OPENCV_JAVA_DIR}/${file}" DESTINATION "${JAVA_INSTALL_ROOT}/../${install_subdir}" COMPONENT java)
endforeach()
```

----------------------------------------

TITLE: Collecting G-API Header Files using CMake
DESCRIPTION: Uses the `file(GLOB ...)` command to find and collect all header files (`.hpp`, `.h`) associated with the G-API module from various subdirectories within the module's include path. The collected list of headers is stored in the `gapi_ext_hdrs` variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
file(GLOB gapi_ext_hdrs
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/*.h"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/cpu/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/fluid/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/gpu/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/infer/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/oak/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/ocl/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/own/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/plaidml/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/python/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/render/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/s11n/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/streaming/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/streaming/gstreamer/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/streaming/onevpl/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/plaidml/*.hpp"
    "${CMAKE_CURRENT_LIST_DIR}/include/opencv2/${name}/util/*.hpp"
    )
```

----------------------------------------

TITLE: Defining OpenJPEG Version Variables in CMake
DESCRIPTION: Sets CMake variables for the OpenJPEG library version components (MAJOR, MINOR, BUILD) and constructs a full version string. It also sets the standard `PACKAGE_VERSION` variable, which is often used by packaging tools.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
#-----------------------------------------------------------------------------
# OPENJPEG version number, useful for packaging and doxygen doc:
set(OPENJPEG_VERSION_MAJOR 2)
set(OPENJPEG_VERSION_MINOR 5)
set(OPENJPEG_VERSION_BUILD 3)
set(OPENJPEG_VERSION
  "${OPENJPEG_VERSION_MAJOR}.${OPENJPEG_VERSION_MINOR}.${OPENJPEG_VERSION_BUILD}")
set(PACKAGE_VERSION
  "${OPENJPEG_VERSION_MAJOR}.${OPENJPEG_VERSION_MINOR}.${OPENJPEG_VERSION_BUILD}")
```

----------------------------------------

TITLE: Finding and Verifying Doxygen in CMake
DESCRIPTION: Locates the Doxygen package using `find_package`. If found, it checks if the Doxygen version is less than 1.12 and issues a warning if it is. Finally, it adds a custom target named `doxygen` to trigger documentation generation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
find_package(Doxygen)
if(DOXYGEN_FOUND)
  if (DOXYGEN_VERSION VERSION_LESS 1.12)
    message(WARNING "Found doxygen ${DOXYGEN_VERSION}, version 1.12 is used for testing, there is "
                    "a chance your documentation will look different or have some limitations.")
  endif()
  add_custom_target(doxygen)
```

----------------------------------------

TITLE: Verifying OpenNI Environment Variables
DESCRIPTION: Uses the 'echo' command to display the values of the OPENNI2_INCLUDE and OPENNI2_REDIST environment variables. This step verifies that the 'OpenNIDevEnvironment' script was sourced correctly and the variables are set to the expected paths for the SDK's include and redistributable directories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
$ echo $OPENNI2_INCLUDE
/home/user/OpenNI_2.3.0.63/Linux/OpenNI-Linux-x64-2.3.0.63/Include
$ echo $OPENNI2_REDIST
/home/user/OpenNI_2.3.0.63/Linux/OpenNI-Linux-x64-2.3.0.63/Redist
```

----------------------------------------

TITLE: Generating OpenCV Module Configuration
DESCRIPTION: Creates an auto-generated configuration file with definitions for the built-in backend of OpenCV's HighGUI module. It modifies the configuration string based on the back-end configuration and updates a header file accordingly. The 'OPENCV_HIGHGUI_BUILTIN_BACKEND' and 'CMAKE_CURRENT_BINARY_DIR' environment variables must be correctly set prior to invocation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_20

LANGUAGE: CMake
CODE:
```
set(CONFIG_STR "// Auto-generated file
#define OPENCV_HIGHGUI_BUILTIN_BACKEND_STR \"${OPENCV_HIGHGUI_BUILTIN_BACKEND}\"
")
if(OPENCV_HIGHGUI_BUILTIN_BACKEND STREQUAL "NONE")
set(CONFIG_STR "${CONFIG_STR}
#define OPENCV_HIGHGUI_WITHOUT_BUILTIN_BACKEND 1
")
endif()

ocv_update_file("${CMAKE_CURRENT_BINARY_DIR}/opencv_highgui_config.hpp" "${CONFIG_STR}")
```

----------------------------------------

TITLE: Setting Module Description and Dispatch Files in CMake
DESCRIPTION: This snippet sets the description for a 2D Features Framework and adds a dispatched file for the SIFT algorithm with support for various SIMD instruction sets such as SSE4.1, AVX2, and AVX512_SKX. These settings are specific to the CMake build system used in OpenCV projects.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(the_description \"2D Features Framework\")\nocv_add_dispatched_file(sift SSE4_1 AVX2 AVX512_SKX)
```

----------------------------------------

TITLE: Selecting Output File for JPEG Compression with jpeg_stdio_dest in C
DESCRIPTION: This code snippet shows how to specify the destination for compressed JPEG data in C using libjpeg. It opens a file in binary write mode and attaches it to the jpeg_compress_struct via jpeg_stdio_dest. The snippet includes typical error handling for file I/O and demonstrates the use of fopen with the 'wb' mode to ensure binary output. The dependency is standard C I/O and libjpeg’s destination management. Parameters include the output filename, the C file pointer, and the JPEG compression structure. This step is necessary to prevent corruption of binary data during image compression.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_3

LANGUAGE: C
CODE:
```
FILE *outfile;
...
if ((outfile = fopen(filename, "wb")) == NULL) {
    fprintf(stderr, "can't open %s\n", filename);
    exit(1);
}
jpeg_stdio_dest(&cinfo, outfile);
```

----------------------------------------

TITLE: Conditionally Exclude C API and Enable IPP Gaussian Blur in OpenCV imgproc Module (CMake)
DESCRIPTION: This CMake code conditionally compiles the imgproc module with the C API excluded if 'OPENCV_CORE_EXCLUDE_C_API' is set, and sets 'OPENCV_EXCLUDE_C_API=1' as a compile definition. If IPP (Intel Performance Primitives) is available and the respective option is enabled, it adds an additional compile definition to enable IPP-optimized Gaussian blur. Dependencies include pre-defined variables like OPENCV_CORE_EXCLUDE_C_API, HAVE_IPP, and CMAKE_CURRENT_SOURCE_DIR. Intended inputs are variable settings at CMake configuration time, and outputs are per-configuration compilation flags for the OpenCV imgproc module.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/imgproc/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
if(OPENCV_CORE_EXCLUDE_C_API)
  ocv_target_compile_definitions(${the_module} PRIVATE "OPENCV_EXCLUDE_C_API=1")
endif()

if(HAVE_IPP)
  # OPENCV_IPP_ENABLE_ALL is defined in modules/core/CMakeList.txt
  OCV_OPTION(OPENCV_IPP_GAUSSIAN_BLUR "Enable IPP optimizations for GaussianBlur (+8Mb in binary size)" OPENCV_IPP_ENABLE_ALL)
  if(OPENCV_IPP_GAUSSIAN_BLUR)
    ocv_append_source_file_compile_definitions(${CMAKE_CURRENT_SOURCE_DIR}/src/smooth.dispatch.cpp "ENABLE_IPP_GAUSSIAN_BLUR=1")
  endif()
endif()
```

----------------------------------------

TITLE: Setting Platform-Specific Compiler Definitions for TBB
DESCRIPTION: Configures platform-specific compiler definitions for Windows (including ARM-specific settings) and Unix platforms. These definitions control TBB's behavior and feature set.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
if (WIN32)
  add_definitions(/D__TBB_DYNAMIC_LOAD_ENABLED=0
                  /D__TBB_BUILD=1
                  /DTBB_NO_LEGACY=1
                  /D_UNICODE
                  /DUNICODE
                  /DWINAPI_FAMILY=WINAPI_FAMILY_APP
                  /DDO_ITT_NOTIFY=0
                  /DUSE_WINTHREAD
               ) # defines were copied from windows.cl.inc

  if (ARM)
    add_definitions(/D_WIN32_WINNT=0x0602
                    /D__TBB_WIN32_USE_CL_BUILTINS
                   )
  endif()

set(CMAKE_LINKER_FLAGS "${CMAKE_LINKER_FLAGS} /APPCONTAINER")
else()
  add_definitions(-D__TBB_DYNAMIC_LOAD_ENABLED=0         #required
                  -D__TBB_WEAK_SYMBOLS_PRESENT=0         #required for 4.3
                  -D__TBB_BUILD=1                        #required
                  -D__TBB_SURVIVE_THREAD_SWITCH=0        #no cilk support
                  -DTBB_USE_DEBUG=0                      #just to be sure
                  -DTBB_NO_LEGACY=1                      #don't need backward compatibility
                  -DDO_ITT_NOTIFY=0                      #it seems that we don't need these notifications
                 )
endif()
```

----------------------------------------

TITLE: NEON Intrinsics Basic Test
DESCRIPTION: Verifies basic NEON intrinsics functionality using vector operations
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: c
CODE:
```
#include <arm_neon.h>
int main(int argc, char **argv) {
  uint16x8_t input = vdupq_n_u16((uint16_t)argc);
  uint8x8_t output = vmovn_u16(input);
  return (int)output[0];
}
```

----------------------------------------

TITLE: Configuring and Building NDSRVP HAL with CMake - CMake
DESCRIPTION: This CMake script initializes logging, sets minimum required CMake version, defines source/include directories, discovers sources and headers, and configures the NDSRVP HAL static library for an OpenCV project. Dependencies include OpenCV's core, imgproc, and features2d modules. It sets output locations, manages installation (differentiating static and shared builds), adds internal build metadata, and explicitly marks HAL components as found and versioned. Key variables such as NDSRVP_INCLUDE_DIR and NDSRVP_SOURCE_DIR must be valid relative paths, and this script is intended to be included as part of the overall OpenCV CMake build process.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ndsrvp/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
message(STATUS "##########")
message(STATUS "# NDSRVP #")
message(STATUS "##########")

cmake_minimum_required(VERSION ${MIN_VER_CMAKE} FATAL_ERROR)

# project setup

set(NDSRVP_INCLUDE_DIR include)
set(NDSRVP_SOURCE_DIR src)

file(GLOB ndsrvp_headers RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "${NDSRVP_INCLUDE_DIR}/*.hpp")
file(GLOB ndsrvp_sources RELATIVE "${CMAKE_CURRENT_LIST_DIR}" "${NDSRVP_SOURCE_DIR}/*.cpp")

add_library(ndsrvp_hal STATIC)
target_sources(ndsrvp_hal PRIVATE ${ndsrvp_headers} ${ndsrvp_sources})

set_target_properties(ndsrvp_hal PROPERTIES ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH})
if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(ndsrvp_hal EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev)
endif()
target_include_directories(ndsrvp_hal PRIVATE
  ${CMAKE_CURRENT_SOURCE_DIR}
  ${CMAKE_SOURCE_DIR}/modules/core/include
  ${CMAKE_SOURCE_DIR}/modules/imgproc/include
  ${CMAKE_SOURCE_DIR}/modules/features2d/include)

# project info

set(NDSRVP_HAL_FOUND TRUE CACHE INTERNAL "")
set(NDSRVP_HAL_VERSION "0.0.1" CACHE INTERNAL "")
set(NDSRVP_HAL_LIBRARIES "ndsrvp_hal" CACHE INTERNAL "")
set(NDSRVP_HAL_HEADERS "ndsrvp_hal.hpp" CACHE INTERNAL "")
set(NDSRVP_HAL_INCLUDE_DIRS "${CMAKE_CURRENT_SOURCE_DIR}" CACHE INTERNAL "")
```

----------------------------------------

TITLE: Configuring GUI Options in CMake for OpenCV
DESCRIPTION: This snippet configures and reports the status of various GUI options for OpenCV, including Wayland, QT, Win32 UI, Cocoa, GTK, Framebuffer, OpenGL, and VTK support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_21

LANGUAGE: CMake
CODE:
```
status("")
status("  GUI: " "${OPENCV_HIGHGUI_BUILTIN_BACKEND}")

if(WITH_WAYLAND OR HAVE_WAYLAND)
  status("    Wayland:" HAVE_WAYLAND THEN "(Experimental) YES" ELSE "NO")
  status("      Wayland Client:" HAVE_WAYLAND_CLIENT THEN "YES (ver ${WAYLAND_CLIENT_VERSION})" ELSE "NO")
  status("      Wayland Cursor:" HAVE_WAYLAND_CURSOR THEN "YES (ver ${WAYLAND_CURSOR_VERSION})" ELSE "NO")
  status("      Wayland Protocols:" HAVE_WAYLAND_PROTOCOLS THEN "YES (ver ${WAYLAND_PROTOCOLS_VERSION})" ELSE "NO")
  status("      Xkbcommon:" HAVE_XKBCOMMON THEN "YES (ver ${XKBCOMMON_VERSION})" ELSE "NO")
  status("      Wayland EGL(Option):" HAVE_WAYLAND_EGL THEN "YES (ver ${WAYLAND_EGL_VERSION})" ELSE "NO")
endif()

if(WITH_QT OR HAVE_QT)
  if(HAVE_QT)
    status("    QT:" "YES (ver ${QT_VERSION_MAJOR}.${QT_VERSION_MINOR}.${QT_VERSION_PATCH} ${QT_EDITION})")
    if(HAVE_QT_OPENGL)
      if(Qt${QT_VERSION_MAJOR}OpenGL_LIBRARIES)
        status("      QT OpenGL support:" HAVE_QT_OPENGL THEN "YES (${Qt${QT_VERSION_MAJOR}OpenGL_LIBRARIES} ${Qt${QT_VERSION_MAJOR}OpenGL_VERSION_STRING})" ELSE NO)
      else()
        status("      QT OpenGL support:" HAVE_QT_OPENGL THEN "YES (${QT_QTOPENGL_LIBRARY})" ELSE NO)
      endif()
    else()
      status("      QT OpenGL support:" "NO")
    endif()
  else()
    status("    QT:" "NO")
  endif()
endif()

if(WITH_WIN32UI)
  status("    Win32 UI:" HAVE_WIN32UI THEN YES ELSE NO)
endif()

if(HAVE_COCOA)  # APPLE
  status("    Cocoa:"  YES)
endif()

if(WITH_GTK OR HAVE_GTK)
  if(HAVE_GTK3)
    status("    GTK+:" "YES (ver ${GTK3_VERSION})")
  elseif(HAVE_GTK)
    status("    GTK+:" "YES (ver ${GTK2_VERSION})")
    status("      GtkGlExt:" HAVE_GTKGLEXT THEN "YES (ver ${GTKGLEXT_VERSION})" ELSE NO)
  else()
    status("    GTK+:" "NO")
  endif()
endif()

if(WITH_FRAMEBUFFER OR HAVE_FRAMEBUFFER)
  status("    Framebuffer UI:" HAVE_FRAMEBUFFER THEN YES ELSE NO)
  if(WITH_FRAMEBUFFER_XVFB OR HAVE_FRAMEBUFFER_XVFB)
    status("    Virtual framebuffer UI:" HAVE_FRAMEBUFFER_XVFB THEN YES ELSE NO)
  endif()
endif()

if(WITH_OPENGL OR HAVE_OPENGL)
  status("    OpenGL support:" HAVE_OPENGL THEN "YES (${OPENGL_LIBRARIES})" ELSE NO)
endif()

if(WITH_VTK OR HAVE_VTK)
  status("    VTK support:" HAVE_VTK THEN "YES (ver ${VTK_VERSION})" ELSE NO)
endif()
```

----------------------------------------

TITLE: Setting Up Python Code Quality Checks in OpenCV CMake
DESCRIPTION: Configures Python code quality checks using Pylint and Flake8 if enabled and Python is available. It sets up custom targets for running these tools on the OpenCV codebase.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_13

LANGUAGE: CMake
CODE:
```
if(ENABLE_PYLINT AND PYTHON_DEFAULT_AVAILABLE)
  include(cmake/OpenCVPylint.cmake)
endif()
if(ENABLE_FLAKE8 AND PYTHON_DEFAULT_AVAILABLE)
  find_package(Flake8 QUIET)
  if(NOT FLAKE8_FOUND OR NOT FLAKE8_EXECUTABLE)
    include("${CMAKE_CURRENT_LIST_DIR}/cmake/FindFlake8.cmake")
  endif()
  if(FLAKE8_FOUND)
    list(APPEND OPENCV_FLAKE8_EXCLUDES ".git" "__pycache__" "config.py" "*.config.py" "config-*.py")
    list(APPEND OPENCV_FLAKE8_EXCLUDES "svgfig.py")  # 3rdparty
    if(NOT PYTHON3_VERSION_STRING VERSION_GREATER 3.6)
      # Python 3.6+ (PEP 526): variable annotations (type hints)
      list(APPEND OPENCV_FLAKE8_EXCLUDES "samples/dnn/dnn_model_runner/dnn_conversion/common/test/configs")
    endif()
    string(REPLACE ";" "," OPENCV_FLAKE8_EXCLUDES_STR "${OPENCV_FLAKE8_EXCLUDES}")
    add_custom_target(check_flake8
        COMMAND "${FLAKE8_EXECUTABLE}" . --count --select=E9,E901,E999,F821,F822,F823 --show-source --statistics --exclude='${OPENCV_FLAKE8_EXCLUDES_STR}'
        WORKING_DIRECTORY "${OpenCV_SOURCE_DIR}"
        COMMENT "Running flake8"
    )
  endif()
endif()
```

----------------------------------------

TITLE: Embedding External Content with HTML iframe
DESCRIPTION: This HTML snippet uses an iframe to embed the content of 'js_semantic_segmentation.html' located two directories up. The iframe spans the full width of its container. Upon loading ('onload' event), a JavaScript snippet adjusts the iframe's height to match the height of the loaded content's body, preventing internal scrollbars.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_dnn/js_semantic_segmentation/js_semantic_segmentation.markdown#2025-04-22_snippet_0

LANGUAGE: html
CODE:
```
<iframe src="../../js_semantic_segmentation.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
```

----------------------------------------

TITLE: Reading Decompressed Scanlines in C using libjpeg
DESCRIPTION: Illustrates the function call `jpeg_read_scanlines` (or its variants `jpeg12_read_scanlines` for 9-12 bit precision, `jpeg16_read_scanlines` for 13-16 bit precision) used within a loop to read decompressed image data. This function is called repeatedly (step 6) until all scanlines specified by `cinfo.output_height` are read. It fills the provided buffer(s) with scanline data and returns the number of lines actually read in that call. The specific function variant depends on the required data precision.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_15

LANGUAGE: C
CODE:
```
jpeg_read_scanlines(...);  /* Use jpeg12_read_scanlines() for 9-bit
                                  through 12-bit data precision and
                                  jpeg16_read_scanlines() for 13-bit
                                  through 16-bit data precision. */
```

----------------------------------------

TITLE: Disabling Compiler Warnings for TBB Build
DESCRIPTION: Disables specific compiler warnings that would otherwise be triggered by the TBB source code. This is necessary to build TBB cleanly across different compilers and platforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/tbb/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
ocv_warnings_disable(CMAKE_CXX_FLAGS
    /wd4702
    -Wshadow
    -Wunused-parameter
    -Wclass-memaccess                  # TBB 2018 under GCC 8+
    -Wimplicit-fallthrough             # TBB 2018 under GCC 7+
    -Wmissing-prototypes               # MacOSX, Android/Clang
    -Wundef -Wmissing-declarations     # TBB 2019
    -Wnon-virtual-dtor                 # oneTBB-2020.2 Android
    -Wunused-but-set-variable          # oneTBB-2020.2 Android
)
```

----------------------------------------

TITLE: Displaying CUDA Integration Status in OpenCV Build
DESCRIPTION: Checks and displays NVIDIA CUDA integration status, including version, supported features (CUFFT, CUBLAS, NVCUVID, etc.), and configured GPU architectures.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_25

LANGUAGE: cmake
CODE:
```
if(WITH_CUDA OR HAVE_CUDA)
  ocv_build_features_string(cuda_features
    IF HAVE_CUFFT THEN "CUFFT"
    IF HAVE_CUBLAS THEN "CUBLAS"
    IF HAVE_NVCUVID THEN "NVCUVID"
    IF HAVE_NVCUVENC THEN "NVCUVENC"
    IF CUDA_FAST_MATH THEN "FAST_MATH"
    ELSE "no extra features")
  status("")
  status("  NVIDIA CUDA:" HAVE_CUDA THEN "YES (ver ${CUDA_VERSION_STRING}, ${cuda_features})" ELSE NO)
  if(HAVE_CUDA)
    status("    NVIDIA GPU arch:"      ${OPENCV_CUDA_ARCH_BIN})
    status("    NVIDIA PTX archs:"     ${OPENCV_CUDA_ARCH_PTX})
  endif()
 endif()
```

----------------------------------------

TITLE: SIMD Failure Handling Macro in CMake
DESCRIPTION: Defines a macro that handles SIMD compilation failures based on whether SIMD is required. If SIMD is required, it fails with an error; otherwise, it continues with reduced performance.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
macro(simd_fail message)
  if(REQUIRE_SIMD)
    message(FATAL_ERROR "${message}.")
  else()
    message(STATUS "${message}.  Performance will suffer.")
    set(WITH_SIMD 0 PARENT_SCOPE)
  endif()
endmacro()
```

----------------------------------------

TITLE: Template License Notice for Source Files (GPLv2)
DESCRIPTION: This is a template comment block recommended for inclusion at the beginning of source files. It declares the program's name and purpose, asserts copyright, states that the program is free software distributable under the terms of the GNU GPL version 2 (or optionally, later versions), explicitly disclaims any warranty (including merchantability and fitness for a particular purpose), and directs the user to the full GPL text for details. It also includes a placeholder for obtaining a copy of the license.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ittnotify/src/ittnotify/GPL-2.0-only.txt#2025-04-22_snippet_0

LANGUAGE: plaintext
CODE:
```
<one line to give the program's name and an idea of what it does.>
Copyright (C) < yyyy> <name of author>

This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
```

----------------------------------------

TITLE: Creating IPP HAL Static Library
DESCRIPTION: Defines the static library target 'ipphal' with its source files for various IPP operations including mean, minmax, norm, cartesian/polar conversions, and transforms.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ipphal/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
add_library(ipphal STATIC
    "${CMAKE_CURRENT_SOURCE_DIR}/src/mean_ipp.cpp"
    "${CMAKE_CURRENT_SOURCE_DIR}/src/minmax_ipp.cpp"
    "${CMAKE_CURRENT_SOURCE_DIR}/src/norm_ipp.cpp"
    "${CMAKE_CURRENT_SOURCE_DIR}/src/cart_polar_ipp.cpp"
    "${CMAKE_CURRENT_SOURCE_DIR}/src/transforms_ipp.cpp"
)
```

----------------------------------------

TITLE: Overriding Fatal Error Handling in JPEG Library (C)
DESCRIPTION: Defines the `error_exit` function signature, a method within the `jpeg_error_mgr` struct. This function is called for fatal errors. It receives a pointer to the JPEG object (`j_common_ptr`). The implementation must not return control to the caller; it should typically call `output_message` to display the error stored in `cinfo->err` and then terminate (e.g., via `longjmp` or `exit`). Overriding this is common to replace the default `exit()` behavior and allow application-level cleanup using `jpeg_abort` or `jpeg_destroy`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_44

LANGUAGE: c
CODE:
```
error_exit (j_common_ptr cinfo)
```

----------------------------------------

TITLE: Setting JFIF Version Number in libjpeg (C)
DESCRIPTION: C fields (`UINT8`) within the compression parameters structure (`cinfo`) specifying the major (`JFIF_major_version`) and minor (`JFIF_minor_version`) version numbers to be written into the JFIF marker if `write_JFIF_header` is TRUE. The default set by `jpeg_set_defaults()` is 1.01. This should be updated to 1.02 if using JFIF 1.02 extension markers.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_39

LANGUAGE: C
CODE:
```
UINT8 JFIF_major_version
```

LANGUAGE: C
CODE:
```
UINT8 JFIF_minor_version
```

----------------------------------------

TITLE: Generating Test Locations List in CMake for OpenCV Python Tests
DESCRIPTION: Creates a list of relative paths to Python test locations for each module. It includes the main test directory and any module-specific test directories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/python/test/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
file(RELATIVE_PATH __loc_relative "${OPENCV_PYTHON_TESTS_CONFIG_FILE_DIR}" "${CMAKE_CURRENT_LIST_DIR}")
set(opencv_tests_locations "${__loc_relative}")
foreach(m ${OPENCV_PYTHON_MODULES})
  set(__loc "${OPENCV_MODULE_${m}_LOCATION}/misc/python/test")
  if(EXISTS "${__loc}")
    file(RELATIVE_PATH __loc_relative "${OPENCV_PYTHON_TESTS_CONFIG_FILE_DIR}" "${__loc}")
    list(APPEND opencv_tests_locations "${__loc_relative}")
  endif()
endforeach(m)
```

----------------------------------------

TITLE: Configuring OpenCV 2.4 Build for Jetson TX1 using CMake (Shell)
DESCRIPTION: Runs CMake to configure the OpenCV 2.4 build specifically for the NVIDIA Jetson TX1 platform (L4T). It sets build type to Release, enables CUDA 8.0 for architecture 5.3, enables Python 2 bindings (`BUILD_opencv_python`), TBB, and FFMPEG, disables precompiled headers, disables several other optional dependencies (PNG, TIFF, Jasper, ZLIB, Java, nonfree modules, OpenCL, OpenMP, GStreamer, VTK, 1394, OpenEXR), and specifies the test data path. Assumes execution from a build directory sibling to `opencv` and `opencv_extra`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_16

LANGUAGE: Shell
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_nonfree=OFF \
    -DBUILD_opencv_python=ON \
    -DENABLE_PRECOMPILED_HEADERS=OFF \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0 \
    -DCUDA_ARCH_BIN=5.3 \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=ON \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Check for System and Linux Include Files in CMake
DESCRIPTION: These snippets check the presence of various system and Linux-specific include files to determine available features using CMake commands like check_include_file. Detected features are then defined as macros for conditional compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: CMake
CODE:
```
#
# Check for standard/system includes
#
check_include_file(arm_acle.h  HAVE_ARM_ACLE_H)
if(HAVE_ARM_ACLE_H)
    add_definitions(-DHAVE_ARM_ACLE_H)
endif()
check_include_file(sys/auxv.h  HAVE_SYS_AUXV_H)
if(HAVE_SYS_AUXV_H)
    add_definitions(-DHAVE_SYS_AUXV_H)
endif()
check_include_file(sys/sdt.h   HAVE_SYS_SDT_H)
if(HAVE_SYS_SDT_H)
    add_definitions(-DHAVE_SYS_SDT_H)
endif()
check_include_file(unistd.h    HAVE_UNISTD_H)

#
# Check for Linux includes
#
check_include_file(linux/auxvec.h HAVE_LINUX_AUXVEC_H)
if(HAVE_LINUX_AUXVEC_H)
    add_definitions(-DHAVE_LINUX_AUXVEC_H)
endif()
```

----------------------------------------

TITLE: Declaring CMake Project for GPU Samples
DESCRIPTION: Declares a CMake project named 'gpu_samples'. This sets up the context for subsequent build commands related to the GPU examples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
project(gpu_samples)
```

----------------------------------------

TITLE: Installing Sample Data Directory (OpenCV Build) in CMake
DESCRIPTION: Conditionally installs the `data` directory (likely containing media files used by examples) into the samples source installation path (`${OPENCV_SAMPLES_SRC_INSTALL_PATH}`) as part of the `samples_data` component. This installation only occurs if `INSTALL_C_EXAMPLES` is enabled during the OpenCV build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: cmake
CODE:
```
if(INSTALL_C_EXAMPLES)
  install(DIRECTORY data DESTINATION "${OPENCV_SAMPLES_SRC_INSTALL_PATH}" COMPONENT samples_data)
endif()
```

----------------------------------------

TITLE: Adding CoinOR CLP Linear Programming Support for OpenCV Contrib (CMake)
DESCRIPTION: This build option adds coinor-clp support to the videostab contrib module in OpenCV. The user must install the development libraries for coinor-clp beforehand. Use -DWITH_CLP=ON to enable, required for certain stabilization features in contrib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_30

LANGUAGE: cmake
CODE:
```
WITH_CLP
```

----------------------------------------

TITLE: Creating Build Directory
DESCRIPTION: Creates and navigates to a build directory for compiling OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_7

LANGUAGE: shell
CODE:
```
mkdir build
cd build
```

----------------------------------------

TITLE: Generating OpenCV Tests Configuration File in CMake
DESCRIPTION: Creates a configuration file for OpenCV tests, including installation prefix and test data path if available. The file is only written if the content has changed.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ts/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
set(OPENCV_TESTS_CONFIG_FILE "${CMAKE_BINARY_DIR}/opencv_tests_config.hpp")
set(OPENCV_TESTS_CONFIG_STR "")
if(CMAKE_INSTALL_PREFIX)
  set(OPENCV_TESTS_CONFIG_STR "${OPENCV_TESTS_CONFIG_STR}
#define OPENCV_INSTALL_PREFIX \"${CMAKE_INSTALL_PREFIX}\"
")
endif()
if(OPENCV_TEST_DATA_INSTALL_PATH)
  set(OPENCV_TESTS_CONFIG_STR "${OPENCV_TESTS_CONFIG_STR}
#define OPENCV_TEST_DATA_INSTALL_PATH \"${OPENCV_TEST_DATA_INSTALL_PATH}\"
")
endif()
if(EXISTS "${OPENCV_TESTS_CONFIG_FILE}")
  file(READ "${OPENCV_TESTS_CONFIG_FILE}" __content)
endif()
if(NOT OPENCV_TESTS_CONFIG_STR STREQUAL "${__content}")
  file(WRITE "${OPENCV_TESTS_CONFIG_FILE}" "${OPENCV_TESTS_CONFIG_STR}")
endif()
```

----------------------------------------

TITLE: Including Directories for libtiff
DESCRIPTION: This part of the CMake script sets include directories for the libtiff library build process. The source and binary directories, along with any required zlib include directories, are included to ensure the compiler can access all necessary headers for the libtiff compilation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
ocv_include_directories("${CMAKE_CURRENT_SOURCE_DIR}" "${CMAKE_CURRENT_BINARY_DIR}" ${ZLIB_INCLUDE_DIRS})
```

----------------------------------------

TITLE: Adding MSVC-specific Definitions for Zlib in CMake
DESCRIPTION: Adds Microsoft Visual C++ specific preprocessor definitions to suppress deprecation warnings when building Zlib with MSVC.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
if(MSVC)
  add_definitions(-D_CRT_SECURE_NO_DEPRECATE)
  add_definitions(-D_CRT_NONSTDC_NO_DEPRECATE)
endif()
```

----------------------------------------

TITLE: Configuring IPP HAL Project Settings
DESCRIPTION: Initializes core project variables including version, library names, and header file locations for the IPP HAL component.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ipphal/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
project(ipphal)

set(IPP_HAL_VERSION 0.0.1 CACHE INTERNAL "")
set(IPP_HAL_LIBRARIES "ipphal" CACHE INTERNAL "")
set(IPP_HAL_INCLUDE_DIRS "${CMAKE_CURRENT_SOURCE_DIR}/include" CACHE INTERNAL "")
set(IPP_HAL_HEADERS
  "${CMAKE_CURRENT_SOURCE_DIR}/include/ipp_hal_core.hpp"
  CACHE INTERNAL "")
```

----------------------------------------

TITLE: Generating Configuration Headers for OpenEXR and IlmBase
DESCRIPTION: This code generates configuration header files for OpenEXR and IlmBase by substituting CMake variables into template files. It also sets up include paths for the OpenEXR components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openexr/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/IlmBaseConfig.h.cmakein"
               "${CMAKE_CURRENT_BINARY_DIR}/IlmBaseConfig.h" @ONLY)
configure_file("${CMAKE_CURRENT_SOURCE_DIR}/OpenEXRConfig.h.cmakein"
               "${CMAKE_CURRENT_BINARY_DIR}/OpenEXRConfig.h" @ONLY)

set(OPENEXR_INCLUDE_PATHS "${CMAKE_CURRENT_SOURCE_DIR}/Half"
                          "${CMAKE_CURRENT_SOURCE_DIR}/Iex"
                          "${CMAKE_CURRENT_SOURCE_DIR}/IlmThread"
                          "${CMAKE_CURRENT_SOURCE_DIR}/Imath"
                          "${CMAKE_CURRENT_SOURCE_DIR}/IlmImf"
                          "${CMAKE_CURRENT_BINARY_DIR}")

ocv_include_directories("${CMAKE_CURRENT_BINARY_DIR}" ${ZLIB_INCLUDE_DIRS} ${OPENEXR_INCLUDE_PATHS})
```

----------------------------------------

TITLE: Implementing FAST Corner Detection Decision Tree in C++
DESCRIPTION: This snippet shows part of the decision tree structure used in the FAST corner detection algorithm. The code compares pixel values at different offsets against brightness thresholds (c_b and cb) to determine if a point is a corner. Success branches lead to corner detection while continue statements skip to the next candidate point.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast.txt#2025-04-22_snippet_38

LANGUAGE: C++
CODE:
```
{} // goto success_homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  continue; // goto homogeneous;
else
  if(ptr[offset8] < c_b)
    if(ptr[offset9] < c_b)
      if(ptr[offset10] < c_b)
        if(ptr[offset6] < c_b)
          {} // goto success_homogeneous;
        else
          if(ptr[offset11] < c_b)
            if(ptr[offset12] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  if(ptr[offset10] < c_b)
    if(ptr[offset11] < c_b)
      if(ptr[offset12] < c_b)
        if(ptr[offset8] < c_b)
          if(ptr[offset9] < c_b)
            if(ptr[offset6] < c_b)
              {} // goto success_homogeneous;
            else
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
          else
            if(ptr[offset1] < c_b)
              if(ptr[offset13] < c_b)
                if(ptr[offset14] < c_b)
                  if(ptr[offset15] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset13] < c_b)
              if(ptr[offset14] < c_b)
                if(ptr[offset15] < c_b)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  if(ptr[offset14] < c_b)
    if(ptr[offset15] < c_b)
      if(ptr[offset1] < c_b)
        if(ptr[offset3] < c_b)
          if(ptr[offset6] < c_b)
            {} // goto success_homogeneous;
          else
            if(ptr[offset13] < c_b)
              {} // goto success_homogeneous;
            else
              continue; // goto homogeneous;
        else
          if(ptr[offset10] < c_b)
            if(ptr[offset11] < c_b)
              if(ptr[offset12] < c_b)
                if(ptr[offset13] < c_b)
                  {} // goto success_homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
      else
        if(ptr[offset8] < c_b)
          if(ptr[offset9] < c_b)
            if(ptr[offset10] < c_b)
              if(ptr[offset11] < c_b)
                if(ptr[offset12] < c_b)
                  if(ptr[offset13] < c_b)
                    {} // goto success_homogeneous;
                  else
                    continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
    continue; // goto homogeneous;
else
  if(ptr[offset12] > cb)
    if(ptr[offset7] > cb)
      if(ptr[offset8] > cb)
        if(ptr[offset9] > cb)
          if(ptr[offset10] > cb)
            if(ptr[offset11] > cb)
              if(ptr[offset13] > cb)
                if(ptr[offset14] > cb)
                  if(ptr[offset6] > cb)
                    {} // goto success_homogeneous;
                  else
                    if(ptr[offset15] > cb)
                      {} // goto success_homogeneous;
                    else
                      continue; // goto homogeneous;
                else
                  continue; // goto homogeneous;
              else
                continue; // goto homogeneous;
            else
              continue; // goto homogeneous;
          else
            continue; // goto homogeneous;
        else
          continue; // goto homogeneous;
      else
        continue; // goto homogeneous;
    else
      continue; // goto homogeneous;
  else
  if(ptr[offset12] < c_b)
    if(ptr[offset13] < c_b)
      if(ptr[offset14] < c_b)
        if(ptr[offset15] < c_b)
          if(ptr[offset1] < c_b)
            if(ptr[offset3] < c_b)
              {} // goto success_homogeneous;
```

----------------------------------------

TITLE: Configuring Multi-Architecture Build Options and Compiler Flags - CMake - CMake
DESCRIPTION: This CMake snippet manages feature detection, variable settings, option toggling, and compiler flags for various architectures such as ARM, PowerPC, RISC-V, IBM Z, and x86. It employs conditional logic to enable or disable SIMD and intrinsics optimizations, adjust compiler warning levels, and manage build-time options for compatibility with compilers like GCC, Clang, Intel, and MSVC. Dependencies include the presence of specific CMake modules (e.g., cmake_dependent_option), CMake version compatibility, and support for platform-specific compiler flags and options. Key parameters define architecture detection flags (e.g., BASEARCH_ARM_FOUND), feature toggles (e.g., WITH_NEON), advanced installation settings, and mechanisms for embedding version-specific build properties. Expected inputs are CMake variables preset by the host environment or toolchain, and outputs are build system configurations optimized for the target architecture. Some features (like AVX, LTO, VFPv4) are auto-detected, and unsupported environments (e.g., old MSVC or unknown architecture) are handled with error or status messages.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
# Add multi-choice option\nset(WITH_SANITIZER AUTO CACHE STRING \"Enable sanitizer support\")\nset_property(CACHE WITH_SANITIZER PROPERTY STRINGS \"Memory\" \"Address\" \"Undefined\" \"Thread\")\n\nif(BASEARCH_ARM_FOUND)\n    option(WITH_ACLE \"Build with ACLE\" ON)\n    option(WITH_NEON \"Build with NEON intrinsics\" ON)\n    cmake_dependent_option(WITH_ARMV6 \"Build with ARMv6 SIMD\" ON \"NOT ARCH STREQUAL \\\"aarch64\\\"\" OFF)\nelif(BASEARCH_PPC_FOUND)\n    option(WITH_ALTIVEC \"Build with AltiVec (VMX) optimisations for PowerPC\" ON)\n    option(WITH_POWER8 \"Build with optimisations for POWER8\" ON)\n    option(WITH_POWER9 \"Build with optimisations for POWER9\" ON)\nelif(BASEARCH_RISCV_FOUND)\n    option(WITH_RVV \"Build with RVV intrinsics\" ON)\nelif(BASEARCH_S360_FOUND)\n    option(WITH_DFLTCC_DEFLATE \"Build with DFLTCC intrinsics for compression on IBM Z\" OFF)\n    option(WITH_DFLTCC_INFLATE \"Build with DFLTCC intrinsics for decompression on IBM Z\" OFF)\n    option(WITH_CRC32_VX \"Build with vectorized CRC32 on IBM Z\" ON)\nelif(BASEARCH_X86_FOUND)\n    option(WITH_SSE2 \"Build with SSE2\" ON)\n    cmake_dependent_option(WITH_SSSE3 \"Build with SSSE3\" ON \"WITH_SSE2\" OFF)\n    cmake_dependent_option(WITH_SSE42 \"Build with SSE42\" ON \"WITH_SSSE3\" OFF)\n    cmake_dependent_option(WITH_PCLMULQDQ \"Build with PCLMULQDQ\" ON \"WITH_SSE42\" OFF)\n    cmake_dependent_option(WITH_AVX2 \"Build with AVX2\" ON \"WITH_SSE42\" OFF)\n    cmake_dependent_option(WITH_AVX512 \"Build with AVX512\" ON \"WITH_AVX2\" OFF)\n    cmake_dependent_option(WITH_AVX512VNNI \"Build with AVX512 VNNI extensions\" ON \"WITH_AVX512\" OFF)\n    cmake_dependent_option(WITH_VPCLMULQDQ \"Build with VPCLMULQDQ\" ON \"WITH_PCLMULQDQ;WITH_AVX512\" OFF)\nendif()\n\noption(INSTALL_UTILS \"Copy minigzip and minideflate during install\" OFF)\n\nset(ZLIB_BUILD_SHARED_LIBS OFF)\nset(SKIP_INSTALL_ALL ON)\nocv_warnings_disable(CMAKE_C_FLAGS -Wmissing-prototypes -Wmissing-declarations -Wundef -Wstrict-prototypes -Wtype-limits)\nocv_warnings_disable(CMAKE_C_FLAGS /wd4819 /wd4244 /wd4334)\n\nmark_as_advanced(FORCE\n    ZLIB_SYMBOL_PREFIX\n    WITH_REDUCED_MEM\n    WITH_ACLE WITH_NEON\n    WITH_ARMV6\n    WITH_DFLTCC_DEFLATE\n    WITH_DFLTCC_INFLATE\n    WITH_CRC32_VX\n    WITH_AVX2 WITH_SSE2\n    WITH_SSSE3 WITH_SSE42\n    WITH_PCLMULQDQ\n    WITH_ALTIVEC\n    WITH_POWER8\n    WITH_POWER9\n    WITH_RVV\n    WITH_INFLATE_STRICT\n    WITH_INFLATE_ALLOW_INVALID_DIST\n    WITH_UNALIGNED\n    INSTALL_UTILS\n    )\n\nif(ZLIB_COMPAT)\n    add_definitions(-DZLIB_COMPAT)\n    set(WITH_GZFILEOP ON)\n    set(SUFFIX \"\")\n    set(ZLIB_FULL_VERSION ${ZLIB_HEADER_VERSION}.zlib-ng)\n    set(EXPORT_NAME ZLIB)\nelse()\n    set(SUFFIX \"-ng\")\n    set(ZLIB_FULL_VERSION ${ZLIBNG_HEADER_VERSION})\n    set(EXPORT_NAME zlib-ng)\nendif()\n\nif(WITH_GZFILEOP)\n    add_definitions(-DWITH_GZFILEOP)\nendif()\n\nif(CMAKE_C_COMPILER_ID MATCHES \"^Intel\")\n    if(CMAKE_HOST_UNIX)\n        set(WARNFLAGS -Wall)\n        set(WARNFLAGS_MAINTAINER -Wall -Wcheck -Wremarks)\n        set(WARNFLAGS_DISABLE)\n    else()\n        set(WARNFLAGS /Wall)\n        set(WARNFLAGS_MAINTAINER /W5)\n        set(WARNFLAGS_DISABLE)\n    endif()\n    check_c_compiler_flag(-diag-disable=10441 HAVE_DIAG_10441)\n    if(HAVE_DIAG_10441)\n        list(APPEND WARNFLAGS_DISABLE \"-diag-disable=10441\")\n        set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -diag-disable=10441\")\n        set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} -diag-disable=10441\")\n    endif()\nelif(MSVC)\n    # Minimum supported MSVC version is 1800 = Visual Studio 12.0/2013\n    # See also https://cmake.org/cmake/help/latest/variable/MSVC_VERSION.html\n    if(MSVC_VERSION VERSION_LESS 1800)\n        message(SEND_ERROR \"Unsupported Visual Studio compiler version (requires 2013 or later).\")\n    endif()\n    # TODO. ICC can be used through MSVC. I'm not sure if we'd ever see that combination\n    # (who'd use cmake from an IDE...) but checking for ICC before checking for MSVC should\n    # avoid mistakes.\n    # /Oi ?\n    set(WARNFLAGS /W3)\n    set(WARNFLAGS_MAINTAINER /W4)\n    set(WARNFLAGS_DISABLE)\n    if(BASEARCH_ARM_FOUND)\n        add_definitions(-D_ARM_WINAPI_PARTITION_DESKTOP_SDK_AVAILABLE)\n        if(NOT \"${ARCH}\" MATCHES \"aarch64\")\n            set(NEONFLAG \"/arch:VFPv4\")\n        endif()\n    endif()\nelif(CMAKE_C_COMPILER_ID MATCHES \"GNU\" OR CMAKE_C_COMPILER_ID MATCHES \"Clang\")\n    # Enable warnings in GCC and Clang\n    set(WARNFLAGS -Wall)\n    set(WARNFLAGS_MAINTAINER -Wextra)\n    set(WARNFLAGS_DISABLE)\n    # Check whether -fno-lto is available\n    set(CMAKE_REQUIRED_FLAGS \"-fno-lto\")\n    check_c_source_compiles(\n        \"int main() { return 0; }\"\n        FNO_LTO_AVAILABLE FAIL_REGEX \"not supported\")\n    set(CMAKE_REQUIRED_FLAGS)\n    if(FNO_LTO_AVAILABLE)\n        set(ZNOLTOFLAG \"-fno-lto\")\n    endif()\n    if(NOT WITH_NATIVE_INSTRUCTIONS)\n        if(BASEARCH_ARM_FOUND)\n            if(\"${ARCH}\" MATCHES \"arm\" AND NOT CMAKE_C_FLAGS MATCHES \"-mfloat-abi\")\n                # Auto-detect support for ARM floating point ABI\n                check_include_file(features.h HAVE_FEATURES_H)\n                if(HAVE_FEATURES_H)\n                    set(CMAKE_REQUIRED_FLAGS -mfloat-abi=softfp)\n                    check_c_source_compiles(\n                        \"#include <features.h>\n                        int main() { return 0; }\"\n                        HAVE_FLOATABI_SOFTFP)\n                    if(HAVE_FLOATABI_SOFTFP)\n                        set(FLOATABI -mfloat-abi=softfp)\n                    else()\n                        set(CMAKE_REQUIRED_FLAGS -mfloat-abi=hard)\n                        check_c_source_compiles(\n                            \"#include <features.h>\n                            int main() { return 0; }\"\n                            HAVE_FLOATABI_HARD)\n                        if(HAVE_FLOATABI_HARD)\n                            set(FLOATABI -mfloat-abi=hard)\n                        endif()\n                    endif()\n                    set(CMAKE_REQUIRED_FLAGS)\n                endif()\n                if(FLOATABI)\n                    message(STATUS \"ARM floating point arch: ${FLOATABI}\")\n                    add_compile_options(${FLOATABI})\n                else()\n                    message(STATUS \"ARM floating point arch not auto-detected\")\n                endif()\n            endif()\n        endif()\n        # Disable LTO unless Native Instructions are enabled\n        if(FNO_LTO_AVAILABLE)\n            set(NOLTOFLAG ${ZNOLTOFLAG})\n        endif()\n    endif()\n    if(MINGW)\n        # Add `-Wno-pedantic-ms-format` only if the toolchain supports it\n        check_c_compiler_flag(-Wno-pedantic-ms-format HAVE_NO_PEDANTIC_MS_FORMAT)\n        if(HAVE_NO_PEDANTIC_MS_FORMAT)\n            list(APPEND WARNFLAGS_DISABLE -Wno-pedantic-ms-format)\n        endif()\n    endif()\nendif()\n\n# Set native march/mcpu\nif(WITH_NATIVE_INSTRUCTIONS)\n    if(NATIVE_ARCH_OVERRIDE)\n        message(STATUS \"WARNING: WITH_NATIVE_INSTRUCTIONS enabled, but running with NATIVE_ARCH_OVERRIDE: ${NATIVE_ARCH_OVERRIDE}\")\n        set(NATIVEFLAG \"${NATIVE_ARCH_OVERRIDE}\")\n    else()\n        if(CMAKE_C_COMPILER_ID MATCHES \"GNU\" OR CMAKE_C_COMPILER_ID MATCHES \"Clang\")\n            check_c_compiler_flag(-march=native HAVE_MARCH_NATIVE)\n            if(HAVE_MARCH_NATIVE)\n                set(NATIVEFLAG \"-march=native\")\n            else()\n                check_c_compiler_flag(-mcpu=native HAVE_MCPU_NATIVE)\n                if(HAVE_MCPU_NATIVE)\n                    set(NATIVEFLAG \"-mcpu=native\")\n                endif()\n            endif()\n            # Fall through\n        endif()\n    endif()\n    if(NATIVEFLAG)\n        # Apply flags to all source files and compilation checks\n        if(WIN32)\n            separate_arguments(NATIVEOPTIONS WINDOWS_COMMAND \"${NATIVEFLAG}\")\n        else()\n            separate_arguments(NATIVEOPTIONS UNIX_COMMAND \"${NATIVEFLAG}\")\n        endif()\n        add_compile_options(${NATIVEOPTIONS})\n        set(WITH_RUNTIME_CPU_DETECTION OFF)\n    else()\n        message(STATUS \"Ignoring WITH_NATIVE_INSTRUCTIONS; not implemented yet on this configuration\")\n        set(WITH_NATIVE_INSTRUCTIONS OFF)\n    endif()\nendif()\n\n# Compile without functable or CPU detection\nif(NOT WITH_RUNTIME_CPU_DETECTION)\n    if(MSVC AND BASEARCH_X86_FOUND)\n        message(STATUS \"WARNING: Microsoft Visual Studio does not support compile time detection of CPU features for \"/arch\" before \"AVX\"\")\n        # Workaround for MSVC. By default MSVC does not define the __SSE*__ macros.\n        # Fix it if AVX is enabled.\n        set(CMAKE_REQUIRED_FLAGS \"${NATIVEFLAG}\")\n        check_c_source_compiles(\n            \"#ifndef __AVX__\n            #  error \\\"AVX is not enabled.\\\"\n            #endif\n            int main(void) { return 0; }\"\n            MSVC_IS_ENABLED_AVX\n        )\n        set(CMAKE_REQUIRED_FLAGS)\n        if(MSVC_IS_ENABLED_AVX)\n            add_definitions(\n                -D__SSE__=1\n                -D__SSE2__=1\n                -D__SSE3__=1\n                -D__SSSE3__=1\n                -D__SSE4_1__=1\n                -D__SSE4_2__=1\n                -D__PCLMUL__=1\n            )\n        endif()\n    endif()\n    add_definitions(-DDISABLE_RUNTIME_CPU_DETECTION)\nendif()\n\n# Force disable LTO if WITH_NATIVE_INSTRUCTIONS is not active\nif(NOT WITH_NATIVE_INSTRUCTIONS)\n    set(CMAKE_INTERPROCEDURAL_OPTIMIZATION OFF)\n    foreach(_cfg_name IN LISTS CMAKE_CONFIGURATION_TYPES)\n        string(TOUPPER \"${_cfg_name}\" _cfg_name_uc)\n        set(CMAKE_INTERPROCEDURAL_OPTIMIZATION_${_cfg_name_uc} OFF)\n    endforeach()\nendif()\n\n# Set architecture alignment requirements\nif(NOT WITH_UNALIGNED)\n    add_definitions(-DNO_UNALIGNED)\n    message(STATUS \"Unaligned reads manually disabled\")\nendif()\n\n# Apply warning compiler flags\nif(WITH_MAINTAINER_WARNINGS)\n    add_compile_options(${WARNFLAGS} ${WARNFLAGS_MAINTAINER} ${WARNFLAGS_DISABLE})\nelse()\n    add_compile_options(${WARNFLAGS} ${WARNFLAGS_DISABLE})\nendif()\n\n# Set code coverage compiler flags\nif(WITH_CODE_COVERAGE)\n    add_code_coverage()\nendif()\n
```

----------------------------------------

TITLE: Checking for Large File Support in Zlib CMake Configuration
DESCRIPTION: Checks if the system supports off64_t type for large file operations and enables large file support if available. This allows Zlib to handle files larger than 2GB.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
check_type_size(off64_t OFF64_T)
if(HAVE_OFF64_T)
  add_definitions(-D_LARGEFILE64_SOURCE=1)
endif()
```

----------------------------------------

TITLE: Setting Android Test Resource Directory in CMake
DESCRIPTION: Specifies the resource directory for Android tests.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/android_test/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
set(ANDROID_TESTS_RES_DIR "'${OpenCV_SOURCE_DIR}/modules/java/test/common_test/res'" CACHE INTERNAL "")
```

----------------------------------------

TITLE: Configuring Android-Specific Settings for OpenCV Java Library in CMake
DESCRIPTION: Sets up Android-specific linking and post-build commands for the OpenCV Java library, including stripping debug information.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jni/CMakeLists.txt#2025-04-22_snippet_5

LANGUAGE: CMake
CODE:
```
if(ANDROID)
  ocv_target_link_libraries(${the_module} PUBLIC    jnigraphics  # for Mat <=> Bitmap converters
                                          INTERFACE jnigraphics
  )
  ocv_target_link_libraries(${the_module} PUBLIC    log dl z
                                          INTERFACE log dl z
  )

  # force strip library after the build command
  # because samples and tests will make a copy of the library before install
  if(NOT BUILD_WITH_DEBUG_INFO AND NOT CMAKE_BUILD_TYPE MATCHES "Debug")
    add_custom_command(TARGET ${the_module} POST_BUILD COMMAND ${CMAKE_STRIP} --strip-unneeded "$<TARGET_FILE:${the_module}>")
  endif()
endif()
```

----------------------------------------

TITLE: Cleaning Up Previous Objective-C Bindings Artifacts in CMake
DESCRIPTION: Removes any previously generated Objective-C bindings for macOS, iOS, and visionOS platforms to ensure a clean build. Forces re-running the generator by removing dependency helper files.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/generator/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
file(REMOVE_RECURSE "${OPENCV_OBJC_BINDINGS_DIR}/osx")
file(REMOVE "${OPENCV_DEPHELPER}/gen_opencv_objc_source_osx")  # force re-run after CMake
file(REMOVE_RECURSE "${OPENCV_OBJC_BINDINGS_DIR}/ios")
file(REMOVE "${OPENCV_DEPHELPER}/gen_opencv_objc_source_ios")  # force re-run after CMake
file(REMOVE_RECURSE "${OPENCV_OBJC_BINDINGS_DIR}/visionos")
file(REMOVE "${OPENCV_DEPHELPER}/gen_opencv_objc_source_visionos")  # force re-run after CMake
```

----------------------------------------

TITLE: Defining Library Target for libwebp in CMake
DESCRIPTION: This snippet defines the library target within CMake and adjusts its configuration based on threading support and platform-specific linker requirements. It also sets various properties related to warnings, output directories, and installation paths. The snippet uses OpenCV-specific utility functions for warning management and installation tasks.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libwebp/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: CMake
CODE:
```
if(NOT OPENCV_DISABLE_THREAD_SUPPORT)
  add_definitions(-DWEBP_USE_THREAD)
endif()

add_library(${WEBP_LIBRARY} STATIC ${OPENCV_3RDPARTY_EXCLUDE_FROM_ALL} ${lib_srcs} ${lib_hdrs})
if(ANDROID)
  target_link_libraries(${WEBP_LIBRARY} ${CPUFEATURES_LIBRARIES})
endif()

ocv_warnings_disable(CMAKE_C_FLAGS -Wunused-variable -Wunused-function -Wshadow -Wmaybe-uninitialized
    -Wmissing-prototypes  # clang
    -Wmissing-declarations # gcc
    -Wimplicit-fallthrough
    -Wunused-but-set-variable # clang15
)
ocv_warnings_disable(CMAKE_C_FLAGS /wd4244 /wd4267) # vs2005

set_target_properties(${WEBP_LIBRARY}
  PROPERTIES OUTPUT_NAME ${WEBP_LIBRARY}
  DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
  COMPILE_PDB_NAME ${WEBP_LIBRARY}
  COMPILE_PDB_NAME_DEBUG "${WEBP_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
  ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
  )

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${WEBP_LIBRARY} PROPERTIES FOLDER "3rdparty")
endif()

if(NOT BUILD_SHARED_LIBS)
  ocv_install_target(${WEBP_LIBRARY} EXPORT OpenCVModules ARCHIVE DESTINATION ${OPENCV_3P_LIB_INSTALL_PATH} COMPONENT dev OPTIONAL)
endif()
```

----------------------------------------

TITLE: Initializing Doxygen Blacklist and Unsetting Variables in CMake
DESCRIPTION: Sets a CMake variable `blacklist` using the value of `DOXYGEN_BLACKLIST` and appends specific modules ('ts', 'world') that should be excluded from documentation. It also unsets CMake variables related to tutorial roots to ensure they are initialized correctly later.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
# not documented modules list
set(blacklist "${DOXYGEN_BLACKLIST}")
list(APPEND blacklist "ts" "world")
unset(CMAKE_DOXYGEN_TUTORIAL_CONTRIB_ROOT)
unset(CMAKE_DOXYGEN_TUTORIAL_JS_ROOT)
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree in C++
DESCRIPTION: A portion of the FAST corner detection algorithm that evaluates whether a pixel is a corner based on intensity comparisons with neighboring pixels. The code uses an efficient nested if-else structure with goto statements to branch to 'is_a_corner' or 'is_not_a_corner' labels based on intensity threshold conditions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_41

LANGUAGE: C++
CODE:
```
                                  goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset6] < c_b)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset8] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset3] > cb)
                                    goto is_a_corner;
                                  else
                                    if(ptr[offset10] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  if(ptr[offset2] > cb)
                    if(ptr[offset9] < c_b)
                      if(ptr[offset1] > cb)
                        if(ptr[offset6] < c_b)
                          goto is_not_a_corner;
                        else
                          if(ptr[offset6] > cb)
                            if(ptr[offset3] > cb)
                              if(ptr[offset4] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset1] < c_b)
                          if(ptr[offset6] < c_b)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset8] > cb)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset6] < c_b)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset8] > cb)
                                    goto is_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                    else
                      if(ptr[offset9] > cb)
                        if(ptr[offset1] < c_b)
                          if(ptr[offset6] < c_b)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset8] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset3] > cb)
                                    goto is_a_corner;
                                  else
                                    if(ptr[offset10] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  if(ptr[offset10] > cb)
                                    if(ptr[offset11] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset1] > cb)
                            if(ptr[offset6] < c_b)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset4] > cb)
                                  if(ptr[offset3] > cb)
                                    goto is_a_corner;
                                  else
                                    if(ptr[offset8] > cb)
                                      if(ptr[offset10] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  if(ptr[offset8] > cb)
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset6] < c_b)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset8] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset3] > cb)
                                      goto is_a_corner;
                                    else
                                      if(ptr[offset10] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                  else
                                    if(ptr[offset10] > cb)
                                      if(ptr[offset11] > cb)
                                        goto is_a_corner;
                                      else
                                        goto is_not_a_corner;
                                    else
                                      goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                      else
                        if(ptr[offset1] > cb)
                          if(ptr[offset6] < c_b)
                            goto is_not_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset3] > cb)
                                if(ptr[offset4] > cb)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset1] < c_b)
                            if(ptr[offset6] < c_b)
                              goto is_not_a_corner;
                            else
                              if(ptr[offset6] > cb)
                                if(ptr[offset3] > cb)
                                  if(ptr[offset4] > cb)
                                    if(ptr[offset8] > cb)
                                      goto is_a_corner;
                                    else
                                      goto is_not_a_corner;
                                  else
                                    goto is_not_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            if(ptr[offset6] < c_b)
                              goto is_not_a_corner;
                            else
```

----------------------------------------

TITLE: Disabling Specific MSVC Compiler Warnings in CMake
DESCRIPTION: Conditionally disables specific Microsoft Visual C++ (MSVC) compiler warnings based on the MSVC version and target architecture. It disables C4503 (decorated name length exceeded) and C4996 (deprecated code) for older MSVC versions, and C4702 (unreachable code) for MSVC 2015/2017 or when targeting ARM/AARCH64.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: cmake
CODE:
```
if(MSVC)
  if(MSVC_VERSION LESS 1910)
    # Disable obsolete warning C4503 popping up on MSVC << 15 2017
    # https://docs.microsoft.com/en-us/cpp/error-messages/compiler-warnings/compiler-warning-level-1-c4503?view=vs-2019
    # and IE deprecated code warning C4996
    ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4503 /wd4996)
  endif()
  if((MSVC_VERSION LESS 1920) OR ARM OR AARCH64) # MSVS 2015/2017 on x86 and ARM
    ocv_warnings_disable(CMAKE_CXX_FLAGS /wd4702)  # 'unreachable code'
  endif()
endif()
```

----------------------------------------

TITLE: Performing Post-Status Verification and Cleanup in CMake
DESCRIPTION: This CMake code conditionally runs configuration verification using the custom function `ocv_verify_config` if the `ENABLE_CONFIG_VERIFICATION` variable is set. It also executes a specific CUDA clean target (`CUDA_BUILD_CLEAN_TARGET`) if CUDA (`HAVE_CUDA`) is enabled and the target command exists. Finally, it runs a `POST_FINALIZE` hook using `ocv_cmake_hook` for any necessary post-finalization actions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_32

LANGUAGE: cmake
CODE:
```
if(ENABLE_CONFIG_VERIFICATION)
  ocv_verify_config()
endif()

if(HAVE_CUDA AND COMMAND CUDA_BUILD_CLEAN_TARGET)
  CUDA_BUILD_CLEAN_TARGET()
endif()

ocv_cmake_hook(POST_FINALIZE)
```

----------------------------------------

TITLE: Implementing Corner Detection Logic in C++
DESCRIPTION: This snippet implements the core logic for corner detection using pixel value comparisons. It uses nested if-else statements to check pixel values at different offsets and determine if a point is a corner.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_30

LANGUAGE: C++
CODE:
```
else
  if(ptr[offset8] < c_b)
    if(ptr[offset10] < c_b)
      if(ptr[offset11] < c_b)
        goto is_a_corner;
      else
        goto is_not_a_corner;
    else
      goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  if(ptr[offset11] < c_b)
    if(ptr[offset3] < c_b)
      if(ptr[offset4] < c_b)
        goto is_a_corner;
      else
        if(ptr[offset10] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
    else
      if(ptr[offset8] < c_b)
        if(ptr[offset10] < c_b)
          goto is_a_corner;
        else
          goto is_not_a_corner;
      else
        goto is_not_a_corner;
  else
    goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  goto is_not_a_corner;
else
  if(ptr[offset2] > cb)
    goto is_not_a_corner;
  else
    if(ptr[offset2] < c_b)
      if(ptr[offset7] > cb)
        if(ptr[offset1] > cb)
          goto is_not_a_corner;
        else
          if(ptr[offset1] < c_b)
            if(ptr[offset6] < c_b)
              if(ptr[offset3] < c_b)
                if(ptr[offset4] < c_b)
                  goto is_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset11] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
          else
            goto is_not_a_corner;
      else
        if(ptr[offset7] < c_b)
          if(ptr[offset1] > cb)
            if(ptr[offset6] > cb)
              goto is_not_a_corner;
            else
              if(ptr[offset6] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    if(ptr[offset8] < c_b)
                      goto is_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
            if(ptr[offset1] < c_b)
              if(ptr[offset6] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
            else
              if(ptr[offset6] > cb)
                goto is_not_a_corner;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      if(ptr[offset8] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
        else
          if(ptr[offset1] > cb)
            goto is_not_a_corner;
          else
            if(ptr[offset1] < c_b)
              if(ptr[offset6] < c_b)
                if(ptr[offset3] < c_b)
                  if(ptr[offset4] < c_b)
                    goto is_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                if(ptr[offset6] > cb)
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  if(ptr[offset3] < c_b)
                    if(ptr[offset4] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
            else
              goto is_not_a_corner;
    else
      goto is_not_a_corner;
else
  if(ptr[offset5] > cb)
    if(ptr[offset2] > cb)
      if(ptr[offset7] < c_b)
        if(ptr[offset9] > cb)
          goto is_not_a_corner;
        else
          if(ptr[offset9] < c_b)
            if(ptr[offset1] > cb)
              if(ptr[offset6] > cb)
                goto is_not_a_corner;
              else
                if(ptr[offset6] < c_b)
                  if(ptr[offset8] < c_b)
                    if(ptr[offset10] < c_b)
                      if(ptr[offset11] < c_b)
                        goto is_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
            else
```

----------------------------------------

TITLE: Configuring x86 SSE4.2 Optimizations for ZLIB in CMake
DESCRIPTION: Checks if SSE4.2 optimization is enabled (WITH_SSE42), if intrinsics are available (HAVE_SSE42_INTRIN), and if SSSE3 is also enabled. If conditions are met, it adds the DX86_SSE42 definition, appends the SSE4.2-specific adler32 source file to ZLIB_ARCH_SRCS, adds feature information, and sets compile flags (SSE42FLAG, NOLTOFLAG). Otherwise, it disables SSE4.2 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_28

LANGUAGE: cmake
CODE:
```
        if(WITH_SSE42)
            check_sse42_intrinsics()
            if(HAVE_SSE42_INTRIN AND WITH_SSSE3)
                add_definitions(-DX86_SSE42)
                set(SSE42_SRCS ${ARCHDIR}/adler32_sse42.c)
                add_feature_info(SSE42_CRC 1 "Support SSE4.2 optimized adler32 hash generation, using \"${SSE42FLAG}\"")
                list(APPEND ZLIB_ARCH_SRCS ${SSE42_SRCS})
                set_property(SOURCE ${SSE42_SRCS} PROPERTY COMPILE_FLAGS "${SSE42FLAG} ${NOLTOFLAG}")
            else()
                set(WITH_SSE42 OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Setting Up Python Virtual Environment for OpenCV DNN - Console
DESCRIPTION: This snippet creates and activates a Python 3.7+ virtual environment required for OpenCV DNN experiments. The first command makes a new environment, and the second one activates it. Ensure that 'virtualenv' is installed beforehand.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/dnn/dnn_pytorch_tf_detection/tf_det_model_conversion_tutorial.md#2025-04-22_snippet_0

LANGUAGE: console
CODE:
```
virtualenv -p /usr/bin/python3.7 <env_dir_path>\nsource <env_dir_path>/bin/activate
```

----------------------------------------

TITLE: Installing OpenCV Java JAR and Configuring Documentation
DESCRIPTION: Sets up installation of the OpenCV Java JAR file and configures the documentation generation process based on the build type (Ant or Java).
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/jar/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
install(FILES ${OPENCV_JAR_FILE} OPTIONAL DESTINATION ${OPENCV_JAR_INSTALL_PATH} COMPONENT java)

add_dependencies(${the_module} ${the_module}_jar)

if(BUILD_DOCS)
  if(OPENCV_JAVA_SDK_BUILD_TYPE STREQUAL "ANT")
    add_custom_command(OUTPUT "${OPENCV_DEPHELPER}/${the_module}doc"
      COMMAND ${ANT_EXECUTABLE} -noinput -k javadoc
      COMMAND ${CMAKE_COMMAND} -E touch "${OPENCV_DEPHELPER}/${the_module}doc"
      WORKING_DIRECTORY "${OPENCV_JAVA_DIR}"
      DEPENDS ${depends}
      COMMENT "Generating Javadoc"
    )
    add_custom_target(${the_module}doc DEPENDS "${OPENCV_DEPHELPER}/${the_module}doc")

    install(DIRECTORY ${OpenCV_BINARY_DIR}/doc/doxygen/html/javadoc
      DESTINATION "${OPENCV_DOC_INSTALL_PATH}/html"
      COMPONENT "docs" OPTIONAL
      ${compatible_MESSAGE_NEVER}
    )
  elseif(OPENCV_JAVA_SDK_BUILD_TYPE STREQUAL "JAVA")
    set(Java_JAVADOC_EXECUTABLE ${Java_JAVADOC_EXECUTABLE} -encoding utf-8)

    create_javadoc(${the_module}
      FILES "@${OPENCV_JAVA_DIR}/java_sources"
      SOURCEPATH "${OPENCV_JAVA_DIR}/java"
      INSTALLPATH "${OPENCV_JAVADOC_DESTINATION}"
      WINDOWTITLE "OpenCV ${OPENCV_VERSION_PLAIN} Java documentation"
      DOCTITLE "OpenCV Java documentation (${OPENCV_VERSION})"
      VERSION TRUE
    )
    add_dependencies(${the_module}_javadoc ${the_module}_jar_sources)
    add_custom_target(${the_module}doc DEPENDS ${the_module}_javadoc)

    install(DIRECTORY ${OpenCV_BINARY_DIR}/doc/doxygen/html/javadoc/${the_module}/
      DESTINATION "${OPENCV_DOC_INSTALL_PATH}/html/javadoc"
      COMPONENT "docs" OPTIONAL
      ${compatible_MESSAGE_NEVER}
    )
  else()
    ocv_assert(0)
  endif()

  set(CMAKE_DOXYGEN_JAVADOC_NODE
    "<tab type=\"user\" url=\"./javadoc/index.html\" title=\"Java documentation\"/>"
    CACHE INTERNAL "Link to the Java documentation") # set to the cache to make it global
  add_custom_target(doxygen_javadoc DEPENDS ${the_module}doc)
  add_dependencies(opencv_docs ${the_module}doc)
else()
  unset(CMAKE_DOXYGEN_JAVADOC_NODE CACHE)
endif()
```

----------------------------------------

TITLE: Configure Debugging and Optimization Options in CMake
DESCRIPTION: The snippet configures compile options based on the build type and compiler (e.g., adding ZLIB_DEBUG for debug builds). It also distinguishes settings for MSVC and x86 architecture, adding specific options to enforce SSE2 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_14

LANGUAGE: CMake
CODE:
```
add_compile_options($<$<CONFIG:Debug>:-DZLIB_DEBUG>)

if(MSVC)
    set(CMAKE_DEBUG_POSTFIX "d")
    add_definitions(-D_CRT_SECURE_NO_DEPRECATE)
    add_definitions(-D_CRT_NONSTDC_NO_DEPRECATE)
endif()

if(BASEARCH_X86_FOUND)
    # FORCE_SSE2 option will only be shown if HAVE_SSE2_INTRIN is true
    if("${ARCH}" MATCHES "i[3-6]86")
        cmake_dependent_option(FORCE_SSE2 "Always assume CPU is SSE2 capable" OFF "HAVE_SSE2_INTRIN" OFF)
    endif()
endif()
```

----------------------------------------

TITLE: Adding ZLIB Dependency for Apple Platforms in CMake
DESCRIPTION: Checks if the target platform is Apple (`APPLE` variable is true). If so, it adds the ZLIB include directories (obtained from the `ZLIB_INCLUDE_DIRS` variable) using `ocv_include_directories` and appends the ZLIB libraries (from `ZLIB_LIBRARIES`) to the `HIGHGUI_LIBRARIES` list. This ensures ZLIB is correctly linked when building highgui on macOS or iOS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
if(APPLE)
  ocv_include_directories(${ZLIB_INCLUDE_DIRS})
  list(APPEND HIGHGUI_LIBRARIES ${ZLIB_LIBRARIES})
endif()
```

----------------------------------------

TITLE: XML Output of Camera Calibration Results
DESCRIPTION: This XML snippet shows the structure of the output file containing camera matrix and distortion coefficients after calibration in OpenCV.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/calib3d/camera_calibration/camera_calibration.markdown#2025-04-22_snippet_13

LANGUAGE: xml
CODE:
```
<camera_matrix type_id="opencv-matrix">
<rows>3</rows>
<cols>3</cols>
<dt>d</dt>
<data>
 6.5746697944293521e+002 0. 3.1950000000000000e+002 0.
 6.5746697944293521e+002 2.3950000000000000e+002 0. 0. 1.</data></camera_matrix>
<distortion_coefficients type_id="opencv-matrix">
<rows>5</rows>
<cols>1</cols>
<dt>d</dt>
<data>
 -4.1802327176423804e-001 5.0715244063187526e-001 0. 0.
 -5.7843597214487474e-001</data></distortion_coefficients>
```

----------------------------------------

TITLE: Generating OpenCV for Windows Store 8.1 x86 using CMake
DESCRIPTION: Invokes CMake directly to generate Visual Studio 2013 project files for OpenCV targeting Windows Store 8.1 on the x86 architecture. Specifies the generator, system name (WindowsStore), and system version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013" -DCMAKE_SYSTEM_NAME=WindowsStore -DCMAKE_SYSTEM_VERSION=8.1 <path-to-source>
```

----------------------------------------

TITLE: FAST Corner Detection Decision Tree Implementation in C++
DESCRIPTION: This snippet is part of a decision tree that examines pixel values (ptr[offset]) against brightness thresholds (c_b and cb) to determine if a point in an image is a corner. The algorithm branches extensively based on comparisons of pixel intensities at various offsets, leading to either 'is_a_corner' or 'is_not_a_corner' labels.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/features2d/doc/agast_score.txt#2025-04-22_snippet_4

LANGUAGE: C++
CODE:
```
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
              if(ptr[offset11] < c_b)
                if(ptr[offset7] < c_b)
                  if(ptr[offset8] < c_b)
                    if(ptr[offset9] < c_b)
                      if(ptr[offset10] < c_b)
                        if(ptr[offset12] < c_b)
                          if(ptr[offset13] < c_b)
                            if(ptr[offset6] < c_b)
                              if(ptr[offset5] < c_b)
                                goto is_a_corner;
                              else
                                if(ptr[offset14] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                            else
                              if(ptr[offset14] < c_b)
                                if(ptr[offset15] < c_b)
                                  goto is_a_corner;
                                else
                                  goto is_not_a_corner;
                              else
                                goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                  else
                    goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
          else
          if(ptr[offset2] < c_b)
            if(ptr[offset9] > cb)
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset12] > cb)
                      if(ptr[offset13] > cb)
                        if(ptr[offset14] > cb)
                          if(ptr[offset15] > cb)
                            goto is_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset5] > cb)
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset4] > cb)
                          if(ptr[offset5] > cb)
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset3] > cb)
                        if(ptr[offset4] > cb)
                          if(ptr[offset5] > cb)
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset1] > cb)
                      if(ptr[offset12] > cb)
                        if(ptr[offset13] > cb)
                          if(ptr[offset14] > cb)
                            if(ptr[offset15] > cb)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
            if(ptr[offset9] < c_b)
              if(ptr[offset7] < c_b)
                if(ptr[offset8] < c_b)
                  if(ptr[offset6] < c_b)
                    if(ptr[offset5] < c_b)
                      if(ptr[offset4] < c_b)
                        if(ptr[offset3] < c_b)
                          if(ptr[offset1] < c_b)
                            goto is_a_corner;
                          else
                            if(ptr[offset10] < c_b)
                              goto is_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset10] < c_b)
                            if(ptr[offset11] < c_b)
                              if(ptr[offset12] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset10] < c_b)
                          if(ptr[offset11] < c_b)
                            if(ptr[offset12] < c_b)
                              if(ptr[offset13] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                    else
                      if(ptr[offset10] < c_b)
                        if(ptr[offset11] < c_b)
                          if(ptr[offset12] < c_b)
                            if(ptr[offset13] < c_b)
                              if(ptr[offset14] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                  else
                    if(ptr[offset10] < c_b)
                      if(ptr[offset11] < c_b)
                        if(ptr[offset12] < c_b)
                          if(ptr[offset13] < c_b)
                            if(ptr[offset14] < c_b)
                              if(ptr[offset15] < c_b)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                        else
                          goto is_not_a_corner;
                      else
                        goto is_not_a_corner;
                    else
                      goto is_not_a_corner;
                else
                  goto is_not_a_corner;
              else
                goto is_not_a_corner;
            else
              goto is_not_a_corner;
          else
            if(ptr[offset9] > cb)
              if(ptr[offset10] > cb)
                if(ptr[offset11] > cb)
                  if(ptr[offset8] > cb)
                    if(ptr[offset12] > cb)
                      if(ptr[offset13] > cb)
                        if(ptr[offset14] > cb)
                          if(ptr[offset15] > cb)
                            goto is_a_corner;
                          else
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                        else
                          if(ptr[offset5] > cb)
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
                                goto is_a_corner;
                              else
                                goto is_not_a_corner;
                            else
                              goto is_not_a_corner;
                          else
                            goto is_not_a_corner;
                      else
                        if(ptr[offset4] > cb)
                          if(ptr[offset5] > cb)
                            if(ptr[offset6] > cb)
                              if(ptr[offset7] > cb)
```

----------------------------------------

TITLE: Build Configuration and Options
DESCRIPTION: Defines build type settings and numerous compilation options for customizing the build process with various features and optimizations
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
get_property(GENERATOR_IS_MULTI_CONFIG GLOBAL PROPERTY GENERATOR_IS_MULTI_CONFIG)
if(NOT GENERATOR_IS_MULTI_CONFIG)
    if(NOT CMAKE_BUILD_TYPE)
        set(CMAKE_BUILD_TYPE "Release" CACHE STRING
            "Choose the type of build, standard options are: Debug Release RelWithDebInfo MinSizeRel."
            FORCE)
        add_feature_info(CMAKE_BUILD_TYPE 1 "Build type: ${CMAKE_BUILD_TYPE} (default)")
    else()
        add_feature_info(CMAKE_BUILD_TYPE 1 "Build type: ${CMAKE_BUILD_TYPE} (selected)")
    endif()
endif()
```

----------------------------------------

TITLE: Checking Host Architecture with DPKG (Bash)
DESCRIPTION: Displays the native architecture of the host system as recognized by `dpkg`. The example output `amd64` indicates a standard 64-bit x86 system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_8

LANGUAGE: bash
CODE:
```
sudo dpkg --print-architecture
amd64
```

----------------------------------------

TITLE: Configuring x86 VPCLMULQDQ Optimization for ZLIB in CMake
DESCRIPTION: Checks if VPCLMULQDQ optimization is enabled (WITH_VPCLMULQDQ), if intrinsics are available (HAVE_VPCLMULQDQ_INTRIN), and if PCLMULQDQ and AVX512 are also enabled. If supported, it adds the DX86_VPCLMULQDQ_CRC definition for CRC32 calculation, appends the specific source file (`crc32_vpclmulqdq.c`), adds feature information, and sets compile flags (PCLMULFLAG, VPCLMULFLAG, AVX512FLAG, NOLTOFLAG). Otherwise, it disables VPCLMULQDQ support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_33

LANGUAGE: cmake
CODE:
```
        if(WITH_VPCLMULQDQ)
            check_vpclmulqdq_intrinsics()
            if(HAVE_VPCLMULQDQ_INTRIN AND WITH_PCLMULQDQ AND WITH_AVX512)
                add_definitions(-DX86_VPCLMULQDQ_CRC)
                set(VPCLMULQDQ_SRCS ${ARCHDIR}/crc32_vpclmulqdq.c)
                add_feature_info(VPCLMUL_CRC 1 "Support CRC hash generation using VPCLMULQDQ, using \"${PCLMULFLAG} ${VPCLMULFLAG} ${AVX512FLAG}\"")
                list(APPEND ZLIB_ARCH_SRCS ${VPCLMULQDQ_SRCS})
                set_property(SOURCE ${VPCLMULQDQ_SRCS} PROPERTY COMPILE_FLAGS "${PCLMULFLAG} ${VPCLMULFLAG} ${AVX512FLAG} ${NOLTOFLAG}")
            else()
                set(WITH_VPCLMULQDQ OFF)
            endif()
        endif()
    endif()
endif()
```

----------------------------------------

TITLE: Including Plugin CMake Script
DESCRIPTION: Includes another CMake script located at `cmake/plugin.cmake` relative to the current script's directory (`CMAKE_CURRENT_LIST_DIR`). This likely incorporates common logic or configurations related to plugin handling within the OpenCV build system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: cmake
CODE:
```
include(${CMAKE_CURRENT_LIST_DIR}/cmake/plugin.cmake)
```

----------------------------------------

TITLE: Setting JAVA_HOME Before Running CMake (Bash)
DESCRIPTION: This Bash snippet demonstrates how to set the JAVA_HOME environment variable before running CMake. This is necessary if CMake cannot automatically locate the Java Development Kit (JDK) installation required for building the Java bindings. Replace the path with the actual JDK installation directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/desktop_java/java_dev_intro.markdown#2025-04-22_snippet_3

LANGUAGE: bash
CODE:
```
export JAVA_HOME=/usr/lib/jvm/java-6-oracle
cmake -DBUILD_SHARED_LIBS=OFF ..
```

----------------------------------------

TITLE: DirectShow Configuration Option in OpenCV
DESCRIPTION: Defines the WITH_DSHOW build option for Windows platforms to enable the older DirectShow framework for camera frame capture. This option is deprecated in favor of MSMF.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/config_reference/config_reference.markdown#2025-04-22_snippet_14

LANGUAGE: markdown
CODE:
```
`WITH_DSHOW` (Windows; default: _ON_)
```

----------------------------------------

TITLE: Configuring Thread Support for OpenCV ts Module in CMake
DESCRIPTION: Disables thread support in the ts module if OPENCV_DISABLE_THREAD_SUPPORT is set, by defining GTEST_HAS_PTHREAD=0.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ts/CMakeLists.txt#2025-04-22_snippet_2

LANGUAGE: CMake
CODE:
```
if(OPENCV_DISABLE_THREAD_SUPPORT)
  # This is required to disable threads in the ts module, as
  # described in `ts_gtest.h`.
  ocv_target_compile_definitions(${the_module} PUBLIC GTEST_HAS_PTHREAD=0)
endif()
```

----------------------------------------

TITLE: Configuring OpenCV 2.4 Build for Jetson TK1 using CMake (Shell)
DESCRIPTION: Runs CMake to configure the OpenCV 2.4 build specifically for the NVIDIA Jetson TK1 platform (L4T). It sets build type to Release, enables CUDA 6.5 for architecture 3.2, enables Python 2 bindings (`BUILD_opencv_python`), NEON, TBB, and FFMPEG, while disabling several other optional dependencies (PNG, TIFF, Jasper, ZLIB, Java, nonfree modules, OpenCL, OpenMP, GStreamer, VTK, 1394, OpenEXR) and specifying the test data path. Assumes execution from a build directory sibling to `opencv` and `opencv_extra`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/building_tegra_cuda/building_tegra_cuda.markdown#2025-04-22_snippet_15

LANGUAGE: Shell
CODE:
```
$ cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_JAVA=OFF \
    -DBUILD_opencv_nonfree=OFF \
    -DBUILD_opencv_python=ON \
    -DENABLE_NEON=ON \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=OFF \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-6.5 \
    -DCUDA_ARCH_BIN=3.2 \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=ON \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../opencv
```

----------------------------------------

TITLE: Configuring x86 AVX512 Optimizations for ZLIB in CMake
DESCRIPTION: Checks if AVX512 optimization is enabled (WITH_AVX512), if intrinsics are available (HAVE_AVX512_INTRIN), and if AVX2 is also enabled. If supported, it adds the DX86_AVX512 definition, appends the AVX512 adler32 source and header files, adds feature information, and sets compile flags (AVX512FLAG, NOLTOFLAG). Otherwise, it disables AVX512 support.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_31

LANGUAGE: cmake
CODE:
```
        if(WITH_AVX512)
            check_avx512_intrinsics()
            if(HAVE_AVX512_INTRIN AND WITH_AVX2)
                add_definitions(-DX86_AVX512)
                list(APPEND AVX512_SRCS ${ARCHDIR}/adler32_avx512.c)
                add_feature_info(AVX512_ADLER32 1 "Support AVX512-accelerated adler32, using \"${AVX512FLAG}\"")
                list(APPEND ZLIB_ARCH_SRCS ${AVX512_SRCS})
                list(APPEND ZLIB_ARCH_HDRS ${ARCHDIR}/adler32_avx512_p.h)
                set_property(SOURCE ${AVX512_SRCS} PROPERTY COMPILE_FLAGS "${AVX512FLAG} ${NOLTOFLAG}")
            else()
                set(WITH_AVX512 OFF)
            endif()
        endif()
```

----------------------------------------

TITLE: Conditionally Exiting Build Script in CMake
DESCRIPTION: Checks if the `BUILD_EXAMPLES` variable is false or if the `OCV_DEPENDENCIES_FOUND` variable (set by `ocv_check_dependencies`) is false. If either condition is true, it stops processing the current CMake script using `return()`, effectively skipping the build of GPU samples.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/gpu/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
if(NOT BUILD_EXAMPLES OR NOT OCV_DEPENDENCIES_FOUND)
  return()
endif()
```

----------------------------------------

TITLE: Configuring x86 XSAVE Intrinsics Support for ZLIB in CMake
DESCRIPTION: Checks for x86 XSAVE intrinsics support (HAVE_XSAVE_INTRIN). If available, it adds feature information, sets compile flags for the x86 features source file (if runtime detection is enabled), and adds the DX86_HAVE_XSAVE_INTRIN definition unless using GCC versions older than 8.2.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_25

LANGUAGE: cmake
CODE:
```
        check_xsave_intrinsics()
        if(HAVE_XSAVE_INTRIN)
            add_feature_info(XSAVE 1 "Support XSAVE intrinsics using \"${XSAVEFLAG}\"")
            if(WITH_RUNTIME_CPU_DETECTION)
                set_property(SOURCE ${ARCHDIR}/x86_features.c PROPERTY COMPILE_FLAGS "${XSAVEFLAG}")
            endif()
            if(NOT (CMAKE_C_COMPILER_ID MATCHES "GNU" AND CMAKE_C_COMPILER_VERSION VERSION_LESS 8.2))
                add_definitions(-DX86_HAVE_XSAVE_INTRIN)
            endif()
        endif()
```

----------------------------------------

TITLE: Checking for Additional System Header Files in CMake
DESCRIPTION: Uses the standard `CHECK_INCLUDE_FILE` CMake command directly (without the custom macro) to check for the presence of several POSIX/Unix-specific header files (`strings.h`, `sys/stat.h`, `sys/types.h`, `unistd.h`). The results are stored in corresponding `HAVE_*` variables.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: cmake
CODE:
```
# why check this one ? for openjpip ?
CHECK_INCLUDE_FILE("strings.h"      HAVE_STRINGS_H)
CHECK_INCLUDE_FILE("sys/stat.h"     HAVE_SYS_STAT_H)
CHECK_INCLUDE_FILE("sys/types.h"    HAVE_SYS_TYPES_H)
CHECK_INCLUDE_FILE("unistd.h"       HAVE_UNISTD_H)
```

----------------------------------------

TITLE: Iterating Through OpenCV Modules for Java Bindings Configuration in CMake
DESCRIPTION: This loop iterates through the list of OpenCV modules specified in the `OPENCV_JAVA_MODULES` variable. For each module, it appends the module's header files and any files found in its `misc/java` directory to the `deps` list. It also constructs a JSON fragment (`__modules_config`) containing the module's sanitized name and relative location. Finally, it calls `ocv_remap_files` to process any template files found within the module's `misc/java` directory.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/generator/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: cmake
CODE:
```
set(__modules_config "") # list of OpenCV modules
foreach(m ${OPENCV_JAVA_MODULES})
  set(module_java_dir "${OPENCV_MODULE_${m}_LOCATION}/misc/java")
  list(APPEND deps ${OPENCV_MODULE_${m}_HEADERS})
  file(GLOB_RECURSE misc_files "${module_java_dir}/*")
  list(APPEND deps ${misc_files})

  string(REGEX REPLACE "^opencv_" "" m_ "${m}")
  if(__modules_config)
    set(__modules_config "${__modules_config},\\n")
  endif()
  file(RELATIVE_PATH rel_path "${OpenCV_SOURCE_DIR}" "${OPENCV_MODULE_${m}_LOCATION}")
  set(__modules_config "${__modules_config}    { \"name\": \"${m_}\", \"location\": \"${rel_path}\" }")

  ocv_remap_files(misc_files)
endforeach(m)
```

----------------------------------------

TITLE: Organizing CMake Project Structure with Solution Folders
DESCRIPTION: This snippet assigns the built libtiff library to a solution folder named '3rdparty' for better project organization when using supported IDEs. This structural organization aids in managing large projects by grouping related components.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libtiff/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: CMake
CODE:
```
if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${TIFF_LIBRARY} PROPERTIES FOLDER "3rdparty")
endif()
```

----------------------------------------

TITLE: Building OpenCV Documentation using Make Doxygen (Shell)
DESCRIPTION: Executes the `doxygen` target using `make` within the build directory. This command processes the source code comments and configuration files to generate HTML documentation for the OpenCV library, typically outputting to `build/doc/doxygen/html/index.html`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_setup/py_setup_in_fedora/py_setup_in_fedora.markdown#2025-04-22_snippet_18

LANGUAGE: sh
CODE:
```
make doxygen
```

----------------------------------------

TITLE: Checking for fseeko Function in Zlib CMake Configuration
DESCRIPTION: Checks if the fseeko function exists in the system and adds a definition to disable it if not available. This is important for handling large files in Zlib.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
check_function_exists(fseeko HAVE_FSEEKO)
if(NOT HAVE_FSEEKO)
  add_definitions(-DNO_FSEEKO)
endif()
```

----------------------------------------

TITLE: Creating OpenCV Java Test Target in CMake
DESCRIPTION: Creates the main target for building OpenCV Java tests. It sets up dependencies and configures project properties for solution folders if enabled.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/java/test/pure_test/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: CMake
CODE:
```
add_custom_target(${PROJECT_NAME} ALL
    DEPENDS ${the_module} "${OPENCV_JAVA_TEST_DIR}/build/jar/opencv-test.jar"
    SOURCES "${CMAKE_CURRENT_SOURCE_DIR}/build.xml"
)

if(ENABLE_SOLUTION_FOLDERS)
  set_target_properties(${PROJECT_NAME} PROPERTIES FOLDER "tests accuracy")
endif()

add_dependencies(opencv_tests ${PROJECT_NAME})
```

----------------------------------------

TITLE: NASM Assembly Configuration for x86/x86-64
DESCRIPTION: Configures NASM assembly compilation for x86 and x86-64 architectures, including object format detection, debug flags, and platform-specific settings
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(CPU_TYPE STREQUAL "x86_64" OR CPU_TYPE STREQUAL "i386")

set(CMAKE_ASM_NASM_FLAGS_DEBUG_INIT "-g")
set(CMAKE_ASM_NASM_FLAGS_RELWITHDEBINFO_INIT "-g")

if(NOT DEFINED CMAKE_ASM_NASM_COMPILER AND DEFINED ENV{ASM_NASM})
  set(CMAKE_ASM_NASM_COMPILER $ENV{ASM_NASM})
endif()
```

----------------------------------------

TITLE: Copying and Packaging OpenCV Libraries as JARs Bash
DESCRIPTION: This series of Bash commands demonstrates how to organize and package OpenCV libraries as JAR files for use in the local Maven repository. The instructions guide users to organize native libraries according to OS and architecture before packaging them with the jar command. Output is a directory layout for the libraries.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/clojure_dev_intro/clojure_dev_intro.markdown#2025-04-22_snippet_2

LANGUAGE: bash
CODE:
```
cd ~/opt\nmkdir clj-opencv\ncd clj-opencv\ncp ~/opt/opencv/build/bin/opencv-247.jar .
```

LANGUAGE: bash
CODE:
```
mkdir -p native/macosx/x86_64\ncp ~/opt/opencv/build/lib/libopencv_java247.dylib native/macosx/x86_64/
```

LANGUAGE: bash
CODE:
```
jar -cMf opencv-native-247.jar native
```

----------------------------------------

TITLE: C Language Standard Configuration
DESCRIPTION: Sets up C language standards and requirements, including C11 as default standard, requiring standard compliance, and disabling compiler extensions
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_1

LANGUAGE: cmake
CODE:
```
if(NOT CMAKE_C_STANDARD)
    set(CMAKE_C_STANDARD 11)          # The C standard whose features are requested to build this target
endif()
if(NOT CMAKE_C_STANDARD_REQUIRED)
    set(CMAKE_C_STANDARD_REQUIRED ON) # Boolean describing whether the value of C_STANDARD is a requirement
endif()
if(NOT CMAKE_C_EXTENSIONS)
    set(CMAKE_C_EXTENSIONS OFF)       # Boolean specifying whether compiler specific extensions are requested
endif()
set(VALID_C_STANDARDS "99" "11")
if(NOT CMAKE_C_STANDARD IN_LIST VALID_C_STANDARDS)
    MESSAGE(FATAL_ERROR "CMAKE_C_STANDARD:STRING=${CMAKE_C_STANDARD} not in known standards list\n ${VALID_C_STANDARDS}")
endif()
```

----------------------------------------

TITLE: Setting Zlib Library Output Properties in CMake
DESCRIPTION: Configures output properties for the Zlib library including naming, debug postfix, and output directory. This ensures consistent library naming and placement.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: CMake
CODE:
```
set_target_properties(${ZLIB_LIBRARY} PROPERTIES
    OUTPUT_NAME ${ZLIB_LIBRARY}
    DEBUG_POSTFIX "${OPENCV_DEBUG_POSTFIX}"
    COMPILE_PDB_NAME ${ZLIB_LIBRARY}
    COMPILE_PDB_NAME_DEBUG "${ZLIB_LIBRARY}${OPENCV_DEBUG_POSTFIX}"
    ARCHIVE_OUTPUT_DIRECTORY ${3P_LIBRARY_OUTPUT_PATH}
)
```

----------------------------------------

TITLE: Defining OpenJPEG Source Files in CMake
DESCRIPTION: Sets up the list of source files that comprise the OpenJPEG library. Includes core functionality files like thread handling, image processing, and memory management.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/openjpeg/openjp2/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(OPENJPEG_SRCS
  ${CMAKE_CURRENT_SOURCE_DIR}/thread.c
  ${CMAKE_CURRENT_SOURCE_DIR}/bio.c
  ${CMAKE_CURRENT_SOURCE_DIR}/cio.c
  ${CMAKE_CURRENT_SOURCE_DIR}/dwt.c
  ${CMAKE_CURRENT_SOURCE_DIR}/event.c
  ${CMAKE_CURRENT_SOURCE_DIR}/ht_dec.c
  ${CMAKE_CURRENT_SOURCE_DIR}/image.c
  ${CMAKE_CURRENT_SOURCE_DIR}/invert.c
  ${CMAKE_CURRENT_SOURCE_DIR}/j2k.c
  ${CMAKE_CURRENT_SOURCE_DIR}/jp2.c
  ${CMAKE_CURRENT_SOURCE_DIR}/mct.c
  ${CMAKE_CURRENT_SOURCE_DIR}/mqc.c
  ${CMAKE_CURRENT_SOURCE_DIR}/openjpeg.c
  ${CMAKE_CURRENT_SOURCE_DIR}/opj_clock.c
  ${CMAKE_CURRENT_SOURCE_DIR}/pi.c
  ${CMAKE_CURRENT_SOURCE_DIR}/t1.c
  ${CMAKE_CURRENT_SOURCE_DIR}/t2.c
  ${CMAKE_CURRENT_SOURCE_DIR}/tcd.c
  ${CMAKE_CURRENT_SOURCE_DIR}/tgt.c
  ${CMAKE_CURRENT_SOURCE_DIR}/function_list.c
  ${CMAKE_CURRENT_SOURCE_DIR}/opj_malloc.c
  ${CMAKE_CURRENT_SOURCE_DIR}/sparse_array.c
)
```

----------------------------------------

TITLE: Configuring VideoIO Plugin Enabling and Plugin Backend List - CMake - CMake
DESCRIPTION: Configures whether to enable the videoio plugin system and sets the backend list for plugin compilation. These CMake commands establish cache variables for build configuration, default plugin enabling based on platform, and manage advanced options presentation. Key parameters include VIDEOIO_ENABLE_PLUGINS_DEFAULT, VIDEOIO_PLUGIN_LIST, and VIDEOIO_ENABLE_PLUGINS, which control plugin building and usage for the VideoIO module. Inputs are provided by CMake variable values or the cache; output is configuration for downstream build logic.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/videoio/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(VIDEOIO_ENABLE_PLUGINS_DEFAULT ON)
if(EMSCRIPTEN OR IOS OR XROS OR WINRT)
  set(VIDEOIO_ENABLE_PLUGINS_DEFAULT OFF)
endif()

set(VIDEOIO_PLUGIN_LIST "" CACHE STRING "List of videoio backends to be compiled as plugins (ffmpeg, gstreamer, mfx, msmf or special value 'all')")
set(VIDEOIO_ENABLE_PLUGINS "${VIDEOIO_ENABLE_PLUGINS_DEFAULT}" CACHE BOOL "Allow building and using of videoio plugins")
mark_as_advanced(VIDEOIO_PLUGIN_LIST VIDEOIO_ENABLE_PLUGINS)
```

----------------------------------------

TITLE: Sample Signature for Copyright Disclaimer
DESCRIPTION: This is a placeholder signature block for the sample employer copyright disclaimer. It indicates where the authorized representative's signature, name, title, and the date should go.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ittnotify/src/ittnotify/GPL-2.0-only.txt#2025-04-22_snippet_4

LANGUAGE: plaintext
CODE:
```
<signature of Ty Coon>, 1 April 1989 Ty Coon, President of Vice
```

----------------------------------------

TITLE: PowerPC Altivec Support Test
DESCRIPTION: Validates PowerPC Altivec vector operations support
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_6

LANGUAGE: c
CODE:
```
#include <altivec.h>
int main(void) {
  __vector int vi = { 0, 0, 0, 0 };
  int i[4];
  vec_st(vi, 0, i);
  return i[0];
}
```

----------------------------------------

TITLE: Checking JPEG Decoding Status
DESCRIPTION: Code symbols for checking JPEG decoding status through return codes from jpeg_consume_input() function and testing jpeg_input_complete().
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_56

LANGUAGE: cpp
CODE:
```
JPEG_REACHED_EOI
JPEG_REACHED_SOS
```

----------------------------------------

TITLE: Defining Table of Contents for 2D Features Framework in Markdown
DESCRIPTION: This snippet defines a table of contents for tutorials related to OpenCV's 2D Features framework using Markdown syntax. It includes links to various tutorials covering different aspects of feature detection, description, and matching.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/features2d/table_of_content_features2d.markdown#2025-04-22_snippet_0

LANGUAGE: markdown
CODE:
```
2D Features framework (feature2d module) {#tutorial_table_of_content_features2d}
=========================================

-   @subpage tutorial_harris_detector
-   @subpage tutorial_good_features_to_track
-   @subpage tutorial_generic_corner_detector
-   @subpage tutorial_corner_subpixels
-   @subpage tutorial_feature_detection
-   @subpage tutorial_feature_description
-   @subpage tutorial_feature_flann_matcher
-   @subpage tutorial_feature_homography
-   @subpage tutorial_detection_of_planar_objects
-   @subpage tutorial_akaze_matching
-   @subpage tutorial_akaze_tracking
-   @subpage tutorial_homography
```

----------------------------------------

TITLE: Installing Orbbec OpenNI SDK on Linux (v2.3.0.63)
DESCRIPTION: Navigates into the extracted Orbbec OpenNI SDK directory for Linux 64-bit (version 2.3.0.63) and executes the installation script with root privileges. This installs the necessary drivers and libraries for the Orbbec Astra camera.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/app/orbbec_astra_openni.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
$ cd Linux/OpenNI-Linux-x64-2.3.0.63/
$ sudo ./install.sh
```

----------------------------------------

TITLE: Template Matching Formula: TM_CCOEFF_NORMED (LaTeX)
DESCRIPTION: Mathematical formula for the Normalized Correlation Coefficient (TM_CCOEFF_NORMED) template matching method used in OpenCV's `matchTemplate` function. It normalizes the correlation coefficient result, making it robust to brightness and contrast changes. R(x,y) is the result, T' is the mean-subtracted template, and I' is the mean-subtracted image patch.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/imgproc/histograms/template_matching/template_matching.markdown#2025-04-22_snippet_6

LANGUAGE: latex
CODE:
```
\f[R(x,y)= \frac{ \sum_{x',y'} (T'(x',y') \cdot I'(x+x',y+y')) }{ \sqrt{\sum_{x',y'}T'(x',y')^2 \cdot \sum_{x',y'} I'(x+x',y+y')^2} }\f]
```

----------------------------------------

TITLE: Generating OpenCV for Windows Phone 8.1 x86 using CMake
DESCRIPTION: Invokes CMake directly to generate Visual Studio 2013 project files for OpenCV targeting Windows Phone 8.1 on the x86 architecture. It specifies the generator, system name, and system version.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_5

LANGUAGE: cmake
CODE:
```
cmake -G "Visual Studio 12 2013" -DCMAKE_SYSTEM_NAME=WindowsPhone -DCMAKE_SYSTEM_VERSION=8.1 <path-to-source>
```

----------------------------------------

TITLE: Defining OpenCV GUI Features Tutorial Section in Markdown
DESCRIPTION: This snippet defines the main heading for the GUI Features tutorial section in OpenCV documentation using Markdown syntax. It includes a reference tag for linking within the documentation system.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_gui/py_table_of_contents_gui.markdown#2025-04-22_snippet_0

LANGUAGE: Markdown
CODE:
```
Gui Features in OpenCV {#tutorial_py_table_of_contents_gui}
======================
```

----------------------------------------

TITLE: Configuring OpenCV ts Module in CMake
DESCRIPTION: Sets up the OpenCV ts module as a static library, configures build options, and includes necessary dependencies. It also handles platform-specific settings for WINRT and QNX.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/ts/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(the_description "The ts module")

if(NOT BUILD_opencv_ts AND NOT BUILD_TESTS AND NOT BUILD_PERF_TESTS)
  ocv_module_disable(ts)
endif()

set(OPENCV_MODULE_TYPE STATIC)
set(OPENCV_MODULE_IS_PART_OF_WORLD FALSE)

if(WINRT)
  # WINRT doesn't have access to environment variables
  # so adding corresponding macros during CMake run
  add_env_definitions(OPENCV_TEST_DATA_PATH)
  add_env_definitions(OPENCV_PERF_VALIDATION_DIR)
endif()

ocv_warnings_disable(CMAKE_CXX_FLAGS -Wundef)

ocv_add_module(ts INTERNAL opencv_core opencv_imgproc opencv_imgcodecs opencv_videoio opencv_highgui)

ocv_glob_module_sources()
ocv_module_include_directories()
ocv_create_module()
```

----------------------------------------

TITLE: Defining Compile Options for OpenCV Module
DESCRIPTION: Sets compile definitions for an OpenCV module and an optional test target to enable plugins. It checks if the 'opencv_test_highgui' target is present and adds the 'ENABLE_PLUGINS' definition. The 'the_module' parameter represents the name of the module being configured. There are no additional inputs or outputs, but the target should exist within the build context.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/highgui/CMakeLists.txt#2025-04-22_snippet_18

LANGUAGE: CMake
CODE:
```
ocv_target_compile_definitions(${the_module} PRIVATE ENABLE_PLUGINS)
if(TARGET opencv_test_highgui)
  ocv_target_compile_definitions(opencv_test_highgui PRIVATE ENABLE_PLUGINS)
endif()
endif()
```

----------------------------------------

TITLE: Configuring G-API Module Sources and Include Paths in CMake
DESCRIPTION: Prepares the source file list, organizes files for IDEs, sets the final header and source lists for the module, and adds necessary include directories. `ocv_list_add_prefix` ensures source paths are relative to the current CMake list directory. `ocv_source_group` improves project organization in IDEs. `ocv_set_module_sources` registers the collected headers and sources. `ocv_module_include_directories` adds the module's 'src' directory and the VASOT include directory to the build's include path.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/CMakeLists.txt#2025-04-22_snippet_9

LANGUAGE: cmake
CODE:
```
ocv_list_add_prefix(gapi_srcs "${CMAKE_CURRENT_LIST_DIR}/")

# For IDE users
ocv_source_group("Src"     FILES ${gapi_srcs} ${gapi_3rdparty_srcs})
ocv_source_group("Include" FILES ${gapi_ext_hdrs})

ocv_set_module_sources(HEADERS ${gapi_ext_hdrs} SOURCES ${gapi_srcs} ${gapi_3rdparty_srcs})
ocv_module_include_directories("${CMAKE_CURRENT_LIST_DIR}/src")

# VAS Object Tracking includes
ocv_module_include_directories(${CMAKE_CURRENT_LIST_DIR}/src/3rdparty/vasot/include)
```

----------------------------------------

TITLE: Defining Zlib Source Files in CMake
DESCRIPTION: Lists all the public headers, private headers, and source files needed to build the Zlib library. This comprehensive listing ensures all necessary files are included in the build.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib/CMakeLists.txt#2025-04-22_snippet_4

LANGUAGE: CMake
CODE:
```
set(ZLIB_PUBLIC_HDRS
    ${CMAKE_CURRENT_BINARY_DIR}/zconf.h
    zlib.h
)
set(ZLIB_PRIVATE_HDRS
    crc32.h
    deflate.h
    gzguts.h
    inffast.h
    inffixed.h
    inflate.h
    inftrees.h
    trees.h
    zutil.h
)
set(ZLIB_SRCS
    adler32.c
    compress.c
    crc32.c
    deflate.c
    gzclose.c
    gzlib.c
    gzread.c
    gzwrite.c
    inflate.c
    infback.c
    inftrees.c
    inffast.c
    trees.c
    uncompr.c
    zutil.c
)
```

----------------------------------------

TITLE: Setting Download Path Environment Variable
DESCRIPTION: Bash commands to set the download path environment variable and execute the download script.
SOURCE: https://github.com/opencv/opencv/blob/4.x/samples/dnn/README.md#2025-04-22_snippet_4

LANGUAGE: bash
CODE:
```
export OPENCV_DOWNLOAD_DATA_PATH=download_folder
python your_script.py
```

----------------------------------------

TITLE: MultiArch Library and Pkg-config File Structure (Unparsed)
DESCRIPTION: Describes the typical directory layout where shared libraries and `pkg-config` (.pc) files are stored for different architectures when using MultiArch. Libraries and specific .pc files reside in architecture-specific subdirectories under `/usr/lib`, while common header-related .pc files might be in `/usr/share/pkgconfig`.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_10

LANGUAGE: unparsed
CODE:
```
/usr
  + lib
    + aarch64-linux-gnu   - shared libraries for arm64
      + pkgconfig         - pkg-config files for arm64 libraries
    + arm-linux-gnueabihf - shared libraries for armhf
      + pkgconfig         - pkg-config files for armhf libraries
  + share
    + pkgconfig         - pkg-config files(for header files)
```

----------------------------------------

TITLE: Setting up the Objective-C Bindings Generator as an OpenCV Module in CMake
DESCRIPTION: Initializes the Objective-C bindings generator as an internal OpenCV module with dependencies on opencv_core and opencv_imgproc. Sets up the necessary directories for binding generation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/objc/generator/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: cmake
CODE:
```
set(MODULE_NAME "objc_bindings_generator")
set(OPENCV_MODULE_IS_PART_OF_WORLD FALSE)
ocv_add_module(${MODULE_NAME} INTERNAL opencv_core opencv_imgproc)

#set(OPENCV_OBJC_SIGNATURES_FILE "${CMAKE_CURRENT_BINARY_DIR}/opencv_objc_signatures.json" CACHE INTERNAL "")
set(OPENCV_OBJC_BINDINGS_DIR "${CMAKE_CURRENT_BINARY_DIR}" CACHE INTERNAL "")
```

----------------------------------------

TITLE: Creating Custom Command for JavaScript Bindings Generation in CMake
DESCRIPTION: Defines a custom command to generate JavaScript bindings using Python scripts, specifying input files, output files, and dependencies.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/js/generator/CMakeLists.txt#2025-04-22_snippet_3

LANGUAGE: CMake
CODE:
```
add_custom_command(
  OUTPUT ${bindings_cpp} "${OPENCV_DEPHELPER}/gen_opencv_js_source"
  COMMAND
      ${PYTHON_DEFAULT_EXECUTABLE}
      "${CMAKE_CURRENT_SOURCE_DIR}/embindgen.py"
      "${scripts_hdr_parser}"
      "${bindings_cpp}"
      "${CMAKE_CURRENT_BINARY_DIR}/headers.txt"
      "${JS_SOURCE_DIR}/src/core_bindings.cpp"
      "${OPENCV_JS_WHITELIST_FILE}"
  COMMAND
      ${CMAKE_COMMAND} -E touch "${OPENCV_DEPHELPER}/gen_opencv_js_source"
  WORKING_DIRECTORY
      "${CMAKE_CURRENT_BINARY_DIR}/gen"
  DEPENDS
      ${JS_SOURCE_DIR}/src/core_bindings.cpp
      ${CMAKE_CURRENT_SOURCE_DIR}/embindgen.py
      ${CMAKE_CURRENT_SOURCE_DIR}/templates.py
      "${OPENCV_JS_WHITELIST_FILE}"
      ${scripts_hdr_parser}
      ${opencv_hdrs}
  COMMENT "Generate source files for JavaScript bindings"
)
```

----------------------------------------

TITLE: Cloning OpenCV Repository in Bash
DESCRIPTION: Commands to clone the OpenCV repository from GitHub using Git in the Terminal on macOS.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/ios/ios_install/ios_install.markdown#2025-04-22_snippet_0

LANGUAGE: bash
CODE:
```
cd ~/<my_working _directory>
git clone https://github.com/opencv/opencv.git
```

----------------------------------------

TITLE: Configuring APT Sources for MultiArch on Ubuntu 23.10 (Unparsed)
DESCRIPTION: Example content to be added to `/etc/apt/sources.list` (or a file in `/etc/apt/sources.list.d/`) using `sudo apt edit-sources`. These lines configure APT to find packages for `arm64` and `armhf` architectures in the Ubuntu 23.10 (Mantic) repositories.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/crosscompilation/crosscompile_with_multiarch.markdown#2025-04-22_snippet_5

LANGUAGE: unparsed
CODE:
```
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic main restricted
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic-updates main restricted
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic universe
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic-updates universe
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic multiverse
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic-updates multiverse
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic-backports main restricted universe multiverse
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic-security main restricted
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic-security universe
deb [arch=arm64,armhf] http://ports.ubuntu.com/ubuntu-ports mantic-security multiverse
```

----------------------------------------

TITLE: Defining and Grouping OpenCV Modules - Doxygen Group Markup
DESCRIPTION: Shows how to declare doxygen groups using @defgroup and nest subgroups for modular organization of code documentation. Classes and functions can be assigned to these groups via @ingroup or @addtogroup. Inputs are group and module names, outputs are grouped documentation pages. Used for clear module hierarchy in OpenCV documentation.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown#2025-04-22_snippet_15

LANGUAGE: cpp
CODE:
```
/**
@defgroup mymodule My great module
    optional description
@{
    @defgroup mymodule_basic Basic operations
        optional description
    @defgroup mymodule_experimental Experimental operations
        optional description
@}
*/
```

----------------------------------------

TITLE: Enabling s390 DFLTCC Deflate Optimization for ZLIB in CMake
DESCRIPTION: Checks if the DFLTCC deflate optimization is enabled (WITH_DFLTCC_DEFLATE) for the s390 architecture. If enabled, it adds the S390_DFLTCC_DEFLATE definition and appends the corresponding source file (`dfltcc_deflate.c`) to the ZLIB architecture-specific source list.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/CMakeLists.txt#2025-04-22_snippet_21

LANGUAGE: cmake
CODE:
```
        if(WITH_DFLTCC_DEFLATE)
            add_definitions(-DS390_DFLTCC_DEFLATE)
            list(APPEND ZLIB_ARCH_SRCS ${ARCHDIR}/dfltcc_deflate.c)
        endif()
```

----------------------------------------

TITLE: Dockerfile for Documentation Build with Doxygen - Dockerfile
DESCRIPTION: This Dockerfile sets up a container based on emscripten/emsdk:2.0.10 and installs the 'doxygen' package to enable documentation generation. Suitable for reproducible documentation builds alongside OpenCV.js source builds. Requires Docker build context. No direct input or output data managed by this Dockerfile.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_setup/js_setup/js_setup.markdown#2025-04-22_snippet_27

LANGUAGE: Dockerfile
CODE:
```
FROM emscripten/emsdk:2.0.10\n\nRUN apt-get update \\n  && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends doxygen \\n  && rm -rf /var/lib/apt/lists/*
```

----------------------------------------

TITLE: Generating and Building All WinRT Configurations using setup_winrt.bat
DESCRIPTION: Navigates to the WinRT platform directory within the OpenCV source and executes the `setup_winrt.bat` script to generate Visual Studio projects for all specified Windows Phone (WP) and Windows Store (WS) versions (8.0, 8.1) and architectures (x86, ARM). The `-b` flag automatically builds the generated solutions in both Debug and Release configurations and runs the INSTALL project.
SOURCE: https://github.com/opencv/opencv/blob/4.x/platforms/winrt/readme.txt#2025-04-22_snippet_0

LANGUAGE: batch
CODE:
```
cd opencv/platforms/winrt
setup_winrt.bat "WP,WS" "8.0,8.1" "x86,ARM" -b
```

----------------------------------------

TITLE: Failing CMake Build for Unsupported CPU for SIMD
DESCRIPTION: This CMake code is executed within an `else()` block, indicating that the preceding `if()` condition (likely checking for specific CPU types supporting SIMD) evaluated to false. It calls the `simd_fail` function (presumably a custom macro or function defined elsewhere in the project) to terminate the CMake configuration process with a fatal error. The error message explicitly states that SIMD extensions are unavailable for the detected CPU, referencing the `CMAKE_SYSTEM_PROCESSOR` variable.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/simd/CMakeLists.txt#2025-04-22_snippet_7

LANGUAGE: cmake
CODE:
```
else()

simd_fail("SIMD extensions not available for this CPU (${CMAKE_SYSTEM_PROCESSOR})")

endif() # CPU_TYPE
```

----------------------------------------

TITLE: Displaying Installation Path and Finalizing Status in CMake
DESCRIPTION: This CMake snippet first calls a custom hook `ocv_cmake_hook` for potentially adding extra status information via `STATUS_DUMP_EXTRA`. It then prints the configured installation directory (`CMAKE_INSTALL_PREFIX`), adds visual separators, and uses the custom function `ocv_finalize_status` to complete the status summary output.
SOURCE: https://github.com/opencv/opencv/blob/4.x/CMakeLists.txt#2025-04-22_snippet_31

LANGUAGE: cmake
CODE:
```
ocv_cmake_hook(STATUS_DUMP_EXTRA)

# ========================== auxiliary ==========================
status("")
status("  Install to:" "${CMAKE_INSTALL_PREFIX}")
status("-----------------------------------------------------------------")
status("")


ocv_finalize_status()
```

----------------------------------------

TITLE: Setting Project Description - CMake
DESCRIPTION: This code snippet sets a CMake variable describing the module as related to camera calibration and 3D reconstruction. It is used for documentation and module metadata within CMake build processes. No dependencies or parameters are required.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/calib3d/CMakeLists.txt#2025-04-22_snippet_0

LANGUAGE: CMake
CODE:
```
set(the_description "Camera Calibration and 3D Reconstruction")
```

----------------------------------------

TITLE: Downloading and Preparing LaTeX Theme - Shell Script
DESCRIPTION: This snippet demonstrates invoking a shell script (get_sty.sh) to download and set up the required Metropolis Beamer theme for the LaTeX presentation. It assumes a Unix-like environment with execute permissions for the script, and requires wget for fetching files. Outputs are the downloaded theme files placed appropriately for later LaTeX compilation. The snippet requires all prerequisite software mentioned in the guide.
SOURCE: https://github.com/opencv/opencv/blob/4.x/modules/gapi/doc/slides/README.md#2025-04-22_snippet_0

LANGUAGE: shell
CODE:
```
$ ./get_sty.sh
```

----------------------------------------

TITLE: Enabling Actions Runner Service
DESCRIPTION: Command to enable and start the actions-runner service using systemctl.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/zlib-ng/arch/s390/README.md#2025-04-22_snippet_5

LANGUAGE: bash
CODE:
```
sudo systemctl enable --now actions-runner
```

----------------------------------------

TITLE: Configuring DOT Image Format for Doxygen in CMake
DESCRIPTION: Sets a CMake cache variable `OPENCV_DOCS_DOT_IMAGE_FORMAT` to control the image format (defaulting to 'svg') generated by DOT for Doxygen diagrams. It also sets the corresponding internal variable `CMAKECONFIG_DOT_IMAGE_FORMAT` used in the Doxyfile template.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/CMakeLists.txt#2025-04-22_snippet_12

LANGUAGE: cmake
CODE:
```
# 'png' is good enough for compatibility (but requires +50% storage space)
set(OPENCV_DOCS_DOT_IMAGE_FORMAT "svg" CACHE STRING "Doxygen/DOT_IMAGE_FORMAT value")
set(CMAKECONFIG_DOT_IMAGE_FORMAT "${OPENCV_DOCS_DOT_IMAGE_FORMAT}")
```

----------------------------------------

TITLE: OpenCV Tutorial Navigation Structure in Markdown
DESCRIPTION: Markdown structure defining the navigation hierarchy and organization of OpenCV tutorials. Includes conditional compilation for CUDA modules.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/tutorials.markdown#2025-04-22_snippet_0

LANGUAGE: markdown
CODE:
```
OpenCV Tutorials {#tutorial_root}
================

- @subpage tutorial_table_of_content_introduction - build and install OpenCV on your computer
- @subpage tutorial_table_of_content_core - basic building blocks of the library
- @subpage tutorial_table_of_content_imgproc - image processing functions
- @subpage tutorial_table_of_content_app - application utils (GUI, image/video input/output)
- @subpage tutorial_table_of_content_calib3d - extract 3D world information from 2D images
- @subpage tutorial_table_of_content_objdetect - INSERT OBJDETECT MODULE INFO
- @subpage tutorial_table_of_content_features2d - feature detectors, descriptors and matching framework
- @subpage tutorial_table_of_content_dnn - infer neural networks using built-in _dnn_ module
- @subpage tutorial_table_of_content_gapi - graph-based approach to computer vision algorithms building
- @subpage tutorial_table_of_content_other - other modules (ml, objdetect, stitching, video, photo)
- @subpage tutorial_table_of_content_ios - running OpenCV on an iDevice
@cond CUDA_MODULES
- @subpage tutorial_table_of_content_gpu - utilizing power of video card to run CV algorithms
@endcond
```

----------------------------------------

TITLE: SVM Kernel Function Calculation
DESCRIPTION: Derivation of kernel function showing how dot product in higher dimensional space can be computed in lower dimensional space.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_ml/py_svm/py_svm_basics/py_svm_basics.markdown#2025-04-22_snippet_2

LANGUAGE: latex
CODE:
```
\begin{aligned}\nK(p,q)  = \phi(p).\phi(q) &= \phi(p)^T \phi(q) \\\n                          &= (p_{1}^2,p_{2}^2,\sqrt{2} p_1 p_2).(q_{1}^2,q_{2}^2,\sqrt{2} q_1 q_2) \\\n                          &= p_{1}^2 q_{1}^2 + p_{2}^2 q_{2}^2 + 2 p_1 q_1 p_2 q_2 \\\n                          &= (p_1 q_1 + p_2 q_2)^2 \\\n          \phi(p).\phi(q) &= (p.q)^2\n\end{aligned}
```

----------------------------------------

TITLE: Controlling Adobe Marker Emission in libjpeg (C)
DESCRIPTION: A C boolean field within the compression parameters structure (`cinfo`). If TRUE, an Adobe-specific APP14 marker is included in the output file, often used to indicate color transforms (e.g., for RGB, CMYK color spaces). `jpeg_set_defaults()` typically sets this based on the color space. It is generally advised not to enable both `write_JFIF_header` and `write_Adobe_marker` simultaneously.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_41

LANGUAGE: C
CODE:
```
boolean write_Adobe_marker
```

----------------------------------------

TITLE: OpenCV Security Team PGP Public Key
DESCRIPTION: PGP public key for encrypting sensitive security vulnerability reports sent to the OpenCV security team. Key was updated on April 19, 2023.
SOURCE: https://github.com/opencv/opencv/blob/4.x/SECURITY.md#2025-04-22_snippet_0

LANGUAGE: text
CODE:
```
-----BEGIN PGP PUBLIC KEY BLOCK-----
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=g4fo
-----END PGP PUBLIC KEY BLOCK-----
```

----------------------------------------

TITLE: Aborting JPEG Compression Cycle in C
DESCRIPTION: This snippet describes how to abort a JPEG compression cycle using 'jpeg_abort_compress' or 'jpeg_abort'. These functions reset the JPEG object to an idle state, releasing memory. This approach is useful for recycling JPEG objects for another image or when an error occurs.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/libjpeg-turbo/src/libjpeg.txt#2025-04-22_snippet_10

LANGUAGE: C
CODE:
```
jpeg_destroy_compress(&cinfo);
```

----------------------------------------

TITLE: Markdown Tutorial Links for OpenCV Modules
DESCRIPTION: Structured markdown document containing tutorial links organized by OpenCV module categories including photo, stitching, video, object detection and machine learning topics.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/tutorials/others/table_of_content_other.markdown#2025-04-22_snippet_0

LANGUAGE: markdown
CODE:
```
Other tutorials (ml, objdetect, photo, stitching, video) {#tutorial_table_of_content_other}
========================================================

-   photo. @subpage tutorial_hdr_imaging
-   stitching. @subpage tutorial_stitcher
-   video. @subpage tutorial_background_subtraction
-   video. @subpage tutorial_meanshift
-   video. @subpage tutorial_optical_flow
-   objdetect. @subpage tutorial_cascade_classifier
-   objdetect. @subpage tutorial_traincascade
-   objdetect. @subpage tutorial_barcode_detect_and_decode
-   ml. @subpage tutorial_introduction_to_svm
-   ml. @subpage tutorial_non_linear_svms
-   ml. @subpage tutorial_introduction_to_pca
```

----------------------------------------

TITLE: Markdown Redirect Stub for OpenCV Object Detection Tutorial
DESCRIPTION: A markdown stub document that redirects readers to the new location of the object detection tutorial content.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/py_tutorials/py_objdetect/py_table_of_contents_objdetect.markdown#2025-04-22_snippet_0

LANGUAGE: markdown
CODE:
```
Object Detection {#tutorial_py_table_of_contents_objdetect}
================

Content has been moved: @ref tutorial_table_of_content_objdetect
```

----------------------------------------

TITLE: Basic LGPL License Notice Template
DESCRIPTION: Standard template for applying LGPL license notice to source files, including copyright statement, license terms, and warranty disclaimer.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ffmpeg/license.txt#2025-04-22_snippet_0

LANGUAGE: text
CODE:
```
<one line to give the library's name and a brief idea of what it does.>
Copyright (C) <year>  <name of author>

This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
```

----------------------------------------

TITLE: Embedding an Interactive OpenCV.js Template Matching Example
DESCRIPTION: This HTML snippet utilizes an `<iframe>` to embed an external HTML page ('js_template_matching_matchTemplate.html'). This page likely provides an interactive JavaScript example demonstrating the OpenCV.js template matching described in the tutorial. The `onload` attribute dynamically adjusts the iframe height based on the loaded content's height.
SOURCE: https://github.com/opencv/opencv/blob/4.x/doc/js_tutorials/js_imgproc/js_template_matching/js_template_matching.markdown#2025-04-22_snippet_0

LANGUAGE: HTML
CODE:
```
<iframe src="../../js_template_matching_matchTemplate.html" width="100%"
        onload="this.style.height=this.contentDocument.body.scrollHeight +'px';">
</iframe>
```

----------------------------------------

TITLE: Copyright Disclaimer Template
DESCRIPTION: Sample template for copyright disclaimer from employer or organization for library contributions.
SOURCE: https://github.com/opencv/opencv/blob/4.x/3rdparty/ffmpeg/license.txt#2025-04-22_snippet_1

LANGUAGE: text
CODE:
```
Yoyodyne, Inc., hereby disclaims all copyright interest in the
library `Frob' (a library for tweaking knobs) written by James Random Hacker.

<signature of Ty Coon>, 1 April 1990
Ty Coon, President of Vice
```